description,diff,concern_count,shas,types
"move toolbar to tab content level

Signed-off-by: Pranav C <pranavxc@gmail.com> | updates the readme to improve the readability and contributing sections","diff --git a/packages/nc-gui-v2/components.d.ts b/packages/nc-gui-v2/components.d.ts
index f6be04b..cf555ef 100644
--- a/packages/nc-gui-v2/components.d.ts
+++ b/packages/nc-gui-v2/components.d.ts
@@ -201,6 +201,7 @@ declare module '@vue/runtime-core' {
     MdiThumbUp: typeof import('~icons/mdi/thumb-up')['default']
     MdiTrashCan: typeof import('~icons/mdi/trash-can')['default']
     MdiTwitter: typeof import('~icons/mdi/twitter')['default']
+    MdiUpload: typeof import('~icons/mdi/upload')['default']
     MdiUploadOutline: typeof import('~icons/mdi/upload-outline')['default']
     MdiViewListOutline: typeof import('~icons/mdi/view-list-outline')['default']
     MdiWhatsapp: typeof import('~icons/mdi/whatsapp')['default']
diff --git a/packages/nc-gui-v2/components/smartsheet-toolbar/ViewActions.vue b/packages/nc-gui-v2/components/smartsheet-toolbar/ViewActions.vue
index c2c87d3..27c0acc 100644
--- a/packages/nc-gui-v2/components/smartsheet-toolbar/ViewActions.vue
+++ b/packages/nc-gui-v2/components/smartsheet-toolbar/ViewActions.vue
@@ -132,7 +132,7 @@ async function changeLockType(type: LockType) {
   <div>
     <a-dropdown>
       <a-button v-t=""['c:actions']"" class=""nc-actions-menu-btn nc-toolbar-btn"">
-        <div class=""flex gap-2 align-center"">
+        <div class=""flex gap-2 items-center"">
           <component
             :is=""viewIcons[selectedView?.type].icon""
             class=""nc-view-icon group-hover:hidden""
@@ -311,6 +311,6 @@ async function changeLockType(type: LockType) {
 
 <style scoped>
 .nc-locked-menu-item > div {
-  @apply grid grid-cols-[30px,auto] gap-2  p-2 align-center;
+  @apply grid grid-cols-[30px,auto] gap-2  p-2 items-center;
 }
 </style>
diff --git a/packages/nc-gui-v2/components/smartsheet/Toolbar.vue b/packages/nc-gui-v2/components/smartsheet/Toolbar.vue
index 5fa555f..d498871 100644
--- a/packages/nc-gui-v2/components/smartsheet/Toolbar.vue
+++ b/packages/nc-gui-v2/components/smartsheet/Toolbar.vue
@@ -36,7 +36,7 @@ const {isOpen} =useSidebar()
 
     <SmartsheetToolbarSearchData v-if=""(isGrid || isGallery) && !isPublic"" class=""shrink mr-2 ml-2"" />
 
-    <ToggleDrawer v-if=""!isOpen""/>
+    <ToggleDrawer class=""mr-2""/>
 
 
   </div>
diff --git a/packages/nc-gui-v2/components/smartsheet/sidebar/index.vue b/packages/nc-gui-v2/components/smartsheet/sidebar/index.vue
index 896ad62..77aee05 100644
--- a/packages/nc-gui-v2/components/smartsheet/sidebar/index.vue
+++ b/packages/nc-gui-v2/components/smartsheet/sidebar/index.vue
@@ -99,6 +99,7 @@ function onCreate(view: GridType | FormType | KanbanType | GalleryType) {
     class=""relative shadow-md h-full""
     theme=""light""
   >
+    <!--
     <Toolbar
       v-if=""isOpen""
       class=""min-h-[var(--toolbar-height)] max-h-[var(--toolbar-height)]""
@@ -128,7 +129,7 @@ function onCreate(view: GridType | FormType | KanbanType | GalleryType) {
         <div v-if=""!isForm"" class=""dot"" />
       </template>
     </Toolbar>
-
+-->
     <div v-if=""isOpen"" class=""flex-1 flex flex-col"">
       <MenuTop @open-modal=""openModal"" @deleted=""loadViews"" @sorted=""loadViews"" />
 
diff --git a/packages/nc-gui-v2/components/smartsheet/sidebar/toolbar/ToggleDrawer.vue b/packages/nc-gui-v2/components/smartsheet/sidebar/toolbar/ToggleDrawer.vue
index 3e3d78a..8441450 100644
--- a/packages/nc-gui-v2/components/smartsheet/sidebar/toolbar/ToggleDrawer.vue
+++ b/packages/nc-gui-v2/components/smartsheet/sidebar/toolbar/ToggleDrawer.vue
@@ -4,7 +4,7 @@ const { isOpen, toggle } = useSidebar({ storageKey: 'nc-right-sidebar' })
 </script>
 
 <template>
-  <a-tooltip :placement=""isOpen ? 'bottomRight' : 'left'"" :mouse-enter-delay=""0.8"">
+<!--  <a-tooltip :placement=""isOpen ? 'bottomRight' : 'left'"" :mouse-enter-delay=""0.8"">
     <template #title> Toggle sidebar</template>
 
     <div class=""nc-sidebar-right-item hover:after:(bg-primary bg-opacity-75) group nc-sidebar-add-row"">
@@ -14,5 +14,11 @@ const { isOpen, toggle } = useSidebar({ storageKey: 'nc-right-sidebar' })
         @click=""toggle(!isOpen)""
       />
     </div>
-  </a-tooltip>
+  </a-tooltip>-->
+
+  <a-button @click=""toggle(!isOpen)"" size=""small"">
+  <div class=""flex items-center gap-2"">  <MdiMenu/> Views
+  </div>
+  </a-button>
+
 </template>
diff --git a/packages/nc-gui-v2/components/tabs/Smartsheet.vue b/packages/nc-gui-v2/components/tabs/Smartsheet.vue
index 4181996..7b7ec36 100644
--- a/packages/nc-gui-v2/components/tabs/Smartsheet.vue
+++ b/packages/nc-gui-v2/components/tabs/Smartsheet.vue
@@ -83,11 +83,11 @@ watch(isLocked, (nextValue) => (treeViewIsLockedInj.value = nextValue), { immedi
 
             <SmartsheetForm v-else-if=""isForm"" />
           </div>
+          <SmartsheetSidebar class=""nc-right-sidebar"" v-if=""meta"" />
         </div>
       </template>
     </div>
 
-    <SmartsheetSidebar class=""nc-right-sidebar"" v-if=""meta"" />
   </div>
 </template>
 

diff --git a/.github/CONTRIBUTING.md b/.github/CONTRIBUTING.md
index 3c4dd8d..f8b8514 100644
--- a/.github/CONTRIBUTING.md
+++ b/.github/CONTRIBUTING.md
@@ -21,7 +21,8 @@ Contributions are always welcome! Please use the following guidelines when contr
     - `chore` - Catch all or things that have to do with the build system, etc
     - `examples` - Changes to existing example, or a new example
  * The `COMPONENT` is optional, and may be a single file, directory, or logical component. Can be omitted if commit applies globally
-5. Run the tests (`cargo test --no-std-features && cargo test --features yaml`)
+5. Run the tests (`cargo test --features ""yaml unstable""`)
+5. Run the lints (`cargo build --features lints`) (requires a nightly compiler)
 6. `git rebase` into concise commits and remove `--fixup`s (`git rebase -i HEAD~NUM` where `NUM` is number of commits back)
 7. Push your changes back to your fork (`git push origin $your-branch`)
 8. Create a pull request! (You can also create the pull request first, and we'll merge when ready. This a good way to discuss proposed changes.)
diff --git a/README.md b/README.md
index 9e6efce..b74405d 100644
--- a/README.md
+++ b/README.md
@@ -31,7 +31,9 @@ Table of Contents
   * [More Information](#more-information)
     * [Video Tutorials](#video-tutorials)
 * [How to Contribute](#how-to-contribute)
-  * [Running the tests](#running-the-tests)
+  * [Testing Code](#testing-code)
+  * [Linting Code](#linting-code)
+  * [Debugging Code](#debugging-code)
   * [Goals](#goals)
   * [Compatibility Policy](#compatibility-policy)
     * [Minimum Version of Rust](#minimum-version-of-rust)
@@ -43,288 +45,83 @@ Created by [gh-md-toc](https://github.com/ekalinin/github-markdown-toc)
 
 ## What's New
 
-Here's what's new in v2.18.0
+Here's the highlights from v2.0.0 to v2.18.0
 
 * **Completions:**  Adds completion support for Microsoft PowerShell! (Thanks to @Arnavion)
-
-Here's what's new in v2.17.1
-
-* Fixes a bug where using low index multiples was propagated to subcommands
-
-Here's what's new in v2.17.0
-
 * Allows specifying the second to last positional argument as `multiple(true)` (i.e. things such as `mv <files>... <target>`)
 * Adds an `App::get_name` and `App::get_bin_name`
-
-Here's what's new in v2.16.4
-
-* Fixes bug that caused panic on subcommands with aliases
 * Conflicting argument errors are now symetrical, meaning more consistent and better usage suggestions
-* Fixes typo in example `13a_enum_values_automatic`
-* Fixes failing yaml example (#715)
-* Fixes the `debug` feature (#716)
-
-Here's the highlights for v2.16.3
-
-* Fixes a bug where the derived display order isn't propagated
-* **yaml-example:**  fixes some inconsistent args in the example
-
-Here's the highlights for v2.16.2
-
-* Fixes a bug where single quotes are not escaped
-
-Here's the highlights for v2.16.1
-
-* **Help Message:**  fixes a regression bug where args with multiple(true) threw off alignment
-
-Here's the highlights for v2.16.0
-
 * **Completions:**  adds automatic ZSH completion script generation support! :tada: :tada:
-
-Here's a gif of them in action!
-
-![zsh-comppletions](http://i.imgur.com/rwlMbAv.gif)
-
-Here's the highlights for v2.15.0
-
 * **AppSettings:**  adds new setting `AppSettings::AllowNegativeNumbers` which functions like `AllowLeadingHyphen` except only allows undefined negative numbers to pass parsing.
-* Improves some of the documentation of `AppSettings` by moving variants into roughly alphabetical order
-
-Here's the highlights for v2.14.1 (Huge thanks to all the contributors who put in a lot of work this cycle! Especially @tormol @nabijaczleweli and @wdv4758h)
-
 * Stabilize `clap_app!` macro (i.e. no longer need to use `unstable` feature)
-* Fixes a bug that made determining when to auto-wrap long help messages inconsistent
-* Fixes fish completions for nested subcommands
-* Improve documentation around features
-* Reword docs for `ErrorKind` and `App::settings`
-* Fix tests that fail when the `suggestions` feature is disabled
-* Fix the `OsString`-using doc-tests
-* Tag non-rust code blocks as such instead of ignoring them
-* Improve some errors about subcommands
-* Makes sure the doc-tests don't fail before ""missing file"" in YAML tests
 * Deprecate `App::with_defaults`
-* Make lints not enable other nightly-requiring features
-
-Here's the highlights for v2.14.0
-
-* One can now alias arguments either visibly (whichc appears in the help text) or invisibly just like subcommands!
+* One can now alias arguments either visibly (which appears in the help text) or invisibly just like subcommands!
 * The `from_usage` parser now correctly handles non-ascii names / options and help!
-* Fixes a bug in the `require_delimiter` code which caused some incorrect parses
-* Fixes various typos in the docs
-* Various other small performance improvements and enhancements
-
-Here's the highlights for v2.13.0
-
 * **Value Delimiters:**  fixes the confusion around implicitly setting value delimiters. (The default is to *not* use a delimiter unless explicitly set)
-* **Docs:** Updates README.md with new website information and updated video tutorials info
-* **Docs:** Updates the docs about removing implicit `value_delimiter(true)`
-* **Docs:** Adds better examples on using default values
-
-
-Here's the highlights for v2.12.1
-
-* Fixes a regression-bug where the old `{n}` newline char stopped being replaced a properly re-aligned newline
-
-Here's the highlights for v2.12.0
-
 * Changes the default value delimiter rules (i.e. the default is `use_delimiter(false)` *unless* a setting/method that implies multiple values was used) **[Bugfix that *may* ""break"" code]**
  * If code breaks, simply add `Arg::use_delimiter(true)` to the affected args
-* Updates the docs for the `Arg::multiple` method WRT value delimiters and default settings
 * Adds ability to hide the possible values from the help text on a per argument basis, instead of command wide
 * Allows for limiting detected terminal width (i.e. wrap at `x` length, unless the terminal width is *smaller*)
-* Removes some redundant `contains()` checks for minor performance improvements
-* Fixes a bug where valid args aren't recognized with the `AppSettings::AllowLeadingHyphen` setting
 * `clap` now ignores hard newlines in help messages and properly re-aligns text, but still wraps if the term width is too small
-* Makes some minor changes to when next line help is automatically used
 * Adds support for the setting `Arg::require_delimiter` from YAML
-* Removes the verbage about using `'{n}'` to insert newlines in help text from the docs (the normal `\n` can now be used)
-* Documents `AppSetting::DisableVersion`
-
-Here's the highlights for v2.11.3
-
 * `clap` no longer requires one to use `{n}` inside help text to insert a newline that is properly aligned. One can now use the normal `\n`.
 * `clap` now ignores hard newlines in help messages and properly re-aligns text, but still wraps if the term width is too small
-* Supports setting `Arg::require_delimiter` from YAML
-
-Here's the highlights for v2.11.2
-
-* Makes some minor changes to when next line help is automatically used for improved wrapping
-
-Here's the highlights for v2.11.1
-
-* Fixes an issue where settings weren't propogated down through grand-child subcommands
 * Errors can now have custom description
 * Uses `term_size` instead of home-grown solution on Windows
-* Updates deps with some minor bug fixes
-
-
-Here's the highlights for v2.11.0
-
 * Adds the ability to wrap help text intelligently on Windows!
-* Moves docs to [docs.rs!](https://docs.rs/clap/)
-* Fixes some usage strings that contain both args in groups and ones that conflict with each other
-* Uses standard conventions for bash completion files, namely `{bin}.bash-completion`
+* Moves docs to [docs.rs!](https://docs.rs/clap/)!
 * Automatically moves help text to the next line and wraps when term width is determined to be too small, or help text is too long
 * Vastly improves *development* error messages when using YAML
-* Adds `App::with_defaults` to automatically use `crate_authors!` and `crate_version!` macros
-* Other minor improvements and bug fixes
-
-Here's the highlights for v2.10.4
-
-* Fixes a bug where help is wrapped incorrectly and causing a panic with some non-English characters
-
-Here's the highlights for v2.10.3
-
-* Fixes a bug with non-English characters in help text wrapping, where the character is stripped or causes a panic
-* Fixes an issue with `strsim` which caused a panic in some scenarios
 * Adds a shorthand way to ignore help text wrapping and use source formatting (i.e. `App::set_term_width(0)`)
-
-Here's the highlights for v2.10.2
-
-* Fixes a critical bug where the help message is printed twice
-
-Here's the highlights for v2.10.1
-
 * **Help Subcommand:**  fixes misleading usage string when using multi-level subcommmands such as `myprog help subcmd1 subcmd2`
 * **YAML:**  allows using lists or single values with certain arg declarations for increased ergonomics
-
-
-Here's the highlights for v2.10.0
-
-
 * **Fish Shell Completions:**  one can generate a basic fish completions script at compile time!
-* **External SubCommands:**  fixes a bug which now correctly preserves external subcommand name along with args to said command (Minor breaking change that breaks no known real world code)
-* **YAML Documentation:**  fixes example 17's incorrect reference to arg_groups instead of groups
-
-
-Here's the highlights for v2.9.3
-
 * Adds the ability to generate completions to an `io::Write` object
 * Adds an `App::unset_setting` and `App::unset_settings`
-* Fixes bug where only first arg in list of `required_unless_one` is recognized
-* Fixes a typo bug `SubcommandsRequired`->`SubcommandRequired`
-
-
-Here's the highlights for v2.9.2
-
-
-* fixes bug where --help and --version short weren't added to the completion list
-* improves completions allowing multiple bins to have seperate completion files
-
-Here's the highlights for v2.9.0
-
 * **Completions:**  one can now [generate a bash completions](https://docs.rs/clap/2.9.0/clap/struct.App.html#method.gen_completions) script at compile time! These completions work with options using [possible values](https://docs.rs/clap/2.9.0/clap/struct.Arg.html#method.possible_values), [subcommand aliases](https://docs.rs/clap/2.9.0/clap/struct.App.html#method.aliases), and even multiple levels of subcommands
-* Minor bug fixes when using `AppSettings::TrailingVarArg` and `AppSettings::AllowLeadingHyphen`
-
-Here's the highlights for v2.8.0
-
 * **Arg:**  adds new optional setting [`Arg::require_delimiter`](https://docs.rs/clap/2.8.0/clap/struct.Arg.html#method.require_delimiter) which requires val delimiter to parse multiple values
 * The terminal sizing portion has been factored out into a separate crate, [term_size](https://crates.io/crates/term_size)
-* Minor bug fixes
-
-
-Here's the highlights for v2.7.1
-
-* **Options:**
-  *  options using multiple values and delimiters no longer parse additional values after a trailing space (i.e. `prog -o 1,2 file.txt` parses as `1,2` for `-o` and `file.txt` for a positional arg)
-  *  using options using multiple values and with an `=` no longer parse args after the trailing space as values (i.e. `prog -o=1 file.txt` parses as `1` for `-o` and `file.txt` for a positional arg)
-
-Here's the highlights for v2.7.0
-
+* Options using multiple values and delimiters no longer parse additional values after a trailing space (i.e. `prog -o 1,2 file.txt` parses as `1,2` for `-o` and `file.txt` for a positional arg)
+* Using options using multiple values and with an `=` no longer parse args after the trailing space as values (i.e. `prog -o=1 file.txt` parses as `1` for `-o` and `file.txt` for a positional arg)
 * **Usage Strings:**  `[FLAGS]` and `[ARGS]` are no longer blindly added to usage strings, instead only when applicable
 * `arg_enum!`:  allows using more than one meta item, or things like `#[repr(C)]` with `arg_enum!`s
 * `App::print_help`: now prints the same as would have been printed by `--help` or the like
-* **Help Messages:**
- *  prevents invoking `<cmd> help help` and displaying incorrect help message
- *  subcommand help messages requested via `<cmd> help <sub>` now correctly match `<cmd> <sub> --help`
-* **`ArgGroup`s:**
- *  one can now specify groups which require AT LEAST one of the args
- *  allows adding multiple ArgGroups per Arg
- * **Documentation:**  vastly improves `ArgGroup` docs by adding better examples
-* **Documentation:**  fixes a bunch of typos in the documentation
-
-Here's the highlights for v2.6.0
-
+* Prevents invoking `<cmd> help help` and displaying incorrect help message
+* Subcommand help messages requested via `<cmd> help <sub>` now correctly match `<cmd> <sub> --help`
+* One can now specify groups which require AT LEAST one of the args
+* Allows adding multiple ArgGroups per Arg
 * **Global Settings:** One can now set an `AppSetting` which is propogated down through child subcommands
 * **Terminal Wrapping:**  Allows wrapping at specified term width (Even on Windows!) (can now set an absolute width to ""smart"" wrap at)
 * **SubCommands/Aliases:**  adds support for visible aliases for subcommands (i.e. aliases that are dipslayed in the help message)
 * **Subcommands/Aliases:**  when viewing the help of an alias, it now display help of the aliased subcommand
-* Improves the default usage string when only a single positional arg is present
 * Adds new setting to stop delimiting values with `--` or `AppSettings::TrailingVarArg`
-* `App::before_help` and `App::after_help` now correctly wrap
-* Fixes bug where positional args are printed out of order when using templates
-* Fixes bug where one can't override the auto-generated version or help flags
-* Fixes issue where `App::before_help` wasn't printed
-* Fixes a failing windows build
-* Fixes bug where new color settings couldn't be converted from strings
-* Adds missing YAML methods for App and Arg
-* Allows printing version to any io::Write object
-* Removes extra newline from help and version output
-
-Here's what's new in v.2.5.2
-
-*   Removes trailing newlines from help and version output
-*   Allows printing version to any io::Write object
-*   Inter-links all types and pages
-*   Makes all publicly available types viewable in docs
-*   Fixes bug where one can't override version or help flags
-*   Fixes bug where args are printed out of order when using templates
-*   Fixes issue where `App::before_help` wasn't printed properly
-
-Here's what's new in v.2.5.0
-
 * Subcommands now support aliases - think of them as hidden subcommands that dispatch to said subcommand automatically
-
-Here's what's new in v2.4.3
-
-* Bug Fixes
- * Usage strings get de-deuplicated when there are args which are also part ``ArgGroup`s`
- * Fixed times when `ArgGroup`s are duplicated in usage strings
-* Improvements
- * Positional arguments which are part of a group are now formatted in a more readable way (fewer brackets)
- * Positional arguments use the standard `<>` brackets to reduce confusion
- * The default help string for the `help` subcommand has been shortened to fit in 80 columns
-
-Here's the highlights from v2.4.0
-
+* Fixed times when `ArgGroup`s are duplicated in usage strings
 * **Before Help:**  adds support for displaying info before help message
 * **Required Unless:**  adds support for allowing args that are required unless certain other args are present
-* Bug fixes
-
-Here's the highlights from v2.3.0
-
 * **New Help Template Engine!**: Now you have full control over the layout of your help message. Major thanks to @hgrecco
 * **Pull crate Authors from Cargo.toml**: One can now use the `crate_authors!` macro to automatically pull the crate authors from their Cargo.toml file
 * **Colored Help Messages**: Help messages can now be optionally colored (See the `AppSettings::ColoredHelp` setting). Screenshot below.
-* A bunch of bug fixes
-
-Here's the highlights from v2.2.1
-
 * **Help text auto wraps and aligns at for subcommands too!** - Long help strings of subcommands will now properly wrap and align to term width on Linux and OS X. This can be turned off as well.
-* Bug fixes
-
-An example of the optional colored help:
-
-![screenshot](http://i.imgur.com/7fs2h5j.png)
-
-Here's the highlights from v2.2.0
-
 * **Help text auto wraps and aligns at term width!** - Long help strings will now properly wrap and align to term width on Linux and OS X (and presumably Unix too). This can be turned off as well.
 * **Can customize the order of opts, flags, and subcommands in help messages**  - Instead of using the default alphabetical order, you can now re-arrange the order of your args and subcommands in help message. This helps to emphasize more popular or important options.
- * **Can auto-derive the order from declaration order** - Have a bunch of args or subcommmands to re-order? You can now just derive the order from the declaration order!
+* **Can auto-derive the order from declaration order** - Have a bunch of args or subcommmands to re-order? You can now just derive the order from the declaration order!
 * **Help subcommand now accepts other subcommands as arguments!** - Similar to other CLI precedents, the `help` subcommand can now accept other subcommands as arguments to display their help message. i.e. `$ myprog help mysubcmd` (*Note* these can even be nested heavily such as `$ myprog help subcmd1 subcmd2 subcmd3` etc.)
+* **Default Values**: Args can now specify default values
+* **Next Line Help**: Args can have help strings on the line following the argument (useful for long arguments, or those with many values). This can be set command-wide or for individual args
 
-* Other minor bug fixes
+Here's a gif of them in action!
+
+![zsh-comppletions](http://i.imgur.com/rwlMbAv.gif)
 
 An example of the help text wrapping at term width:
 
 ![screenshot](http://i.imgur.com/PAJzJJG.png)
 
-In v2.1.2
+An example of the optional colored help:
+
+![screenshot](http://i.imgur.com/7fs2h5j.png)
 
- * **Default Values**: Args can now specify default values
- * **Next Line Help**: Args can have help strings on the line following the argument (useful for long arguments, or those with many values). This can be set command-wide or for individual args
- * **Documentation Examples**: The examples in the documentation have been vastly improved
 
 For full details, see [CHANGELOG.md](https://github.com/kbknapp/clap-rs/blob/master/CHANGELOG.md)
 
@@ -697,6 +494,7 @@ features = [ ""suggestions"", ""color"" ]
 #### Opt-in features
 
 * **""yaml""**: Enables building CLIs from YAML documents. (builds dependency `yaml-rust`)
+* **""unstable""**: Enables unstable `clap` features that may change from release to release
 
 ### Dependencies Tree
 
@@ -707,6 +505,7 @@ The following graphic depicts `clap`s dependency graph (generated using [cargo-g
  * **Blue** Color: Dev dependency, only used while developing.
 
 ![clap dependencies](clap_dep_graph.png)
+
 ### More Information
 
 You can find complete documentation on the [docs.rs](https://docs.rs/clap/) for this project.
@@ -727,20 +526,65 @@ Another really great way to help is if you find an interesting, or helpful way i
 
 Please read [CONTRIBUTING.md](.github/CONTRIBUTING.md) before you start contributing.
 
+
+### Testing Code
+
 To test with all features both enabled and disabled, you can run theese commands:
 
 ```sh
 $ cargo test --no-default-features
-$ cargo test --features yaml
+$ cargo test --features ""yaml unstable""
 ```
 
-If you have a nightly compiler you can append `--features lints` to both commands
-to get style warnings and code smells; If you get one from code you think is fine,
-you can ignore it by prepending `#[cfg_attr(feature=""lints"", allow(lint_name))]`
-to the function or impl block.
+Alternatively, if you have [`just`](https://github.com/casey/just) installed you can run the prebuilt recipies. *Not* using `just` is prfeclty fine as well, it simply bundles commands automatically.
+
+For example, to test the code, as above simply run:
+
+```sh
+$ just run-tests`
+```
+
+From here on, I will lis the appropriate `cargo` command as well as the `just` command.
+
+Sometimes it's helpful to only run a subset of the tests, which can be done via:
+
+```sh
+$ cargo test --test <test_name>
+
+# Or
+
+$ just run-test <test_name>
+```
 
-If you are debugging (or just trying to understand the code) you can enable the
-""debug"" feature which will trace function calls and brances in some parts of the code.
+### Linting Code
+
+During the CI process `clap` runs against many different lints using [`clippy`](https://github.com/Manishearth/rust-clippy). In order to check if these lints pass on your own computer prior to submitting a PR you'll need a nightly compiler.
+
+In order to check the code for lints run either:
+
+```sh
+$ rustup override add nightly
+$ cargo build --features lints
+$ rustup override remove
+
+# Or
+
+$ just lint
+```
+
+### Debugging Code
+
+Another helpful technique is to see the `clap` debug output while developing features. In order to see the debug output while running the full test suite or individual tests, run:
+
+```sh
+$ cargo test --features debug
+
+# Or for individual tests
+$ cargo test --test <test_name> --features debug
+
+# The corresponding just command for individual debugging tests is:
+$ just debug <test_name>
+```
 
 ### Goals
 
",2,"[""bf95d5d0b34d32ef2684488feb3de01cb824b2b4"", ""eb51316cdfdc7258d287ba13b67ef2f42bd2b8f6""]","[""refactor"", ""docs""]"
"skip if related view/hook/column of a filter is not found

Signed-off-by: Pranav C <pranavxc@gmail.com> | Add ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>","diff --git a/packages/nocodb/src/lib/version-upgrader/ncFilterUpgrader.ts b/packages/nocodb/src/lib/version-upgrader/ncFilterUpgrader.ts
index 1515f88..6c250bd 100644
--- a/packages/nocodb/src/lib/version-upgrader/ncFilterUpgrader.ts
+++ b/packages/nocodb/src/lib/version-upgrader/ncFilterUpgrader.ts
@@ -21,7 +21,13 @@ export default async function ({ ncMeta }: NcUpgraderCtx) {
     } else {
       continue;
     }
-    if (filter.project_id != model.project_id) {
+
+    // skip if related model is not found
+    if (!model) {
+      continue;
+    }
+
+    if (filter.project_id !== model.project_id) {
       await ncMeta.metaUpdate(
         null,
         null,

diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}
",2,"[""ab1e60a97c6d5c688dacbd23bca40cb8f20c4ac3"", ""f823cf28652987d43c8324b4f5b203240032383a""]","[""fix"", ""feat""]"
fix unit tests,"diff --git a/src/components/__tests__/__snapshots__/BottomNavigation.test.js.snap b/src/components/__tests__/__snapshots__/BottomNavigation.test.js.snap
index 4d771d6..9f9683c 100644
--- a/src/components/__tests__/__snapshots__/BottomNavigation.test.js.snap
+++ b/src/components/__tests__/__snapshots__/BottomNavigation.test.js.snap
@@ -9,9 +9,6 @@ exports[`renders custom icon and label in non-shifting bottom navigation 1`] = `
       Object {
         ""flex"": 1,
       },
-      Object {
-        ""backgroundColor"": ""#000000"",
-      },
       undefined,
     ]
   }
@@ -132,6 +129,33 @@ exports[`renders custom icon and label in non-shifting bottom navigation 1`] = `
         ]
       }
     >
+      <AnimatedComponent
+        pointerEvents=""none""
+        style={
+          Array [
+            Object {
+              ""position"": ""absolute"",
+            },
+            Object {
+              ""backgroundColor"": ""rgba(0, 0, 0, 0.12)"",
+              ""borderRadius"": 48,
+              ""height"": 96,
+              ""left"": -54.666666666666664,
+              ""opacity"": 0.002,
+              ""top"": -20,
+              ""transform"": Array [
+                Object {
+                  ""translateX"": 0,
+                },
+                Object {
+                  ""scale"": 0.001,
+                },
+              ],
+              ""width"": 96,
+            },
+          ]
+        }
+      />
       <TouchableWithoutFeedback
         key=""key-0""
         onPress={[Function]}
@@ -599,9 +623,6 @@ exports[`renders custom icon and label in shifting bottom navigation 1`] = `
       Object {
         ""flex"": 1,
       },
-      Object {
-        ""backgroundColor"": ""#000000"",
-      },
       undefined,
     ]
   }
@@ -783,12 +804,15 @@ exports[`renders custom icon and label in shifting bottom navigation 1`] = `
               ""backgroundColor"": undefined,
               ""borderRadius"": 0,
               ""height"": 0,
-              ""left"": 6,
+              ""left"": -4,
               ""opacity"": 0,
               ""top"": 28,
               ""transform"": Array [
                 Object {
-                  ""scale"": 0.002,
+                  ""translateX"": 10,
+                },
+                Object {
+                  ""scale"": 0.008,
                 },
               ],
               ""width"": 0,
@@ -805,17 +829,20 @@ exports[`renders custom icon and label in shifting bottom navigation 1`] = `
             },
             Object {
               ""backgroundColor"": ""rgba(255, 255, 255, 0.12)"",
-              ""borderRadius"": 36,
-              ""height"": 72,
-              ""left"": -30,
-              ""opacity"": 0,
-              ""top"": -8,
+              ""borderRadius"": 48,
+              ""height"": 96,
+              ""left"": -52,
+              ""opacity"": 0.002,
+              ""top"": -20,
               ""transform"": Array [
                 Object {
-                  ""scale"": 0.002,
+                  ""translateX"": 10,
+                },
+                Object {
+                  ""scale"": 0.001,
                 },
               ],
-              ""width"": 72,
+              ""width"": 96,
             },
           ]
         }
@@ -1374,9 +1401,6 @@ exports[`renders non-shifting bottom navigation 1`] = `
       Object {
         ""flex"": 1,
       },
-      Object {
-        ""backgroundColor"": ""#000000"",
-      },
       undefined,
     ]
   }
@@ -1497,6 +1521,33 @@ exports[`renders non-shifting bottom navigation 1`] = `
         ]
       }
     >
+      <AnimatedComponent
+        pointerEvents=""none""
+        style={
+          Array [
+            Object {
+              ""position"": ""absolute"",
+            },
+            Object {
+              ""backgroundColor"": ""rgba(0, 0, 0, 0.12)"",
+              ""borderRadius"": 48,
+              ""height"": 96,
+              ""left"": -54.666666666666664,
+              ""opacity"": 0.002,
+              ""top"": -20,
+              ""transform"": Array [
+                Object {
+                  ""translateX"": 0,
+                },
+                Object {
+                  ""scale"": 0.001,
+                },
+              ],
+              ""width"": 96,
+            },
+          ]
+        }
+      />
       <TouchableWithoutFeedback
         key=""key-0""
         onPress={[Function]}
@@ -2072,9 +2123,6 @@ exports[`renders shifting bottom navigation 1`] = `
       Object {
         ""flex"": 1,
       },
-      Object {
-        ""backgroundColor"": ""#000000"",
-      },
       undefined,
     ]
   }
@@ -2256,12 +2304,15 @@ exports[`renders shifting bottom navigation 1`] = `
               ""backgroundColor"": undefined,
               ""borderRadius"": 0,
               ""height"": 0,
-              ""left"": 6,
+              ""left"": -4,
               ""opacity"": 0,
               ""top"": 28,
               ""transform"": Array [
                 Object {
-                  ""scale"": 0.002,
+                  ""translateX"": 10,
+                },
+                Object {
+                  ""scale"": 0.008,
                 },
               ],
               ""width"": 0,
@@ -2278,17 +2329,20 @@ exports[`renders shifting bottom navigation 1`] = `
             },
             Object {
               ""backgroundColor"": ""rgba(255, 255, 255, 0.12)"",
-              ""borderRadius"": 36,
-              ""height"": 72,
-              ""left"": -30,
-              ""opacity"": 0,
-              ""top"": -8,
+              ""borderRadius"": 48,
+              ""height"": 96,
+              ""left"": -52,
+              ""opacity"": 0.002,
+              ""top"": -20,
               ""transform"": Array [
                 Object {
-                  ""scale"": 0.002,
+                  ""translateX"": 10,
+                },
+                Object {
+                  ""scale"": 0.001,
                 },
               ],
-              ""width"": 72,
+              ""width"": 96,
             },
           ]
         }
",1,"[""87427fe39d165bee2acedde8dbaa237cca3fb61e""]","[""test""]"
"build improvements | reintroduce timeout for assertion

The timeout had been removed by a previous commit. Without the timeout the test might be flaky.
Also removed obsolete code","diff --git a/.travis.yml b/.travis.yml
index 9e1b926..3144244 100644
--- a/.travis.yml
+++ b/.travis.yml
@@ -1,5 +1,6 @@
 language: node_js
 dist: trusty
+sudo: required
 node_js:
   - '6.9.5'
 before_install:
diff --git a/e2e/schematics/command-line.test.ts b/e2e/schematics/command-line.test.ts
index 16d8b34..ea91494 100644
--- a/e2e/schematics/command-line.test.ts
+++ b/e2e/schematics/command-line.test.ts
@@ -68,8 +68,6 @@ describe('Command line', () => {
 
       updateFile('apps/myapp/src/app/app.component.spec.ts', `import '@nrwl/mylib';`);
 
-      updateRunAffectedToWorkInE2ESetup();
-
       const affectedApps = runCommand('npm run affected:apps -- --files=""libs/mylib/index.ts""');
       expect(affectedApps).toContain('myapp');
       expect(affectedApps).not.toContain('myapp2');
@@ -147,11 +145,3 @@ describe('Command line', () => {
     1000000
   );
 });
-
-function updateRunAffectedToWorkInE2ESetup() {
-  const runAffected = readFile('node_modules/@nrwl/schematics/src/command-line/affected.js');
-  const newRunAffected = runAffected
-    .replace('ng build', '../../node_modules/.bin/ng build')
-    .replace('ng e2e', '../../node_modules/.bin/ng e2e');
-  updateFile('node_modules/@nrwl/schematics/src/command-line/affected.js', newRunAffected);
-}
diff --git a/e2e/schematics/workspace.test.ts b/e2e/schematics/workspace.test.ts
index 8a41070..8749926 100644
--- a/e2e/schematics/workspace.test.ts
+++ b/e2e/schematics/workspace.test.ts
@@ -82,7 +82,7 @@ describe('Nrwl Convert to Nx Workspace', () => {
 
   it('should generate a workspace and not change dependencies or devDependencies if they already exist', () => {
     // create a new AngularCLI app
-    runNgNew('--skip-install');
+    runNgNew();
     const nxVersion = '0.0.0';
     const schematicsVersion = '0.0.0';
     const ngrxVersion = '0.0.0';
diff --git a/e2e/utils.ts b/e2e/utils.ts
index 422d866..a03104f 100644
--- a/e2e/utils.ts
+++ b/e2e/utils.ts
@@ -17,8 +17,7 @@ export function newProject(): void {
     copyMissingPackages();
     execSync('mv ./tmp/proj ./tmp/proj_backup');
   }
-  execSync('cp -r ./tmp/proj_backup ./tmp/proj');
-  setUpSynLink();
+  execSync('cp -a ./tmp/proj_backup ./tmp/proj');
 }
 
 export function copyMissingPackages(): void {
@@ -26,14 +25,9 @@ export function copyMissingPackages(): void {
   modulesToCopy.forEach(m => copyNodeModule(projectName, m));
 }
 
-export function setUpSynLink(): void {
-  execSync(`ln -s ../@nrwl/schematics/src/command-line/nx.js tmp/${projectName}/node_modules/.bin/nx`);
-  execSync(`chmod +x tmp/${projectName}/node_modules/.bin/nx`);
-}
-
 function copyNodeModule(path: string, name: string) {
   execSync(`rm -rf tmp/${path}/node_modules/${name}`);
-  execSync(`cp -r node_modules/${name} tmp/${path}/node_modules/${name}`);
+  execSync(`cp -a node_modules/${name} tmp/${path}/node_modules/${name}`);
 }
 
 export function runCLI(
@@ -43,7 +37,7 @@ export function runCLI(
   }
 ): string {
   try {
-    return execSync(`../../node_modules/.bin/ng ${command}`, {
+    return execSync(`./node_modules/.bin/ng ${command}`, {
       cwd: `./tmp/${projectName}`
     })
       .toString()
@@ -67,7 +61,7 @@ export function newLib(name: string): string {
 }
 
 export function runSchematic(command: string): string {
-  return execSync(`../../node_modules/.bin/schematics ${command}`, {
+  return execSync(`./node_modules/.bin/schematics ${command}`, {
     cwd: `./tmp/${projectName}`
   }).toString();
 }
diff --git a/package.json b/package.json
index bef54f8..9186a58 100644
--- a/package.json
+++ b/package.json
@@ -6,7 +6,7 @@
   ""private"": true,
   ""scripts"": {
     ""build"": ""./scripts/build.sh"",
-    ""e2e"": ""yarn build && ./scripts/e2e.sh"",
+    ""e2e"": ""./scripts/e2e.sh"",
     ""format"": ""./scripts/format.sh"",
     ""linknpm"": ""./scripts/link.sh"",
     ""package"": ""./scripts/package.sh"",
@@ -14,7 +14,7 @@
     ""copy"": ""./scripts/copy.sh"",
     ""test:schematics"": ""yarn build && ./scripts/test_schematics.sh"",
     ""test:nx"": ""yarn build && ./scripts/test_nx.sh"",
-    ""test"": ""yarn build && ./scripts/test_nx.sh && ./scripts/test_schematics.sh"",
+    ""test"": ""yarn linknpm && ./scripts/test_nx.sh && ./scripts/test_schematics.sh"",
     ""checkformat"": ""./scripts/check-format.sh"",
     ""publish_npm"": ""./scripts/publish.sh""
   },
diff --git a/packages/schematics/src/collection/workspace/index.ts b/packages/schematics/src/collection/workspace/index.ts
index 8f8897f..c70d161 100644
--- a/packages/schematics/src/collection/workspace/index.ts
+++ b/packages/schematics/src/collection/workspace/index.ts
@@ -254,20 +254,7 @@ function moveFiles(options: Schema) {
 
 function copyAngularCliTgz() {
   return (host: Tree) => {
-    copyFile(
-      path.join(
-        'node_modules',
-        '@nrwl',
-        'schematics',
-        'src',
-        'collection',
-        'application',
-        'files',
-        '__directory__',
-        '.angular_cli.tgz'
-      ),
-      '.'
-    );
+    copyFile(path.join(__dirname, '..', 'application', 'files', '__directory__', '.angular_cli.tgz'), '.');
     return host;
   };
 }
diff --git a/packages/schematics/src/command-line/affected.ts b/packages/schematics/src/command-line/affected.ts
index b7f9173..89a4f72 100644
--- a/packages/schematics/src/command-line/affected.ts
+++ b/packages/schematics/src/command-line/affected.ts
@@ -1,5 +1,7 @@
 import { execSync } from 'child_process';
 import { getAffectedApps, parseFiles } from './shared';
+import * as path from 'path';
+import * as resolve from 'resolve';
 
 export function affected(args: string[]): void {
   const command = args[0];
@@ -39,7 +41,7 @@ function build(apps: string[], rest: string[]) {
   if (apps.length > 0) {
     console.log(`Building ${apps.join(', ')}`);
     apps.forEach(app => {
-      execSync(`ng build ${rest.join(' ')} -a=${app}`, { stdio: [0, 1, 2] });
+      execSync(`${ngPath()} build ${rest.join(' ')} -a=${app}`, { stdio: [0, 1, 2] });
     });
   } else {
     console.log('No apps to build');
@@ -50,9 +52,13 @@ function e2e(apps: string[], rest: string[]) {
   if (apps.length > 0) {
     console.log(`Testing ${apps.join(', ')}`);
     apps.forEach(app => {
-      execSync(`ng e2e ${rest.join(' ')} -a=${app}`, { stdio: [0, 1, 2] });
+      execSync(`${ngPath()} e2e ${rest.join(' ')} -a=${app}`, { stdio: [0, 1, 2] });
     });
   } else {
-    console.log('No apps to tst');
+    console.log('No apps to test');
   }
 }
+
+function ngPath() {
+  return `${path.dirname(path.dirname(path.dirname(resolve.sync('@angular/cli', { basedir: __dirname }))))}/bin/ng`;
+}
diff --git a/scripts/build.sh b/scripts/build.sh
index ac533b5..9b8891b 100755
--- a/scripts/build.sh
+++ b/scripts/build.sh
@@ -3,6 +3,8 @@
 rm -rf build
 ngc
 rsync -a --exclude=*.ts packages/ build/packages
+chmod +x build/packages/schematics/bin/create-nx-workspace.js
+chmod +x build/packages/schematics/src/command-line/nx.js
 rm -rf build/packages/install
 cp README.md build/packages/schematics
 cp README.md build/packages/nx
\ No newline at end of file

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
index d0ee4f3..c2ab83c 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
@@ -13,6 +13,7 @@ import static io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent.ACTI
 import static io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent.ELEMENT_ACTIVATING;
 import static java.util.function.Predicate.isEqual;
 import static org.assertj.core.api.Assertions.assertThat;
+import static org.awaitility.Awaitility.await;
 import static org.mockito.ArgumentMatchers.any;
 import static org.mockito.ArgumentMatchers.anyLong;
 import static org.mockito.ArgumentMatchers.eq;
@@ -30,7 +31,6 @@ import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.streamprocessor.StreamProcessor;
 import io.camunda.zeebe.streamprocessor.StreamProcessor.Phase;
 import io.camunda.zeebe.streamprocessor.StreamProcessorMode;
-import org.awaitility.Awaitility;
 import org.junit.Rule;
 import org.junit.Test;
 import org.mockito.InOrder;
@@ -71,7 +71,7 @@ public final class StreamProcessorReplayModeTest {
     // when
     startStreamProcessor(replayUntilEnd);
 
-    Awaitility.await()
+    await()
         .untilAsserted(
             () -> assertThat(getCurrentPhase(replayUntilEnd)).isEqualTo(Phase.PROCESSING));
 
@@ -163,7 +163,7 @@ public final class StreamProcessorReplayModeTest {
         command().processInstance(ACTIVATE_ELEMENT, RECORD),
         event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
 
-    Awaitility.await(""should have replayed first events"")
+    await(""should have replayed first events"")
         .until(replayContinuously::getLastSuccessfulProcessedRecordPosition, (pos) -> pos > 0);
 
     // when
@@ -210,7 +210,7 @@ public final class StreamProcessorReplayModeTest {
         command().processInstance(ACTIVATE_ELEMENT, RECORD),
         event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
 
-    Awaitility.await(""should have replayed first events"")
+    await(""should have replayed first events"")
         .until(replayContinuously::getLastSuccessfulProcessedRecordPosition, (pos) -> pos > 0);
     streamProcessor.pauseProcessing().join();
     replayContinuously.writeBatch(
@@ -244,7 +244,7 @@ public final class StreamProcessorReplayModeTest {
     // then
     verify(eventApplier, TIMEOUT).applyState(anyLong(), eq(ELEMENT_ACTIVATING), any());
 
-    Awaitility.await()
+    await()
         .untilAsserted(
             () -> {
               final var lastProcessedPosition = getLastProcessedPosition(replayContinuously);
@@ -273,8 +273,7 @@ public final class StreamProcessorReplayModeTest {
 
     verify(eventApplier, TIMEOUT).applyState(anyLong(), eq(ELEMENT_ACTIVATING), any());
 
-    Awaitility.await()
-        .until(() -> getLastProcessedPosition(replayContinuously), isEqual(commandPosition));
+    await().until(() -> getLastProcessedPosition(replayContinuously), isEqual(commandPosition));
 
     // then
     assertThat(replayContinuously.getLastSuccessfulProcessedRecordPosition())
@@ -285,7 +284,6 @@ public final class StreamProcessorReplayModeTest {
   @Test
   public void shouldNotSetLastProcessedPositionIfLessThanSnapshotPosition() {
     // given
-    final var commandPositionBeforeSnapshot = 1L;
     final var snapshotPosition = 2L;
 
     startStreamProcessor(replayContinuously);
@@ -298,23 +296,20 @@ public final class StreamProcessorReplayModeTest {
     // when
     startStreamProcessor(replayContinuously);
 
-    Awaitility.await()
+    await()
         .untilAsserted(
             () -> assertThat(getCurrentPhase(replayContinuously)).isEqualTo(Phase.REPLAY));
 
-    final var eventPosition =
-        replayContinuously.writeEvent(
-            ELEMENT_ACTIVATING,
-            RECORD,
-            writer -> writer.sourceRecordPosition(commandPositionBeforeSnapshot));
-
     // then
     final var lastProcessedPositionState = replayContinuously.getLastProcessedPositionState();
 
-    assertThat(lastProcessedPositionState.getLastSuccessfulProcessedRecordPosition())
-        .describedAs(
-            ""Expected that the last processed position is not less than the snapshot position"")
-        .isEqualTo(snapshotPosition);
+    await()
+        .untilAsserted(
+            () ->
+                assertThat(lastProcessedPositionState.getLastSuccessfulProcessedRecordPosition())
+                    .describedAs(
+                        ""Expected that the last processed position is not less than the snapshot position"")
+                    .isEqualTo(snapshotPosition));
   }
 
   private StreamProcessor startStreamProcessor(final StreamProcessorRule streamProcessorRule) {
",2,"[""e0a977b2d316e7612b5d72cb02cd7d78e75dbc55"", ""0d23f1b3ed22e615b9611bb4eae01d2241e64dff""]","[""build"", ""refactor""]"
"fix monorepo.dir prop

Signed-off-by: Carlos Alexandro Becker <caarlos0@gmail.com> | tests","diff --git a/www/docs/customization/monorepo.md b/www/docs/customization/monorepo.md
index 6d0e857..e45490f 100644
--- a/www/docs/customization/monorepo.md
+++ b/www/docs/customization/monorepo.md
@@ -18,7 +18,7 @@ project_name: subproj1
 
 monorepo:
   tag_prefix: subproject1/
-  folder: subproj1
+  dir: subproj1
 ```
 
 Then, you can release with (from the project's root directory):
@@ -30,11 +30,11 @@ goreleaser release --rm-dist -f ./subproj1/.goreleaser.yml
 Then, the following is different from a ""regular"" run:
 
 - GoReleaser will then look if current commit has a tag prefixed with `subproject1`, and also the previous tag with the same prefix;
-- Changelog will include only commits that contain changes to files within the `subproj1` folder;
+- Changelog will include only commits that contain changes to files within the `subproj1` directory;
 - Release name gets prefixed with `{{ .ProjectName }} ` if empty;
-- All build's `dir` setting get set to `monorepo.folder` if empty;
+- All build's `dir` setting get set to `monorepo.dir` if empty;
   - if yours is not, you might want to change that manually;
-- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.folder`;
+- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.dir`;
 - On templates, `{{.PrefixedTag}}` will be `monorepo.prefix/tag` (aka the actual tag name), and `{{.Tag}}` has the prefix stripped;
 
 The rest of the release process should work as usual.

diff --git a/client/src/components/Profile/__test__/EducationCard.test.tsx b/client/src/components/Profile/__test__/EducationCard.test.tsx
index 44b6e00..14539dd 100644
--- a/client/src/components/Profile/__test__/EducationCard.test.tsx
+++ b/client/src/components/Profile/__test__/EducationCard.test.tsx
@@ -53,7 +53,7 @@ describe('EducationCard', () => {
   });
 
   describe('filterPermissions', () => {
-    it('should left only contacts in ""permissionsSettings"" object', () => {
+    it('should left only ""isEducationVisible"" in ""permissionsSettings"" object', () => {
       const permissionsSettings = {
         isProfileVisible: { all: true },
         isAboutVisible: { all: true, mentor: true, student: true },
diff --git a/client/src/components/Profile/__test__/MainCard.test.tsx b/client/src/components/Profile/__test__/MainCard.test.tsx
index 8fb2840..552804b 100644
--- a/client/src/components/Profile/__test__/MainCard.test.tsx
+++ b/client/src/components/Profile/__test__/MainCard.test.tsx
@@ -3,6 +3,8 @@ import { shallow } from 'enzyme';
 import { shallowToJson } from 'enzyme-to-json';
 import MainCard from '../MainCard';
 
+// TODO: Known Issue: https://stackoverflow.com/questions/59942808/how-can-i-use-jest-coverage-in-next-js-styled-jsx
+
 describe('MainCard', () => {
   describe('Should render correctly', () => {
     it('if is editing mode disabled', () => {
@@ -21,49 +23,89 @@ describe('MainCard', () => {
       );
       expect(shallowToJson(output)).toMatchSnapshot();
     });
+    it('if is editing mode enabled', () => {
+      const output = shallow(
+        <MainCard
+          data={{
+            name: 'Petr Pervyi',
+            githubId: 'piter',
+            locationName: 'SPB',
+            locationId: '1',
+          }}
+          isEditingModeEnabled={true}
+          onPermissionsSettingsChange={() => {}}
+          onProfileSettingsChange={() => {}}
+        />,
+      );
+      expect(shallowToJson(output)).toMatchSnapshot();
+    });
   });
 
-  // const wrapper = shallow(
-  //   <MainCard
-  //     data={{
-  //       name: 'Petr Pervyi',
-  //       githubId: 'piter',
-  //       locationName: 'SPB',
-  //       locationId: '1',
-  //     }}
-  //     isEditingModeEnabled={false}
-  //     onPermissionsSettingsChange={() => {}}
-  //     onProfileSettingsChange={() => {}}
-  //   />);
-  // const instance = wrapper.instance();
-  // describe('showVisibilitySettings', () => {
-  //   it('should set ""state.isVisibilitySettingsVisible"" as ""true""', () => {
-  //     expect(instance.state.isVisibilitySettingsVisible).toBe(false);
-  //     instance.showVisibilitySettings();
-  //     expect(instance.state.isVisibilitySettingsVisible).toBe(true);
-  //   });
-  // });
-  // describe('hideVisibilitySettings', () => {
-  //   it('should set ""state.isVisibilitySettingsVisible"" as ""false""', () => {
-  //     instance.state.isVisibilitySettingsVisible = true;
-  //     expect(instance.state.isVisibilitySettingsVisible).toBe(true);
-  //     instance.hideVisibilitySettings();
-  //     expect(instance.state.isVisibilitySettingsVisible).toBe(false);
-  //   });
-  // });
-  // describe('showProfileSettings', () => {
-  //   it('should set ""state.isProfileSettingsVisible"" as ""true""', () => {
-  //     expect(instance.state.isProfileSettingsVisible).toBe(false);
-  //     instance.showProfileSettings();
-  //     expect(instance.state.isProfileSettingsVisible).toBe(true);
-  //   });
-  // });
-  // describe('hideProfileSettings', () => {
-  //   it('should set ""state.isProfileSettingsVisible"" as ""false""', () => {
-  //     instance.state.isProfileSettingsVisible = true;
-  //     expect(instance.state.isProfileSettingsVisible).toBe(true);
-  //     instance.hideProfileSettings();
-  //     expect(instance.state.isProfileSettingsVisible).toBe(false);
-  //   });
-  // });
+  const wrapper = shallow(
+    <MainCard
+      data={{
+        name: 'Petr Pervyi',
+        githubId: 'piter',
+        locationName: 'SPB',
+        locationId: '1',
+      }}
+      isEditingModeEnabled={false}
+      onPermissionsSettingsChange={() => {}}
+      onProfileSettingsChange={() => {}}
+    />);
+  const instance = wrapper.instance();
+  describe('showVisibilitySettings', () => {
+    it('should set ""state.isVisibilitySettingsVisible"" as ""true""', () => {
+      expect(instance.state.isVisibilitySettingsVisible).toBe(false);
+      instance.showVisibilitySettings();
+      expect(instance.state.isVisibilitySettingsVisible).toBe(true);
+    });
+  });
+  describe('hideVisibilitySettings', () => {
+    it('should set ""state.isVisibilitySettingsVisible"" as ""false""', () => {
+      instance.state.isVisibilitySettingsVisible = true;
+      expect(instance.state.isVisibilitySettingsVisible).toBe(true);
+      instance.hideVisibilitySettings();
+      expect(instance.state.isVisibilitySettingsVisible).toBe(false);
+    });
+  });
+  describe('showProfileSettings', () => {
+    it('should set ""state.isProfileSettingsVisible"" as ""true""', () => {
+      expect(instance.state.isProfileSettingsVisible).toBe(false);
+      instance.showProfileSettings();
+      expect(instance.state.isProfileSettingsVisible).toBe(true);
+    });
+  });
+  describe('hideProfileSettings', () => {
+    it('should set ""state.isProfileSettingsVisible"" as ""false""', () => {
+      instance.state.isProfileSettingsVisible = true;
+      expect(instance.state.isProfileSettingsVisible).toBe(true);
+      instance.hideProfileSettings();
+      expect(instance.state.isProfileSettingsVisible).toBe(false);
+    });
+  });
+  describe('filterPermissions', () => {
+    it('should left only ""isProfileVisible"" in ""permissionsSettings"" object', () => {
+      const permissionsSettings = {
+        isProfileVisible: { all: true },
+        isAboutVisible: { all: true, mentor: true, student: true },
+        isEducationVisible: { all: true, mentor: true, student: true },
+        isEnglishVisible: { all: false, student: false },
+        isEmailVisible: { all: true, student: true },
+        isTelegramVisible: { all: false, student: false },
+        isSkypeVisible: { all: true, student: true },
+        isPhoneVisible: { all: false, student: false },
+        isContactsNotesVisible: { all: true, student: true },
+        isLinkedInVisible: { all: false, mentor: false, student: false },
+        isPublicFeedbackVisible: { all: true, mentor: true, student: true },
+        isMentorStatsVisible: { all: true, mentor: true, student: true },
+        isStudentStatsVisible: { all: true, student: true },
+      };
+      const instance = wrapper.instance();
+      const result = instance.filterPermissions(permissionsSettings);
+      expect(result).toEqual({
+        isProfileVisible: { all: true },
+      });
+    });
+  });
 });
diff --git a/client/src/components/Profile/__test__/__snapshots__/MainCard.test.tsx.snap b/client/src/components/Profile/__test__/__snapshots__/MainCard.test.tsx.snap
index 40331eb..fef20dd 100644
--- a/client/src/components/Profile/__test__/__snapshots__/MainCard.test.tsx.snap
+++ b/client/src/components/Profile/__test__/__snapshots__/MainCard.test.tsx.snap
@@ -71,3 +71,158 @@ exports[`MainCard Should render correctly if is editing mode disabled 1`] = `
   </Card>
 </Fragment>
 `;
+
+exports[`MainCard Should render correctly if is editing mode enabled 1`] = `
+<Fragment>
+  <Card
+    actions={
+      Array [
+        <ForwardRef(EditOutlined)
+          onClick={[Function]}
+        />,
+        <ForwardRef(SettingOutlined)
+          onClick={[Function]}
+        />,
+      ]
+    }
+  >
+    <GithubAvatar
+      githubId=""piter""
+      size={96}
+      style={
+        Object {
+          ""display"": ""block"",
+          ""margin"": ""0 auto 10px"",
+        }
+      }
+    />
+    <Title
+      level={1}
+      style={
+        Object {
+          ""fontSize"": 24,
+          ""margin"": 0,
+          ""textAlign"": ""center"",
+        }
+      }
+    >
+      Petr Pervyi
+    </Title>
+    <Paragraph
+      style={
+        Object {
+          ""marginBottom"": 20,
+          ""textAlign"": ""center"",
+        }
+      }
+    >
+      <a
+        href=""https://github.com/piter""
+        style={
+          Object {
+            ""fontSize"": 16,
+            ""marginLeft"": ""-14px"",
+          }
+        }
+        target=""_blank""
+      >
+        <ForwardRef(GithubFilled) />
+         
+        piter
+      </a>
+    </Paragraph>
+    <Paragraph
+      style={
+        Object {
+          ""margin"": 0,
+          ""textAlign"": ""center"",
+        }
+      }
+    >
+      <span
+        style={
+          Object {
+            ""marginLeft"": ""-14px"",
+          }
+        }
+      >
+        <ForwardRef(EnvironmentFilled) />
+         
+        SPB
+      </span>
+    </Paragraph>
+    <PermissionsSettingsDrawer
+      hideSettings={[Function]}
+      isSettingsVisible={false}
+      onPermissionsSettingsChange={[Function]}
+    />
+    <ProfileSettingsDrawer
+      content={
+        <div>
+          <p
+            style={
+              Object {
+                ""fontSize"": 18,
+                ""marginBottom"": 5,
+              }
+            }
+          >
+            <Text
+              strong={true}
+            >
+              Name:
+            </Text>
+          </p>
+          <p
+            style={
+              Object {
+                ""marginBottom"": 20,
+              }
+            }
+          >
+            <Input
+              onChange={[Function]}
+              placeholder=""Firstname Lastname""
+              type=""text""
+              value=""Petr Pervyi""
+            />
+          </p>
+          <p
+            style={
+              Object {
+                ""fontSize"": 18,
+                ""marginBottom"": 5,
+              }
+            }
+          >
+            <Text
+              strong={true}
+            >
+              Location:
+            </Text>
+          </p>
+          <div
+            style={
+              Object {
+                ""marginBottom"": 5,
+              }
+            }
+          >
+            <LocationSelect
+              defaultValue=""1""
+              onChange={[Function]}
+              style={
+                Object {
+                  ""width"": ""100%"",
+                }
+              }
+            />
+          </div>
+        </div>
+      }
+      hideSettings={[Function]}
+      isSettingsVisible={false}
+    />
+  </Card>
+</Fragment>
+`;
diff --git a/client/src/jest.config.js b/client/src/jest.config.js
index df39788..654f9f3 100644
--- a/client/src/jest.config.js
+++ b/client/src/jest.config.js
@@ -7,4 +7,5 @@ module.exports = {
     '^services(.*)$': '<rootDir>/services/$1',
     '^utils(.*)$': '<rootDir>/utils/$1',
   },
+  verbose: true,
 };
",2,"[""9ed3c0c4a72af977fc9150512fb6538f20a94b22"", ""f87659953e9af59bc7cb314a22dd076d988ef607""]","[""docs"", ""test""]"
add Expr.equals benchmark,"diff --git a/ibis/tests/benchmarks/test_benchmarks.py b/ibis/tests/benchmarks/test_benchmarks.py
index 78305bb..9c7e6d7 100644
--- a/ibis/tests/benchmarks/test_benchmarks.py
+++ b/ibis/tests/benchmarks/test_benchmarks.py
@@ -1,3 +1,4 @@
+import copy
 import functools
 import itertools
 import string
@@ -340,8 +341,9 @@ def test_execute(benchmark, expression_fn, pt):
     benchmark(expr.execute)
 
 
-def test_repr_tpc_h02(benchmark):
-    part = ibis.table(
+@pytest.fixture
+def part():
+    return ibis.table(
         dict(
             p_partkey=""int64"",
             p_size=""int64"",
@@ -350,7 +352,11 @@ def test_repr_tpc_h02(benchmark):
         ),
         name=""part"",
     )
-    supplier = ibis.table(
+
+
+@pytest.fixture
+def supplier():
+    return ibis.table(
         dict(
             s_suppkey=""int64"",
             s_nationkey=""int64"",
@@ -362,7 +368,11 @@ def test_repr_tpc_h02(benchmark):
         ),
         name=""supplier"",
     )
-    partsupp = ibis.table(
+
+
+@pytest.fixture
+def partsupp():
+    return ibis.table(
         dict(
             ps_partkey=""int64"",
             ps_suppkey=""int64"",
@@ -370,14 +380,25 @@ def test_repr_tpc_h02(benchmark):
         ),
         name=""partsupp"",
     )
-    nation = ibis.table(
+
+
+@pytest.fixture
+def nation():
+    return ibis.table(
         dict(n_nationkey=""int64"", n_regionkey=""int64"", n_name=""string""),
         name=""nation"",
     )
-    region = ibis.table(
+
+
+@pytest.fixture
+def region():
+    return ibis.table(
         dict(r_regionkey=""int64"", r_name=""string""), name=""region""
     )
 
+
+@pytest.fixture
+def tpc_h02(part, supplier, partsupp, nation, region):
     REGION = ""EUROPE""
     SIZE = 25
     TYPE = ""BRASS""
@@ -420,7 +441,7 @@ def test_repr_tpc_h02(benchmark):
         ]
     )
 
-    expr = q.sort_by(
+    return q.sort_by(
         [
             ibis.desc(q.s_acctbal),
             q.n_name,
@@ -429,7 +450,9 @@ def test_repr_tpc_h02(benchmark):
         ]
     ).limit(100)
 
-    benchmark(repr, expr)
+
+def test_repr_tpc_h02(benchmark, tpc_h02):
+    benchmark(repr, tpc_h02)
 
 
 def test_repr_huge_union(benchmark):
@@ -478,3 +501,7 @@ def test_complex_datatype_builtins(benchmark, func):
         )
     )
     benchmark(func, datatype)
+
+
+def test_large_expr_equals(benchmark, tpc_h02):
+    benchmark(ir.Expr.equals, tpc_h02, copy.deepcopy(tpc_h02))
",1,"[""b700285c1f27588922d9c56527cee721bb884682""]","[""test""]"
use `regexp_instr != 0` instead of `REGEXP` keyword | add instruction for finding version | use an action for issue assignment,"diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(

diff --git a/.github/ISSUE_TEMPLATE/_bug_report_chs.md b/.github/ISSUE_TEMPLATE/_bug_report_chs.md
index 42a2e0f..44a33db 100644
--- a/.github/ISSUE_TEMPLATE/_bug_report_chs.md
+++ b/.github/ISSUE_TEMPLATE/_bug_report_chs.md
@@ -36,7 +36,7 @@ assignees: ''
 ## 
 - : [] <!--  [Window10] -->
 - : [] <!--  [Chrome77] -->
-- : [] <!--  [v7.0.0] -->
+- : [] <!--  [v7.0.0]  -->
 
 <!--  ##  -->
 

diff --git a/.github/workflows/assign.yml b/.github/workflows/assign.yml
index 29d92a8..758874e 100644
--- a/.github/workflows/assign.yml
+++ b/.github/workflows/assign.yml
@@ -8,8 +8,6 @@ jobs:
     runs-on: ubuntu-latest
     if: ${{ github.event.comment.body == '/take' }}
     steps:
-      - uses: actions/checkout@v2
-      - name: Assign issue ${{ github.event.issue.number }} to ${{ github.event.comment.user.login }}
-        run: gh issue edit ${{ github.event.issue.number }} --add-assignee ""${{ github.event.comment.user.login }}""
-        env:
-          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+      - uses: pozil/auto-assign-issue@v1.1.0
+        with:
+          assignees: ${{ github.event.comment.user.login }}
",3,"[""06e2be4e2019b6fa714e1fcb34485860ef1ede79"", ""af0a5f7ab9d71fe20aa0888f682368f32b26fe18"", ""fb3a231b29bc8bff9270b99dd4aff9dad599f21f""]","[""fix"", ""docs"", ""cicd""]"
"deploy dmn using java client

This test is an acceptance test that verifies that the java client can
deploy a dmn decision model using the newDeployCommand client method.

It verifies that the model was resource was parsed and deployed,
resulting in a response that contains metadata of the deployed decision
requirements graph and the decisions it contains. | make it mode less | increment failing test retries","diff --git a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/client/command/CreateDeploymentTest.java b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/client/command/CreateDeploymentTest.java
index f36465b..6b6ab48 100644
--- a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/client/command/CreateDeploymentTest.java
+++ b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/client/command/CreateDeploymentTest.java
@@ -67,6 +67,49 @@ public final class CreateDeploymentTest {
   }
 
   @Test
+  public void shouldDeployDecisionModel() {
+    // given
+    final String resourceName = ""dmn/drg-force-user.dmn"";
+
+    // when
+    final DeploymentEvent result =
+        CLIENT_RULE
+            .getClient()
+            .newDeployCommand()
+            .addResourceFromClasspath(resourceName)
+            .send()
+            .join();
+
+    // then
+    assertThat(result.getKey()).isPositive();
+    assertThat(result.getDecisionRequirements()).hasSize(1);
+    assertThat(result.getDecisions()).hasSize(2);
+
+    final var decisionRequirements = result.getDecisionRequirements().get(0);
+    assertThat(decisionRequirements.getDmnDecisionRequirementsId()).isEqualTo(""force_users"");
+    assertThat(decisionRequirements.getDmnDecisionRequirementsName()).isEqualTo(""Force Users"");
+    assertThat(decisionRequirements.getVersion()).isEqualTo(1);
+    assertThat(decisionRequirements.getDecisionRequirementsKey()).isPositive();
+    assertThat(decisionRequirements.getResourceName()).isEqualTo(resourceName);
+
+    final var decision1 = result.getDecisions().get(0);
+    assertThat(decision1.getDmnDecisionId()).isEqualTo(""jedi_or_sith"");
+    assertThat(decision1.getDmnDecisionName()).isEqualTo(""Jedi or Sith"");
+    assertThat(decision1.getVersion()).isEqualTo(1);
+    assertThat(decision1.getDecisionKey()).isPositive();
+    assertThat(decision1.getDmnDecisionRequirementsId()).isEqualTo(""force_users"");
+    assertThat(decision1.getDecisionRequirementsKey()).isPositive();
+
+    final var decision2 = result.getDecisions().get(1);
+    assertThat(decision2.getDmnDecisionId()).isEqualTo(""force_user"");
+    assertThat(decision2.getDmnDecisionName()).isEqualTo(""Which force user?"");
+    assertThat(decision2.getVersion()).isEqualTo(1);
+    assertThat(decision2.getDecisionKey()).isPositive();
+    assertThat(decision2.getDmnDecisionRequirementsId()).isEqualTo(""force_users"");
+    assertThat(decision2.getDecisionRequirementsKey()).isPositive();
+  }
+
+  @Test
   public void shouldRejectDeployIfProcessIsInvalid() {
     // given
     final BpmnModelInstance process =
diff --git a/qa/integration-tests/src/test/resources/dmn/drg-force-user.dmn b/qa/integration-tests/src/test/resources/dmn/drg-force-user.dmn
new file mode 100644
index 0000000..8d55c55
--- /dev/null
+++ b/qa/integration-tests/src/test/resources/dmn/drg-force-user.dmn
@@ -0,0 +1,144 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<definitions xmlns=""https://www.omg.org/spec/DMN/20191111/MODEL/"" xmlns:dmndi=""https://www.omg.org/spec/DMN/20191111/DMNDI/"" xmlns:dc=""http://www.omg.org/spec/DMN/20180521/DC/"" xmlns:biodi=""http://bpmn.io/schema/dmn/biodi/2.0"" xmlns:di=""http://www.omg.org/spec/DMN/20180521/DI/"" id=""force_users"" name=""Force Users""  namespace=""http://camunda.org/schema/1.0/dmn"" exporter=""Camunda Modeler"" exporterVersion=""4.12.0"">
+  <decision id=""jedi_or_sith"" name=""Jedi or Sith"">
+    <decisionTable id=""DecisionTable_14n3bxx"">
+      <input id=""Input_1"" label=""Lightsaber color"" biodi:width=""192"">
+        <inputExpression id=""InputExpression_1"" typeRef=""string"">
+          <text>lightsaberColor</text>
+        </inputExpression>
+      </input>
+      <output id=""Output_1"" label=""Jedi or Sith"" name=""jedi_or_sith"" typeRef=""string"" biodi:width=""192"">
+        <outputValues id=""UnaryTests_0hj346a"">
+          <text>""Jedi"",""Sith""</text>
+        </outputValues>
+      </output>
+      <rule id=""DecisionRule_0zumznl"">
+        <inputEntry id=""UnaryTests_0leuxqi"">
+          <text>""blue""</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_0c9vpz8"">
+          <text>""Jedi""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_1utwb1e"">
+        <inputEntry id=""UnaryTests_1v3sd4m"">
+          <text>""green""</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_0tgh8k1"">
+          <text>""Jedi""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_1bwgcym"">
+        <inputEntry id=""UnaryTests_0n1ewm3"">
+          <text>""red""</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_19xnlkw"">
+          <text>""Sith""</text>
+        </outputEntry>
+      </rule>
+    </decisionTable>
+  </decision>
+  <decision id=""force_user"" name=""Which force user?"">
+    <informationRequirement id=""InformationRequirement_1o8esai"">
+      <requiredDecision href=""#jedi_or_sith"" />
+    </informationRequirement>
+    <decisionTable id=""DecisionTable_07g94t1"" hitPolicy=""FIRST"">
+      <input id=""InputClause_0qnqj25"" label=""Jedi or Sith"">
+        <inputExpression id=""LiteralExpression_00lcyt5"" typeRef=""string"">
+          <text>jedi_or_sith</text>
+        </inputExpression>
+        <inputValues id=""UnaryTests_1xjidd8"">
+          <text>""Jedi"",""Sith""</text>
+        </inputValues>
+      </input>
+      <input id=""InputClause_0k64hys"" label=""Body height"">
+        <inputExpression id=""LiteralExpression_0ib6fnk"" typeRef=""number"">
+          <text>height</text>
+        </inputExpression>
+      </input>
+      <output id=""OutputClause_0hhe1yo"" label=""Force user"" name=""force_user"" typeRef=""string"" />
+      <rule id=""DecisionRule_13zidc5"">
+        <inputEntry id=""UnaryTests_056skcq"">
+          <text>""Jedi""</text>
+        </inputEntry>
+        <inputEntry id=""UnaryTests_0l4xksq"">
+          <text>&gt; 190</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_0hclhw3"">
+          <text>""Mace Windu""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_0uin2hk"">
+        <description></description>
+        <inputEntry id=""UnaryTests_16maepk"">
+          <text>""Jedi""</text>
+        </inputEntry>
+        <inputEntry id=""UnaryTests_0rv0nwf"">
+          <text>&gt; 180</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_0t82c11"">
+          <text>""Obi-Wan Kenobi""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_0mpio0p"">
+        <inputEntry id=""UnaryTests_09eicyc"">
+          <text>""Jedi""</text>
+        </inputEntry>
+        <inputEntry id=""UnaryTests_1bekl8k"">
+          <text>&lt; 70</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_0brx3vt"">
+          <text>""Yoda""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_06paffx"">
+        <inputEntry id=""UnaryTests_1baiid4"">
+          <text>""Sith""</text>
+        </inputEntry>
+        <inputEntry id=""UnaryTests_0fcdq0i"">
+          <text>&gt; 200</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_02oibi4"">
+          <text>""Darth Vader""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_1ua4pcl"">
+        <inputEntry id=""UnaryTests_1s1h3nm"">
+          <text>""Sith""</text>
+        </inputEntry>
+        <inputEntry id=""UnaryTests_1pnvw8p"">
+          <text>&gt; 170</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_1w1n2rc"">
+          <text>""Darth Sidius""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_00ew25e"">
+        <inputEntry id=""UnaryTests_07uxyug"">
+          <text></text>
+        </inputEntry>
+        <inputEntry id=""UnaryTests_1he6fym"">
+          <text></text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_07i3sc8"">
+          <text>""unknown""</text>
+        </outputEntry>
+      </rule>
+    </decisionTable>
+  </decision>
+  <dmndi:DMNDI>
+    <dmndi:DMNDiagram>
+      <dmndi:DMNShape dmnElementRef=""jedi_or_sith"">
+        <dc:Bounds height=""80"" width=""180"" x=""160"" y=""280"" />
+      </dmndi:DMNShape>
+      <dmndi:DMNShape id=""DMNShape_1sb3tre"" dmnElementRef=""force_user"">
+        <dc:Bounds height=""80"" width=""180"" x=""280"" y=""80"" />
+      </dmndi:DMNShape>
+      <dmndi:DMNEdge id=""DMNEdge_0gt1p1u"" dmnElementRef=""InformationRequirement_1o8esai"">
+        <di:waypoint x=""250"" y=""280"" />
+        <di:waypoint x=""370"" y=""180"" />
+        <di:waypoint x=""370"" y=""160"" />
+      </dmndi:DMNEdge>
+    </dmndi:DMNDiagram>
+  </dmndi:DMNDI>
+</definitions>

diff --git a/core/src/components/slides/slides.tsx b/core/src/components/slides/slides.tsx
index 48fd53f..d5c2f75 100644
--- a/core/src/components/slides/slides.tsx
+++ b/core/src/components/slides/slides.tsx
@@ -1,7 +1,6 @@
 import { Component, Element, Event, EventEmitter, Method, Prop, Watch } from '@stencil/core';
 
 import { Mode } from '../../interface.js';
-import { createThemedClasses } from '../../utils/theme.js';
 
 import { Swiper } from './vendor/swiper.js';
 
@@ -15,6 +14,7 @@ import { Swiper } from './vendor/swiper.js';
   shadow: true
 })
 export class Slides {
+
   private container!: HTMLElement;
   private swiper: any;
 
@@ -391,12 +391,6 @@ export class Slides {
     return { ...swiperOptions, ...this.options, ...eventOptions };
   }
 
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'slides')
-    };
-  }
-
   render() {
     return (
       <div class=""swiper-container"" ref={el => this.container = el as HTMLElement }>
diff --git a/core/src/components/thumbnail/thumbnail.ios.scss b/core/src/components/thumbnail/thumbnail.ios.scss
deleted file mode 100644
index e3add45..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.ios.vars"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-ios-width};
-  --border-radius: #{$thumbnail-ios-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.ios.vars.scss b/core/src/components/thumbnail/thumbnail.ios.vars.scss
deleted file mode 100644
index 85d53e5..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.ios"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-ios-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-ios-height:                  $thumbnail-ios-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-ios-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.md.scss b/core/src/components/thumbnail/thumbnail.md.scss
deleted file mode 100644
index 0fbb2ca..0000000
--- a/core/src/components/thumbnail/thumbnail.md.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.md.vars"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-md-width};
-  --border-radius: #{$thumbnail-md-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.md.vars.scss b/core/src/components/thumbnail/thumbnail.md.vars.scss
deleted file mode 100644
index 94e48b2..0000000
--- a/core/src/components/thumbnail/thumbnail.md.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.md"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-md-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-md-height:                  $thumbnail-md-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-md-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.scss b/core/src/components/thumbnail/thumbnail.scss
index 8ac3a22..8af268d 100644
--- a/core/src/components/thumbnail/thumbnail.scss
+++ b/core/src/components/thumbnail/thumbnail.scss
@@ -9,6 +9,8 @@
    * @prop --border-radius: Border radius of the thumbnail
    * @prop --size: Size of the thumbnail
    */
+  --size: 48px;
+  --border-radius: 0;
 
   @include border-radius(var(--border-radius));
 
diff --git a/core/src/components/thumbnail/thumbnail.tsx b/core/src/components/thumbnail/thumbnail.tsx
index 50ff2c2..de76593 100644
--- a/core/src/components/thumbnail/thumbnail.tsx
+++ b/core/src/components/thumbnail/thumbnail.tsx
@@ -1,25 +1,11 @@
 import { Component } from '@stencil/core';
 
-import { Mode } from '../../interface';
-import { createThemedClasses } from '../../utils/theme';
-
 @Component({
   tag: 'ion-thumbnail',
-  styleUrls: {
-    ios: 'thumbnail.ios.scss',
-    md: 'thumbnail.md.scss'
-  },
+  styleUrl: 'thumbnail.scss',
   shadow: true
 })
 export class Thumbnail {
-  mode!: Mode;
-
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'thumbnail')
-    };
-  }
-
   render() {
     return <slot></slot>;
   }

diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
",3,"[""73eac947689e3fc6b53bf626a6b4604056166d6e"", ""771857b1df9470ebc15357e8879118a72c649d5b"", ""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57""]","[""test"", ""refactor"", ""cicd""]"
rename ELECTRON_CACHE env variable to electron_config_cache (#21313) | run pyspark tests in parallel,"diff --git a/docs/tutorial/installation.md b/docs/tutorial/installation.md
index d4af120..1a09eea 100644
--- a/docs/tutorial/installation.md
+++ b/docs/tutorial/installation.md
@@ -82,7 +82,7 @@ with the network at all.
 On environments that have been using older versions of Electron, you might find the
 cache also in `~/.electron`.
 
-You can also override the local cache location by providing a `ELECTRON_CACHE`
+You can also override the local cache location by providing a `electron_config_cache`
 environment variable.
 
 The cache contains the version's official zip file as well as a checksum, stored as

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index e23088e..9708157 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -202,11 +202,11 @@ jobs:
         run: poetry install --without dev --without docs --extras ${{ matrix.backend.name }} --extras geospatial
 
       - name: ""run parallel tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name != 'pyspark' && matrix.backend.name != 'impala'
+        if: matrix.backend.name != 'impala'
         run: just ci-check -m ${{ matrix.backend.name }} --numprocesses auto --dist=loadgroup
 
       - name: ""run serial tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name == 'pyspark' || matrix.backend.name == 'impala'
+        if: matrix.backend.name == 'impala'
         run: just ci-check -m ${{ matrix.backend.name }}
         env:
           IBIS_TEST_NN_HOST: localhost
",2,"[""f2f52c23b513dd857350f3c163f676d37189d0d3"", ""4cbbd2552ba0de273e1dfe7d453c5b3efed751a3""]","[""docs"", ""cicd""]"
parallelize pybind11 build,"diff --git a/poetry-overrides.nix b/poetry-overrides.nix
index d37c5ed..aaaaf02 100644
--- a/poetry-overrides.nix
+++ b/poetry-overrides.nix
@@ -82,4 +82,11 @@ self: super:
     {
       patches = (attrs.patches or [ ]) ++ [ ./patches/watchdog-force-kqueue.patch ];
     });
+
+  pybind11 = super.pybind11.overridePythonAttrs (_: {
+    postBuild = ''
+      # build tests
+      make -j $NIX_BUILD_CORES -l $NIX_BUILD_CORES
+    '';
+  });
 }
",1,"[""9ab4c61975e073e214646443d088339cfdbaa88d""]","[""build""]"
"add more tests for Utils.lookupPathFromDecorator | project user api path correction

Signed-off-by: Pranav C <pranavxc@gmail.com>","diff --git a/lib/utils/Utils.ts b/lib/utils/Utils.ts
index 6de6e05..b03b3e9 100644
--- a/lib/utils/Utils.ts
+++ b/lib/utils/Utils.ts
@@ -338,15 +338,8 @@ export class Utils {
       line++;
     }
 
-    if (stack[line].match(/\(.+\)/i)) {
-      meta.path = Utils.normalizePath(
-        stack[line].match(/\((.*):\d+:\d+\)/)![1],
-      );
-    } else {
-      meta.path = Utils.normalizePath(
-        stack[line].match(/at\s*(.*):\d+:\d+$/)![1],
-      );
-    }
+    const re = stack[line].match(/\(.+\)/i) ? /\((.*):\d+:\d+\)/ : /at\s*(.*):\d+:\d+$/;
+    meta.path = Utils.normalizePath(stack[line].match(re)![1]);
 
     return meta.path;
   }
diff --git a/tests/Utils.test.ts b/tests/Utils.test.ts
index c3e9aa1..4d2a209 100644
--- a/tests/Utils.test.ts
+++ b/tests/Utils.test.ts
@@ -256,7 +256,7 @@ describe('Utils', () => {
       '    at Object.__decorate (/usr/local/var/www/my-project/node_modules/tslib/tslib.js:92:96)',
       '    at Object.<anonymous> (/usr/local/var/www/my-project/dist/entities/Customer.js:20:9)',
       '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
-      '    at Object.Module._extensions..js (internal/modules/cjs/loader.js:787:10)',
+      '    at Object.Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
       '    at Module.load (internal/modules/cjs/loader.js:643:32)',
       '    at Function.Module._load (internal/modules/cjs/loader.js:556:12)',
     ];
@@ -272,10 +272,25 @@ describe('Utils', () => {
       '    at Object.<anonymous> (/usr/local/var/www/my-project/src/entities/Customer.ts:9:3)',
       '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
       '    at Module.m._compile (/usr/local/var/www/my-project/node_modules/ts-node/src/index.ts:473:23)',
-      '    at Module._extensions..js (internal/modules/cjs/loader.js:787:10)',
+      '    at Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
       '    at Object.require.extensions.<computed> [as .ts] (/usr/local/var/www/my-project/node_modules/ts-node/src/index.ts:476:12)',
     ];
     expect(Utils.lookupPathFromDecorator({} as any, stack2)).toBe('/usr/local/var/www/my-project/src/entities/Customer.ts');
+
+    // no parens
+    const stack3 = [
+      '    at Function.lookupPathFromDecorator (/usr/local/var/www/my-project/node_modules/mikro-orm/dist/utils/Utils.js:170:23)',
+      '    at /usr/local/var/www/my-project/node_modules/mikro-orm/dist/decorators/PrimaryKey.js:12:23',
+      '    at DecorateProperty (/usr/local/var/www/my-project/node_modules/reflect-metadata/Reflect.js:553:33)',
+      '    at Object.decorate (/usr/local/var/www/my-project/node_modules/reflect-metadata/Reflect.js:123:24)',
+      '    at Object.__decorate (/usr/local/var/www/my-project/node_modules/tslib/tslib.js:92:96)',
+      '    at /usr/local/var/www/my-project/dist/entities/Customer.js:20:9',
+      '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
+      '    at Object.Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
+      '    at Module.load (internal/modules/cjs/loader.js:643:32)',
+      '    at Function.Module._load (internal/modules/cjs/loader.js:556:12)',
+    ];
+    expect(Utils.lookupPathFromDecorator({} as any, stack3)).toBe('/usr/local/var/www/my-project/dist/entities/Customer.js');
   });
 
   test('lookup path from decorator on windows', () => {
@@ -287,7 +302,7 @@ describe('Utils', () => {
       '    at Object.<anonymous> (C:\\www\\my-project\\src\\entities\\Customer.ts:7:5)',
       '    at Module._compile (internal/modules/cjs/loader.js:936:30)',
       '    at Module.m._compile (C:\\www\\my-project\\node_modules\\ts-node\\src\\index.ts:493:23)',
-      '    at Module._extensions..js (internal/modules/cjs/loader.js:947:10)',
+      '    at Module._extensions.js (internal/modules/cjs/loader.js:947:10)',
       '    at Object.require.extensions.<computed> [as .ts] (C:\\www\\my-project\\node_modules\\ts-node\\src\\index.ts:496:12)',
       '    at Module.load (internal/modules/cjs/loader.js:790:32)',
       '    at Function.Module._load (internal/modules/cjs/loader.js:703:12)',

diff --git a/packages/nc-gui/plugins/tele.js b/packages/nc-gui/plugins/tele.js
index 113f52b..1e63e13 100644
--- a/packages/nc-gui/plugins/tele.js
+++ b/packages/nc-gui/plugins/tele.js
@@ -14,8 +14,8 @@ export default function({
       socket.disconnect()
     }
     const isUrl = $axios.defaults.baseURL.startsWith('http')
-    const url = isUrl ? $axios.defaults.baseURL : window.location.href.split(/[?#]/)[0]
-    const path = isUrl ? undefined : $axios.defaults.baseURL
+    const url = isUrl ? $axios.defaults.baseURL : window.location.origin
+    const path = isUrl ? undefined : ($axios.defaults.baseURL === '..' ? window.location.path.split('/').slice(0, -1).join('/') : $axios.defaults.baseURL)
 
     socket = io(url, {
       path,
diff --git a/packages/nocodb/src/lib/noco/meta/api/projectUserApis.ts b/packages/nocodb/src/lib/noco/meta/api/projectUserApis.ts
index ecd05c3..ef49ce7 100644
--- a/packages/nocodb/src/lib/noco/meta/api/projectUserApis.ts
+++ b/packages/nocodb/src/lib/noco/meta/api/projectUserApis.ts
@@ -249,17 +249,20 @@ async function resendInvite(req, res, next): Promise<any> {
 }
 
 const router = Router({ mergeParams: true });
-router.get('/projects/:projectId/users', ncMetaAclMw(userList, 'userList'));
+router.get(
+  '/api/v1/db/meta/projects/:projectId/users',
+  ncMetaAclMw(userList, 'userList')
+);
 router.post(
-  '/projects/:projectId/users',
+  '/api/v1/db/meta/projects/:projectId/users',
   ncMetaAclMw(userInvite, 'userInvite')
 );
 router.patch(
-  '/projects/:projectId/users/:userId',
+  '/api/v1/db/meta/projects/:projectId/users/:userId',
   ncMetaAclMw(projectUserUpdate, 'projectUserUpdate')
 );
 router.delete(
-  '/projects/:projectId/users/:userId',
+  '/api/v1/db/meta/projects/:projectId/users/:userId',
   ncMetaAclMw(projectUserDelete, 'projectUserDelete')
 );
 export default router;
",2,"[""c5e86dbc00a13a355bffadeb2db197e2fea5640f"", ""2a58c82b808593d13451af2e86758ecff17d0bd4""]","[""test"", ""fix""]"
update version (nightly.0) | fixed tick interval,"diff --git a/Cargo.lock b/Cargo.lock
index f949506..6a10219 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -94,7 +94,7 @@ dependencies = [
 
 [[package]]
 name = ""els""
-version = ""0.1.22""
+version = ""0.1.23-nightly.0""
 dependencies = [
  ""erg_common"",
  ""erg_compiler"",
@@ -105,7 +105,7 @@ dependencies = [
 
 [[package]]
 name = ""erg""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""els"",
  ""erg_common"",
@@ -115,7 +115,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_common""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""backtrace-on-stack-overflow"",
  ""crossterm"",
@@ -126,7 +126,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_compiler""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""erg_common"",
  ""erg_parser"",
@@ -134,7 +134,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_parser""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""erg_common"",
  ""unicode-xid"",
diff --git a/Cargo.toml b/Cargo.toml
index 04fdad7..ecc45e5 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -20,7 +20,7 @@ members = [
 ]
 
 [workspace.package]
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 authors = [""erg-lang team <moderation.erglang@gmail.com>""]
 license = ""MIT OR Apache-2.0""
 edition = ""2021""
@@ -64,10 +64,10 @@ full-repl = [""erg_common/full-repl""]
 full = [""els"", ""full-repl"", ""unicode"", ""pretty""]
 
 [workspace.dependencies]
-erg_common = { version = ""0.6.10"", path = ""./crates/erg_common"" }
-erg_parser = { version = ""0.6.10"", path = ""./crates/erg_parser"" }
-erg_compiler = { version = ""0.6.10"", path = ""./crates/erg_compiler"" }
-els = { version = ""0.1.22"", path = ""./crates/els"" }
+erg_common = { version = ""0.6.11-nightly.0"", path = ""./crates/erg_common"" }
+erg_parser = { version = ""0.6.11-nightly.0"", path = ""./crates/erg_parser"" }
+erg_compiler = { version = ""0.6.11-nightly.0"", path = ""./crates/erg_compiler"" }
+els = { version = ""0.1.23-nightly.0"", path = ""./crates/els"" }
 
 [dependencies]
 erg_common = { workspace = true }
diff --git a/crates/els/Cargo.toml b/crates/els/Cargo.toml
index bc031e6..7c9455f 100644
--- a/crates/els/Cargo.toml
+++ b/crates/els/Cargo.toml
@@ -2,7 +2,7 @@
 name = ""els""
 description = ""An Erg compiler frontend for IDEs, implements LSP.""
 documentation = ""http://docs.rs/els""
-version = ""0.1.22""
+version = ""0.1.23-nightly.0""
 authors.workspace = true
 license.workspace = true
 edition.workspace = true

diff --git a/backend/services/integrations/main.go b/backend/services/integrations/main.go
index 4a5e764..35c3ff2 100644
--- a/backend/services/integrations/main.go
+++ b/backend/services/integrations/main.go
@@ -54,7 +54,7 @@ func main() {
 	sigchan := make(chan os.Signal, 1)
 	signal.Notify(sigchan, syscall.SIGINT, syscall.SIGTERM)
 
-	tick := time.Tick(intervals.INTEGRATIONS_REQUEST_INTERVAL)
+	tick := time.Tick(intervals.INTEGRATIONS_REQUEST_INTERVAL * time.Millisecond)
 
 	log.Printf(""Integration service started\n"")
 	manager.RequestAll()
@@ -66,7 +66,7 @@ func main() {
 			pg.Close()
 			os.Exit(0)
 		case <-tick:
-			// log.Printf(""Requesting all...\n"")
+			log.Printf(""Requesting all...\n"")
 			manager.RequestAll()
 		case event := <-manager.Events:
 			// log.Printf(""New integration event: %v\n"", *event.RawErrorEvent)
",2,"[""607ecc92b5f8c084304e406eec725b7dcfa0a562"", ""7dc3b70fe40fc7de255a28bb3098bcb8c0d35365""]","[""build"", ""fix""]"
switch to callback ref | Downgrade @azure/* deps for Node.sj 10 compability | right side menus,"diff --git a/src/notebook/components/transforms/html.js b/src/notebook/components/transforms/html.js
index 83fc1fb..021cc65 100644
--- a/src/notebook/components/transforms/html.js
+++ b/src/notebook/components/transforms/html.js
@@ -8,16 +8,16 @@ type Props = {
 
 export default class HTMLDisplay extends React.Component {
   props: Props;
+  el: HTMLElement;
 
   componentDidMount(): void {
-    if (this.refs.here) {
-      if (document.createRange && Range && Range.prototype.createContextualFragment) {
-        const range = document.createRange();
-        const fragment = range.createContextualFragment(this.props.data);
-        ReactDOM.findDOMNode(this.refs.here).appendChild(fragment);
-      } else {
-        ReactDOM.findDOMNode(this.refs.here).innerHTML = this.props.data;
-      }
+    // Create a range to ensure that scripts are invoked from within the HTML
+    if (document.createRange && Range && Range.prototype.createContextualFragment) {
+      const range = document.createRange();
+      const fragment = range.createContextualFragment(this.props.data);
+      this.el.appendChild(fragment);
+    } else {
+      this.el.innerHTML = this.props.data;
     }
   }
 
@@ -27,7 +27,7 @@ export default class HTMLDisplay extends React.Component {
 
   render(): ?React.Element<any> {
     return (
-      <div ref=""here"" />
+      <div ref={(el) => { this.el = el; }} />
     );
   }
 }

diff --git a/package.json b/package.json
index 911f8cd..ac29f54 100644
--- a/package.json
+++ b/package.json
@@ -79,7 +79,13 @@
   ""resolutions"": {
     ""@types/ramda"": ""0.27.40"",
     ""rc-tree"": ""4.1.5"",
+    ""@azure/storage-blob"": ""12.7.0"",
+    ""@azure/core-paging"": ""1.1.3"",
+    ""@azure/logger"": ""1.0.0"",
     ""@azure/core-auth"": ""1.2.0"",
+    ""@azure/core-lro"": ""1.0.5"",
+    ""@azure/core-tracing"": ""1.0.0-preview.10"",
+    ""@azure/core-http"": ""1.2.6"",
     ""testcontainers"": ""7.12.1""
   },
   ""license"": ""MIT""
diff --git a/yarn.lock b/yarn.lock
index 5019f68..99235b5 100644
--- a/yarn.lock
+++ b/yarn.lock
@@ -1144,19 +1144,19 @@
     ""@azure/abort-controller"" ""^1.0.0""
     tslib ""^2.0.0""
 
-""@azure/core-http@^2.0.0"":
-  version ""2.2.2""
-  resolved ""https://registry.yarnpkg.com/@azure/core-http/-/core-http-2.2.2.tgz#573798f087d808d39aa71fd7c52b8d7b89f440da""
-  integrity sha512-V1DdoO9V/sFimKpdWoNBgsE+QUjQgpXYnxrTdUp5RyhsTJjvEVn/HKmTQXIHuLUUo6IyIWj+B+Dg4VaXse9dIA==
+""@azure/core-http@1.2.6"", ""@azure/core-http@^1.2.0"", ""@azure/core-http@^2.0.0"":
+  version ""1.2.6""
+  resolved ""https://registry.yarnpkg.com/@azure/core-http/-/core-http-1.2.6.tgz#9cd508418572d2062fd3175274219438772bdb65""
+  integrity sha512-odtH7UMKtekc5YQ86xg9GlVHNXR6pq2JgJ5FBo7/jbOjNGdBqcrIVrZx2bevXVJz/uUTSx6vUf62gzTXTfqYSQ==
   dependencies:
     ""@azure/abort-controller"" ""^1.0.0""
     ""@azure/core-asynciterator-polyfill"" ""^1.0.0""
     ""@azure/core-auth"" ""^1.3.0""
-    ""@azure/core-tracing"" ""1.0.0-preview.13""
+    ""@azure/core-tracing"" ""1.0.0-preview.11""
     ""@azure/logger"" ""^1.0.0""
     ""@types/node-fetch"" ""^2.5.0""
-    ""@types/tunnel"" ""^0.0.3""
-    form-data ""^4.0.0""
+    ""@types/tunnel"" ""^0.0.1""
+    form-data ""^3.0.0""
     node-fetch ""^2.6.0""
     process ""^0.11.10""
     tough-cookie ""^4.0.0""
@@ -1165,38 +1165,39 @@
     uuid ""^8.3.0""
     xml2js ""^0.4.19""
 
-""@azure/core-lro@^2.2.0"":
-  version ""2.2.1""
-  resolved ""https://registry.yarnpkg.com/@azure/core-lro/-/core-lro-2.2.1.tgz#5527b41037c658d3aefc19d68633e51e53d6e6a3""
-  integrity sha512-HE6PBl+mlKa0eBsLwusHqAqjLc5n9ByxeDo3Hz4kF3B1hqHvRkBr4oMgoT6tX7Hc3q97KfDctDUon7EhvoeHPA==
+""@azure/core-lro@1.0.5"", ""@azure/core-lro@^2.0.0"":
+  version ""1.0.5""
+  resolved ""https://registry.yarnpkg.com/@azure/core-lro/-/core-lro-1.0.5.tgz#856a2cb6a9bec739ee9cde33a27cc28f81ac0522""
+  integrity sha512-0EFCFZxARrIoLWMIRt4vuqconRVIO2Iin7nFBfJiYCCbKp5eEmxutNk8uqudPmG0XFl5YqlVh68/al/vbE5OOg==
   dependencies:
     ""@azure/abort-controller"" ""^1.0.0""
-    ""@azure/core-tracing"" ""1.0.0-preview.13""
-    ""@azure/logger"" ""^1.0.0""
-    tslib ""^2.2.0""
+    ""@azure/core-http"" ""^1.2.0""
+    ""@azure/core-tracing"" ""1.0.0-preview.11""
+    events ""^3.0.0""
+    tslib ""^2.0.0""
 
-""@azure/core-paging@^1.1.1"":
-  version ""1.2.0""
-  resolved ""https://registry.yarnpkg.com/@azure/core-paging/-/core-paging-1.2.0.tgz#3754da429e8687bdc3613c750e79a564582e802b""
-  integrity sha512-ZX1bCjm/MjKPCN6kQD/9GJErYSoKA8YWp6YWoo5EIzcTWlSBLXu3gNaBTUl8usGl+UShiKo7b4Gdy1NSTIlpZg==
+""@azure/core-paging@1.1.3"", ""@azure/core-paging@^1.1.1"":
+  version ""1.1.3""
+  resolved ""https://registry.yarnpkg.com/@azure/core-paging/-/core-paging-1.1.3.tgz#3587c9898a0530cacb64bab216d7318468aa5efc""
+  integrity sha512-his7Ah40ThEYORSpIAwuh6B8wkGwO/zG7gqVtmSE4WAJ46e36zUDXTKReUCLBDc6HmjjApQQxxcRFy5FruG79A==
   dependencies:
     ""@azure/core-asynciterator-polyfill"" ""^1.0.0""
-    tslib ""^2.2.0""
 
-""@azure/core-tracing@1.0.0-preview.13"":
-  version ""1.0.0-preview.13""
-  resolved ""https://registry.yarnpkg.com/@azure/core-tracing/-/core-tracing-1.0.0-preview.13.tgz#55883d40ae2042f6f1e12b17dd0c0d34c536d644""
-  integrity sha512-KxDlhXyMlh2Jhj2ykX6vNEU0Vou4nHr025KoSEiz7cS3BNiHNaZcdECk/DmLkEB0as5T7b/TpRcehJ5yV6NeXQ==
+""@azure/core-tracing@1.0.0-preview.10"", ""@azure/core-tracing@1.0.0-preview.11"", ""@azure/core-tracing@1.0.0-preview.13"":
+  version ""1.0.0-preview.10""
+  resolved ""https://registry.yarnpkg.com/@azure/core-tracing/-/core-tracing-1.0.0-preview.10.tgz#e7060272145dddad4486765030d1b037cd52a8ea""
+  integrity sha512-iIwjtMwQnsxB7cYkugMx+s4W1nfy3+pT/ceo+uW1fv4YDgYe84nh+QP0fEC9IH/3UATLSWbIBemdMHzk2APUrw==
   dependencies:
-    ""@opentelemetry/api"" ""^1.0.1""
-    tslib ""^2.2.0""
+    ""@opencensus/web-types"" ""0.0.7""
+    ""@opentelemetry/api"" ""^0.10.2""
+    tslib ""^2.0.0""
 
-""@azure/logger@^1.0.0"":
-  version ""1.0.3""
-  resolved ""https://registry.yarnpkg.com/@azure/logger/-/logger-1.0.3.tgz#6e36704aa51be7d4a1bae24731ea580836293c96""
-  integrity sha512-aK4s3Xxjrx3daZr3VylxejK3vG5ExXck5WOHDJ8in/k9AqlfIyFMMT1uG7u8mNjX+QRILTIn0/Xgschfh/dQ9g==
+""@azure/logger@1.0.0"", ""@azure/logger@^1.0.0"":
+  version ""1.0.0""
+  resolved ""https://registry.yarnpkg.com/@azure/logger/-/logger-1.0.0.tgz#48b371dfb34288c8797e5c104f6c4fb45bf1772c""
+  integrity sha512-g2qLDgvmhyIxR3JVS8N67CyIOeFRKQlX/llxYJQr1OSGQqM3HTpVP8MjmjcEKbL/OIt2N9C9UFaNQuKOw1laOA==
   dependencies:
-    tslib ""^2.2.0""
+    tslib ""^1.9.3""
 
 ""@azure/ms-rest-azure-env@^2.0.0"":
   version ""2.0.0""
@@ -1227,19 +1228,19 @@
     ""@azure/ms-rest-js"" ""^2.0.4""
     adal-node ""^0.2.2""
 
-""@azure/storage-blob@^12.5.0"":
-  version ""12.8.0""
-  resolved ""https://registry.yarnpkg.com/@azure/storage-blob/-/storage-blob-12.8.0.tgz#97b7ecc6c7b17bcbaf0281c79c16af6f512d6130""
-  integrity sha512-c8+Wz19xauW0bGkTCoqZH4dYfbtBniPiGiRQOn1ca6G5jsjr4azwaTk9gwjVY8r3vY2Taf95eivLzipfIfiS4A==
+""@azure/storage-blob@12.7.0"", ""@azure/storage-blob@^12.5.0"":
+  version ""12.7.0""
+  resolved ""https://registry.yarnpkg.com/@azure/storage-blob/-/storage-blob-12.7.0.tgz#f17f278000a46bca516e5864d846cd8fa57d6d7d""
+  integrity sha512-7YEWEx03Us/YBxthzBv788R7jokwpCD5KcIsvtE5xRaijNX9o80KXpabhEwLR9DD9nmt/AlU/c1R+aXydgCduQ==
   dependencies:
     ""@azure/abort-controller"" ""^1.0.0""
     ""@azure/core-http"" ""^2.0.0""
-    ""@azure/core-lro"" ""^2.2.0""
+    ""@azure/core-lro"" ""^2.0.0""
     ""@azure/core-paging"" ""^1.1.1""
     ""@azure/core-tracing"" ""1.0.0-preview.13""
     ""@azure/logger"" ""^1.0.0""
     events ""^3.0.0""
-    tslib ""^2.2.0""
+    tslib ""^2.0.0""
 
 ""@babel/cli@^7.5.5"":
   version ""7.16.0""
@@ -2888,9 +2889,9 @@
   integrity sha512-82cpyJyKRoQoRi+14ibCeGPu0CwypgtBAdBhq1WfvagpCZNKqwXbKwXllYSMG91DhmG4jt9gN8eP6lGOtozuaw==
 
 ""@google-cloud/bigquery@^5.6.0"":
-  version ""5.9.1""
-  resolved ""https://registry.yarnpkg.com/@google-cloud/bigquery/-/bigquery-5.9.1.tgz#96cee86fa0caef4a7e1470efde9295bc09f5981f""
-  integrity sha512-80pMzhAC299CSiXW9TvR8AARLaPRDeQg8pSAvrVcLXcUkx1hWvVx2m94nBZ4KUoZb4LVWIHHYhvFB6XvIcxqjw==
+  version ""5.9.2""
+  resolved ""https://registry.yarnpkg.com/@google-cloud/bigquery/-/bigquery-5.9.2.tgz#d53eac984fdd256d31be490762157e5f6c5b82c3""
+  integrity sha512-lJiMsSekcnhrzzR9e48yx8iOx+ElP3r/wOoionXL6eDPbA41RgP12if5NmMqHZzfWdKlWV2plspEPrbjhJAzCw==
   dependencies:
     ""@google-cloud/common"" ""^3.1.0""
     ""@google-cloud/paginator"" ""^3.0.0""
@@ -4831,11 +4832,28 @@
   resolved ""https://registry.yarnpkg.com/@oozcitak/util/-/util-8.3.8.tgz#10f65fe1891fd8cde4957360835e78fd1936bfdd""
   integrity sha512-T8TbSnGsxo6TDBJx/Sgv/BlVJL3tshxZP7Aq5R1mSnM5OcHY2dQaxLMu2+E8u3gN0MLOzdjurqN4ZRVuzQycOQ==
 
-""@opentelemetry/api@^1.0.0"", ""@opentelemetry/api@^1.0.1"":
+""@opencensus/web-types@0.0.7"":
+  version ""0.0.7""
+  resolved ""https://registry.yarnpkg.com/@opencensus/web-types/-/web-types-0.0.7.tgz#4426de1fe5aa8f624db395d2152b902874f0570a""
+  integrity sha512-xB+w7ZDAu3YBzqH44rCmG9/RlrOmFuDPt/bpf17eJr8eZSrLt7nc7LnWdxM9Mmoj/YKMHpxRg28txu3TcpiL+g==
+
+""@opentelemetry/api@^0.10.2"":
+  version ""0.10.2""
+  resolved ""https://registry.yarnpkg.com/@opentelemetry/api/-/api-0.10.2.tgz#9647b881f3e1654089ff7ea59d587b2d35060654""
+  integrity sha512-GtpMGd6vkzDMYcpu2t9LlhEgMy/SzBwRnz48EejlRArYqZzqSzAsKmegUK7zHgl+EOIaK9mKHhnRaQu3qw20cA==
+  dependencies:
+    ""@opentelemetry/context-base"" ""^0.10.2""
+
+""@opentelemetry/api@^1.0.0"":
   version ""1.0.3""
   resolved ""https://registry.yarnpkg.com/@opentelemetry/api/-/api-1.0.3.tgz#13a12ae9e05c2a782f7b5e84c3cbfda4225eaf80""
   integrity sha512-puWxACExDe9nxbBB3lOymQFrLYml2dVOrd7USiVRnSbgXE+KwBu+HxFvxrzfqsiSda9IWsXJG1ef7C1O2/GmKQ==
 
+""@opentelemetry/context-base@^0.10.2"":
+  version ""0.10.2""
+  resolved ""https://registry.yarnpkg.com/@opentelemetry/context-base/-/context-base-0.10.2.tgz#55bea904b2b91aa8a8675df9eaba5961bddb1def""
+  integrity sha512-hZNKjKOYsckoOEgBziGMnBcX0M7EtstnCmwz5jZUOUYwlZ+/xxX6z3jPu1XVO2Jivk0eLfuP9GP+vFD49CMetw==
+
 ""@opentelemetry/semantic-conventions@^0.24.0"":
   version ""0.24.0""
   resolved ""https://registry.yarnpkg.com/@opentelemetry/semantic-conventions/-/semantic-conventions-0.24.0.tgz#1028ef0e0923b24916158d80d2ddfd67ea8b6740""
@@ -5564,9 +5582,9 @@
   integrity sha1-7ihweulOEdK4J7y+UnC86n8+ce4=
 
 ""@types/jsonwebtoken@^8.5.0"":
-  version ""8.5.5""
-  resolved ""https://registry.yarnpkg.com/@types/jsonwebtoken/-/jsonwebtoken-8.5.5.tgz#da5f2f4baee88f052ef3e4db4c1a0afb46cff22c""
-  integrity sha512-OGqtHQ7N5/Ap/TUwO6IgHDuLiAoTmHhGpNvgkCm/F4N6pKzx/RBSfr2OXZSwC6vkfnsEdb6+7DNZVtiXiwdwFw==
+  version ""8.5.6""
+  resolved ""https://registry.yarnpkg.com/@types/jsonwebtoken/-/jsonwebtoken-8.5.6.tgz#1913e5a61e70a192c5a444623da4901a7b1a9d42""
+  integrity sha512-+P3O/xC7nzVizIi5VbF34YtqSonFsdnbXBnWUCYRiKOi1f9gA4sEFvXkrGr/QVV23IbMYvcoerI7nnhDUiWXRQ==
   dependencies:
     ""@types/node"" ""*""
 
@@ -5753,18 +5771,18 @@
     ""@types/react"" ""*""
 
 ""@types/react@*"", ""@types/react@^17.0.3"":
-  version ""17.0.34""
-  resolved ""https://registry.yarnpkg.com/@types/react/-/react-17.0.34.tgz#797b66d359b692e3f19991b6b07e4b0c706c0102""
-  integrity sha512-46FEGrMjc2+8XhHXILr+3+/sTe3OfzSPU9YGKILLrUYbQ1CLQC9Daqo1KzENGXAWwrFwiY0l4ZbF20gRvgpWTg==
+  version ""17.0.35""
+  resolved ""https://registry.yarnpkg.com/@types/react/-/react-17.0.35.tgz#217164cf830267d56cd1aec09dcf25a541eedd4c""
+  integrity sha512-r3C8/TJuri/SLZiiwwxQoLAoavaczARfT9up9b4Jr65+ErAUX3MIkU0oMOQnrpfgHme8zIqZLX7O5nnjm5Wayw==
   dependencies:
     ""@types/prop-types"" ""*""
     ""@types/scheduler"" ""*""
     csstype ""^3.0.2""
 
 ""@types/react@^16.9.41"":
-  version ""16.14.20""
-  resolved ""https://registry.yarnpkg.com/@types/react/-/react-16.14.20.tgz#ff6e932ad71d92c27590e4a8667c7a53a7d0baad""
-  integrity sha512-SV7TaVc8e9E/5Xuv6TIyJ5VhQpZoVFJqX6IZgj5HZoFCtIDCArE3qXkcHlc6O/Ud4UwcMoX+tlvDA95YrKdLgA==
+  version ""16.14.21""
+  resolved ""https://registry.yarnpkg.com/@types/react/-/react-16.14.21.tgz#35199b21a278355ec7a3c40003bd6a334bd4ae4a""
+  integrity sha512-rY4DzPKK/4aohyWiDRHS2fotN5rhBSK6/rz1X37KzNna9HJyqtaGAbq9fVttrEPWF5ywpfIP1ITL8Xi2QZn6Eg==
   dependencies:
     ""@types/prop-types"" ""*""
     ""@types/scheduler"" ""*""
@@ -5950,10 +5968,10 @@
   resolved ""https://registry.yarnpkg.com/@types/tough-cookie/-/tough-cookie-4.0.1.tgz#8f80dd965ad81f3e1bc26d6f5c727e132721ff40""
   integrity sha512-Y0K95ThC3esLEYD6ZuqNek29lNX2EM1qxV8y2FTLUB0ff5wWrk7az+mLrnNFUnaXcgKye22+sFBRXOgpPILZNg==
 
-""@types/tunnel@^0.0.3"":
-  version ""0.0.3""
-  resolved ""https://registry.yarnpkg.com/@types/tunnel/-/tunnel-0.0.3.tgz#f109e730b072b3136347561fc558c9358bb8c6e9""
-  integrity sha512-sOUTGn6h1SfQ+gbgqC364jLFBw2lnFqkgF3q0WovEHRLMrVD1sd5aufqi/aJObLekJO+Aq5z646U4Oxy6shXMA==
+""@types/tunnel@^0.0.1"":
+  version ""0.0.1""
+  resolved ""https://registry.yarnpkg.com/@types/tunnel/-/tunnel-0.0.1.tgz#0d72774768b73df26f25df9184273a42da72b19c""
+  integrity sha512-AOqu6bQu5MSWwYvehMXLukFHnupHrpZ8nvgae5Ggie9UwzDR1CCwoXgSSWNZJuyOlCdfdsWMA5F2LlmvyoTv8A==
   dependencies:
     ""@types/node"" ""*""
 
@@ -5999,9 +6017,9 @@
     source-map ""^0.6.1""
 
 ""@types/webpack@^4"", ""@types/webpack@^4.0.0"", ""@types/webpack@^4.41.8"":
-  version ""4.41.31""
-  resolved ""https://registry.yarnpkg.com/@types/webpack/-/webpack-4.41.31.tgz#c35f252a3559ddf9c85c0d8b0b42019025e581aa""
-  integrity sha512-/i0J7sepXFIp1ZT7FjUGi1eXMCg8HCCzLJEQkKsOtbJFontsJLolBcDC+3qxn5pPwiCt1G0ZdRmYRzNBtvpuGQ==
+  version ""4.41.32""
+  resolved ""https://registry.yarnpkg.com/@types/webpack/-/webpack-4.41.32.tgz#a7bab03b72904070162b2f169415492209e94212""
+  integrity sha512-cb+0ioil/7oz5//7tZUSwbrSAN/NWHrQylz5cW8G0dWTcF/g+/dSdMlKVZspBYuMAN1+WnwHrkxiRrLcwd0Heg==
   dependencies:
     ""@types/node"" ""*""
     ""@types/tapable"" ""^1""
@@ -7624,9 +7642,9 @@ autoprefixer@^9.6.1, autoprefixer@^9.6.5, autoprefixer@^9.8.6:
     postcss-value-parser ""^4.1.0""
 
 aws-sdk@^2.404.0, aws-sdk@^2.787.0, aws-sdk@^2.819.0, aws-sdk@^2.878.0:
-  version ""2.1028.0""
-  resolved ""https://registry.yarnpkg.com/aws-sdk/-/aws-sdk-2.1028.0.tgz#ce076076174afa9bd311406b8186ea90163e3331""
-  integrity sha512-OmR0NcpU8zsDcUOZhM+eZ6CzlUFtuaEuRyjm6mxDO0KI7lJAp7/NzB6tcellRrgWxL+NO7b5TSxi+m28qu5ocQ==
+  version ""2.1029.0""
+  resolved ""https://registry.yarnpkg.com/aws-sdk/-/aws-sdk-2.1029.0.tgz#702d4d6092adcf0ceaf37ae0da6fee07a71f39dd""
+  integrity sha512-nCmaMPkJr3EATXaeqR3JeNC0GTDH2lJZ3Xq/ZCAW+yrfaPQWv8HqJJHBCNGtmk3FmcCoxc7ed/gEB8XSl0tocA==
   dependencies:
     buffer ""4.9.2""
     events ""1.1.1""
@@ -8596,11 +8614,16 @@ bytes@3.0.0:
   resolved ""https://registry.yarnpkg.com/bytes/-/bytes-3.0.0.tgz#d32815404d689699f85a4ea4fa8755dd13a96048""
   integrity sha1-0ygVQE1olpn4Wk6k+odV3ROpYEg=
 
-bytes@3.1.0, bytes@^3.1.0:
+bytes@3.1.0:
   version ""3.1.0""
   resolved ""https://registry.yarnpkg.com/bytes/-/bytes-3.1.0.tgz#f6cf7933a360e0588fa9fde85651cdc7f805d1f6""
   integrity sha512-zauLjrfCG+xvoyaqLoV8bLVXXNGC4JqlxFCutSDWA6fJrTo2ZuvLYTqZ7aHBLZSMOopbzwv8f+wZcVzfVTI2Dg==
 
+bytes@^3.1.0:
+  version ""3.1.1""
+  resolved ""https://registry.yarnpkg.com/bytes/-/bytes-3.1.1.tgz#3f018291cb4cbad9accb6e6970bca9c8889e879a""
+  integrity sha512-dWe4nWO/ruEOY7HkUJ5gFt1DCFV9zPRoJr8pV0/ASQermOZjtq8jMjOprC0Kd10GLN+l7xaUPvxzJFWtxGu8Fg==
+
 cacache@15.0.3:
   version ""15.0.3""
   resolved ""https://registry.yarnpkg.com/cacache/-/cacache-15.0.3.tgz#2225c2d1dd8e872339950d6a39c051e0e9334392""
@@ -11359,9 +11382,9 @@ ejs@^2.6.1:
   integrity sha512-7vmuyh5+kuUyJKePhQfRQBhXV5Ce+RnaeeQArKu1EAMpL3WbgMt5WG6uQZpEVvYSSsxMXRKOewtDk9RaTKXRlA==
 
 electron-to-chromium@^1.3.564, electron-to-chromium@^1.3.896:
-  version ""1.3.896""
-  resolved ""https://registry.yarnpkg.com/electron-to-chromium/-/electron-to-chromium-1.3.896.tgz#4a94efe4870b1687eafd5c378198a49da06e8a1b""
-  integrity sha512-NcGkBVXePiuUrPLV8IxP43n1EOtdg+dudVjrfVEUd/bOqpQUFZ2diL5PPYzbgEhZFEltdXV3AcyKwGnEQ5lhMA==
+  version ""1.3.899""
+  resolved ""https://registry.yarnpkg.com/electron-to-chromium/-/electron-to-chromium-1.3.899.tgz#4d7d040e73def3d5f5bd6b8a21049025dce6fce0""
+  integrity sha512-w16Dtd2zl7VZ4N4Db+FIa7n36sgPGCKjrKvUUmp5ialsikvcQLjcJR9RWnlYNxIyEHLdHaoIZEqKsPxU9MdyBg==
 
 elegant-spinner@^1.0.1:
   version ""1.0.1""
@@ -12887,15 +12910,6 @@ form-data@^3.0.0:
     combined-stream ""^1.0.8""
     mime-types ""^2.1.12""
 
-form-data@^4.0.0:
-  version ""4.0.0""
-  resolved ""https://registry.yarnpkg.com/form-data/-/form-data-4.0.0.tgz#93919daeaf361ee529584b9b31664dc12c9fa452""
-  integrity sha512-ETEklSGi5t0QMZuiXoA/Q6vcnxcLQP5vdugSpuAyi6SVGi2clPPp+xgEhuMaHC+zGgn31Kd235W35f7Hykkaww==
-  dependencies:
-    asynckit ""^0.4.0""
-    combined-stream ""^1.0.8""
-    mime-types ""^2.1.12""
-
 form-data@~2.3.2:
   version ""2.3.3""
   resolved ""https://registry.yarnpkg.com/form-data/-/form-data-2.3.3.tgz#dcce52c05f644f298c6a7ab936bd724ceffbf3a6""
@@ -21198,11 +21212,13 @@ proto-list@~1.2.1:
   integrity sha1-IS1b/hMYMGpCD2QCuOJv85ZHqEk=
 
 proto3-json-serializer@^0.1.5:
-  version ""0.1.5""
-  resolved ""https://registry.yarnpkg.com/proto3-json-serializer/-/proto3-json-serializer-0.1.5.tgz#c619769a59dc7fd8adf4e6c5060b9bf3039c8304""
-  integrity sha512-G395jcZkgNXNeS+6FGqd09TsXeoCs9wmBWByDiwFy7Yd7HD8pyfyvf6q+rGh7PhT4AshRpG4NowzoKYUtkNjKg==
+  version ""0.1.6""
+  resolved ""https://registry.yarnpkg.com/proto3-json-serializer/-/proto3-json-serializer-0.1.6.tgz#67cf3b8d5f4c8bebfc410698ad3b1ed64da39c7b""
+  integrity sha512-tGbV6m6Kad8NqxMh5hw87euPS0YoZSAOIfvR01zYkQV8Gpx1V/8yU/0gCKCvfCkhAJsjvzzhnnsdQxA1w7PSog==
+  dependencies:
+    protobufjs ""^6.11.2""
 
-protobufjs@6.11.2, protobufjs@^6.10.0:
+protobufjs@6.11.2, protobufjs@^6.10.0, protobufjs@^6.11.2:
   version ""6.11.2""
   resolved ""https://registry.yarnpkg.com/protobufjs/-/protobufjs-6.11.2.tgz#de39fabd4ed32beaa08e9bb1e30d08544c1edf8b""
   integrity sha512-4BQJoPooKJl2G9j3XftkIXjoC9C0Av2NOrWmbLWT1vH32GcSUHjM0Arra6UfTsVyfMAuFzaLucXn1sadxJydAw==

diff --git a/ionic/components/menu/menu-types.scss b/ionic/components/menu/menu-types.scss
index dbbfdda..5e4f990 100644
--- a/ionic/components/menu/menu-types.scss
+++ b/ionic/components/menu/menu-types.scss
@@ -35,3 +35,7 @@ ion-menu[type=overlay] {
     }
   }
 }
+
+ion-menu[type=overlay][side=right] {
+  left: 8px;
+}
diff --git a/ionic/components/menu/menu-types.ts b/ionic/components/menu/menu-types.ts
index 360aeb4..0666a38 100644
--- a/ionic/components/menu/menu-types.ts
+++ b/ionic/components/menu/menu-types.ts
@@ -10,7 +10,7 @@ import {Animation} from 'ionic/animations/animation';
  */
 export class MenuType {
 
-  constructor(menu: Menu) {
+  constructor() {
     this.open = new Animation();
     this.close = new Animation();
   }
@@ -88,16 +88,17 @@ class MenuRevealType extends MenuType {
     let duration = 250;
 
     let openedX = (menu.width() * (menu.side == 'right' ? -1 : 1)) + 'px';
+    let closedX = '0px'
 
     this.open.easing(easing).duration(duration);
     this.close.easing(easing).duration(duration);
 
     let contentOpen = new Animation(menu.getContentElement());
-    contentOpen.fromTo(TRANSLATE_X, CENTER, openedX);
+    contentOpen.fromTo(TRANSLATE_X, closedX, openedX);
     this.open.add(contentOpen);
 
     let contentClose = new Animation(menu.getContentElement());
-    contentClose.fromTo(TRANSLATE_X, openedX, CENTER);
+    contentClose.fromTo(TRANSLATE_X, openedX, closedX);
     this.close.add(contentClose);
   }
 }
@@ -117,13 +118,23 @@ class MenuOverlayType extends MenuType {
     let duration = 250;
     let backdropOpacity = 0.5;
 
-    let closedX = (menu.width() * (menu.side == 'right' ? 1 : -1)) + 'px';
+    let closedX, openedX;
+    if (menu.side == 'right') {
+      // right side
+      closedX = menu.platform.width() + 'px';
+      openedX = (menu.platform.width() - menu.width() - 8) + 'px';
+
+    } else {
+      // left side
+      closedX = -menu.width() + 'px';
+      openedX = '8px';
+    }
 
     this.open.easing(easing).duration(duration);
     this.close.easing(easing).duration(duration);
 
     let menuOpen = new Animation(menu.getMenuElement());
-    menuOpen.fromTo(TRANSLATE_X, closedX, '8px');
+    menuOpen.fromTo(TRANSLATE_X, closedX, openedX);
     this.open.add(menuOpen);
 
     let backdropOpen = new Animation(menu.getBackdropElement());
@@ -131,7 +142,7 @@ class MenuOverlayType extends MenuType {
     this.open.add(backdropOpen);
 
     let menuClose = new Animation(menu.getMenuElement());
-    menuClose.fromTo(TRANSLATE_X, '8px', closedX);
+    menuClose.fromTo(TRANSLATE_X, openedX, closedX);
     this.close.add(menuClose);
 
     let backdropClose = new Animation(menu.getBackdropElement());
@@ -144,4 +155,3 @@ Menu.register('overlay', MenuOverlayType);
 
 const OPACITY = 'opacity';
 const TRANSLATE_X = 'translateX';
-const CENTER = '0px';
diff --git a/ionic/components/menu/menu.ts b/ionic/components/menu/menu.ts
index d911b2e..e980069 100644
--- a/ionic/components/menu/menu.ts
+++ b/ionic/components/menu/menu.ts
@@ -4,6 +4,7 @@ import {Ion} from '../ion';
 import {IonicApp} from '../app/app';
 import {IonicConfig} from '../../config/config';
 import {IonicComponent} from '../../config/annotations';
+import {IonicPlatform} from '../../platform/platform';
 import * as gestures from  './menu-gestures';
 
 
@@ -35,10 +36,16 @@ import * as gestures from  './menu-gestures';
 })
 export class Menu extends Ion {
 
-  constructor(app: IonicApp, elementRef: ElementRef, config: IonicConfig) {
+  constructor(
+    app: IonicApp,
+    elementRef: ElementRef,
+    config: IonicConfig,
+    platform: IonicPlatform
+  ) {
     super(elementRef, config);
-
     this.app = app;
+    this.platform = platform;
+
     this.opening = new EventEmitter('opening');
     this.isOpen = false;
     this._disableTime = 0;
@@ -46,9 +53,9 @@ export class Menu extends Ion {
 
   onInit() {
     super.onInit();
-    this.contentElement = (this.content instanceof Node) ? this.content : this.content.getNativeElement();
+    this._cntEle = (this.content instanceof Node) ? this.content : this.content.getNativeElement();
 
-    if (!this.contentElement) {
+    if (!this._cntEle) {
       return console.error('Menu: must have a [content] element to listen for drag events on. Example:\n\n<ion-menu [content]=""content""></ion-menu>\n\n<ion-content #content></ion-content>');
     }
 
@@ -61,8 +68,8 @@ export class Menu extends Ion {
     this._initGesture();
     this._initType(this.type);
 
-    this.contentElement.classList.add('menu-content');
-    this.contentElement.classList.add('menu-content-' + this.type);
+    this._cntEle.classList.add('menu-content');
+    this._cntEle.classList.add('menu-content-' + this.type);
 
     let self = this;
     this.onContentClick = function(ev) {
@@ -161,11 +168,11 @@ export class Menu extends Ion {
 
     this.isOpen = isOpen;
 
-    this.contentElement.classList[isOpen ? 'add' : 'remove']('menu-content-open');
+    this._cntEle.classList[isOpen ? 'add' : 'remove']('menu-content-open');
 
-    this.contentElement.removeEventListener('click', this.onContentClick);
+    this._cntEle.removeEventListener('click', this.onContentClick);
     if (isOpen) {
-      this.contentElement.addEventListener('click', this.onContentClick);
+      this._cntEle.addEventListener('click', this.onContentClick);
 
     } else {
       this.getNativeElement().classList.remove('show-menu');
@@ -220,7 +227,7 @@ export class Menu extends Ion {
    * @return {Element} The Menu's associated content element.
    */
   getContentElement() {
-    return this.contentElement;
+    return this._cntEle;
   }
 
   /**
@@ -239,7 +246,7 @@ export class Menu extends Ion {
     this.app.unregister(this.id);
     this._gesture && this._gesture.destroy();
     this._type && this._type.onDestroy();
-    this.contentElement = null;
+    this._cntEle = null;
   }
 
 }
diff --git a/ionic/components/menu/test/basic/index.ts b/ionic/components/menu/test/basic/index.ts
index 698cec4..65952ff 100644
--- a/ionic/components/menu/test/basic/index.ts
+++ b/ionic/components/menu/test/basic/index.ts
@@ -36,9 +36,9 @@ class E2EApp {
     ];
   }
 
-  openPage(menu, page) {
+  openPage(page) {
     // close the menu when clicking a link from the menu
-    menu.close();
+    this.app.getComponent('leftMenu').close();
 
     // Reset the content nav to have just this page
     // we wouldn't want the back button to show in this scenario
diff --git a/ionic/components/menu/test/basic/main.html b/ionic/components/menu/test/basic/main.html
index 9bdeb5c..4905ae6 100644
--- a/ionic/components/menu/test/basic/main.html
+++ b/ionic/components/menu/test/basic/main.html
@@ -1,4 +1,4 @@
-<ion-menu #menu [content]=""content"">
+<ion-menu [content]=""content"" id=""leftMenu"">
 
   <ion-toolbar secondary>
     <ion-title>Left Menu</ion-title>
@@ -8,11 +8,35 @@
 
     <ion-list>
 
-      <button ion-item *ng-for=""#p of pages"" (click)=""openPage(menu, p)"">
+      <button ion-item *ng-for=""#p of pages"" (click)=""openPage(p)"">
         {{p.title}}
       </button>
 
-      <button ion-item menu-toggle no-forward-icon class=""e2eCloseMenu"">
+      <button ion-item menu-toggle=""leftMenu"" no-forward-icon class=""e2eCloseMenu"">
+        Close Menu
+      </button>
+
+    </ion-list>
+  </ion-content>
+
+</ion-menu>
+
+
+<ion-menu side=""right"" [content]=""content"" id=""rightMenu"">
+
+  <ion-toolbar secondary>
+    <ion-title>Right Menu</ion-title>
+  </ion-toolbar>
+
+  <ion-content>
+
+    <ion-list>
+
+      <button ion-item *ng-for=""#p of pages"" (click)=""openPage(p)"">
+        {{p.title}}
+      </button>
+
+      <button ion-item menu-toggle=""rightMenu"" no-forward-icon class=""e2eCloseMenu"">
         Close Menu
       </button>
 
diff --git a/ionic/components/menu/test/basic/page1.html b/ionic/components/menu/test/basic/page1.html
index 1881d9e..2bc5c79 100644
--- a/ionic/components/menu/test/basic/page1.html
+++ b/ionic/components/menu/test/basic/page1.html
@@ -1,7 +1,7 @@
 
 <ion-navbar *navbar>
 
-  <a menu-toggle>
+  <a menu-toggle=""leftMenu"">
     <icon menu></icon>
   </a>
 
@@ -21,19 +21,23 @@
     </button>
   </ion-nav-items>
 
-  <a menu-toggle secondary>
+  <a menu-toggle=""rightMenu"" secondary>
     <icon menu></icon>
   </a>
 
 </ion-navbar>
 
 
-<ion-content #content padding>
+<ion-content padding>
 
   <h3>Page 1</h3>
 
   <p>
-    <button class=""e2eContentToggleMenu"" menu-toggle>Toggle Menu</button>
+    <button class=""e2eContentToggleMenu"" menu-toggle=""leftMenu"">Toggle Left Menu</button>
+  </p>
+
+  <p>
+    <button class=""e2eContentToggleMenu"" menu-toggle=""rightMenu"">Toggle Right Menu</button>
   </p>
 
   <f></f><f></f><f></f><f></f><f></f><f></f><f></f><f></f>
diff --git a/ionic/components/menu/test/basic/page2.html b/ionic/components/menu/test/basic/page2.html
index 9801c4f..098f3e1 100644
--- a/ionic/components/menu/test/basic/page2.html
+++ b/ionic/components/menu/test/basic/page2.html
@@ -1,7 +1,7 @@
 
 <ion-navbar *navbar>
 
-  <a menu-toggle>
+  <a menu-toggle=""leftMenu"">
     <icon menu></icon>
   </a>
 
@@ -11,12 +11,12 @@
 
 </ion-navbar>
 
-<ion-content #content padding>
+<ion-content padding>
 
   <h3>Page 2</h3>
 
   <p>
-    <button menu-toggle class=""e2eContentToggleMenu"">Toggle Menu</button>
+    <button menu-toggle=""leftMenu"" class=""e2eContentToggleMenu"">Toggle Left Menu</button>
   </p>
 
   <p>
diff --git a/ionic/components/menu/test/basic/page3.html b/ionic/components/menu/test/basic/page3.html
index a2d65e2..079a3e9 100644
--- a/ionic/components/menu/test/basic/page3.html
+++ b/ionic/components/menu/test/basic/page3.html
@@ -1,7 +1,7 @@
 
 <ion-navbar *navbar>
 
-  <a menu-toggle>
+  <a menu-toggle=""leftMenu"">
     <icon menu></icon>
   </a>
 
@@ -12,12 +12,12 @@
 </ion-navbar>
 
 
-<ion-content #content padding>
+<ion-content padding>
 
   <h3>Page 3</h3>
 
   <p>
-    <button menu-toggle>Toggle Menu</button>
+    <button menu-toggle=""leftMenu"">Toggle Left Menu</button>
   </p>
 
   <f></f><f></f><f></f><f></f><f></f><f></f><f></f><f></f>
diff --git a/ionic/components/toolbar/modes/md.scss b/ionic/components/toolbar/modes/md.scss
index 984e758..339169a 100644
--- a/ionic/components/toolbar/modes/md.scss
+++ b/ionic/components/toolbar/modes/md.scss
@@ -43,6 +43,12 @@ $toolbar-md-button-font-size:        1.4rem !default;
     }
   }
 
+  [menu-toggle][secondary],
+  [menu-toggle][secondary].activated {
+    margin: 0 2px;
+    min-width: 28px;
+  }
+
 }
 
 ion-title {
",3,"[""ee4bf61fb8836e249fb4ef3507dc938e70696b3f"", ""5ef4fd29a4cef69c6c348dd25156934df041f183"", ""1a60540f2bcda48d33f015e31f3728ac2c59a159""]","[""refactor"", ""build"", ""feat""]"
"add .nullif() example | allow disabling dynamic queue | enable recovery test

related to camunda-tngp/zeebe#353","diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        
+         sex    
+        
+         string 
+        
+         male   
+         female 
+         female 
+         NULL   
+         female 
+        
+        >>> vals.nullif(""male"")
+        
+         NullIf(sex, 'male') 
+        
+         string              
+        
+         NULL                
+         female              
+         female              
+         NULL                
+         female              
+        
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 

diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);

diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
index 22b8590..db1b553 100644
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
@@ -116,7 +116,6 @@ public class BrokerRecoveryTest
         ClockUtil.reset();
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldCreateWorkflowInstanceAfterRestart()
     {
@@ -136,7 +135,6 @@ public class BrokerRecoveryTest
         waitUntil(() -> eventRecorder.hasWorkflowInstanceEvent(wfInstanceEvent(""WORKFLOW_INSTANCE_CREATED"")));
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldContinueWorkflowInstanceAtTaskAfterRestart()
     {
@@ -166,7 +164,6 @@ public class BrokerRecoveryTest
         waitUntil(() -> eventRecorder.hasWorkflowInstanceEvent(wfInstanceEvent(""WORKFLOW_INSTANCE_COMPLETED"")));
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldContinueWorkflowInstanceWithLockedTaskAfterRestart()
     {
@@ -200,7 +197,6 @@ public class BrokerRecoveryTest
         waitUntil(() -> eventRecorder.hasWorkflowInstanceEvent(wfInstanceEvent(""WORKFLOW_INSTANCE_COMPLETED"")));
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldContinueWorkflowInstanceAtSecondTaskAfterRestart()
     {
@@ -237,7 +233,6 @@ public class BrokerRecoveryTest
         waitUntil(() -> eventRecorder.hasWorkflowInstanceEvent(wfInstanceEvent(""WORKFLOW_INSTANCE_COMPLETED"")));
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldDeployNewWorkflowVersionAfterRestart()
     {
@@ -412,7 +407,6 @@ public class BrokerRecoveryTest
         waitUntil(() -> eventRecorder.hasTaskEvent(taskEvent(""COMPLETED"")));
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldResolveIncidentAfterRestart()
     {
@@ -443,7 +437,6 @@ public class BrokerRecoveryTest
         waitUntil(() -> eventRecorder.hasTaskEvent(taskEvent(""CREATED"")));
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldResolveFailedIncidentAfterRestart()
     {
",3,"[""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21"", ""9ef5c0d14193a9abb09b39856f58477d1f4b0d77"", ""f2cc48b74bf92fe22cc265cff4224565f910a921""]","[""docs"", ""fix"", ""test""]"
"tests | only run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com> | Introduce timediff fn (stub)","diff --git a/client/src/components/Profile/__test__/EducationCard.test.tsx b/client/src/components/Profile/__test__/EducationCard.test.tsx
index 44b6e00..14539dd 100644
--- a/client/src/components/Profile/__test__/EducationCard.test.tsx
+++ b/client/src/components/Profile/__test__/EducationCard.test.tsx
@@ -53,7 +53,7 @@ describe('EducationCard', () => {
   });
 
   describe('filterPermissions', () => {
-    it('should left only contacts in ""permissionsSettings"" object', () => {
+    it('should left only ""isEducationVisible"" in ""permissionsSettings"" object', () => {
       const permissionsSettings = {
         isProfileVisible: { all: true },
         isAboutVisible: { all: true, mentor: true, student: true },
diff --git a/client/src/components/Profile/__test__/MainCard.test.tsx b/client/src/components/Profile/__test__/MainCard.test.tsx
index 8fb2840..552804b 100644
--- a/client/src/components/Profile/__test__/MainCard.test.tsx
+++ b/client/src/components/Profile/__test__/MainCard.test.tsx
@@ -3,6 +3,8 @@ import { shallow } from 'enzyme';
 import { shallowToJson } from 'enzyme-to-json';
 import MainCard from '../MainCard';
 
+// TODO: Known Issue: https://stackoverflow.com/questions/59942808/how-can-i-use-jest-coverage-in-next-js-styled-jsx
+
 describe('MainCard', () => {
   describe('Should render correctly', () => {
     it('if is editing mode disabled', () => {
@@ -21,49 +23,89 @@ describe('MainCard', () => {
       );
       expect(shallowToJson(output)).toMatchSnapshot();
     });
+    it('if is editing mode enabled', () => {
+      const output = shallow(
+        <MainCard
+          data={{
+            name: 'Petr Pervyi',
+            githubId: 'piter',
+            locationName: 'SPB',
+            locationId: '1',
+          }}
+          isEditingModeEnabled={true}
+          onPermissionsSettingsChange={() => {}}
+          onProfileSettingsChange={() => {}}
+        />,
+      );
+      expect(shallowToJson(output)).toMatchSnapshot();
+    });
   });
 
-  // const wrapper = shallow(
-  //   <MainCard
-  //     data={{
-  //       name: 'Petr Pervyi',
-  //       githubId: 'piter',
-  //       locationName: 'SPB',
-  //       locationId: '1',
-  //     }}
-  //     isEditingModeEnabled={false}
-  //     onPermissionsSettingsChange={() => {}}
-  //     onProfileSettingsChange={() => {}}
-  //   />);
-  // const instance = wrapper.instance();
-  // describe('showVisibilitySettings', () => {
-  //   it('should set ""state.isVisibilitySettingsVisible"" as ""true""', () => {
-  //     expect(instance.state.isVisibilitySettingsVisible).toBe(false);
-  //     instance.showVisibilitySettings();
-  //     expect(instance.state.isVisibilitySettingsVisible).toBe(true);
-  //   });
-  // });
-  // describe('hideVisibilitySettings', () => {
-  //   it('should set ""state.isVisibilitySettingsVisible"" as ""false""', () => {
-  //     instance.state.isVisibilitySettingsVisible = true;
-  //     expect(instance.state.isVisibilitySettingsVisible).toBe(true);
-  //     instance.hideVisibilitySettings();
-  //     expect(instance.state.isVisibilitySettingsVisible).toBe(false);
-  //   });
-  // });
-  // describe('showProfileSettings', () => {
-  //   it('should set ""state.isProfileSettingsVisible"" as ""true""', () => {
-  //     expect(instance.state.isProfileSettingsVisible).toBe(false);
-  //     instance.showProfileSettings();
-  //     expect(instance.state.isProfileSettingsVisible).toBe(true);
-  //   });
-  // });
-  // describe('hideProfileSettings', () => {
-  //   it('should set ""state.isProfileSettingsVisible"" as ""false""', () => {
-  //     instance.state.isProfileSettingsVisible = true;
-  //     expect(instance.state.isProfileSettingsVisible).toBe(true);
-  //     instance.hideProfileSettings();
-  //     expect(instance.state.isProfileSettingsVisible).toBe(false);
-  //   });
-  // });
+  const wrapper = shallow(
+    <MainCard
+      data={{
+        name: 'Petr Pervyi',
+        githubId: 'piter',
+        locationName: 'SPB',
+        locationId: '1',
+      }}
+      isEditingModeEnabled={false}
+      onPermissionsSettingsChange={() => {}}
+      onProfileSettingsChange={() => {}}
+    />);
+  const instance = wrapper.instance();
+  describe('showVisibilitySettings', () => {
+    it('should set ""state.isVisibilitySettingsVisible"" as ""true""', () => {
+      expect(instance.state.isVisibilitySettingsVisible).toBe(false);
+      instance.showVisibilitySettings();
+      expect(instance.state.isVisibilitySettingsVisible).toBe(true);
+    });
+  });
+  describe('hideVisibilitySettings', () => {
+    it('should set ""state.isVisibilitySettingsVisible"" as ""false""', () => {
+      instance.state.isVisibilitySettingsVisible = true;
+      expect(instance.state.isVisibilitySettingsVisible).toBe(true);
+      instance.hideVisibilitySettings();
+      expect(instance.state.isVisibilitySettingsVisible).toBe(false);
+    });
+  });
+  describe('showProfileSettings', () => {
+    it('should set ""state.isProfileSettingsVisible"" as ""true""', () => {
+      expect(instance.state.isProfileSettingsVisible).toBe(false);
+      instance.showProfileSettings();
+      expect(instance.state.isProfileSettingsVisible).toBe(true);
+    });
+  });
+  describe('hideProfileSettings', () => {
+    it('should set ""state.isProfileSettingsVisible"" as ""false""', () => {
+      instance.state.isProfileSettingsVisible = true;
+      expect(instance.state.isProfileSettingsVisible).toBe(true);
+      instance.hideProfileSettings();
+      expect(instance.state.isProfileSettingsVisible).toBe(false);
+    });
+  });
+  describe('filterPermissions', () => {
+    it('should left only ""isProfileVisible"" in ""permissionsSettings"" object', () => {
+      const permissionsSettings = {
+        isProfileVisible: { all: true },
+        isAboutVisible: { all: true, mentor: true, student: true },
+        isEducationVisible: { all: true, mentor: true, student: true },
+        isEnglishVisible: { all: false, student: false },
+        isEmailVisible: { all: true, student: true },
+        isTelegramVisible: { all: false, student: false },
+        isSkypeVisible: { all: true, student: true },
+        isPhoneVisible: { all: false, student: false },
+        isContactsNotesVisible: { all: true, student: true },
+        isLinkedInVisible: { all: false, mentor: false, student: false },
+        isPublicFeedbackVisible: { all: true, mentor: true, student: true },
+        isMentorStatsVisible: { all: true, mentor: true, student: true },
+        isStudentStatsVisible: { all: true, student: true },
+      };
+      const instance = wrapper.instance();
+      const result = instance.filterPermissions(permissionsSettings);
+      expect(result).toEqual({
+        isProfileVisible: { all: true },
+      });
+    });
+  });
 });
diff --git a/client/src/components/Profile/__test__/__snapshots__/MainCard.test.tsx.snap b/client/src/components/Profile/__test__/__snapshots__/MainCard.test.tsx.snap
index 40331eb..fef20dd 100644
--- a/client/src/components/Profile/__test__/__snapshots__/MainCard.test.tsx.snap
+++ b/client/src/components/Profile/__test__/__snapshots__/MainCard.test.tsx.snap
@@ -71,3 +71,158 @@ exports[`MainCard Should render correctly if is editing mode disabled 1`] = `
   </Card>
 </Fragment>
 `;
+
+exports[`MainCard Should render correctly if is editing mode enabled 1`] = `
+<Fragment>
+  <Card
+    actions={
+      Array [
+        <ForwardRef(EditOutlined)
+          onClick={[Function]}
+        />,
+        <ForwardRef(SettingOutlined)
+          onClick={[Function]}
+        />,
+      ]
+    }
+  >
+    <GithubAvatar
+      githubId=""piter""
+      size={96}
+      style={
+        Object {
+          ""display"": ""block"",
+          ""margin"": ""0 auto 10px"",
+        }
+      }
+    />
+    <Title
+      level={1}
+      style={
+        Object {
+          ""fontSize"": 24,
+          ""margin"": 0,
+          ""textAlign"": ""center"",
+        }
+      }
+    >
+      Petr Pervyi
+    </Title>
+    <Paragraph
+      style={
+        Object {
+          ""marginBottom"": 20,
+          ""textAlign"": ""center"",
+        }
+      }
+    >
+      <a
+        href=""https://github.com/piter""
+        style={
+          Object {
+            ""fontSize"": 16,
+            ""marginLeft"": ""-14px"",
+          }
+        }
+        target=""_blank""
+      >
+        <ForwardRef(GithubFilled) />
+         
+        piter
+      </a>
+    </Paragraph>
+    <Paragraph
+      style={
+        Object {
+          ""margin"": 0,
+          ""textAlign"": ""center"",
+        }
+      }
+    >
+      <span
+        style={
+          Object {
+            ""marginLeft"": ""-14px"",
+          }
+        }
+      >
+        <ForwardRef(EnvironmentFilled) />
+         
+        SPB
+      </span>
+    </Paragraph>
+    <PermissionsSettingsDrawer
+      hideSettings={[Function]}
+      isSettingsVisible={false}
+      onPermissionsSettingsChange={[Function]}
+    />
+    <ProfileSettingsDrawer
+      content={
+        <div>
+          <p
+            style={
+              Object {
+                ""fontSize"": 18,
+                ""marginBottom"": 5,
+              }
+            }
+          >
+            <Text
+              strong={true}
+            >
+              Name:
+            </Text>
+          </p>
+          <p
+            style={
+              Object {
+                ""marginBottom"": 20,
+              }
+            }
+          >
+            <Input
+              onChange={[Function]}
+              placeholder=""Firstname Lastname""
+              type=""text""
+              value=""Petr Pervyi""
+            />
+          </p>
+          <p
+            style={
+              Object {
+                ""fontSize"": 18,
+                ""marginBottom"": 5,
+              }
+            }
+          >
+            <Text
+              strong={true}
+            >
+              Location:
+            </Text>
+          </p>
+          <div
+            style={
+              Object {
+                ""marginBottom"": 5,
+              }
+            }
+          >
+            <LocationSelect
+              defaultValue=""1""
+              onChange={[Function]}
+              style={
+                Object {
+                  ""width"": ""100%"",
+                }
+              }
+            />
+          </div>
+        </div>
+      }
+      hideSettings={[Function]}
+      isSettingsVisible={false}
+    />
+  </Card>
+</Fragment>
+`;
diff --git a/client/src/jest.config.js b/client/src/jest.config.js
index df39788..654f9f3 100644
--- a/client/src/jest.config.js
+++ b/client/src/jest.config.js
@@ -7,4 +7,5 @@ module.exports = {
     '^services(.*)$': '<rootDir>/services/$1',
     '^utils(.*)$': '<rootDir>/utils/$1',
   },
+  verbose: true,
 };

diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest

diff --git a/rust/Cargo.lock b/rust/Cargo.lock
index b42616f..4795eb6 100644
--- a/rust/Cargo.lock
+++ b/rust/Cargo.lock
@@ -1287,7 +1287,7 @@ dependencies = [
 [[package]]
 name = ""datafusion""
 version = ""5.1.0""
-source = ""git+https://github.com/cube-js/arrow-datafusion.git?rev=8df4132b83d896a0d3db5c82a4eaaa3eaa285d15#8df4132b83d896a0d3db5c82a4eaaa3eaa285d15""
+source = ""git+https://github.com/cube-js/arrow-datafusion.git?rev=868f3c4de13d13cda84cee33475b9782b94fa60c#868f3c4de13d13cda84cee33475b9782b94fa60c""
 dependencies = [
  ""ahash 0.7.4"",
  ""arrow 6.0.0"",
diff --git a/rust/cubesql/Cargo.toml b/rust/cubesql/Cargo.toml
index 3cb386a..9aef494 100644
--- a/rust/cubesql/Cargo.toml
+++ b/rust/cubesql/Cargo.toml
@@ -9,7 +9,7 @@ documentation = ""https://cube.dev/docs""
 homepage = ""https://cube.dev""
 
 [dependencies]
-datafusion = { git = 'https://github.com/cube-js/arrow-datafusion.git', rev = ""8df4132b83d896a0d3db5c82a4eaaa3eaa285d15"", default-features = false, features = [""unicode_expressions""] }
+datafusion = { git = 'https://github.com/cube-js/arrow-datafusion.git', rev = ""868f3c4de13d13cda84cee33475b9782b94fa60c"", default-features = false, features = [""unicode_expressions""] }
 anyhow = ""1.0""
 thiserror = ""1.0""
 cubeclient = { path = ""../cubeclient"" }
diff --git a/rust/cubesql/src/compile/engine/df/intervals.rs b/rust/cubesql/src/compile/engine/df/intervals.rs
new file mode 100644
index 0000000..9e6cb7e
--- /dev/null
+++ b/rust/cubesql/src/compile/engine/df/intervals.rs
@@ -0,0 +1,51 @@
+#[macro_export]
+macro_rules! make_string_interval_year_month {
+    ($array: ident, $row: ident) => {{
+        let s = if $array.is_null($row) {
+            ""NULL"".to_string()
+        } else {
+            let interval = $array.value($row) as f64;
+            let years = (interval / 12_f64).floor();
+            let month = interval - (years * 12_f64);
+
+            format!(
+                ""{} years {} mons 0 days 0 hours 0 mins 0.00 secs"",
+                years, month,
+            )
+        };
+
+        s
+    }};
+}
+
+#[macro_export]
+macro_rules! make_string_interval_day_time {
+    ($array: ident, $row: ident) => {{
+        let s = if $array.is_null($row) {
+            ""NULL"".to_string()
+        } else {
+            let value: u64 = $array.value($row) as u64;
+
+            let days_parts: i32 = ((value & 0xFFFFFFFF00000000) >> 32) as i32;
+            let milliseconds_part: i32 = (value & 0xFFFFFFFF) as i32;
+
+            let secs = milliseconds_part / 1000;
+            let mins = secs / 60;
+            let hours = mins / 60;
+
+            let secs = secs - (mins * 60);
+            let mins = mins - (hours * 60);
+
+            format!(
+                ""0 years 0 mons {} days {} hours {} mins {}.{:02} secs"",
+                days_parts,
+                hours,
+                mins,
+                secs,
+                (milliseconds_part % 1000),
+            )
+        };
+
+        s
+    }};
+}
diff --git a/rust/cubesql/src/compile/engine/df/mod.rs b/rust/cubesql/src/compile/engine/df/mod.rs
index a19a970..3097523 100644
--- a/rust/cubesql/src/compile/engine/df/mod.rs
+++ b/rust/cubesql/src/compile/engine/df/mod.rs
@@ -1 +1,2 @@
 pub mod coerce;
+pub mod intervals;
diff --git a/rust/cubesql/src/compile/engine/udf.rs b/rust/cubesql/src/compile/engine/udf.rs
index 55b8bc1..0e160b3 100644
--- a/rust/cubesql/src/compile/engine/udf.rs
+++ b/rust/cubesql/src/compile/engine/udf.rs
@@ -1,14 +1,19 @@
 use std::any::type_name;
 use std::sync::Arc;
 
+
 use datafusion::{
     arrow::{
         array::{
             ArrayRef, BooleanArray, BooleanBuilder, GenericStringArray, Int32Builder,
-            PrimitiveArray, StringBuilder, UInt32Builder,
+            IntervalDayTimeBuilder, PrimitiveArray, StringBuilder,
+            UInt32Builder,
         },
         compute::cast,
-        datatypes::{DataType, Int64Type},
+        datatypes::{
+            DataType, Int64Type, IntervalUnit, TimeUnit,
+            TimestampNanosecondType,
+        },
     },
     error::DataFusionError,
     logical_plan::create_udf,
@@ -399,3 +404,63 @@ pub fn create_convert_tz_udf() -> ScalarUDF {
         &fun,
     )
 }
+
+pub fn create_timediff_udf() -> ScalarUDF {
+    let fun = make_scalar_function(move |args: &[ArrayRef]| {
+        assert!(args.len() == 2);
+
+        let left_dt = &args[0];
+        let right_dt = &args[1];
+
+        let left_date = match left_dt.data_type() {
+            DataType::Timestamp(TimeUnit::Nanosecond, _) => {
+                let arr = downcast_primitive_arg!(left_dt, ""left_dt"", TimestampNanosecondType);
+                let ts = arr.value(0);
+
+                // NaiveDateTime::from_timestamp(ts, 0)
+                ts
+            }
+            _ => {
+                return Err(DataFusionError::Execution(format!(
+                    ""left_dt argument must be a Timestamp, actual: {}"",
+                    left_dt.data_type()
+                )));
+            }
+        };
+
+        let right_date = match right_dt.data_type() {
+            DataType::Timestamp(TimeUnit::Nanosecond, _) => {
+                let arr = downcast_primitive_arg!(right_dt, ""right_dt"", TimestampNanosecondType);
+                arr.value(0)
+            }
+            _ => {
+                return Err(DataFusionError::Execution(format!(
+                    ""right_dt argument must be a Timestamp, actual: {}"",
+                    right_dt.data_type()
+                )));
+            }
+        };
+
+        let diff = right_date - left_date;
+        if diff != 0 {
+            return Err(DataFusionError::NotImplemented(format!(
+                ""timediff is not implemented, it's stub""
+            )));
+        }
+
+        let mut interal_arr = IntervalDayTimeBuilder::new(1);
+        interal_arr.append_value(diff)?;
+
+        Ok(Arc::new(interal_arr.finish()) as ArrayRef)
+    });
+
+    let return_type: ReturnTypeFunction =
+        Arc::new(move |_| Ok(Arc::new(DataType::Interval(IntervalUnit::DayTime))));
+
+    ScalarUDF::new(
+        ""timediff"",
+        &Signature::any(2, Volatility::Immutable),
+        &return_type,
+        &fun,
+    )
+}
diff --git a/rust/cubesql/src/compile/mod.rs b/rust/cubesql/src/compile/mod.rs
index a88da57..6121aa0 100644
--- a/rust/cubesql/src/compile/mod.rs
+++ b/rust/cubesql/src/compile/mod.rs
@@ -32,8 +32,8 @@ use self::engine::context::SystemVar;
 use self::engine::provider::CubeContext;
 use self::engine::udf::{
     create_connection_id_udf, create_convert_tz_udf, create_current_user_udf, create_db_udf,
-    create_if_udf, create_instr_udf, create_isnull_udf, create_least_udf, create_user_udf,
-    create_version_udf,
+    create_if_udf, create_instr_udf, create_isnull_udf, create_least_udf, create_timediff_udf,
+    create_user_udf, create_version_udf,
 };
 use self::parser::parse_sql_to_statement;
 
@@ -1450,6 +1450,7 @@ impl QueryPlanner {
         ctx.register_udf(create_if_udf());
         ctx.register_udf(create_least_udf());
         ctx.register_udf(create_convert_tz_udf());
+        ctx.register_udf(create_timediff_udf());
 
         let state = ctx.state.lock().unwrap().clone();
         let cube_ctx = CubeContext::new(&state, &self.context.cubes);
@@ -3226,6 +3227,25 @@ mod tests {
     }
 
     #[tokio::test]
+    async fn test_timediff() -> Result<(), CubeError> {
+        assert_eq!(
+            execute_df_query(
+                ""select \
+                    timediff('1994-11-26T13:25:00.000Z'::timestamp, '1994-11-26T13:25:00.000Z'::timestamp) as r1
+                "".to_string()
+            )
+            .await?,
+            ""+------------------------------------------------+\n\
+            | r1                                             |\n\
+            +------------------------------------------------+\n\
+            | 0 years 0 mons 0 days 0 hours 0 mins 0.00 secs |\n\
+            +------------------------------------------------+""
+        );
+
+        Ok(())
+    }
+
+    #[tokio::test]
     async fn test_metabase() -> Result<(), CubeError> {
         assert_eq!(
             execute_df_query(
diff --git a/rust/cubesql/src/mysql/dataframe.rs b/rust/cubesql/src/mysql/dataframe.rs
index fa246aa..2443458 100644
--- a/rust/cubesql/src/mysql/dataframe.rs
+++ b/rust/cubesql/src/mysql/dataframe.rs
@@ -3,9 +3,10 @@ use std::fmt::{self, Debug, Formatter};
 use chrono::{SecondsFormat, TimeZone, Utc};
 use comfy_table::{Cell, Table};
 use datafusion::arrow::array::{
-    Array, Float64Array, Int32Array, Int64Array, StringArray, TimestampMicrosecondArray,
-    UInt32Array,
+    Array, Float64Array, Int32Array, Int64Array, IntervalDayTimeArray, IntervalYearMonthArray,
+    StringArray, TimestampMicrosecondArray, UInt32Array,
 };
+use datafusion::arrow::datatypes::IntervalUnit;
 use datafusion::arrow::{
     array::{BooleanArray, TimestampNanosecondArray, UInt64Array},
     datatypes::{DataType, TimeUnit},
@@ -15,6 +16,7 @@ use log::{error, warn};
 use msql_srv::{ColumnFlags, ColumnType};
 
 use crate::{compile::builder::CompiledQueryFieldMeta, CubeError};
+use crate::{make_string_interval_day_time, make_string_interval_year_month};
 
 #[derive(Clone, Debug)]
 pub struct Column {
@@ -309,6 +311,7 @@ pub fn arrow_to_column_type(arrow_type: DataType) -> Result<ColumnType, CubeErro
         DataType::Binary => Ok(ColumnType::MYSQL_TYPE_BLOB),
         DataType::Utf8 | DataType::LargeUtf8 => Ok(ColumnType::MYSQL_TYPE_STRING),
         DataType::Timestamp(_, _) => Ok(ColumnType::MYSQL_TYPE_STRING),
+        DataType::Interval(_) => Ok(ColumnType::MYSQL_TYPE_STRING),
         DataType::Float16 | DataType::Float64 => Ok(ColumnType::MYSQL_TYPE_DOUBLE),
         DataType::Boolean => Ok(ColumnType::MYSQL_TYPE_TINY),
         DataType::Int8
@@ -402,6 +405,24 @@ pub fn batch_to_dataframe(batches: &Vec<RecordBatch>) -> Result<DataFrame, CubeE
                         });
                     }
                 }
+                DataType::Interval(IntervalUnit::DayTime) => {
+                    let a = array
+                        .as_any()
+                        .downcast_ref::<IntervalDayTimeArray>()
+                        .unwrap();
+                    for i in 0..num_rows {
+                        rows[i].push(TableValue::String(make_string_interval_day_time!(a, i)));
+                    }
+                }
+                DataType::Interval(IntervalUnit::YearMonth) => {
+                    let a = array
+                        .as_any()
+                        .downcast_ref::<IntervalYearMonthArray>()
+                        .unwrap();
+                    for i in 0..num_rows {
+                        rows[i].push(TableValue::String(make_string_interval_year_month!(a, i)));
+                    }
+                }
                 DataType::Boolean => {
                     let a = array.as_any().downcast_ref::<BooleanArray>().unwrap();
                     for i in 0..num_rows {
",3,"[""f87659953e9af59bc7cb314a22dd076d988ef607"", ""dbb537a26e388a8d7d17faf131abc30c2f7a84e6"", ""29dfb9716298c5a579c0ffba6742e13a29325670""]","[""test"", ""cicd"", ""feat""]"
"added changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284 | conditionals and iterators in rsx | unset DOCKER_HOST set to swarm by jenkins

- fixes issue where old images are pushed to registry","diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')

diff --git a/packages/interpreter/src/interpreter.js b/packages/interpreter/src/interpreter.js
index 2f5c06f..58613ea 100644
--- a/packages/interpreter/src/interpreter.js
+++ b/packages/interpreter/src/interpreter.js
@@ -172,7 +172,7 @@ export class Interpreter {
         node.style = {};
       }
       node.style[name] = value;
-    } else if (ns != null || ns != undefined) {
+    } else if (ns != null && ns != undefined) {
       node.setAttributeNS(ns, name, value);
     } else {
       switch (name) {
@@ -266,7 +266,7 @@ export class Interpreter {
         this.AssignId(edit.path, edit.id);
         break;
       case ""CreateElement"":
-        if (edit.namespace !== null || edit.namespace !== undefined) {
+        if (edit.namespace !== null && edit.namespace !== undefined) {
           this.CreateElementNs(edit.name, edit.id, edit.namespace);
         } else {
           this.CreateElement(edit.name, edit.id);
diff --git a/packages/rsx/src/lib.rs b/packages/rsx/src/lib.rs
index 09c6bd6..d974a6c 100644
--- a/packages/rsx/src/lib.rs
+++ b/packages/rsx/src/lib.rs
@@ -245,7 +245,11 @@ impl<'a> DynamicContext<'a> {
                 quote! { ::dioxus::core::TemplateNode::Text(#text) }
             }
 
-            BodyNode::Text(_) | BodyNode::RawExpr(_) | BodyNode::Component(_) => {
+            BodyNode::RawExpr(_)
+            | BodyNode::Text(_)
+            | BodyNode::ForLoop(_)
+            | BodyNode::IfChain(_)
+            | BodyNode::Component(_) => {
                 let ct = self.dynamic_nodes.len();
                 self.dynamic_nodes.push(root);
                 self.node_paths.push(self.current_path.clone());
diff --git a/packages/rsx/src/node.rs b/packages/rsx/src/node.rs
index 4013c9c..7b4bd23 100644
--- a/packages/rsx/src/node.rs
+++ b/packages/rsx/src/node.rs
@@ -5,7 +5,7 @@ use quote::{quote, ToTokens, TokenStreamExt};
 use syn::{
     parse::{Parse, ParseStream},
     spanned::Spanned,
-    token, Expr, LitStr, Result,
+    token, Block, Expr, ExprIf, LitStr, Pat, Result,
 };
 
 /*
@@ -20,6 +20,8 @@ Parse
 pub enum BodyNode {
     Element(Element),
     Component(Component),
+    ForLoop(ForLoop),
+    IfChain(ExprIf),
     Text(IfmtInput),
     RawExpr(Expr),
 }
@@ -35,6 +37,8 @@ impl BodyNode {
             BodyNode::Component(component) => component.name.span(),
             BodyNode::Text(text) => text.source.span(),
             BodyNode::RawExpr(exp) => exp.span(),
+            BodyNode::ForLoop(fl) => fl.for_token.span(),
+            BodyNode::IfChain(f) => f.if_token.span(),
         }
     }
 }
@@ -89,6 +93,28 @@ impl Parse for BodyNode {
             }
         }
 
+        // Transform for loops into into_iter calls
+        if stream.peek(Token![for]) {
+            let _f = stream.parse::<Token![for]>()?;
+            let pat = stream.parse::<Pat>()?;
+            let _i = stream.parse::<Token![in]>()?;
+            let expr = stream.parse::<Box<Expr>>()?;
+            let body = stream.parse::<Block>()?;
+
+            return Ok(BodyNode::ForLoop(ForLoop {
+                for_token: _f,
+                pat,
+                in_token: _i,
+                expr,
+                body,
+            }));
+        }
+
+        // Transform unterminated if statements into terminated optional if statements
+        if stream.peek(Token![if]) {
+            return Ok(BodyNode::IfChain(stream.parse()?));
+        }
+
         Ok(BodyNode::RawExpr(stream.parse::<Expr>()?))
     }
 }
@@ -104,6 +130,104 @@ impl ToTokens for BodyNode {
             BodyNode::RawExpr(exp) => tokens.append_all(quote! {
                  __cx.fragment_from_iter(#exp)
             }),
+            BodyNode::ForLoop(exp) => {
+                let ForLoop {
+                    pat, expr, body, ..
+                } = exp;
+
+                tokens.append_all(quote! {
+                     __cx.fragment_from_iter(
+                        (#expr).into_iter().map(|#pat| {
+                            #body
+                        })
+                     )
+                })
+            }
+            BodyNode::IfChain(chain) => {
+                if is_if_chain_terminated(chain) {
+                    tokens.append_all(quote! {
+                         __cx.fragment_from_iter(#chain)
+                    });
+                } else {
+                    let ExprIf {
+                        cond,
+                        then_branch,
+                        else_branch,
+                        ..
+                    } = chain;
+
+                    let mut body = TokenStream2::new();
+
+                    body.append_all(quote! {
+                        if #cond {
+                            Some(#then_branch)
+                        }
+                    });
+
+                    let mut elif = else_branch;
+
+                    while let Some((_, ref branch)) = elif {
+                        match branch.as_ref() {
+                            Expr::If(ref eelif) => {
+                                let ExprIf {
+                                    cond,
+                                    then_branch,
+                                    else_branch,
+                                    ..
+                                } = eelif;
+
+                                body.append_all(quote! {
+                                    else if #cond {
+                                        Some(#then_branch)
+                                    }
+                                });
+
+                                elif = else_branch;
+                            }
+                            _ => {
+                                body.append_all(quote! {
+                                    else {
+                                        #branch
+                                    }
+                                });
+                                break;
+                            }
+                        }
+                    }
+
+                    body.append_all(quote! {
+                        else { None }
+                    });
+
+                    tokens.append_all(quote! {
+                        __cx.fragment_from_iter(#body)
+                    });
+                }
+            }
+        }
+    }
+}
+
+#[derive(PartialEq, Eq, Clone, Debug, Hash)]
+pub struct ForLoop {
+    pub for_token: Token![for],
+    pub pat: Pat,
+    pub in_token: Token![in],
+    pub expr: Box<Expr>,
+    pub body: Block,
+}
+
+fn is_if_chain_terminated(chain: &ExprIf) -> bool {
+    let mut current = chain;
+    loop {
+        if let Some((_, else_block)) = &current.else_branch {
+            if let Expr::If(else_if) = else_block.as_ref() {
+                current = else_if;
+            } else {
+                return true;
+            }
+        } else {
+            return false;
         }
     }
 }

diff --git a/.ci/docker.dsl b/.ci/docker.dsl
index 4768cb8..9f6a4c9 100644
--- a/.ci/docker.dsl
+++ b/.ci/docker.dsl
@@ -8,6 +8,9 @@ def dockerHubUpload =
 '''\
 #!/bin/bash -xeu
 
+# clear docker host env set by jenkins job
+unset DOCKER_HOST
+
 VERSION=${RELEASE_VERSION}
 
 if [ ""${RELEASE_VERSION}"" = ""SNAPSHOT"" ]; then
@@ -26,9 +29,6 @@ docker login --username ${DOCKER_HUB_USERNAME} --password ${DOCKER_HUB_PASSWORD}
 docker push camunda/zeebe:${RELEASE_VERSION}
 
 if [ ""${IS_LATEST}"" = ""true"" ]; then
-    # to make sure we can tag latest, there were problems before
-    docker rmi camunda/zeebe:latest
-
     docker tag -f camunda/zeebe:${RELEASE_VERSION} camunda/zeebe:latest
     docker push camunda/zeebe:latest
 fi
",3,"[""aca23027da1295c78fdf42ba9687d8ccc88784d7"", ""6b473cbdc5997af47c56a2a74f5b64da6d4c2ad7"", ""8b18a58969ed2adf2df2a8bfe91aedacad3868f5""]","[""docs"", ""feat"", ""cicd""]"
"unset DOCKER_HOST set to swarm by jenkins

- fixes issue where old images are pushed to registry | fix error spacing","diff --git a/.ci/docker.dsl b/.ci/docker.dsl
index 4768cb8..9f6a4c9 100644
--- a/.ci/docker.dsl
+++ b/.ci/docker.dsl
@@ -8,6 +8,9 @@ def dockerHubUpload =
 '''\
 #!/bin/bash -xeu
 
+# clear docker host env set by jenkins job
+unset DOCKER_HOST
+
 VERSION=${RELEASE_VERSION}
 
 if [ ""${RELEASE_VERSION}"" = ""SNAPSHOT"" ]; then
@@ -26,9 +29,6 @@ docker login --username ${DOCKER_HUB_USERNAME} --password ${DOCKER_HUB_PASSWORD}
 docker push camunda/zeebe:${RELEASE_VERSION}
 
 if [ ""${IS_LATEST}"" = ""true"" ]; then
-    # to make sure we can tag latest, there were problems before
-    docker rmi camunda/zeebe:latest
-
     docker tag -f camunda/zeebe:${RELEASE_VERSION} camunda/zeebe:latest
     docker push camunda/zeebe:latest
 fi

diff --git a/cmd/infracost/main.go b/cmd/infracost/main.go
index 425aef1..fcc9eb5 100644
--- a/cmd/infracost/main.go
+++ b/cmd/infracost/main.go
@@ -149,7 +149,7 @@ Example:
 			}
 
 			if appErr.Error() != """" {
-				fmt.Fprintf(os.Stderr, ""\n%s\n"", color.HiRedString(appErr.Error()))
+				fmt.Fprintf(os.Stderr, ""%s\n"", color.HiRedString(appErr.Error()))
 			}
 		}
 
",2,"[""8b18a58969ed2adf2df2a8bfe91aedacad3868f5"", ""c623b3622058b913290120b06ccdc779a4e4413d""]","[""cicd"", ""fix""]"
"add getter for protocol id | initialize threejs objects in defaultRef, to fix undefined type errors | extract _value expr from predicate","diff --git a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
index ad0015f..68624d8 100644
--- a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
+++ b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
@@ -50,4 +50,9 @@ public class TransportHeaderDescriptor
         return this;
     }
 
+    public int protocolId()
+    {
+        return buffer.getShort(PROTOCOL_ID_OFFSET);
+    }
+
 }

diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number

diff --git a/predicate/src/delete_predicate.rs b/predicate/src/delete_predicate.rs
index 02e679a..6368df3 100644
--- a/predicate/src/delete_predicate.rs
+++ b/predicate/src/delete_predicate.rs
@@ -120,6 +120,7 @@ impl From<DeletePredicate> for crate::predicate::Predicate {
             partition_key: None,
             range: Some(pred.range),
             exprs: pred.exprs.into_iter().map(|expr| expr.into()).collect(),
+            value_expr: vec![],
         }
     }
 }
diff --git a/predicate/src/predicate.rs b/predicate/src/predicate.rs
index d7f3b62..2aa8fdf 100644
--- a/predicate/src/predicate.rs
+++ b/predicate/src/predicate.rs
@@ -11,7 +11,7 @@ use std::{
 use data_types::timestamp::TimestampRange;
 use datafusion::{
     error::DataFusionError,
-    logical_plan::{col, lit_timestamp_nano, Expr, Operator},
+    logical_plan::{col, lit_timestamp_nano, Column, Expr, Operator},
     optimizer::utils,
 };
 use datafusion_util::{make_range_expr, AndExprBuilder};
@@ -26,6 +26,7 @@ pub const EMPTY_PREDICATE: Predicate = Predicate {
     exprs: vec![],
     range: None,
     partition_key: None,
+    value_expr: vec![],
 };
 
 #[derive(Debug, Clone, Copy)]
@@ -72,6 +73,11 @@ pub struct Predicate {
     /// these expressions should be returned. Other rows are excluded
     /// from the results.
     pub exprs: Vec<Expr>,
+
+    /// Optional arbitrary predicates on the special `_value` column. These
+    /// expressions are applied to `field_columns` projections in the form of
+    /// `CASE` statement conditions.
+    pub value_expr: Vec<BinaryExpr>,
 }
 
 impl Predicate {
@@ -469,6 +475,14 @@ impl PredicateBuilder {
     }
 }
 
+// A representation of the `BinaryExpr` variant of a Datafusion expression.
+#[derive(Clone, Debug, PartialEq, PartialOrd)]
+pub struct BinaryExpr {
+    pub left: Column,
+    pub op: Operator,
+    pub right: Expr,
+}
+
 #[cfg(test)]
 mod tests {
     use super::*;
diff --git a/query/src/frontend/influxrpc.rs b/query/src/frontend/influxrpc.rs
index 5ac7a2e..70c43f2 100644
--- a/query/src/frontend/influxrpc.rs
+++ b/query/src/frontend/influxrpc.rs
@@ -9,8 +9,7 @@ use data_types::chunk_metadata::ChunkId;
 use datafusion::{
     error::{DataFusionError, Result as DatafusionResult},
     logical_plan::{
-        binary_expr, lit, Column, DFSchemaRef, Expr, ExprRewriter, LogicalPlan, LogicalPlanBuilder,
-        Operator,
+        lit, Column, DFSchemaRef, Expr, ExprRewriter, LogicalPlan, LogicalPlanBuilder, Operator,
     },
     optimizer::utils::expr_to_columns,
     prelude::col,
@@ -20,7 +19,7 @@ use datafusion_util::AsExpr;
 
 use hashbrown::{HashMap, HashSet};
 use observability_deps::tracing::{debug, trace};
-use predicate::predicate::{Predicate, PredicateMatch};
+use predicate::predicate::{BinaryExpr, Predicate, PredicateMatch};
 use schema::selection::Selection;
 use schema::{InfluxColumnType, Schema, TIME_COLUMN_NAME};
 use snafu::{ensure, OptionExt, ResultExt, Snafu};
@@ -243,7 +242,6 @@ impl InfluxRpcPlanner {
         // and which chunks needs full plan and group them into their table
         for chunk in database.chunks(normalizer.unnormalized()) {
             let table_name = chunk.table_name();
-            let schema = chunk.schema();
 
             // Table is already in the returned table list, no longer needs to discover it from other chunks
             if builder.contains_meta_data_table(table_name.to_string()) {
@@ -260,7 +258,7 @@ impl InfluxRpcPlanner {
             } else {
                 // See if we can have enough info from the chunk's meta data to answer
                 // that this table participates in the request
-                let predicate = normalizer.normalized(table_name, schema);
+                let predicate = normalizer.normalized(table_name);
                 //
                 // Try and apply the predicate using only metadata
                 let pred_result = chunk
@@ -346,7 +344,7 @@ impl InfluxRpcPlanner {
             let mut do_full_plan = chunk.has_delete_predicates();
 
             let table_name = chunk.table_name();
-            let predicate = normalizer.normalized(table_name, chunk.schema());
+            let predicate = normalizer.normalized(table_name);
 
             // Try and apply the predicate using only metadata
             let pred_result = chunk
@@ -474,7 +472,7 @@ impl InfluxRpcPlanner {
             let mut do_full_plan = chunk.has_delete_predicates();
 
             let table_name = chunk.table_name();
-            let predicate = normalizer.normalized(table_name, chunk.schema());
+            let predicate = normalizer.normalized(table_name);
 
             // Try and apply the predicate using only metadata
             let pred_result = chunk
@@ -821,7 +819,7 @@ impl InfluxRpcPlanner {
     {
         let mut table_chunks = BTreeMap::new();
         for chunk in chunks {
-            let predicate = normalizer.normalized(chunk.table_name(), chunk.schema());
+            let predicate = normalizer.normalized(chunk.table_name());
             // Try and apply the predicate using only metadata
             let pred_result = chunk
                 .apply_predicate_to_metadata(&predicate)
@@ -1040,9 +1038,8 @@ impl InfluxRpcPlanner {
         C: QueryChunk + 'static,
     {
         let table_name = table_name.as_ref();
-        let scan_and_filter =
-            self.scan_and_filter(table_name, Arc::clone(&schema), normalizer, chunks)?;
-        let predicate = normalizer.normalized(table_name, schema);
+        let scan_and_filter = self.scan_and_filter(table_name, schema, normalizer, chunks)?;
+        let predicate = normalizer.normalized(table_name);
 
         let TableScanAndFilter {
             plan_builder,
@@ -1152,9 +1149,8 @@ impl InfluxRpcPlanner {
         C: QueryChunk + 'static,
     {
         let table_name = table_name.into();
-        let scan_and_filter =
-            self.scan_and_filter(&table_name, Arc::clone(&schema), normalizer, chunks)?;
-        let predicate = normalizer.normalized(&table_name, schema);
+        let scan_and_filter = self.scan_and_filter(&table_name, schema, normalizer, chunks)?;
+        let predicate = normalizer.normalized(&table_name);
 
         let TableScanAndFilter {
             plan_builder,
@@ -1263,9 +1259,8 @@ impl InfluxRpcPlanner {
         C: QueryChunk + 'static,
     {
         let table_name = table_name.into();
-        let scan_and_filter =
-            self.scan_and_filter(&table_name, Arc::clone(&schema), normalizer, chunks)?;
-        let predicate = normalizer.normalized(&table_name, schema);
+        let scan_and_filter = self.scan_and_filter(&table_name, schema, normalizer, chunks)?;
+        let predicate = normalizer.normalized(&table_name);
 
         let TableScanAndFilter {
             plan_builder,
@@ -1342,7 +1337,7 @@ impl InfluxRpcPlanner {
     where
         C: QueryChunk + 'static,
     {
-        let predicate = normalizer.normalized(table_name, Arc::clone(&schema));
+        let predicate = normalizer.normalized(table_name);
 
         // Scan all columns to begin with (DataFusion projection
         // push-down optimization will prune out unneeded columns later)
@@ -1701,13 +1696,13 @@ impl PredicateNormalizer {
 
     /// Return a reference to a predicate specialized for `table_name` based on
     /// its `schema`.
-    fn normalized(&mut self, table_name: &str, schema: Arc<Schema>) -> Arc<Predicate> {
+    fn normalized(&mut self, table_name: &str) -> Arc<Predicate> {
         if let Some(normalized_predicate) = self.normalized.get(table_name) {
             return normalized_predicate.inner();
         }
 
         let normalized_predicate =
-            TableNormalizedPredicate::new(table_name, schema, self.unnormalized.clone());
+            TableNormalizedPredicate::new(table_name, self.unnormalized.clone());
 
         self.normalized
             .entry(table_name.to_string())
@@ -1752,13 +1747,18 @@ struct TableNormalizedPredicate {
 }
 
 impl TableNormalizedPredicate {
-    fn new(table_name: &str, schema: Arc<Schema>, mut inner: Predicate) -> Self {
+    fn new(table_name: &str, mut inner: Predicate) -> Self {
         let mut field_projections = BTreeSet::new();
+        let mut field_value_exprs = vec![];
+
         inner.exprs = inner
             .exprs
             .into_iter()
             .map(|e| rewrite_measurement_references(table_name, e))
-            .map(|e| rewrite_field_value_references(Arc::clone(&schema), e))
+            // Rewrite any references to `_value = some_value` to literal true values.
+            // Keeps track of these expressions, which can then be used to
+            // augment field projections with conditions using `CASE` statements.
+            .map(|e| rewrite_field_value_references(&mut field_value_exprs, e))
             .map(|e| {
                 // Rewrite any references to `_field = a_field_name` with a literal true
                 // and keep track of referenced field names to add to the field
@@ -1766,6 +1766,8 @@ impl TableNormalizedPredicate {
                 rewrite_field_column_references(&mut field_projections, e)
             })
             .collect::<Vec<_>>();
+        // Store any field value (`_value`) expressions on the `Predicate`.
+        inner.value_expr = field_value_exprs;
 
         if !field_projections.is_empty() {
             match &mut inner.field_columns {
@@ -1811,23 +1813,19 @@ impl ExprRewriter for MeasurementRewriter<'_> {
     }
 }
 
-/// Rewrites a predicate on `_value` to a disjunctive set of expressions on each
-/// distinct field column in the table.
-///
-/// For example, the predicate `_value = 1.77` on a table with three field
-/// columns would be rewritten to:
-///
-/// `(field1 = 1.77 OR field2 = 1.77 OR field3 = 1.77)`.
-fn rewrite_field_value_references(schema: Arc<Schema>, expr: Expr) -> Expr {
-    let mut rewriter = FieldValueRewriter { schema };
+/// Rewrites an expression on `_value` as a boolean true literal, pushing any
+/// encountered expressions onto `value_exprs` so they can be moved onto column
+/// projections.
+fn rewrite_field_value_references(value_exprs: &mut Vec<BinaryExpr>, expr: Expr) -> Expr {
+    let mut rewriter = FieldValueRewriter { value_exprs };
     expr.rewrite(&mut rewriter).expect(""rewrite is infallible"")
 }
 
-struct FieldValueRewriter {
-    schema: Arc<Schema>,
+struct FieldValueRewriter<'a> {
+    value_exprs: &'a mut Vec<BinaryExpr>,
 }
 
-impl ExprRewriter for FieldValueRewriter {
+impl<'a> ExprRewriter for FieldValueRewriter<'a> {
     fn mutate(&mut self, expr: Expr) -> DatafusionResult<Expr> {
         Ok(match expr {
             Expr::BinaryExpr {
@@ -1836,21 +1834,16 @@ impl ExprRewriter for FieldValueRewriter {
                 ref right,
             } => {
                 if let Expr::Column(inner) = &**left {
-                    if inner.name != VALUE_COLUMN_NAME {
-                        return Ok(expr); // column name not `_value`.
+                    if inner.name == VALUE_COLUMN_NAME {
+                        self.value_exprs.push(BinaryExpr {
+                            left: inner.to_owned(),
+                            op,
+                            right: right.as_expr(),
+                        });
+                        return Ok(Expr::Literal(ScalarValue::Boolean(Some(true))));
                     }
-
-                    // build a disjunctive expression using binary expressions
-                    // for each field column and the original expression's
-                    // operator and rhs.
-                    self.schema
-                        .fields_iter()
-                        .map(|field| binary_expr(col(field.name()), op, *right.clone()))
-                        .reduce(|a, b| a.or(b))
-                        .expect(""at least one field column"")
-                } else {
-                    expr
                 }
+                expr
             }
             _ => expr,
         })
@@ -1918,7 +1911,7 @@ pub fn schema_has_all_expr_columns(schema: &Schema, expr: &Expr) -> bool {
 
 #[cfg(test)]
 mod tests {
-    use datafusion::logical_plan::Operator;
+    use datafusion::logical_plan::{binary_expr, Operator};
     use schema::builder::SchemaBuilder;
 
     use super::*;
@@ -1958,56 +1951,57 @@ mod tests {
 
     #[test]
     fn test_field_value_rewriter() {
-        let schema = SchemaBuilder::new()
-            .tag(""t1"")
-            .tag(""t2"")
-            .field(""f1"", DataType::Float64)
-            .field(""f2"", DataType::Float64)
-            .timestamp()
-            .build()
-            .unwrap();
-
         let mut rewriter = FieldValueRewriter {
-            schema: Arc::new(schema),
+            value_exprs: &mut vec![],
         };
 
         let cases = vec![
             (
                 binary_expr(col(""f1""), Operator::Eq, lit(1.82)),
                 binary_expr(col(""f1""), Operator::Eq, lit(1.82)),
+                vec![],
             ),
-            (col(""t2""), col(""t2"")),
+            (col(""t2""), col(""t2""), vec![]),
             (
                 binary_expr(col(VALUE_COLUMN_NAME), Operator::Eq, lit(1.82)),
-                //
-                // _value = 1.82 -> f1 = (1.82 OR f2 = 1.82)
-                //
-                binary_expr(
-                    binary_expr(col(""f1""), Operator::Eq, lit(1.82)),
-                    Operator::Or,
-                    binary_expr(col(""f2""), Operator::Eq, lit(1.82)),
-                ),
+                // _value = 1.82 -> true
+                lit(true),
+                vec![BinaryExpr {
+                    left: Column {
+                        relation: None,
+                        name: VALUE_COLUMN_NAME.into(),
+                    },
+                    op: Operator::Eq,
+                    right: lit(1.82),
+                }],
             ),
         ];
 
-        for (input, exp) in cases {
+        for (input, exp, mut value_exprs) in cases {
             let rewritten = input.rewrite(&mut rewriter).unwrap();
             assert_eq!(rewritten, exp);
+            assert_eq!(rewriter.value_exprs, &mut value_exprs);
         }
 
         // Test case with single field.
-        let schema = SchemaBuilder::new()
-            .field(""f1"", DataType::Float64)
-            .timestamp()
-            .build()
-            .unwrap();
         let mut rewriter = FieldValueRewriter {
-            schema: Arc::new(schema),
+            value_exprs: &mut vec![],
         };
 
         let input = binary_expr(col(VALUE_COLUMN_NAME), Operator::Gt, lit(1.88));
         let rewritten = input.rewrite(&mut rewriter).unwrap();
-        assert_eq!(rewritten, binary_expr(col(""f1""), Operator::Gt, lit(1.88)));
+        assert_eq!(rewritten, lit(true));
+        assert_eq!(
+            rewriter.value_exprs,
+            &mut vec![BinaryExpr {
+                left: Column {
+                    relation: None,
+                    name: VALUE_COLUMN_NAME.into(),
+                },
+                op: Operator::Gt,
+                right: lit(1.88),
+            }]
+        );
     }
 
     #[test]
",3,"[""dc5238b2bda98a7c4f2fe9584fc3b0191a408109"", ""2561f4ade46fc9d59f289f328cc77733a6443697"", ""0cb9751b0a1bdd8d2c88b45d4366e760d6b1bbed""]","[""feat"", ""fix"", ""refactor""]"
"change notice from 'danger' > 'info'

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com> | remove ubuntu-latest from job title where that is the only os | removing automatic page push on nav","diff --git a/packages/noco-docs/docs/030.workspaces/040.actions-on-workspace.md b/packages/noco-docs/docs/030.workspaces/040.actions-on-workspace.md
index 17a1d85..b8c3f52 100644
--- a/packages/noco-docs/docs/030.workspaces/040.actions-on-workspace.md
+++ b/packages/noco-docs/docs/030.workspaces/040.actions-on-workspace.md
@@ -20,7 +20,7 @@ To update the workspace name:
 ## Delete workspace
 If you determine that a workspace is no longer necessary, you have the option to permanently remove it from your settings. Deleting a workspace will delete all the bases and data associated with it.
 
-:::danger
+:::info
 **This action cannot be undone.**
 :::
 
diff --git a/packages/noco-docs/docs/040.bases/070.actions-on-base.md b/packages/noco-docs/docs/040.bases/070.actions-on-base.md
index b8e5723..7207971 100644
--- a/packages/noco-docs/docs/040.bases/070.actions-on-base.md
+++ b/packages/noco-docs/docs/040.bases/070.actions-on-base.md
@@ -69,7 +69,7 @@ To duplicate a base, you can follow these straightforward steps:
 
 If you determine that a base is no longer necessary, you have the option to permanently remove it from your workspace. Deleting a base will delete all the tables and data associated with it.
 
-:::danger
+:::info
 **This action cannot be undone.**
 :::
 
diff --git a/packages/noco-docs/docs/050.tables/060.actions-on-table.md b/packages/noco-docs/docs/050.tables/060.actions-on-table.md
index 3cf03d3..8ae9ade 100644
--- a/packages/noco-docs/docs/050.tables/060.actions-on-table.md
+++ b/packages/noco-docs/docs/050.tables/060.actions-on-table.md
@@ -46,7 +46,7 @@ A new table will be generated, mirroring the original table's schema and content
 
 ## Delete table
 
-:::danger
+:::info
 **This action cannot be undone.**
 :::
 
diff --git a/packages/noco-docs/docs/070.fields/060.actions-on-field.md b/packages/noco-docs/docs/070.fields/060.actions-on-field.md
index 600c6fd..fe2cfa8 100644
--- a/packages/noco-docs/docs/070.fields/060.actions-on-field.md
+++ b/packages/noco-docs/docs/070.fields/060.actions-on-field.md
@@ -83,7 +83,7 @@ New field will be created to the right of the original field.
 New field will be created to the left of the original field.
 
 ### Delete field
-:::danger
+:::info
 **This action cannot be undone.**
 :::
 
diff --git a/packages/noco-docs/docs/080.records/070.actions-on-record.md b/packages/noco-docs/docs/080.records/070.actions-on-record.md
index a9245ff..6d4774a 100644
--- a/packages/noco-docs/docs/080.records/070.actions-on-record.md
+++ b/packages/noco-docs/docs/080.records/070.actions-on-record.md
@@ -54,8 +54,8 @@ On the bulk update modal,
 5. Click on the `Bulk Update all` button
 6. A confirmation dialog will be displayed. Click on `Confirm` to update the records.
 
-:::danger
-This operation cannot be undone.
+:::info
+**This action cannot be undone.**
 :::
 
 ![Bulk Update](/img/v2/records/bulk-update-1.png)
diff --git a/packages/noco-docs/docs/090.views/090.actions-on-view.md b/packages/noco-docs/docs/090.views/090.actions-on-view.md
index c6c6ab2..7d23959 100644
--- a/packages/noco-docs/docs/090.views/090.actions-on-view.md
+++ b/packages/noco-docs/docs/090.views/090.actions-on-view.md
@@ -41,7 +41,7 @@ The view context menu provides a set of tools to interact with the view. The vie
 
 ## Delete view
 
-:::danger
+:::info
 **This action cannot be undone.**
 :::
 

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index 4dea4c9..006290a 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -122,7 +122,7 @@ jobs:
           path: junit.xml
 
   test_postgres:
-    name: PostgreSQL ubuntu-latest deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
+    name: PostgreSQL deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -204,7 +204,7 @@ jobs:
           path: junit.xml
 
   test_pyspark:
-    name: PySpark ${{ matrix.pyspark.version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: PySpark ${{ matrix.pyspark.version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -279,7 +279,7 @@ jobs:
           path: junit.xml
 
   test_impala:
-    name: Impala ubuntu-latest python-${{ matrix.python-version }}
+    name: Impala python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     env:
       IBIS_TEST_NN_HOST: localhost
@@ -386,7 +386,7 @@ jobs:
           path: junit.xml
 
   test_mysql_clickhouse:
-    name: ${{ matrix.backend.title }} ubuntu-latest python-${{ matrix.python-version }}
+    name: ${{ matrix.backend.title }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -460,7 +460,7 @@ jobs:
           path: junit.xml
 
   test_datafusion:
-    name: DataFusion ${{ matrix.datafusion-version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: DataFusion ${{ matrix.datafusion-version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false

diff --git a/ionic/components/nav/test/basic/index.ts b/ionic/components/nav/test/basic/index.ts
index 4b1a8ea..2834f68 100644
--- a/ionic/components/nav/test/basic/index.ts
+++ b/ionic/components/nav/test/basic/index.ts
@@ -63,12 +63,6 @@ class FirstPage {
     }
   }
 
-  onPageDidEnter() {
-    setTimeout(() => {
-      this.nav.push(PrimaryHeaderPage);
-    }, 1000);
-  }
-
   setPages() {
     let items = [
       PrimaryHeaderPage
",3,"[""2ba752d45350a676babe553dd68f019af81b512b"", ""74e9de5ec97dc013a52aa063dff0f40ac74c407b"", ""cd9e6a2ab17c5961b0f977bb8a06f8545da49a97""]","[""docs"", ""cicd"", ""test""]"
remove unnecessary import | make jq use compact json for rebase branch query,"diff --git a/transport/src/main/java/io/camunda/zeebe/transport/stream/impl/LogicalId.java b/transport/src/main/java/io/camunda/zeebe/transport/stream/impl/LogicalId.java
index 14c6f30..ebaef60 100644
--- a/transport/src/main/java/io/camunda/zeebe/transport/stream/impl/LogicalId.java
+++ b/transport/src/main/java/io/camunda/zeebe/transport/stream/impl/LogicalId.java
@@ -8,7 +8,6 @@
 package io.camunda.zeebe.transport.stream.impl;
 
 import io.camunda.zeebe.util.buffer.BufferUtil;
-import org.agrona.BitUtil;
 import org.agrona.concurrent.UnsafeBuffer;
 
 /**

diff --git a/.github/workflows/ibis-rebase-nightly.yml b/.github/workflows/ibis-rebase-nightly.yml
index 0e284b0..4a3ec7a 100644
--- a/.github/workflows/ibis-rebase-nightly.yml
+++ b/.github/workflows/ibis-rebase-nightly.yml
@@ -22,7 +22,7 @@ jobs:
               | cut -d ' ' -f2 \
               | grep -P '\d+\.x\.x' \
               | xargs printf '""%s""' \
-              | jq -s '{branch: .}')
+              | jq -rcMs '{branch: .}')
 
           echo ""::set-output name=matrix::$branches""
 
",2,"[""84529bcb10c6fe02e2c0079d069ab6c6ac7683d6"", ""4638dcdf7011e8e42d11fde04f068f22ee20fa1d""]","[""refactor"", ""cicd""]"
remove unused branches and ignore envrc file | simplyfy statement | add tests for ProfilePage methods,"diff --git a/.github/workflows/ibis-backends-cloud.yml b/.github/workflows/ibis-backends-cloud.yml
index 2003e8e..7c7fd26 100644
--- a/.github/workflows/ibis-backends-cloud.yml
+++ b/.github/workflows/ibis-backends-cloud.yml
@@ -5,9 +5,12 @@ on:
     # Skip the backend suite if all changes are in the docs directory
     paths-ignore:
       - ""docs/**""
+      - ""**/*.md""
+      - ""**/*.qmd""
+      - ""codecov.yml""
+      - "".envrc""
     branches:
       - master
-      - quarto
 
 permissions:
   # this allows extractions/setup-just to list releases for `just` at a higher
diff --git a/.github/workflows/ibis-backends-skip-helper.yml b/.github/workflows/ibis-backends-skip-helper.yml
index 5d5f3f7..0471994 100644
--- a/.github/workflows/ibis-backends-skip-helper.yml
+++ b/.github/workflows/ibis-backends-skip-helper.yml
@@ -9,20 +9,20 @@ on:
       - ""**/*.md""
       - ""**/*.qmd""
       - ""codecov.yml""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     paths:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
       - ""codecov.yml""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 jobs:
   test_backends:
diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index 4a1cae9..30e6c1a 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -8,10 +8,10 @@ on:
       - ""**/*.md""
       - ""**/*.qmd""
       - ""codecov.yml""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     # Skip the backend suite if all changes are docs
     paths-ignore:
@@ -19,10 +19,10 @@ on:
       - ""**/*.md""
       - ""**/*.qmd""
       - ""codecov.yml""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 permissions:
diff --git a/.github/workflows/ibis-docs-lint.yml b/.github/workflows/ibis-docs-lint.yml
index 1adda11..b528a30 100644
--- a/.github/workflows/ibis-docs-lint.yml
+++ b/.github/workflows/ibis-docs-lint.yml
@@ -5,12 +5,10 @@ on:
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 concurrency:
diff --git a/.github/workflows/ibis-main-skip-helper.yml b/.github/workflows/ibis-main-skip-helper.yml
index a5fdc6f..0fb5dea 100644
--- a/.github/workflows/ibis-main-skip-helper.yml
+++ b/.github/workflows/ibis-main-skip-helper.yml
@@ -8,19 +8,19 @@ on:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     paths:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 jobs:
   test_core:
diff --git a/.github/workflows/ibis-main.yml b/.github/workflows/ibis-main.yml
index aa31436..0b1536a 100644
--- a/.github/workflows/ibis-main.yml
+++ b/.github/workflows/ibis-main.yml
@@ -7,20 +7,20 @@ on:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     # Skip the test suite if all changes are in the docs directory
     paths-ignore:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 permissions:
diff --git a/.github/workflows/ibis-tpch-queries-skip-helper.yml b/.github/workflows/ibis-tpch-queries-skip-helper.yml
index 1f1c0bc..f10fb8d 100644
--- a/.github/workflows/ibis-tpch-queries-skip-helper.yml
+++ b/.github/workflows/ibis-tpch-queries-skip-helper.yml
@@ -6,19 +6,19 @@ on:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     paths:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 concurrency:
diff --git a/.github/workflows/ibis-tpch-queries.yml b/.github/workflows/ibis-tpch-queries.yml
index b4f8a48..9e65a61 100644
--- a/.github/workflows/ibis-tpch-queries.yml
+++ b/.github/workflows/ibis-tpch-queries.yml
@@ -6,19 +6,19 @@ on:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     paths-ignore:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 concurrency:
diff --git a/.github/workflows/nix-skip-helper.yml b/.github/workflows/nix-skip-helper.yml
index 677b4d7..e0ab8f7 100644
--- a/.github/workflows/nix-skip-helper.yml
+++ b/.github/workflows/nix-skip-helper.yml
@@ -9,19 +9,19 @@ on:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     paths:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 jobs:
diff --git a/.github/workflows/nix.yml b/.github/workflows/nix.yml
index f2dd3f0..7ea9e26 100644
--- a/.github/workflows/nix.yml
+++ b/.github/workflows/nix.yml
@@ -6,19 +6,19 @@ on:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     paths-ignore:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 concurrency:

diff --git a/src/Object/Merge.ts b/src/Object/Merge.ts
index 1f48efb..06caad1 100644
--- a/src/Object/Merge.ts
+++ b/src/Object/Merge.ts
@@ -96,9 +96,11 @@ type ChooseMergeDeep<OK, O1K, K extends Key, OOK extends Key, style extends Merg
 @hidden
 */
 export type _MergeDeep<O, O1, K extends Key, OOK extends Key, style extends MergeStyle> =
-    Or<Extends<[O], [never]>, Extends<[O1], [never]>> extends 1 // filter never
+    [O] extends [never]
     ? MergeProp<O, O1, K, OOK, style>
-    : LibStyle<ChooseMergeDeep<NoList<O>, NoList<O1>, K, OOK, style>, O, O1, style>
+    : [O1] extends [never]
+      ? MergeProp<O, O1, K, OOK, style>
+      : LibStyle<ChooseMergeDeep<NoList<O>, NoList<O1>, K, OOK, style>, O, O1, style>
 
 /**
 @hidden
diff --git a/src/Object/Patch.ts b/src/Object/Patch.ts
index 2d73784..2c8bd42 100644
--- a/src/Object/Patch.ts
+++ b/src/Object/Patch.ts
@@ -89,9 +89,11 @@ type ChoosePatchDeep<OK, O1K, K extends Key, OOK extends Key, style extends Merg
 @hidden
 */
 export type _PatchDeep<O, O1, K extends Key, OOK extends Key, style extends MergeStyle> =
-    Or<Extends<[O], [never]>, Extends<[O1], [never]>> extends 1 // filter never
+    [O] extends [never]
     ? PatchProp<O, O1, K, OOK>
-    : LibStyle<ChoosePatchDeep<NoList<O>, NoList<O1>, K, OOK, style>, O, O1, style>
+    : [O1] extends [never]
+      ? PatchProp<O, O1, K, OOK>
+      : LibStyle<ChoosePatchDeep<NoList<O>, NoList<O1>, K, OOK, style>, O, O1, style>
 
 /**
 @hidden

diff --git a/client/src/components/Profile/PreScreeningIviewCard.tsx b/client/src/components/Profile/PreScreeningIviewCard.tsx
index f84392a..2031203 100644
--- a/client/src/components/Profile/PreScreeningIviewCard.tsx
+++ b/client/src/components/Profile/PreScreeningIviewCard.tsx
@@ -27,7 +27,7 @@ type State = {
   isPreScreeningIviewModalVisible: boolean;
 };
 
-class CoreJSIviewsCard extends React.PureComponent<Props, State> {
+class PreScreeningIviewsCard extends React.PureComponent<Props, State> {
   state = {
     courseIndex: 0,
     isPreScreeningIviewModalVisible: false,
@@ -98,4 +98,4 @@ class CoreJSIviewsCard extends React.PureComponent<Props, State> {
   }
 }
 
-export default CoreJSIviewsCard;
+export default PreScreeningIviewsCard;
diff --git a/client/src/components/Profile/__test__/__snapshots__/PreScreeningIviewCard.test.tsx.snap b/client/src/components/Profile/__test__/__snapshots__/PreScreeningIviewCard.test.tsx.snap
index 7b73c3f..54b378c 100644
--- a/client/src/components/Profile/__test__/__snapshots__/PreScreeningIviewCard.test.tsx.snap
+++ b/client/src/components/Profile/__test__/__snapshots__/PreScreeningIviewCard.test.tsx.snap
@@ -1,7 +1,7 @@
 // Jest Snapshot v1, https://goo.gl/fbAQLP
 
 exports[`PreScreeningIviewCard Should render correctly 1`] = `
-<CoreJSIviewsCard
+<PreScreeningIviewsCard
   data={
     Array [
       Object {
@@ -3015,5 +3015,5 @@ exports[`PreScreeningIviewCard Should render correctly 1`] = `
       </div>
     </Card>
   </CommonCard>
-</CoreJSIviewsCard>
+</PreScreeningIviewsCard>
 `;
diff --git a/client/src/pages/profile/__tests__/ProfilePage.tests.tsx b/client/src/pages/profile/__tests__/ProfilePage.tests.tsx
index 079d966..95f3e49 100644
--- a/client/src/pages/profile/__tests__/ProfilePage.tests.tsx
+++ b/client/src/pages/profile/__tests__/ProfilePage.tests.tsx
@@ -4,7 +4,6 @@ import { shallowToJson } from 'enzyme-to-json';
 import { NextRouter } from 'next/router';
 import { Session } from 'components/withSession';
 import { ProfilePage } from '../index';
-// import { GeneralInfo } from '../../../../../common/models/profile';
 
 jest.mock('next/config', () => () => ({}));
 jest.mock('services/user', () => ({
@@ -12,80 +11,378 @@ jest.mock('services/user', () => ({
       getProfileInfo() {
         return jest.fn();
       }
+      saveProfileInfo() {
+        return jest.fn();
+      }
     },
   }),
 );
 
-describe('ProfilePage', () => {
-  const profile = {
-    generalInfo: {
-      name: 'Dzmitry Petrov',
-      githubId: 'petrov',
-      aboutMyself: 'Test',
+const profile = {
+  permissionsSettings: {
+    isProfileVisible: { all: true },
+    isAboutVisible: { mentor: true, student: false, all: false },
+    isEducationVisible: { mentor: true, student: false, all: false },
+    isEnglishVisible: { student: false, all: false },
+    isEmailVisible: { student: false, all: false },
+    isTelegramVisible: { student: false, all: false },
+    isSkypeVisible: { student: false, all: false },
+    isPhoneVisible: { student: false, all: false },
+    isContactsNotesVisible: { student: true, all: false },
+    isLinkedInVisible: { mentor: true, student: false, all: false },
+    isPublicFeedbackVisible: { mentor: true, student: true, all: false },
+    isMentorStatsVisible: { mentor: true, student: true, all: false },
+    isStudentStatsVisible: { student: false, all: false },
+  },
+  generalInfo: {
+    aboutMyself: 'Test',
+    educationHistory: [{
+      graduationYear: '2019',
+      faculty: 'TT',
+      university: 'Test',
+    }],
+    englishLevel: 'a2+',
+    locationId: 456,
+    locationName: 'Brest',
+  },
+  contacts: {},
+  mentorStats: [
+    {},
+  ],
+  studentStats: [
+    {
+      courseFullName: 'test',
+      courseName: 'test',
       locationName: 'Minsk',
-      locationId: '1',
-      educationHistory: null,
-      englishLevel: 'a2+',
-    },
-    permissionsSettings: {
-      isProfileVisible: { all: true },
-      isAboutVisible: { mentor: true, student: false, all: false },
-      isEducationVisible: { mentor: true, student: false, all: false },
-      isEnglishVisible: { student: false, all: false },
-      isEmailVisible: { student: false, all: false },
-      isTelegramVisible: { student: false, all: false },
-      isSkypeVisible: { student: false, all: false },
-      isPhoneVisible: { student: false, all: false },
-      isContactsNotesVisible: { student: true, all: false },
-      isLinkedInVisible: { mentor: true, student: false, all: false },
-      isPublicFeedbackVisible: { mentor: true, student: true, all: false },
-      isMentorStatsVisible: { mentor: true, student: true, all: false },
-      isStudentStatsVisible: { student: false, all: false },
-    },
-    contacts: {
-      phone: '+375292123456',
-      email: 'petro@gmail.com',
-      skype: 'petro:live',
-      telegram: 'petro',
-      notes: 'discord: @petro, instagram: @petro12',
-    },
-    isPermissionsSettingsChanged: true,
-    isProfileSettingsChanged: true,
-  };
-  const session = {
-    id: 2020,
-    githubId: 'mikhama',
-    isAdmin: true,
-    isHirer: false,
-    isActivist: false,
-    roles: {
-      1: 'mentor',
-      2: 'student',
-      11: 'mentor',
-    },
-    coursesRoles: {
-      13: [
-        'manager',
+      tasks: [
+        {
+          interviewFormAnswers: {},
+        },
       ],
     },
-  } as Session;
-  const router = {
-    query: {
-      githubId: 'petrov',
-    },
-    asPath: '/#edit/',
-  } as unknown as NextRouter;
+  ],
+  publicFeedback: [
+    {},
+  ],
+  stageInterviewFeedback: [
+    {},
+  ],
+};
+const session = {
+  id: 2020,
+  githubId: 'mikhama',
+  isAdmin: true,
+  isHirer: false,
+  isActivist: false,
+  roles: {
+    1: 'mentor',
+    2: 'student',
+    11: 'mentor',
+  },
+  coursesRoles: {
+    13: [
+      'manager',
+    ],
+  },
+} as Session;
+const router = {
+  query: {
+    githubId: 'petrov',
+  },
+  asPath: '/#edit/',
+} as unknown as NextRouter;
+const state = {
+  profile,
+  isInitialPermissionsSettingsChanged: false,
+  isInitialProfileSettingsChanged: false,
+};
 
+describe('ProfilePage', () => {
   describe('Should render correctly', () => {
-    it('if full info about profile is in the state', () => {
+    it('if full profile info is in the state', () => {
       const wrapper = shallow(
         <ProfilePage
           session={session}
           router={router}
         />,
       );
-      wrapper.setState({ profile });
+      wrapper.setState(state);
       expect(shallowToJson(wrapper)).toMatchSnapshot();
     });
   });
+
+  const wrapper = shallow(
+    <ProfilePage
+      session={session}
+      router={router}
+    />,
+  );
+  const instance = wrapper.instance();
+  describe('onPermissionsSettingsChange', () => {
+    describe('Should set state correctly', () => {
+      it('if permissions for student role were changed', async () => {
+        const event = {
+          target: {
+            checked: true,
+          },
+        }
+        const changedPermissionsSettings = {
+          permissionName: 'isEmailVisible',
+          role: 'student',
+        };
+        wrapper.setState(state);
+        await instance.onPermissionsSettingsChange(event, changedPermissionsSettings);
+        expect(wrapper.state().profile.permissionsSettings.isEmailVisible).toEqual({
+          student: true, all: false,
+        });
+        expect(wrapper.state().isInitialPermissionsSettingsChanged).toBe(true);
+      });
+      it('if permissions for mentor role were changed', async () => {
+        const event = {
+          target: {
+            checked: false,
+          },
+        }
+        const changedPermissionsSettings = {
+          permissionName: 'isLinkedInVisible',
+          role: 'mentor',
+        };
+        wrapper.setState(state);
+        await instance.onPermissionsSettingsChange(event, changedPermissionsSettings);
+        expect(wrapper.state().profile.permissionsSettings.isLinkedInVisible).toEqual({
+          mentor: false, student: false, all: false,
+        });
+        expect(wrapper.state().isInitialPermissionsSettingsChanged).toBe(true);
+      });
+      it('if permissions for all roles were changed', async () => {
+        const event = {
+          target: {
+            checked: true,
+          },
+        }
+        const changedPermissionsSettings = {
+          permissionName: 'isEducationVisible',
+          role: 'all',
+        };
+        wrapper.setState(state);
+        await instance.onPermissionsSettingsChange(event, changedPermissionsSettings);
+        expect(wrapper.state().profile.permissionsSettings.isEducationVisible).toEqual({
+          mentor: true, student: true, all: true,
+        });
+        expect(wrapper.state().isInitialPermissionsSettingsChanged).toBe(true);
+      });
+    });
+  });
+  describe('onProfileSettingsChange', () => {
+    describe('Should set state correctly', () => {
+      it('if ""profile.generalInfo.location"" was changed', async () => {
+        const event = {
+          id: 123,
+          name: 'Minsk',
+        }
+        const path = 'generalInfo.location';
+        wrapper.setState(state);
+        await instance.onProfileSettingsChange(event, path);
+        expect(wrapper.state().profile.generalInfo.locationId).toBe(123);
+        expect(wrapper.state().profile.generalInfo.locationName).toBe('Minsk');
+        expect(wrapper.state().isInitialProfileSettingsChanged).toBe(true);
+      });
+      it('if ""profile.generalInfo.englishLevel"" was changed', async () => {
+        const event = 'b2+';
+        const path = 'generalInfo.englishLevel';
+        wrapper.setState(state);
+        await instance.onProfileSettingsChange(event, path);
+        expect(wrapper.state().profile.generalInfo.englishLevel).toBe('b2+');
+      });
+      it('if field added to ""profile.generalInfo.educationHistory""', async () => {
+        const event = {
+          type: 'add',
+        };
+        const path = 'generalInfo.educationHistory';
+        wrapper.setState(state);
+        await instance.onProfileSettingsChange(event, path);
+        expect(wrapper.state().profile.generalInfo.educationHistory).toEqual([
+          {
+            graduationYear: '2019',
+            faculty: 'TT',
+            university: 'Test',
+          },
+          {
+            graduationYear: null,
+            faculty: null,
+            university: null,
+          },
+        ]);
+        expect(wrapper.state().isInitialProfileSettingsChanged).toBe(true);
+      });
+      it('if field deleted from ""profile.generalInfo.educationHistory""', async () => {
+        const event = {
+          type: 'delete',
+          index: 0,
+        };
+        const path = 'generalInfo.educationHistory';
+        wrapper.setState(state);
+        await instance.onProfileSettingsChange(event, path);
+        expect(wrapper.state().profile.generalInfo.educationHistory).toEqual([]);
+      });
+      it('if some other field was changed', async () => {
+        const event = {
+          target: {
+            value: 'Hello everyone, my name is Mike.',
+          }
+        };
+        const path = 'generalInfo.aboutMyself';
+        wrapper.setState(state);
+        await instance.onProfileSettingsChange(event, path);
+        expect(wrapper.state().profile.generalInfo.aboutMyself).toEqual('Hello everyone, my name is Mike.');
+        expect(wrapper.state().isInitialProfileSettingsChanged).toBe(true);
+      });
+    });
+  });
+  describe('changeProfilePageMode', () => {
+    describe('Should set state correctly', () => {
+      it('if mode = ""edit"" was passed', async () => {
+        const mode = 'edit';
+        wrapper.setState({ ...state, isEditingModeEnabled: false });
+        expect(wrapper.state().isEditingModeEnabled).toBe(false);
+        await instance.changeProfilePageMode(mode);
+        expect(wrapper.state().isEditingModeEnabled).toBe(true);
+      });
+      it('if mode = ""view"" was passed', async () => {
+        const mode = 'view';
+        wrapper.setState({ ...state, isEditingModeEnabled: true });
+        expect(wrapper.state().isEditingModeEnabled).toBe(true);
+        await instance.changeProfilePageMode(mode);
+        expect(wrapper.state().isEditingModeEnabled).toBe(false);
+      });
+    });
+  });
+  describe('saveProfile', () => {
+    it('Should set state correctly', async () => {
+      const profile = {
+        generalInfo: {
+          aboutMyself: 'Hello',
+          educationHistory: [{
+            graduationYear: '2019',
+            faculty: 'TT',
+            university: 'Test',
+          }],
+          englishLevel: 'c1',
+          locationId: 778,
+          locationName: 'Hrodna',
+        },
+        contacts: {
+          telegram: 'test',
+        },
+        permissionsSettings: {
+          isProfileVisible: { all: true },
+          isAboutVisible: { mentor: true, student: false, all: false },
+          isEducationVisible: { mentor: true, student: false, all: false },
+          isEnglishVisible: { student: true, all: true },
+          isEmailVisible: { student: true, all: true },
+          isTelegramVisible: { student: true, all: true },
+          isSkypeVisible: { student: true, all: false },
+          isPhoneVisible: { student: true, all: false },
+          isContactsNotesVisible: { student: true, all: false },
+          isLinkedInVisible: { mentor: true, student: false, all: false },
+          isPublicFeedbackVisible: { mentor: true, student: true, all: false },
+          isMentorStatsVisible: { mentor: true, student: true, all: false },
+          isStudentStatsVisible: { student: false, all: false },
+        },
+      };
+      wrapper.setState({
+        ...state,
+        profile,
+        isInitialPermissionsSettingsChanged: true,
+        isInitialProfileSettingsChanged: true,
+      });
+      await instance.saveProfile();
+      expect(wrapper.state().isSaving).toBe(false);
+      expect(wrapper.state().isInitialPermissionsSettingsChanged).toBe(false);
+      expect(wrapper.state().isInitialProfileSettingsChanged).toBe(false);
+      expect(wrapper.state().initialPermissionsSettings).toEqual(profile.permissionsSettings);
+      expect(wrapper.state().initialProfileSettings).toEqual(profile);
+    });
+  });
+  describe('hadStudentCoreJSInterview', () => {
+    describe('Should return', () => {
+      it('""true"" if student has an ""interviewFormAnswers"" in one of the task', () => {
+        const studentStats = [
+          {
+            courseFullName: 'test',
+            courseName: 'test',
+            locationName: 'Minsk',
+            tasks: [
+              {},
+              {
+                interviewFormAnswers: {},
+              },
+              {},
+              {},
+            ],
+          },
+        ];
+        const result = instance.hadStudentCoreJSInterview(studentStats);
+        expect(result).toBe(true);
+      });
+      it('""false"" if student has not an ""interviewFormAnswers"" in one of the task', () => {
+        const studentStats = [
+          {
+            courseFullName: 'test',
+            courseName: 'test',
+            locationName: 'Minsk',
+            tasks: [
+              {},
+              {},
+              {},
+            ],
+          },
+        ];
+        const result = instance.hadStudentCoreJSInterview(studentStats);
+        expect(result).toBe(false);
+      });
+    });
+  });
+  describe('getStudentCoreJSInterviews', () => {
+    it('Should return info about CoreJS interviews', () => {
+      const studentStats = [
+        {
+          courseFullName: 'test',
+          courseName: 'test',
+          locationName: 'Minsk',
+          tasks: [
+            {},
+            {},
+            {
+              interviewer: {
+                name: 'Dima Petrov',
+                githubId: 'dip',
+              },
+              comment: 'Test',
+              score: 9,
+              interviewFormAnswers: {},
+            },
+            {},
+          ],
+        },
+      ];
+      const result = instance.getStudentCoreJSInterviews(studentStats);
+      expect(result).toEqual([
+        {
+          courseFullName: 'test',
+          courseName: 'test',
+          interview: {
+            answers: {},
+            interviewer: {
+              name: 'Dima Petrov',
+              githubId: 'dip',
+            },
+            comment: 'Test',
+            score: 9,
+          },
+          locationName: 'Minsk',
+        },
+      ]);
+    });
+  });
 });
diff --git a/client/src/pages/profile/__tests__/__snapshots__/ProfilePage.tests.tsx.snap b/client/src/pages/profile/__tests__/__snapshots__/ProfilePage.tests.tsx.snap
index fbd133c..729b2de 100644
--- a/client/src/pages/profile/__tests__/__snapshots__/ProfilePage.tests.tsx.snap
+++ b/client/src/pages/profile/__tests__/__snapshots__/ProfilePage.tests.tsx.snap
@@ -1,6 +1,6 @@
 // Jest Snapshot v1, https://goo.gl/fbAQLP
 
-exports[`ProfilePage Should render correctly if  1`] = `
+exports[`ProfilePage Should render correctly if full profile info is in the state 1`] = `
 <Fragment>
   <LoadingScreen
     show={true}
@@ -50,12 +50,16 @@ exports[`ProfilePage Should render correctly if  1`] = `
               data={
                 Object {
                   ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
+                  ""educationHistory"": Array [
+                    Object {
+                      ""faculty"": ""TT"",
+                      ""graduationYear"": ""2019"",
+                      ""university"": ""Test"",
+                    },
+                  ],
                   ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
+                  ""locationId"": 456,
+                  ""locationName"": ""Brest"",
                 }
               }
               isEditingModeEnabled={false}
@@ -135,12 +139,16 @@ exports[`ProfilePage Should render correctly if  1`] = `
               data={
                 Object {
                   ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
+                  ""educationHistory"": Array [
+                    Object {
+                      ""faculty"": ""TT"",
+                      ""graduationYear"": ""2019"",
+                      ""university"": ""Test"",
+                    },
+                  ],
                   ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
+                  ""locationId"": 456,
+                  ""locationName"": ""Brest"",
                 }
               }
               isEditingModeEnabled={false}
@@ -220,12 +228,16 @@ exports[`ProfilePage Should render correctly if  1`] = `
               data={
                 Object {
                   ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
+                  ""educationHistory"": Array [
+                    Object {
+                      ""faculty"": ""TT"",
+                      ""graduationYear"": ""2019"",
+                      ""university"": ""Test"",
+                    },
+                  ],
                   ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
+                  ""locationId"": 456,
+                  ""locationName"": ""Brest"",
                 }
               }
               isEditingModeEnabled={false}
@@ -305,12 +317,16 @@ exports[`ProfilePage Should render correctly if  1`] = `
               data={
                 Object {
                   ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
+                  ""educationHistory"": Array [
+                    Object {
+                      ""faculty"": ""TT"",
+                      ""graduationYear"": ""2019"",
+                      ""university"": ""Test"",
+                    },
+                  ],
                   ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
+                  ""locationId"": 456,
+                  ""locationName"": ""Brest"",
                 }
               }
               isEditingModeEnabled={false}
@@ -387,15 +403,7 @@ exports[`ProfilePage Should render correctly if  1`] = `
             }
           >
             <ContactsCard
-              data={
-                Object {
-                  ""email"": ""petro@gmail.com"",
-                  ""notes"": ""discord: @petro, instagram: @petro12"",
-                  ""phone"": ""+375292123456"",
-                  ""skype"": ""petro:live"",
-                  ""telegram"": ""petro"",
-                }
-              }
+              data={Object {}}
               isEditingModeEnabled={false}
               onPermissionsSettingsChange={[Function]}
               onProfileSettingsChange={[Function]}
@@ -461,84 +469,22 @@ exports[`ProfilePage Should render correctly if  1`] = `
               }
             />
           </div>
-        </Masonry>
-        <JSXStyle
-          id=""3803498300""
-        >
-          div.jsx-3803498300{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin-left:-16px;width:auto;}
-        </JSXStyle>
-        <JSXStyle
-          id=""110195169""
-        >
-          div.jsx-110195169{padding-left:16px;background-clip:padding-box;}
-        </JSXStyle>
-      </div>
-    </Spin>
-  </LoadingScreen>
-</Fragment>
-`;
-
-exports[`ProfilePage Should render correctly if full info about profile is in the state 1`] = `
-<Fragment>
-  <LoadingScreen
-    show={true}
-  >
-    <Header
-      isProfileEditingModeEnabled={false}
-      isProfilePage={false}
-      isSaveButtonVisible={false}
-      onChangeProfilePageMode={[Function]}
-      onSaveClick={[Function]}
-      username=""mikhama""
-    />
-    <Spin
-      delay={200}
-      size=""default""
-      spinning={false}
-      wrapperClassName=""""
-    >
-      <div
-        style={
-          Object {
-            ""padding"": 10,
-          }
-        }
-      >
-        <Masonry
-          breakpointCols={
-            Object {
-              ""1100"": 3,
-              ""500"": 1,
-              ""700"": 2,
-              ""default"": 4,
-            }
-          }
-          className=""jsx-3803498300""
-          columnClassName=""jsx-110195169""
-        >
           <div
-            key=""card-0""
+            key=""card-5""
             style={
               Object {
                 ""marginBottom"": 16,
               }
             }
           >
-            <MainCard
+            <PublicFeedbackCard
               data={
-                Object {
-                  ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
-                  ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
-                }
+                Array [
+                  Object {},
+                ]
               }
               isEditingModeEnabled={false}
               onPermissionsSettingsChange={[Function]}
-              onProfileSettingsChange={[Function]}
               permissionsSettings={
                 Object {
                   ""isAboutVisible"": Object {
@@ -602,28 +548,30 @@ exports[`ProfilePage Should render correctly if full info about profile is in th
             />
           </div>
           <div
-            key=""card-1""
+            key=""card-6""
             style={
               Object {
                 ""marginBottom"": 16,
               }
             }
           >
-            <AboutCard
+            <StudentStatsCard
               data={
-                Object {
-                  ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
-                  ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
-                }
+                Array [
+                  Object {
+                    ""courseFullName"": ""test"",
+                    ""courseName"": ""test"",
+                    ""locationName"": ""Minsk"",
+                    ""tasks"": Array [
+                      Object {
+                        ""interviewFormAnswers"": Object {},
+                      },
+                    ],
+                  },
+                ]
               }
               isEditingModeEnabled={false}
               onPermissionsSettingsChange={[Function]}
-              onProfileSettingsChange={[Function]}
               permissionsSettings={
                 Object {
                   ""isAboutVisible"": Object {
@@ -687,28 +635,21 @@ exports[`ProfilePage Should render correctly if full info about profile is in th
             />
           </div>
           <div
-            key=""card-2""
+            key=""card-7""
             style={
               Object {
                 ""marginBottom"": 16,
               }
             }
           >
-            <EnglishCard
+            <MentorStatsCard
               data={
-                Object {
-                  ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
-                  ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
-                }
+                Array [
+                  Object {},
+                ]
               }
               isEditingModeEnabled={false}
               onPermissionsSettingsChange={[Function]}
-              onProfileSettingsChange={[Function]}
               permissionsSettings={
                 Object {
                   ""isAboutVisible"": Object {
@@ -772,170 +713,44 @@ exports[`ProfilePage Should render correctly if full info about profile is in th
             />
           </div>
           <div
-            key=""card-3""
+            key=""card-8""
             style={
               Object {
                 ""marginBottom"": 16,
               }
             }
           >
-            <EducationCard
+            <CoreJSIviewsCard
               data={
-                Object {
-                  ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
-                  ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
-                }
-              }
-              isEditingModeEnabled={false}
-              onPermissionsSettingsChange={[Function]}
-              onProfileSettingsChange={[Function]}
-              permissionsSettings={
-                Object {
-                  ""isAboutVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": false,
-                  },
-                  ""isContactsNotesVisible"": Object {
-                    ""all"": false,
-                    ""student"": true,
-                  },
-                  ""isEducationVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": false,
-                  },
-                  ""isEmailVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isEnglishVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isLinkedInVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": false,
-                  },
-                  ""isMentorStatsVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": true,
-                  },
-                  ""isPhoneVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isProfileVisible"": Object {
-                    ""all"": true,
-                  },
-                  ""isPublicFeedbackVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": true,
-                  },
-                  ""isSkypeVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isStudentStatsVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isTelegramVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                }
+                Array [
+                  Object {
+                    ""courseFullName"": ""test"",
+                    ""courseName"": ""test"",
+                    ""interview"": Object {
+                      ""answers"": Object {},
+                      ""comment"": undefined,
+                      ""interviewer"": undefined,
+                      ""score"": undefined,
+                    },
+                    ""locationName"": ""Minsk"",
+                  },
+                ]
               }
             />
           </div>
           <div
-            key=""card-4""
+            key=""card-9""
             style={
               Object {
                 ""marginBottom"": 16,
               }
             }
           >
-            <ContactsCard
+            <PreScreeningIviewsCard
               data={
-                Object {
-                  ""email"": ""petro@gmail.com"",
-                  ""notes"": ""discord: @petro, instagram: @petro12"",
-                  ""phone"": ""+375292123456"",
-                  ""skype"": ""petro:live"",
-                  ""telegram"": ""petro"",
-                }
-              }
-              isEditingModeEnabled={false}
-              onPermissionsSettingsChange={[Function]}
-              onProfileSettingsChange={[Function]}
-              permissionsSettings={
-                Object {
-                  ""isAboutVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": false,
-                  },
-                  ""isContactsNotesVisible"": Object {
-                    ""all"": false,
-                    ""student"": true,
-                  },
-                  ""isEducationVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": false,
-                  },
-                  ""isEmailVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isEnglishVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isLinkedInVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": false,
-                  },
-                  ""isMentorStatsVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": true,
-                  },
-                  ""isPhoneVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isProfileVisible"": Object {
-                    ""all"": true,
-                  },
-                  ""isPublicFeedbackVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": true,
-                  },
-                  ""isSkypeVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isStudentStatsVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isTelegramVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                }
+                Array [
+                  Object {},
+                ]
               }
             />
           </div>
",3,"[""d0c6476df61b9c6ab07b87e1724ea7c5318595bb"", ""f86944ff00b970d7e2da48abbff43e58bdf29b99"", ""11ffd5174bd61a2939ae58d2b2d43284302ae490""]","[""cicd"", ""refactor"", ""test""]"
remove duplicated variables | update README.md about the NPM package,"diff --git a/packages/core/src/components/item/item.ios.scss b/packages/core/src/components/item/item.ios.scss
index 4de5455..6c4d11a 100644
--- a/packages/core/src/components/item/item.ios.scss
+++ b/packages/core/src/components/item/item.ios.scss
@@ -47,15 +47,6 @@ $item-ios-detail-push-color:              $list-ios-border-color !default;
 /// @prop - Icon for the detail arrow
 $item-ios-detail-push-svg:                ""<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 12 20'><path d='M2,20l-2-2l8-8L0,2l2-2l10,10L2,20z' fill='#{$item-ios-detail-push-color}'/></svg>"" !default;
 
-/// @prop - Background for the divider
-$item-ios-divider-background:             #f7f7f7 !default;
-
-/// @prop - Color for the divider
-$item-ios-divider-color:                  #222 !default;
-
-/// @prop - Padding for the divider
-$item-ios-divider-padding:                5px 15px !default;
-
 
 // iOS Item
 // --------------------------------------------------
diff --git a/packages/core/src/components/item/item.md.scss b/packages/core/src/components/item/item.md.scss
index 1dd1800..3dadbc0 100644
--- a/packages/core/src/components/item/item.md.scss
+++ b/packages/core/src/components/item/item.md.scss
@@ -35,21 +35,6 @@ $item-md-detail-push-color:          $list-md-border-color !default;
 /// @prop - Icon for the detail arrow
 $item-md-detail-push-svg:            ""<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 12 20'><path d='M2,20l-2-2l8-8L0,2l2-2l10,10L2,20z' fill='#{$item-md-detail-push-color}'/></svg>"" !default;
 
-/// @prop - Color for the divider
-$item-md-divider-color:              #858585 !default;
-
-/// @prop - Background for the divider
-$item-md-divider-background:         #fff !default;
-
-/// @prop - Font size for the divider
-$item-md-divider-font-size:          $item-md-body-text-font-size !default;
-
-/// @prop - Border bottom for the divider
-$item-md-divider-border-bottom:      1px solid $list-md-border-color !default;
-
-/// @prop - Padding for the divider
-$item-md-divider-padding:            5px 15px !default;
-
 
 .item-md {
   @include padding-horizontal($item-md-padding-start, 0);
diff --git a/packages/core/src/components/item/item.wp.scss b/packages/core/src/components/item/item.wp.scss
index 2c4aae6..07b9266 100644
--- a/packages/core/src/components/item/item.wp.scss
+++ b/packages/core/src/components/item/item.wp.scss
@@ -41,21 +41,6 @@ $item-wp-detail-push-color:          $input-wp-border-color !default;
 /// @prop - Icon for the detail arrow
 $item-wp-detail-push-svg:            ""<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 12 20'><path d='M2,20l-2-2l8-8L0,2l2-2l10,10L2,20z' fill='#{$item-wp-detail-push-color}'/></svg>"" !default;
 
-/// @prop - Color for the divider
-$item-wp-divider-color:              $list-wp-text-color !default;
-
-/// @prop - Background for the divider
-$item-wp-divider-background:         #fff !default;
-
-/// @prop - Bodrer bottom for the divider
-$item-wp-divider-border-bottom:      1px solid $list-wp-border-color !default;
-
-/// @prop - Font size for the divider
-$item-wp-divider-font-size:          2rem !default;
-
-/// @prop - Padding for the divider
-$item-wp-divider-padding:            5px 15px !default;
-
 
 .item-wp {
   @include padding-horizontal($item-wp-padding-start, 0);

diff --git a/README.md b/README.md
index 9faf168..bbb5b5c 100644
--- a/README.md
+++ b/README.md
@@ -126,23 +126,24 @@ pacman -S git-cliff
 
 ### From NPM
 
-[git-cliff](https://www.npmjs.com/package/git-cliff) can be installed from NPM:
+
+You can install and run [git-cliff](https://www.npmjs.com/package/git-cliff) with a single command:
 
 ```sh
-yarn add -D git-cliff
+npx git-cliff@latest
 ```
 
-or:
+Also, if you want to add `git-cliff` to your project:
 
 ```sh
+# with yarn
+yarn add -D git-cliff
+
+# with npm
 npm install git-cliff --save-dev
 ```
 
-You can also use `git-cliff` directly with `npx`:
-
-```sh
-npx git-cliff
-```
+Afterwards, you can run `git-cliff` via `npm exec git-cliff` or `npx git-cliff@latest`.
 
 ### From MacPorts
 
",2,"[""cd7e8c3d3549ea05115b3f02586eeba894d86906"", ""e0177c25e13812306aab0b0991562d58b6d14767""]","[""refactor"", ""docs""]"
"removed files | fixing deploying to kubernetes

Signed-off-by: Rajesh Rajendran <rjshrjndrn@gmail.com>","diff --git a/packages/tui/src/widgets/button.rs b/packages/tui/src/widgets/button.rs
index f3ebc79..845a60c 100644
--- a/packages/tui/src/widgets/button.rs
+++ b/packages/tui/src/widgets/button.rs
@@ -32,7 +32,6 @@ pub(crate) fn Button<'a>(cx: Scope<'a, ButtonProps>) -> Element<'a> {
             callback.call(FormData {
                 value: text.to_string(),
                 values: HashMap::new(),
-                files: None,
             });
         }
         state.set(new_state);
diff --git a/packages/tui/src/widgets/checkbox.rs b/packages/tui/src/widgets/checkbox.rs
index 4831172..90c7212 100644
--- a/packages/tui/src/widgets/checkbox.rs
+++ b/packages/tui/src/widgets/checkbox.rs
@@ -56,7 +56,6 @@ pub(crate) fn CheckBox<'a>(cx: Scope<'a, CheckBoxProps>) -> Element<'a> {
                     ""on"".to_string()
                 },
                 values: HashMap::new(),
-                files: None,
             });
         }
         state.set(new_state);
diff --git a/packages/tui/src/widgets/number.rs b/packages/tui/src/widgets/number.rs
index 05cb2d6..93f9edd 100644
--- a/packages/tui/src/widgets/number.rs
+++ b/packages/tui/src/widgets/number.rs
@@ -84,7 +84,6 @@ pub(crate) fn NumbericInput<'a>(cx: Scope<'a, NumbericInputProps>) -> Element<'a
             input_handler.call(FormData {
                 value: text,
                 values: HashMap::new(),
-                files: None,
             });
         }
     };
diff --git a/packages/tui/src/widgets/password.rs b/packages/tui/src/widgets/password.rs
index 7f8455d..d7e978f 100644
--- a/packages/tui/src/widgets/password.rs
+++ b/packages/tui/src/widgets/password.rs
@@ -99,7 +99,6 @@ pub(crate) fn Password<'a>(cx: Scope<'a, PasswordProps>) -> Element<'a> {
                     input_handler.call(FormData{
                         value: text.clone(),
                         values: HashMap::new(),
-                        files: None
                     });
                 }
 
diff --git a/packages/tui/src/widgets/slider.rs b/packages/tui/src/widgets/slider.rs
index 43f0ac7..257c765 100644
--- a/packages/tui/src/widgets/slider.rs
+++ b/packages/tui/src/widgets/slider.rs
@@ -58,7 +58,6 @@ pub(crate) fn Slider<'a>(cx: Scope<'a, SliderProps>) -> Element<'a> {
             oninput.call(FormData {
                 value,
                 values: HashMap::new(),
-                files: None,
             });
         }
     };
diff --git a/packages/tui/src/widgets/textbox.rs b/packages/tui/src/widgets/textbox.rs
index 8628fca..ce0ffcc 100644
--- a/packages/tui/src/widgets/textbox.rs
+++ b/packages/tui/src/widgets/textbox.rs
@@ -95,7 +95,6 @@ pub(crate) fn TextBox<'a>(cx: Scope<'a, TextBoxProps>) -> Element<'a> {
                     input_handler.call(FormData{
                         value: text.clone(),
                         values: HashMap::new(),
-                        files: None
                     });
                 }
 
diff --git a/packages/web/src/dom.rs b/packages/web/src/dom.rs
index 7fa3d20..5037c4d 100644
--- a/packages/web/src/dom.rs
+++ b/packages/web/src/dom.rs
@@ -331,11 +331,7 @@ fn read_input_to_data(target: Element) -> Rc<FormData> {
         }
     }
 
-    Rc::new(FormData {
-        value,
-        values,
-        files: None,
-    })
+    Rc::new(FormData { value, values })
 }
 
 fn walk_event_for_id(event: &web_sys::Event) -> Option<(ElementId, web_sys::Element)> {

diff --git a/.github/workflows/frontend.yaml b/.github/workflows/frontend.yaml
index 7e42967..77e4abf 100644
--- a/.github/workflows/frontend.yaml
+++ b/.github/workflows/frontend.yaml
@@ -22,26 +22,22 @@ jobs:
           ${{ runner.OS }}-build-
           ${{ runner.OS }}-
 
+    - uses: azure/k8s-set-context@v1
+      with:
+        method: kubeconfig
+        kubeconfig: ${{ secrets.OSS_KUBECONFIG }} # Use content of kubeconfig in secret.
+      id: setcontext
     - name: Install
       run: npm install
 
-    - name: Build
-      run: npm run build:staging
-      env:
-        ENVIRONMENT: staging
-
-    - name: Deploy
-      env:
-        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
-        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
-        AWS_REGION: eu-central-1
-        AWS_S3_BUCKET_NAME: ${{ secrets.AWS_S3_BUCKET_NAME }}
+    - name: Build and deploy
       run: |
-        aws configure set default.s3.signature_version s3v4
-        aws --endpoint-url https://${{secrets.DOMAIN_NAME}}/frontend/ s3 cp \
-          --recursive \
-          --region ""$AWS_REGION"" \
-          public s3://$AWS_S3_BUCKET_NAME
+        cd frontend
+        bash build.sh
+        cp -arl public frontend
+        minio_pod=$(kubectl get po -n db -l app.kubernetes.io/name=minio -n db --output custom-columns=name:.metadata.name | tail -n+2)
+        kubectl -n db cp frontend $minio_pod:/data/
+        rm -rf frontend
 
     # - name: Debug Job
     #   if: ${{ failure() }}
",2,"[""a81bbb83d64867f08c4d1be10919ef6806a1bf51"", ""3f2eec37f76c1ad9408e423e49fe5bfe3e17d943""]","[""fix"", ""cicd""]"
"getBorderSize() missing ""width""

The correct property name to use is ""borderWidth"", not just ""border"".
""border"" works in Chrome but was breaking in Firefox.

Also had to change .ui-grid-header's box-sizing to content-box so IE11
would include the border in height calcs. AND finally IE11 was returning
fractional heights so Grid parseInt()s the returned values. | fix readme","diff --git a/src/js/core/factories/Grid.js b/src/js/core/factories/Grid.js
index dcf10af..2be7842 100644
--- a/src/js/core/factories/Grid.js
+++ b/src/js/core/factories/Grid.js
@@ -1525,7 +1525,7 @@ angular.module('ui.grid')
             var oldHeaderHeight = container.headerHeight;
             var headerHeight = gridUtil.outerElementHeight(container.header);
 
-            container.headerHeight = headerHeight;
+            container.headerHeight = parseInt(headerHeight, 10);
 
             if (oldHeaderHeight !== headerHeight) {
               rebuildStyles = true;
@@ -1534,7 +1534,9 @@ angular.module('ui.grid')
             // Get the ""inner"" header height, that is the height minus the top and bottom borders, if present. We'll use it to make sure all the headers have a consistent height
             var topBorder = gridUtil.getBorderSize(container.header, 'top');
             var bottomBorder = gridUtil.getBorderSize(container.header, 'bottom');
-            var innerHeaderHeight = headerHeight - topBorder - bottomBorder;
+            var innerHeaderHeight = parseInt(headerHeight - topBorder - bottomBorder, 10);
+
+            innerHeaderHeight  = innerHeaderHeight < 0 ? 0 : innerHeaderHeight;
 
             container.innerHeaderHeight = innerHeaderHeight;
 
diff --git a/src/js/core/services/ui-grid-util.js b/src/js/core/services/ui-grid-util.js
index 2c32cbe..cc7c36c 100644
--- a/src/js/core/services/ui-grid-util.js
+++ b/src/js/core/services/ui-grid-util.js
@@ -757,6 +757,8 @@ module.service('gridUtil', ['$log', '$window', '$document', '$http', '$templateC
       borderType = 'border';
     }
 
+    borderType += 'Width';
+
     var val = parseInt(styles[borderType], 10);
 
     if (isNaN(val)) {
diff --git a/src/less/header.less b/src/less/header.less
index 5468a43..de8ff0b 100644
--- a/src/less/header.less
+++ b/src/less/header.less
@@ -7,6 +7,7 @@
 
 .ui-grid-header {
   border-bottom: 1px solid @borderColor;
+  box-sizing: content-box;;
 }
 
 .ui-grid-top-panel {

diff --git a/crates/dagger-sdk/README.md b/crates/dagger-sdk/README.md
index ed96be1..974fb7f 100644
--- a/crates/dagger-sdk/README.md
+++ b/crates/dagger-sdk/README.md
@@ -29,9 +29,9 @@ fn main() -> eyre::Result<()> {
     let client = dagger_sdk::connect()?;
 
     let version = client
-        .container(None)
-        .from(""golang:1.19"".into())
-        .with_exec(vec![""go"".into(), ""version"".into()], None)
+        .container()
+        .from(""golang:1.19"")
+        .with_exec(vec![""go"", ""version""])
         .stdout()?;
 
     println!(""Hello from Dagger and {}"", version.trim());
",2,"[""174f25214caa10ec643db6c81aaa0f3511bf78f4"", ""04e70ce964b343e28b3dbd0c46d10ccda958ab8c""]","[""fix"", ""docs""]"
switch to throwing errors | permission check | Publish crates,"diff --git a/src/background/sync-manager/services/shanbay/index.ts b/src/background/sync-manager/services/shanbay/index.ts
index 651fd1b..de17a45 100644
--- a/src/background/sync-manager/services/shanbay/index.ts
+++ b/src/background/sync-manager/services/shanbay/index.ts
@@ -24,7 +24,7 @@ export class Service extends SyncService<SyncConfig> {
 
   async init() {
     if (!(await this.isLogin())) {
-      return Promise.reject('login')
+      throw new Error('login')
     }
 
     await setSyncConfig<SyncConfig>(Service.id, this.config)
@@ -85,11 +85,11 @@ export class Service extends SyncService<SyncConfig> {
         encodeURIComponent(text)
       var resSearch = await fetch(url).then(r => r.json())
     } catch (e) {
-      return Promise.reject('network')
+      throw new Error('network')
     }
 
     if (!resSearch || !resSearch.data) {
-      return Promise.reject('word')
+      throw new Error('word')
     }
 
     try {
@@ -104,11 +104,14 @@ export class Service extends SyncService<SyncConfig> {
         }
       ).then(r => r.json())
     } catch (e) {
-      return Promise.reject('network')
+      if (process.env.DEBUG) {
+        console.error(e)
+      }
+      throw new Error('network')
     }
 
     if (!resLearning || resLearning.status_code !== 0) {
-      return Promise.reject('word')
+      throw new Error('word')
     }
   }
 

diff --git a/server/src/routes/course/index.ts b/server/src/routes/course/index.ts
index 557f5fb..bc0e490 100644
--- a/server/src/routes/course/index.ts
+++ b/server/src/routes/course/index.ts
@@ -209,7 +209,7 @@ function addStudentApi(router: Router, logger: ILogger) {
   router.post('/student/:githubId/status', ...mentorValidators, updateStudentStatus(logger));
   router.post('/student/:githubId/status-self', courseGuard, selfUpdateStudentStatus(logger));
   router.get('/student/:githubId/score', courseGuard, getScoreByStudent(logger));
-  router.post('/student/:githubId/certificate', courseManagerGuard, ...validators, postStudentCertificate(logger));
+  router.post('/student/:githubId/certificate', courseManagerGuard, validateGithubId, postStudentCertificate(logger));
 
   router.get('/students', courseSupervisorGuard, getStudents(logger));
   router.get('/students/csv', courseSupervisorGuard, getStudentsCsv(logger));

diff --git a/CHANGELOG.md b/CHANGELOG.md
index 7b98b44..f17ad6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -7,6 +7,9 @@
 
 - **(css/parser)** Fix parsing of at rules (#3328) ([506a310](https://github.com/swc-project/swc/commit/506a31078aaebf50129658f096bbd5929995205f))
 
+
+- **(es/compat)** Fix regression of `destructuring` (#3326) ([6d1ad36](https://github.com/swc-project/swc/commit/6d1ad368aca53ee64a63ae565cd015909f2f4458))
+
 ### Performance
 
 
diff --git a/Cargo.lock b/Cargo.lock
index 3c6598b..4baa252 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -2652,7 +2652,7 @@ dependencies = [
 
 [[package]]
 name = ""swc""
-version = ""0.116.15""
+version = ""0.116.16""
 dependencies = [
  ""ahash"",
  ""anyhow"",
@@ -3097,7 +3097,7 @@ dependencies = [
 
 [[package]]
 name = ""swc_ecma_transforms""
-version = ""0.113.3""
+version = ""0.113.4""
 dependencies = [
  ""pretty_assertions 0.7.2"",
  ""sourcemap"",
@@ -3157,7 +3157,7 @@ dependencies = [
 
 [[package]]
 name = ""swc_ecma_transforms_compat""
-version = ""0.68.2""
+version = ""0.68.3""
 dependencies = [
  ""ahash"",
  ""arrayvec 0.7.2"",
@@ -3366,7 +3366,7 @@ dependencies = [
 
 [[package]]
 name = ""swc_ecmascript""
-version = ""0.110.14""
+version = ""0.110.15""
 dependencies = [
  ""swc_ecma_ast"",
  ""swc_ecma_codegen"",
diff --git a/crates/swc/Cargo.toml b/crates/swc/Cargo.toml
index 756cfc8..2f02d22 100644
--- a/crates/swc/Cargo.toml
+++ b/crates/swc/Cargo.toml
@@ -9,7 +9,7 @@ include = [""Cargo.toml"", ""src/**/*.rs""]
 license = ""Apache-2.0""
 name = ""swc""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.116.15""
+version = ""0.116.16""
 
 [lib]
 name = ""swc""
@@ -55,7 +55,7 @@ swc_ecma_loader = {version = ""0.27.0"", path = ""../swc_ecma_loader"", features = [
 swc_ecma_minifier = {version = ""0.70.9"", path = ""../swc_ecma_minifier""}
 swc_ecma_parser = {version = ""0.87.0"", path = ""../swc_ecma_parser""}
 swc_ecma_preset_env = {version = ""0.86.1"", path = ""../swc_ecma_preset_env""}
-swc_ecma_transforms = {version = ""0.113.3"", path = ""../swc_ecma_transforms"", features = [
+swc_ecma_transforms = {version = ""0.113.4"", path = ""../swc_ecma_transforms"", features = [
   ""compat"",
   ""module"",
   ""optimization"",
@@ -64,11 +64,11 @@ swc_ecma_transforms = {version = ""0.113.3"", path = ""../swc_ecma_transforms"", fea
   ""typescript"",
 ]}
 swc_ecma_transforms_base = {version = ""0.57.1"", path = ""../swc_ecma_transforms_base""}
-swc_ecma_transforms_compat = {version = ""0.68.2"", path = ""../swc_ecma_transforms_compat""}
+swc_ecma_transforms_compat = {version = ""0.68.3"", path = ""../swc_ecma_transforms_compat""}
 swc_ecma_transforms_optimization = {version = ""0.83.0"", path = ""../swc_ecma_transforms_optimization""}
 swc_ecma_utils = {version = ""0.64.0"", path = ""../swc_ecma_utils""}
 swc_ecma_visit = {version = ""0.51.1"", path = ""../swc_ecma_visit""}
-swc_ecmascript = {version = ""0.110.14"", path = ""../swc_ecmascript""}
+swc_ecmascript = {version = ""0.110.15"", path = ""../swc_ecmascript""}
 swc_node_comments = {version = ""0.4.0"", path = ""../swc_node_comments""}
 swc_plugin_runner = {version = ""0.30.0"", path = ""../swc_plugin_runner"", optional = true}
 swc_visit = {version = ""0.3.0"", path = ""../swc_visit""}
diff --git a/crates/swc_ecma_transforms/Cargo.toml b/crates/swc_ecma_transforms/Cargo.toml
index 1604f4e..a0aafae 100644
--- a/crates/swc_ecma_transforms/Cargo.toml
+++ b/crates/swc_ecma_transforms/Cargo.toml
@@ -6,7 +6,7 @@ edition = ""2021""
 license = ""Apache-2.0""
 name = ""swc_ecma_transforms""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.113.3""
+version = ""0.113.4""
 
 [package.metadata.docs.rs]
 all-features = true
@@ -28,7 +28,7 @@ swc_common = {version = ""0.17.0"", path = ""../swc_common""}
 swc_ecma_ast = {version = ""0.65.0"", path = ""../swc_ecma_ast""}
 swc_ecma_parser = {version = ""0.87.0"", path = ""../swc_ecma_parser""}
 swc_ecma_transforms_base = {version = ""0.57.1"", path = ""../swc_ecma_transforms_base""}
-swc_ecma_transforms_compat = {version = ""0.68.2"", path = ""../swc_ecma_transforms_compat"", optional = true}
+swc_ecma_transforms_compat = {version = ""0.68.3"", path = ""../swc_ecma_transforms_compat"", optional = true}
 swc_ecma_transforms_module = {version = ""0.74.0"", path = ""../swc_ecma_transforms_module"", optional = true}
 swc_ecma_transforms_optimization = {version = ""0.83.0"", path = ""../swc_ecma_transforms_optimization"", optional = true}
 swc_ecma_transforms_proposal = {version = ""0.74.0"", path = ""../swc_ecma_transforms_proposal"", optional = true}
diff --git a/crates/swc_ecma_transforms_compat/Cargo.toml b/crates/swc_ecma_transforms_compat/Cargo.toml
index 0ea6609..58374e3 100644
--- a/crates/swc_ecma_transforms_compat/Cargo.toml
+++ b/crates/swc_ecma_transforms_compat/Cargo.toml
@@ -6,7 +6,7 @@ edition = ""2021""
 license = ""Apache-2.0""
 name = ""swc_ecma_transforms_compat""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.68.2""
+version = ""0.68.3""
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [features]
diff --git a/crates/swc_ecmascript/Cargo.toml b/crates/swc_ecmascript/Cargo.toml
index 63680a0..775208a 100644
--- a/crates/swc_ecmascript/Cargo.toml
+++ b/crates/swc_ecmascript/Cargo.toml
@@ -6,7 +6,7 @@ edition = ""2021""
 license = ""Apache-2.0""
 name = ""swc_ecmascript""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.110.14""
+version = ""0.110.15""
 
 [package.metadata.docs.rs]
 all-features = true
@@ -39,7 +39,7 @@ swc_ecma_dep_graph = {version = ""0.58.0"", path = ""../swc_ecma_dep_graph"", option
 swc_ecma_minifier = {version = ""0.70.9"", path = ""../swc_ecma_minifier"", optional = true}
 swc_ecma_parser = {version = ""0.87.0"", path = ""../swc_ecma_parser"", optional = true, default-features = false}
 swc_ecma_preset_env = {version = ""0.86.1"", path = ""../swc_ecma_preset_env"", optional = true}
-swc_ecma_transforms = {version = ""0.113.3"", path = ""../swc_ecma_transforms"", optional = true}
+swc_ecma_transforms = {version = ""0.113.4"", path = ""../swc_ecma_transforms"", optional = true}
 swc_ecma_utils = {version = ""0.64.0"", path = ""../swc_ecma_utils"", optional = true}
 swc_ecma_visit = {version = ""0.51.1"", path = ""../swc_ecma_visit"", optional = true}
 
",3,"[""c527037074641064d267f46c1350bb2afc48320e"", ""33c25b2f59c931a7f4af994365522221a7821dca"", ""af53b9487f74ff28438928903fb1f2db93fe4fa8""]","[""refactor"", ""fix"", ""build""]"
allow disabling dynamic queue,"diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);
",1,"[""9ef5c0d14193a9abb09b39856f58477d1f4b0d77""]","[""fix""]"
added suported tuple types,"diff --git a/src/List/Tuple.ts b/src/List/Tuple.ts
index 4c59caa..6e45503 100644
--- a/src/List/Tuple.ts
+++ b/src/List/Tuple.ts
@@ -1,15 +1,17 @@
-/** A [[Tuple]]
+import {NonNullable} from '../Object/NonNullable'
+
+/** A [[Tuple]] (supported)
  * @param A its type
- * @returns **`any[]`**
+ * @returns **`A[]`**
  * @example
  * ```ts
- * type list0 = [1, 2, 3]
- * type list1 = number[]
+ * type tuple0 = [1, 20, 42]
+ * type tuple1 = ['at', 420]
  * ```
  */
-export type Tuple = [
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-]
+export type Tuple<A = any> = NonNullable<[
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+]>
",1,"[""2954a0955ce9af6acb345ed1e8328e145ad30475""]","[""refactor""]"
"remove deprecated settings

Removes deprecated ZEEBE_HOST environment variable, and removes
unnecessary log level environment variable, since it's already the
default in the log file | switch to callback ref","diff --git a/Dockerfile b/Dockerfile
index 6762a39..7f380cd 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -34,7 +34,6 @@ RUN wget -O - https://github.com/jvm-profiling-tools/async-profiler/releases/dow
 FROM ${APP_ENV} as app
 
 ENV ZB_HOME=/usr/local/zeebe \
-    ZEEBE_LOG_LEVEL=info \
     ZEEBE_BROKER_GATEWAY_NETWORK_HOST=0.0.0.0 \
     ZEEBE_STANDALONE_GATEWAY=false
 ENV PATH ""${ZB_HOME}/bin:${PATH}""
diff --git a/docker/utils/startup.sh b/docker/utils/startup.sh
index bc8d2fc..0fcde2b 100755
--- a/docker/utils/startup.sh
+++ b/docker/utils/startup.sh
@@ -1,17 +1,14 @@
 #!/bin/bash -xeu
 
-# legacy support
-# This environment variable was used to set the gatewway cluster host in standalone and embedded mode.
-# Now, there are two dedicated environment variables for the two different deployment scenarios.
-export ZEEBE_HOST=${ZEEBE_HOST:-$(hostname -i)}
-# Legacy support
+HOST=$(hostname -i)
 
 if [ ""$ZEEBE_STANDALONE_GATEWAY"" = ""true"" ]; then
-    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_GATEWAY_NETWORK_HOST=${ZEEBE_GATEWAY_NETWORK_HOST:-${HOST}}
+    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${HOST}}
 
     exec /usr/local/zeebe/bin/gateway
 else
-    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${HOST}}
     export ZEEBE_BROKER_GATEWAY_CLUSTER_HOST=${ZEEBE_BROKER_GATEWAY_CLUSTER_HOST:-${ZEEBE_BROKER_NETWORK_HOST}}
 
     exec /usr/local/zeebe/bin/broker

diff --git a/src/notebook/components/transforms/html.js b/src/notebook/components/transforms/html.js
index 83fc1fb..021cc65 100644
--- a/src/notebook/components/transforms/html.js
+++ b/src/notebook/components/transforms/html.js
@@ -8,16 +8,16 @@ type Props = {
 
 export default class HTMLDisplay extends React.Component {
   props: Props;
+  el: HTMLElement;
 
   componentDidMount(): void {
-    if (this.refs.here) {
-      if (document.createRange && Range && Range.prototype.createContextualFragment) {
-        const range = document.createRange();
-        const fragment = range.createContextualFragment(this.props.data);
-        ReactDOM.findDOMNode(this.refs.here).appendChild(fragment);
-      } else {
-        ReactDOM.findDOMNode(this.refs.here).innerHTML = this.props.data;
-      }
+    // Create a range to ensure that scripts are invoked from within the HTML
+    if (document.createRange && Range && Range.prototype.createContextualFragment) {
+      const range = document.createRange();
+      const fragment = range.createContextualFragment(this.props.data);
+      this.el.appendChild(fragment);
+    } else {
+      this.el.innerHTML = this.props.data;
     }
   }
 
@@ -27,7 +27,7 @@ export default class HTMLDisplay extends React.Component {
 
   render(): ?React.Element<any> {
     return (
-      <div ref=""here"" />
+      <div ref={(el) => { this.el = el; }} />
     );
   }
 }
",2,"[""e4a11fd5c34942ba12737f1c8c084489428ee274"", ""ee4bf61fb8836e249fb4ef3507dc938e70696b3f""]","[""build"", ""refactor""]"
"remove duplicated variables | add jackson dependencies for zb-bpmn-model | add hardware back button

Closes #5071","diff --git a/packages/core/src/components/item/item.ios.scss b/packages/core/src/components/item/item.ios.scss
index 4de5455..6c4d11a 100644
--- a/packages/core/src/components/item/item.ios.scss
+++ b/packages/core/src/components/item/item.ios.scss
@@ -47,15 +47,6 @@ $item-ios-detail-push-color:              $list-ios-border-color !default;
 /// @prop - Icon for the detail arrow
 $item-ios-detail-push-svg:                ""<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 12 20'><path d='M2,20l-2-2l8-8L0,2l2-2l10,10L2,20z' fill='#{$item-ios-detail-push-color}'/></svg>"" !default;
 
-/// @prop - Background for the divider
-$item-ios-divider-background:             #f7f7f7 !default;
-
-/// @prop - Color for the divider
-$item-ios-divider-color:                  #222 !default;
-
-/// @prop - Padding for the divider
-$item-ios-divider-padding:                5px 15px !default;
-
 
 // iOS Item
 // --------------------------------------------------
diff --git a/packages/core/src/components/item/item.md.scss b/packages/core/src/components/item/item.md.scss
index 1dd1800..3dadbc0 100644
--- a/packages/core/src/components/item/item.md.scss
+++ b/packages/core/src/components/item/item.md.scss
@@ -35,21 +35,6 @@ $item-md-detail-push-color:          $list-md-border-color !default;
 /// @prop - Icon for the detail arrow
 $item-md-detail-push-svg:            ""<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 12 20'><path d='M2,20l-2-2l8-8L0,2l2-2l10,10L2,20z' fill='#{$item-md-detail-push-color}'/></svg>"" !default;
 
-/// @prop - Color for the divider
-$item-md-divider-color:              #858585 !default;
-
-/// @prop - Background for the divider
-$item-md-divider-background:         #fff !default;
-
-/// @prop - Font size for the divider
-$item-md-divider-font-size:          $item-md-body-text-font-size !default;
-
-/// @prop - Border bottom for the divider
-$item-md-divider-border-bottom:      1px solid $list-md-border-color !default;
-
-/// @prop - Padding for the divider
-$item-md-divider-padding:            5px 15px !default;
-
 
 .item-md {
   @include padding-horizontal($item-md-padding-start, 0);
diff --git a/packages/core/src/components/item/item.wp.scss b/packages/core/src/components/item/item.wp.scss
index 2c4aae6..07b9266 100644
--- a/packages/core/src/components/item/item.wp.scss
+++ b/packages/core/src/components/item/item.wp.scss
@@ -41,21 +41,6 @@ $item-wp-detail-push-color:          $input-wp-border-color !default;
 /// @prop - Icon for the detail arrow
 $item-wp-detail-push-svg:            ""<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 12 20'><path d='M2,20l-2-2l8-8L0,2l2-2l10,10L2,20z' fill='#{$item-wp-detail-push-color}'/></svg>"" !default;
 
-/// @prop - Color for the divider
-$item-wp-divider-color:              $list-wp-text-color !default;
-
-/// @prop - Background for the divider
-$item-wp-divider-background:         #fff !default;
-
-/// @prop - Bodrer bottom for the divider
-$item-wp-divider-border-bottom:      1px solid $list-wp-border-color !default;
-
-/// @prop - Font size for the divider
-$item-wp-divider-font-size:          2rem !default;
-
-/// @prop - Padding for the divider
-$item-wp-divider-padding:            5px 15px !default;
-
 
 .item-wp {
   @include padding-horizontal($item-wp-padding-start, 0);

diff --git a/parent/pom.xml b/parent/pom.xml
index d475131..6290e66 100644
--- a/parent/pom.xml
+++ b/parent/pom.xml
@@ -35,6 +35,7 @@
     <version.mockito>1.8.5</version.mockito>
     <version.assertj>3.8.0</version.assertj>
     <version.msgpack>0.8.13</version.msgpack>
+    <version.jackson>2.9.0</version.jackson>
     <version.jmh>1.11.2</version.jmh>
     <version.sbe>1.5.6</version.sbe>
     <version.slf4j>1.7.23</version.slf4j>
@@ -64,6 +65,18 @@
       </dependency>
 
       <dependency>
+        <groupId>com.fasterxml.jackson.core</groupId>
+        <artifactId>jackson-databind</artifactId>
+        <version>${version.jackson}</version>
+      </dependency>
+
+      <dependency>
+        <groupId>com.fasterxml.jackson.dataformat</groupId>
+        <artifactId>jackson-dataformat-yaml</artifactId>
+        <version>${version.jackson}</version>
+      </dependency>
+
+      <dependency>
         <groupId>org.msgpack</groupId>
         <artifactId>msgpack-core</artifactId>
         <version>${version.msgpack}</version>

diff --git a/ionic/components/app/app.ts b/ionic/components/app/app.ts
index 04d8c57..08aab92 100644
--- a/ionic/components/app/app.ts
+++ b/ionic/components/app/app.ts
@@ -3,8 +3,7 @@ import {Title} from 'angular2/platform/browser';
 
 import {Config} from '../../config/config';
 import {ClickBlock} from '../../util/click-block';
-import {Nav} from '../nav/nav';
-import {Tabs} from '../tabs/tabs';
+import {Platform} from '../../platform/platform';
 
 
 /**
@@ -23,8 +22,20 @@ export class IonicApp {
 
   constructor(
     private _config: Config,
-    private _clickBlock: ClickBlock
-  ) {}
+    private _clickBlock: ClickBlock,
+    platform: Platform
+  ) {
+    platform.backButton.subscribe(() => {
+      let activeNav = this.getActiveNav();
+      if (activeNav) {
+        if (activeNav.length() === 1) {
+          platform.exitApp();
+        } else {
+          activeNav.pop();
+        }
+      }
+    });
+  }
 
   /**
    * Sets the document title.
@@ -102,7 +113,7 @@ export class IonicApp {
   /**
    * @private
    */
-  getActiveNav(): Nav | Tabs {
+  getActiveNav(): any {
     var nav = this._rootNav || null;
     var activeChildNav;
 
",3,"[""cd7e8c3d3549ea05115b3f02586eeba894d86906"", ""fab09655d5cc30727289cc3f26e5396fce235cd3"", ""68278b00450f2679761a2999500f6d87a579376b""]","[""refactor"", ""build"", ""feat""]"
permission check,"diff --git a/server/src/routes/course/index.ts b/server/src/routes/course/index.ts
index 557f5fb..bc0e490 100644
--- a/server/src/routes/course/index.ts
+++ b/server/src/routes/course/index.ts
@@ -209,7 +209,7 @@ function addStudentApi(router: Router, logger: ILogger) {
   router.post('/student/:githubId/status', ...mentorValidators, updateStudentStatus(logger));
   router.post('/student/:githubId/status-self', courseGuard, selfUpdateStudentStatus(logger));
   router.get('/student/:githubId/score', courseGuard, getScoreByStudent(logger));
-  router.post('/student/:githubId/certificate', courseManagerGuard, ...validators, postStudentCertificate(logger));
+  router.post('/student/:githubId/certificate', courseManagerGuard, validateGithubId, postStudentCertificate(logger));
 
   router.get('/students', courseSupervisorGuard, getStudents(logger));
   router.get('/students/csv', courseSupervisorGuard, getStudentsCsv(logger));
",1,"[""33c25b2f59c931a7f4af994365522221a7821dca""]","[""fix""]"
"Adjust test scenario

With the new version of the FEEL engine, a non-existing variable results in `null`. Previously, the evaluation failed
with an error.

To keep the semantics of the test cases, create the incident by failing the job. | correct code comment","diff --git a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
index c0a3472..6a9389b 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
@@ -759,7 +759,7 @@ public final class ProcessExecutionCleanStateTest {
         .withXmlResource(
             Bpmn.createExecutableProcess(PROCESS_ID)
                 .startEvent()
-                .serviceTask(""task"", t -> t.zeebeJobType(""test"").zeebeOutputExpression(""x"", ""y""))
+                .serviceTask(""task"", t -> t.zeebeJobType(""test""))
                 .endEvent()
                 .done())
         .deploy();
@@ -768,7 +768,7 @@ public final class ProcessExecutionCleanStateTest {
     final var processInstanceKey =
         engineRule.processInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    engineRule.job().ofInstance(processInstanceKey).withType(""test"").complete();
+    engineRule.job().ofInstance(processInstanceKey).withType(""test"").withRetries(0).fail();
 
     RecordingExporter.incidentRecords(IncidentIntent.CREATED)
         .withProcessInstanceKey(processInstanceKey)

diff --git a/server/src/db.rs b/server/src/db.rs
index bfc5e17..0fb4d55 100644
--- a/server/src/db.rs
+++ b/server/src/db.rs
@@ -389,7 +389,7 @@ impl Db {
             let partition = LockableCatalogPartition::new(Arc::clone(&self), partition);
 
             // Do lock dance to get a write lock on the partition as well
-            // as on all of the chunks
+            // as on the to-be-dropped chunk.
             let partition = partition.read();
 
             let chunk = self.lockable_chunk(table_name, partition_key, chunk_id)?;
",2,"[""f411e58cd510f8a2b980b2f1932003a0c0e9f8f3"", ""cccdd8a43fea7614f78b6f1dcf1765100928a3db""]","[""test"", ""docs""]"
ignore all markdown files for backend and main test suites,"diff --git a/.github/workflows/ibis-backends-skip-helper.yml b/.github/workflows/ibis-backends-skip-helper.yml
index efd0953..058f8b6 100644
--- a/.github/workflows/ibis-backends-skip-helper.yml
+++ b/.github/workflows/ibis-backends-skip-helper.yml
@@ -7,6 +7,7 @@ on:
     paths:
       - ""docs/**""
       - ""mkdocs.yml""
+      - ""**/*.md""
     branches:
       - master
       - ""*.x.x""
@@ -14,6 +15,7 @@ on:
     paths:
       - ""docs/**""
       - ""mkdocs.yml""
+      - ""**/*.md""
     branches:
       - master
       - ""*.x.x""
diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index d18e62d..144562c 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -3,18 +3,20 @@ name: Backends
 
 on:
   push:
-    # Skip the backend suite if all changes are in the docs directory
+    # Skip the backend suite if all changes are docs
     paths-ignore:
       - ""docs/**""
       - ""mkdocs.yml""
+      - ""**/*.md""
     branches:
       - master
       - ""*.x.x""
   pull_request:
-    # Skip the backend suite if all changes are in the docs directory
+    # Skip the backend suite if all changes are docs
     paths-ignore:
       - ""docs/**""
       - ""mkdocs.yml""
+      - ""**/*.md""
     branches:
       - master
       - ""*.x.x""
diff --git a/.github/workflows/ibis-main-skip-helper.yml b/.github/workflows/ibis-main-skip-helper.yml
index f6086e1..7d79af7 100644
--- a/.github/workflows/ibis-main-skip-helper.yml
+++ b/.github/workflows/ibis-main-skip-helper.yml
@@ -7,6 +7,7 @@ on:
     paths:
       - ""docs/**""
       - ""mkdocs.yml""
+      - ""**/*.md""
     branches:
       - master
       - ""*.x.x""
@@ -14,6 +15,7 @@ on:
     paths:
       - ""docs/**""
       - ""mkdocs.yml""
+      - ""**/*.md""
     branches:
       - master
       - ""*.x.x""
diff --git a/.github/workflows/ibis-main.yml b/.github/workflows/ibis-main.yml
index d5b0735..3d22bff 100644
--- a/.github/workflows/ibis-main.yml
+++ b/.github/workflows/ibis-main.yml
@@ -7,6 +7,7 @@ on:
     paths-ignore:
       - ""docs/**""
       - ""mkdocs.yml""
+      - ""**/*.md""
     branches:
       - master
       - ""*.x.x""
@@ -15,6 +16,7 @@ on:
     paths-ignore:
       - ""docs/**""
       - ""mkdocs.yml""
+      - ""**/*.md""
     branches:
       - master
       - ""*.x.x""
",1,"[""370830b8c9f971fa537f42308ab5e3ff356919f8""]","[""cicd""]"
"move toolbar to tab content level

Signed-off-by: Pranav C <pranavxc@gmail.com> | update the formatting for python integration example","diff --git a/packages/nc-gui-v2/components.d.ts b/packages/nc-gui-v2/components.d.ts
index f6be04b..cf555ef 100644
--- a/packages/nc-gui-v2/components.d.ts
+++ b/packages/nc-gui-v2/components.d.ts
@@ -201,6 +201,7 @@ declare module '@vue/runtime-core' {
     MdiThumbUp: typeof import('~icons/mdi/thumb-up')['default']
     MdiTrashCan: typeof import('~icons/mdi/trash-can')['default']
     MdiTwitter: typeof import('~icons/mdi/twitter')['default']
+    MdiUpload: typeof import('~icons/mdi/upload')['default']
     MdiUploadOutline: typeof import('~icons/mdi/upload-outline')['default']
     MdiViewListOutline: typeof import('~icons/mdi/view-list-outline')['default']
     MdiWhatsapp: typeof import('~icons/mdi/whatsapp')['default']
diff --git a/packages/nc-gui-v2/components/smartsheet-toolbar/ViewActions.vue b/packages/nc-gui-v2/components/smartsheet-toolbar/ViewActions.vue
index c2c87d3..27c0acc 100644
--- a/packages/nc-gui-v2/components/smartsheet-toolbar/ViewActions.vue
+++ b/packages/nc-gui-v2/components/smartsheet-toolbar/ViewActions.vue
@@ -132,7 +132,7 @@ async function changeLockType(type: LockType) {
   <div>
     <a-dropdown>
       <a-button v-t=""['c:actions']"" class=""nc-actions-menu-btn nc-toolbar-btn"">
-        <div class=""flex gap-2 align-center"">
+        <div class=""flex gap-2 items-center"">
           <component
             :is=""viewIcons[selectedView?.type].icon""
             class=""nc-view-icon group-hover:hidden""
@@ -311,6 +311,6 @@ async function changeLockType(type: LockType) {
 
 <style scoped>
 .nc-locked-menu-item > div {
-  @apply grid grid-cols-[30px,auto] gap-2  p-2 align-center;
+  @apply grid grid-cols-[30px,auto] gap-2  p-2 items-center;
 }
 </style>
diff --git a/packages/nc-gui-v2/components/smartsheet/Toolbar.vue b/packages/nc-gui-v2/components/smartsheet/Toolbar.vue
index 5fa555f..d498871 100644
--- a/packages/nc-gui-v2/components/smartsheet/Toolbar.vue
+++ b/packages/nc-gui-v2/components/smartsheet/Toolbar.vue
@@ -36,7 +36,7 @@ const {isOpen} =useSidebar()
 
     <SmartsheetToolbarSearchData v-if=""(isGrid || isGallery) && !isPublic"" class=""shrink mr-2 ml-2"" />
 
-    <ToggleDrawer v-if=""!isOpen""/>
+    <ToggleDrawer class=""mr-2""/>
 
 
   </div>
diff --git a/packages/nc-gui-v2/components/smartsheet/sidebar/index.vue b/packages/nc-gui-v2/components/smartsheet/sidebar/index.vue
index 896ad62..77aee05 100644
--- a/packages/nc-gui-v2/components/smartsheet/sidebar/index.vue
+++ b/packages/nc-gui-v2/components/smartsheet/sidebar/index.vue
@@ -99,6 +99,7 @@ function onCreate(view: GridType | FormType | KanbanType | GalleryType) {
     class=""relative shadow-md h-full""
     theme=""light""
   >
+    <!--
     <Toolbar
       v-if=""isOpen""
       class=""min-h-[var(--toolbar-height)] max-h-[var(--toolbar-height)]""
@@ -128,7 +129,7 @@ function onCreate(view: GridType | FormType | KanbanType | GalleryType) {
         <div v-if=""!isForm"" class=""dot"" />
       </template>
     </Toolbar>
-
+-->
     <div v-if=""isOpen"" class=""flex-1 flex flex-col"">
       <MenuTop @open-modal=""openModal"" @deleted=""loadViews"" @sorted=""loadViews"" />
 
diff --git a/packages/nc-gui-v2/components/smartsheet/sidebar/toolbar/ToggleDrawer.vue b/packages/nc-gui-v2/components/smartsheet/sidebar/toolbar/ToggleDrawer.vue
index 3e3d78a..8441450 100644
--- a/packages/nc-gui-v2/components/smartsheet/sidebar/toolbar/ToggleDrawer.vue
+++ b/packages/nc-gui-v2/components/smartsheet/sidebar/toolbar/ToggleDrawer.vue
@@ -4,7 +4,7 @@ const { isOpen, toggle } = useSidebar({ storageKey: 'nc-right-sidebar' })
 </script>
 
 <template>
-  <a-tooltip :placement=""isOpen ? 'bottomRight' : 'left'"" :mouse-enter-delay=""0.8"">
+<!--  <a-tooltip :placement=""isOpen ? 'bottomRight' : 'left'"" :mouse-enter-delay=""0.8"">
     <template #title> Toggle sidebar</template>
 
     <div class=""nc-sidebar-right-item hover:after:(bg-primary bg-opacity-75) group nc-sidebar-add-row"">
@@ -14,5 +14,11 @@ const { isOpen, toggle } = useSidebar({ storageKey: 'nc-right-sidebar' })
         @click=""toggle(!isOpen)""
       />
     </div>
-  </a-tooltip>
+  </a-tooltip>-->
+
+  <a-button @click=""toggle(!isOpen)"" size=""small"">
+  <div class=""flex items-center gap-2"">  <MdiMenu/> Views
+  </div>
+  </a-button>
+
 </template>
diff --git a/packages/nc-gui-v2/components/tabs/Smartsheet.vue b/packages/nc-gui-v2/components/tabs/Smartsheet.vue
index 4181996..7b7ec36 100644
--- a/packages/nc-gui-v2/components/tabs/Smartsheet.vue
+++ b/packages/nc-gui-v2/components/tabs/Smartsheet.vue
@@ -83,11 +83,11 @@ watch(isLocked, (nextValue) => (treeViewIsLockedInj.value = nextValue), { immedi
 
             <SmartsheetForm v-else-if=""isForm"" />
           </div>
+          <SmartsheetSidebar class=""nc-right-sidebar"" v-if=""meta"" />
         </div>
       </template>
     </div>
 
-    <SmartsheetSidebar class=""nc-right-sidebar"" v-if=""meta"" />
   </div>
 </template>
 

diff --git a/website/docs/integration/python.md b/website/docs/integration/python.md
index 064cae3..b6b720d 100644
--- a/website/docs/integration/python.md
+++ b/website/docs/integration/python.md
@@ -13,6 +13,7 @@ header = ""All notable changes to this project will be documented in this file.""
 body = ""...""
 footer = ""<!-- generated by git-cliff -->""
 # see [changelog] section for more keys
+
 [tool.git-cliff.git]
 conventional_commits = true
 commit_parsers = []
",2,"[""bf95d5d0b34d32ef2684488feb3de01cb824b2b4"", ""3ee672483790ec71c700907a6e93af4698492026""]","[""refactor"", ""docs""]"
"added resize observer, this will replace window.resize if available","diff --git a/engine/src/Utils/EventListeners.ts b/engine/src/Utils/EventListeners.ts
index 9e7b189..a29cab4 100644
--- a/engine/src/Utils/EventListeners.ts
+++ b/engine/src/Utils/EventListeners.ts
@@ -47,6 +47,7 @@ export class EventListeners {
 
     private canPush: boolean;
     private resizeTimeout?: NodeJS.Timeout;
+    private resizeObserver?: ResizeObserver;
 
     /**
      * Events listener constructor
@@ -144,7 +145,31 @@ export class EventListeners {
         }
 
         if (options.interactivity.events.resize) {
-            manageListener(window, Constants.resizeEvent, this.resizeHandler, add);
+            if (typeof ResizeObserver !== ""undefined"") {
+                if (this.resizeObserver && !add) {
+                    if (container.canvas.element) {
+                        this.resizeObserver.unobserve(container.canvas.element);
+                    }
+
+                    this.resizeObserver.disconnect();
+
+                    delete this.resizeObserver;
+                } else if (!this.resizeObserver && add && container.canvas.element) {
+                    this.resizeObserver = new ResizeObserver((entries) => {
+                        const entry = entries.find((e) => e.target === container.canvas.element);
+
+                        if (!entry) {
+                            return;
+                        }
+
+                        this.handleWindowResize();
+                    });
+
+                    this.resizeObserver.observe(container.canvas.element);
+                }
+            } else {
+                manageListener(window, Constants.resizeEvent, this.resizeHandler, add);
+            }
         }
 
         if (document) {
",1,"[""4197f2654e8767039dbfd66eca34f261ee3d88c8""]","[""feat""]"
add title to badge icon | xfail on to_parquet and to_csv that use pyarrow write options,"diff --git a/kibbeh/src/modules/room/chat/RoomChatList.tsx b/kibbeh/src/modules/room/chat/RoomChatList.tsx
index a7418e6..805a9a4 100644
--- a/kibbeh/src/modules/room/chat/RoomChatList.tsx
+++ b/kibbeh/src/modules/room/chat/RoomChatList.tsx
@@ -16,6 +16,11 @@ interface ChatListProps {
   users: RoomUser[];
 }
 
+interface BadgeIconData {
+  emoji: string,
+  title: string
+}
+
 export const RoomChatList: React.FC<ChatListProps> = ({ room, users }) => {
   const { setData } = useContext(UserPreviewModalContext);
   const { messages, toggleFrozen } = useRoomChatStore();
@@ -48,11 +53,14 @@ export const RoomChatList: React.FC<ChatListProps> = ({ room, users }) => {
   const getBadgeIcon = (m: Message) => {
     const user = users.find((u) => u.id === m.userId);
     const isSpeaker = room.creatorId === user?.id || user?.roomPermissions?.isSpeaker;
-    let emoji = null;
+    let badgeIconData: BadgeIconData | null = null;
     if (isSpeaker) {
-      emoji = """";
+      badgeIconData = {
+        emoji: """",
+        title: ""Speaker""
+      };
     }
-    return emoji && <Twemoji text={emoji} style={{ marginRight: ""1ch"" }}/>;
+    return badgeIconData && <Twemoji text={badgeIconData.emoji} title={badgeIconData.title} style={{ marginRight: ""1ch"" }}/>;
   };
 
   return (

diff --git a/ibis/backends/tests/test_export.py b/ibis/backends/tests/test_export.py
index 4d536d7..5bb9775 100644
--- a/ibis/backends/tests/test_export.py
+++ b/ibis/backends/tests/test_export.py
@@ -222,18 +222,23 @@ def test_table_to_parquet(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs""), [({""version"": ""1.0""}), ({""version"": ""2.6""})])
-def test_table_to_parquet_writer_kwargs(kwargs, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.NotSupportedError,
+)
+@pytest.mark.parametrize(""version"", [""1.0"", ""2.6""])
+def test_table_to_parquet_writer_kwargs(version, tmp_path, backend, awards_players):
     outparquet = tmp_path / ""out.parquet""
-    awards_players.to_parquet(outparquet, **kwargs)
+    awards_players.to_parquet(outparquet, version=version)
 
     df = pd.read_parquet(outparquet)
 
     backend.assert_frame_equal(awards_players.to_pandas(), df)
 
-    file = pa.parquet.ParquetFile(outparquet)
+    md = pa.parquet.read_metadata(outparquet)
 
-    assert file.metadata.format_version == kwargs[""version""]
+    assert md.format_version == version
 
 
 @pytest.mark.notimpl(
@@ -316,14 +321,20 @@ def test_table_to_csv(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs"", ""delimiter""), [({""write_options"": pcsv.WriteOptions(delimiter="";"")}, "";""), ({""write_options"": pcsv.WriteOptions(delimiter=""\t"")}, ""\t"")])
-def test_table_to_csv_writer_kwargs(kwargs, delimiter, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.ProgrammingError,
+)
+@pytest.mark.parametrize(""delimiter"", ["";"", ""\t""], ids=[""semicolon"", ""tab""])
+def test_table_to_csv_writer_kwargs(delimiter, tmp_path, awards_players):
     outcsv = tmp_path / ""out.csv""
     # avoid pandas NaNonense
     awards_players = awards_players.select(""playerID"", ""awardID"", ""yearID"", ""lgID"")
 
-    awards_players.to_csv(outcsv, **kwargs)
-    pd.read_csv(outcsv, delimiter=delimiter)
+    awards_players.to_csv(outcsv, write_options=pcsv.WriteOptions(delimiter=delimiter))
+    df = pd.read_csv(outcsv, delimiter=delimiter, nrows=1)
+    assert len(df) == 1
 
 
 @pytest.mark.parametrize(
",2,"[""6e5098655e6d9bb13f6423abe780cdf6b50ff13a"", ""bedc7950b24c37809e36a585b7985d5aa5e3e458""]","[""feat"", ""test""]"
"rework RaftCommittedEntryListener

Iterate over RaftCommittedEntryListener and refactor the listener such it serves the actual need.

We have some services (to be specific the AsyncSnapshotDirector) which need the committed position, and
want to listen to new updates. In raft we know which record we are committing and whether it was an application record so we can pass this information threw the listeners.

This avoids to pass in the whole IndexedRecord object, and reduce the potential of going out of OOM because of keeping to much data in heap (when commit is not possible). | add hardware back button

Closes #5071 | fix `get-deploy-tags.sh`","diff --git a/atomix/cluster/src/main/java/io/atomix/raft/RaftApplicationEntryCommittedPositionListener.java b/atomix/cluster/src/main/java/io/atomix/raft/RaftApplicationEntryCommittedPositionListener.java
new file mode 100644
index 0000000..57c28a9
--- /dev/null
+++ b/atomix/cluster/src/main/java/io/atomix/raft/RaftApplicationEntryCommittedPositionListener.java
@@ -0,0 +1,31 @@
+/*
+ * Copyright 2016-present Open Networking Foundation
+ * Copyright  2020 camunda services GmbH (info@camunda.com)
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package io.atomix.raft;
+
+/**
+ * This listener will only be called by the Leader, when it commits an application entry.
+ *
+ * <p>If RAFT is currently running in a follower role, it will not call this listener.
+ */
+@FunctionalInterface
+public interface RaftApplicationEntryCommittedPositionListener {
+
+  /**
+   * @param committedPosition the new committed position which is related to the application entries
+   */
+  void onCommit(long committedPosition);
+}
diff --git a/atomix/cluster/src/main/java/io/atomix/raft/RaftCommittedEntryListener.java b/atomix/cluster/src/main/java/io/atomix/raft/RaftCommittedEntryListener.java
deleted file mode 100644
index 3d11d75..0000000
--- a/atomix/cluster/src/main/java/io/atomix/raft/RaftCommittedEntryListener.java
+++ /dev/null
@@ -1,32 +0,0 @@
-/*
- * Copyright 2016-present Open Networking Foundation
- * Copyright  2020 camunda services GmbH (info@camunda.com)
- *
- * Licensed under the Apache License, Version 2.0 (the ""License"");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an ""AS IS"" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package io.atomix.raft;
-
-import io.atomix.raft.storage.log.IndexedRaftLogEntry;
-
-/**
- * This listener will only be called by the Leader, when it commits an entry. If RAFT is currently
- * running in a follower role, it will not call this listener.
- */
-@FunctionalInterface
-public interface RaftCommittedEntryListener {
-
-  /**
-   * @param indexedRaftLogEntry the new committed entry
-   */
-  void onCommit(IndexedRaftLogEntry indexedRaftLogEntry);
-}
diff --git a/atomix/cluster/src/main/java/io/atomix/raft/impl/RaftContext.java b/atomix/cluster/src/main/java/io/atomix/raft/impl/RaftContext.java
index 1f4ee98..c177cb1 100644
--- a/atomix/cluster/src/main/java/io/atomix/raft/impl/RaftContext.java
+++ b/atomix/cluster/src/main/java/io/atomix/raft/impl/RaftContext.java
@@ -27,8 +27,8 @@ import io.atomix.cluster.MemberId;
 import io.atomix.cluster.messaging.MessagingException.NoRemoteHandler;
 import io.atomix.cluster.messaging.MessagingException.NoSuchMemberException;
 import io.atomix.raft.ElectionTimer;
+import io.atomix.raft.RaftApplicationEntryCommittedPositionListener;
 import io.atomix.raft.RaftCommitListener;
-import io.atomix.raft.RaftCommittedEntryListener;
 import io.atomix.raft.RaftError;
 import io.atomix.raft.RaftException.ProtocolException;
 import io.atomix.raft.RaftRoleChangeListener;
@@ -61,7 +61,6 @@ import io.atomix.raft.roles.PromotableRole;
 import io.atomix.raft.roles.RaftRole;
 import io.atomix.raft.storage.RaftStorage;
 import io.atomix.raft.storage.StorageException;
-import io.atomix.raft.storage.log.IndexedRaftLogEntry;
 import io.atomix.raft.storage.log.RaftLog;
 import io.atomix.raft.storage.system.MetaStore;
 import io.atomix.raft.utils.StateUtil;
@@ -115,7 +114,7 @@ public class RaftContext implements AutoCloseable, HealthMonitorable {
   private final Set<Consumer<State>> stateChangeListeners = new CopyOnWriteArraySet<>();
   private final Set<Consumer<RaftMember>> electionListeners = new CopyOnWriteArraySet<>();
   private final Set<RaftCommitListener> commitListeners = new CopyOnWriteArraySet<>();
-  private final Set<RaftCommittedEntryListener> committedEntryListeners =
+  private final Set<RaftApplicationEntryCommittedPositionListener> committedEntryListeners =
       new CopyOnWriteArraySet<>();
   private final Set<SnapshotReplicationListener> snapshotReplicationListeners =
       new CopyOnWriteArraySet<>();
@@ -433,21 +432,23 @@ public class RaftContext implements AutoCloseable, HealthMonitorable {
    * <p>Note that it will be called on the Raft thread, and as such should not perform any heavy
    * computation.
    *
-   * @param raftCommittedEntryListener the listener to add
+   * @param raftApplicationEntryCommittedPositionListener the listener to add
    */
   public void addCommittedEntryListener(
-      final RaftCommittedEntryListener raftCommittedEntryListener) {
-    committedEntryListeners.add(raftCommittedEntryListener);
+      final RaftApplicationEntryCommittedPositionListener
+          raftApplicationEntryCommittedPositionListener) {
+    committedEntryListeners.add(raftApplicationEntryCommittedPositionListener);
   }
 
   /**
    * Removes registered committedEntryListener
    *
-   * @param raftCommittedEntryListener the listener to remove
+   * @param raftApplicationEntryCommittedPositionListener the listener to remove
    */
   public void removeCommittedEntryListener(
-      final RaftCommittedEntryListener raftCommittedEntryListener) {
-    committedEntryListeners.remove(raftCommittedEntryListener);
+      final RaftApplicationEntryCommittedPositionListener
+          raftApplicationEntryCommittedPositionListener) {
+    committedEntryListeners.remove(raftApplicationEntryCommittedPositionListener);
   }
 
   /**
@@ -464,7 +465,7 @@ public class RaftContext implements AutoCloseable, HealthMonitorable {
    *
    * @param committedEntry the most recently committed entry
    */
-  public void notifyCommittedEntryListeners(final IndexedRaftLogEntry committedEntry) {
+  public void notifyApplicationEntryCommittedPositionListeners(final long committedEntry) {
     committedEntryListeners.forEach(listener -> listener.onCommit(committedEntry));
   }
 
diff --git a/atomix/cluster/src/main/java/io/atomix/raft/partition/impl/RaftPartitionServer.java b/atomix/cluster/src/main/java/io/atomix/raft/partition/impl/RaftPartitionServer.java
index 56c7172..d075fca 100644
--- a/atomix/cluster/src/main/java/io/atomix/raft/partition/impl/RaftPartitionServer.java
+++ b/atomix/cluster/src/main/java/io/atomix/raft/partition/impl/RaftPartitionServer.java
@@ -21,8 +21,8 @@ import io.atomix.cluster.MemberId;
 import io.atomix.cluster.messaging.ClusterCommunicationService;
 import io.atomix.primitive.partition.Partition;
 import io.atomix.primitive.partition.PartitionMetadata;
+import io.atomix.raft.RaftApplicationEntryCommittedPositionListener;
 import io.atomix.raft.RaftCommitListener;
-import io.atomix.raft.RaftCommittedEntryListener;
 import io.atomix.raft.RaftRoleChangeListener;
 import io.atomix.raft.RaftServer;
 import io.atomix.raft.RaftServer.Role;
@@ -205,16 +205,20 @@ public class RaftPartitionServer implements HealthMonitorable {
   }
 
   /**
-   * @see io.atomix.raft.impl.RaftContext#addCommittedEntryListener(RaftCommittedEntryListener)
+   * @see
+   *     io.atomix.raft.impl.RaftContext#addCommittedEntryListener(RaftApplicationEntryCommittedPositionListener)
    */
-  public void addCommittedEntryListener(final RaftCommittedEntryListener commitListener) {
+  public void addCommittedEntryListener(
+      final RaftApplicationEntryCommittedPositionListener commitListener) {
     server.getContext().addCommittedEntryListener(commitListener);
   }
 
   /**
-   * @see io.atomix.raft.impl.RaftContext#removeCommittedEntryListener(RaftCommittedEntryListener)
+   * @see
+   *     io.atomix.raft.impl.RaftContext#removeCommittedEntryListener(RaftApplicationEntryCommittedPositionListener)
    */
-  public void removeCommittedEntryListener(final RaftCommittedEntryListener commitListener) {
+  public void removeCommittedEntryListener(
+      final RaftApplicationEntryCommittedPositionListener commitListener) {
     server.getContext().removeCommittedEntryListener(commitListener);
   }
 
diff --git a/atomix/cluster/src/main/java/io/atomix/raft/roles/LeaderRole.java b/atomix/cluster/src/main/java/io/atomix/raft/roles/LeaderRole.java
index e54df1a..fcfd177 100644
--- a/atomix/cluster/src/main/java/io/atomix/raft/roles/LeaderRole.java
+++ b/atomix/cluster/src/main/java/io/atomix/raft/roles/LeaderRole.java
@@ -630,27 +630,47 @@ public final class LeaderRole extends ActiveRole implements ZeebeLogAppender {
 
   private void replicate(final IndexedRaftLogEntry indexed, final AppendListener appendListener) {
     raft.checkThread();
-    appender
-        .appendEntries(indexed.index())
-        .whenCompleteAsync(
-            (commitIndex, commitError) -> {
-              if (!isRunning()) {
-                return;
-              }
+    final var appendEntriesFuture = appender.appendEntries(indexed.index());
+
+    final boolean applicationEntryWasCommitted = indexed.isApplicationEntry();
+    if (applicationEntryWasCommitted) {
+      // We have some services which are waiting for the application records, especially position
+      // to be committed. This is our glue code to notify them, instead of
+      // passing the complete object (IndexedRaftLogEntry) threw the listeners and
+      // keep them in heap until they are committed. This had the risk of going out of OOM
+      // if records can't be committed, see https://github.com/camunda/zeebe/issues/14275
+      final var committedPosition = indexed.getApplicationEntry().highestPosition();
+      appendEntriesFuture.whenCompleteAsync(
+          (commitIndex, commitError) -> {
+            if (!isRunning()) {
+              return;
+            }
+
+            if (commitError == null) {
+              raft.notifyApplicationEntryCommittedPositionListeners(committedPosition);
+            }
+          },
+          raft.getThreadContext());
+    }
 
-              // have the state machine apply the index which should do nothing but ensures it keeps
-              // up to date with the latest entries, so it can handle configuration and initial
-              // entries properly on fail over
-              if (commitError == null) {
-                appendListener.onCommit(indexed.index());
-                raft.notifyCommittedEntryListeners(indexed);
-              } else {
-                appendListener.onCommitError(indexed.index(), commitError);
-                // replicating the entry will be retried on the next append request
-                log.error(""Failed to replicate entry: {}"", indexed, commitError);
-              }
-            },
-            raft.getThreadContext());
+    appendEntriesFuture.whenCompleteAsync(
+        (commitIndex, commitError) -> {
+          if (!isRunning()) {
+            return;
+          }
+
+          // have the state machine apply the index which should do nothing but ensures it keeps
+          // up to date with the latest entries, so it can handle configuration and initial
+          // entries properly on fail over
+          if (commitError == null) {
+            appendListener.onCommit(indexed.index());
+          } else {
+            appendListener.onCommitError(indexed.index(), commitError);
+            // replicating the entry will be retried on the next append request
+            log.error(""Failed to replicate entry: {}"", indexed, commitError);
+          }
+        },
+        raft.getThreadContext());
   }
 
   public synchronized void onInitialEntriesCommitted(final Runnable runnable) {
diff --git a/atomix/cluster/src/test/java/io/atomix/raft/RaftAppendTest.java b/atomix/cluster/src/test/java/io/atomix/raft/RaftAppendTest.java
index b217586..8029766 100644
--- a/atomix/cluster/src/test/java/io/atomix/raft/RaftAppendTest.java
+++ b/atomix/cluster/src/test/java/io/atomix/raft/RaftAppendTest.java
@@ -82,7 +82,7 @@ public class RaftAppendTest {
   @Test
   public void shouldNotifyCommittedEntryListenerOnLeaderOnly() throws Throwable {
     // given
-    final var committedEntryListener = mock(RaftCommittedEntryListener.class);
+    final var committedEntryListener = mock(RaftApplicationEntryCommittedPositionListener.class);
     raftRule.addCommittedEntryListener(committedEntryListener);
 
     // when
diff --git a/atomix/cluster/src/test/java/io/atomix/raft/RaftRule.java b/atomix/cluster/src/test/java/io/atomix/raft/RaftRule.java
index 8f73cba..193a176 100644
--- a/atomix/cluster/src/test/java/io/atomix/raft/RaftRule.java
+++ b/atomix/cluster/src/test/java/io/atomix/raft/RaftRule.java
@@ -644,9 +644,12 @@ public final class RaftRule extends ExternalResource {
   }
 
   public void addCommittedEntryListener(
-      final RaftCommittedEntryListener raftCommittedEntryListener) {
+      final RaftApplicationEntryCommittedPositionListener
+          raftApplicationEntryCommittedPositionListener) {
     servers.forEach(
-        (id, raft) -> raft.getContext().addCommittedEntryListener(raftCommittedEntryListener));
+        (id, raft) ->
+            raft.getContext()
+                .addCommittedEntryListener(raftApplicationEntryCommittedPositionListener));
   }
 
   public void partition(final RaftServer follower) {
diff --git a/broker/src/main/java/io/camunda/zeebe/broker/system/partitions/impl/AsyncSnapshotDirector.java b/broker/src/main/java/io/camunda/zeebe/broker/system/partitions/impl/AsyncSnapshotDirector.java
index a61571f..6c082d7 100644
--- a/broker/src/main/java/io/camunda/zeebe/broker/system/partitions/impl/AsyncSnapshotDirector.java
+++ b/broker/src/main/java/io/camunda/zeebe/broker/system/partitions/impl/AsyncSnapshotDirector.java
@@ -7,8 +7,7 @@
  */
 package io.camunda.zeebe.broker.system.partitions.impl;
 
-import io.atomix.raft.RaftCommittedEntryListener;
-import io.atomix.raft.storage.log.IndexedRaftLogEntry;
+import io.atomix.raft.RaftApplicationEntryCommittedPositionListener;
 import io.camunda.zeebe.broker.system.partitions.NoEntryAtSnapshotPosition;
 import io.camunda.zeebe.broker.system.partitions.StateController;
 import io.camunda.zeebe.logstreams.impl.Loggers;
@@ -36,7 +35,7 @@ import java.util.function.Consumer;
 import org.slf4j.Logger;
 
 public final class AsyncSnapshotDirector extends Actor
-    implements RaftCommittedEntryListener, HealthMonitorable {
+    implements RaftApplicationEntryCommittedPositionListener, HealthMonitorable {
 
   public static final Duration MINIMUM_SNAPSHOT_PERIOD = Duration.ofMinutes(1);
 
@@ -115,7 +114,7 @@ public final class AsyncSnapshotDirector extends Actor
   @Override
   protected void handleFailure(final Throwable failure) {
     LOG.error(
-        ""No snapshot was taken due to failure in '{}'. Will try to take snapshot after snapshot period {}. {}"",
+        ""No snapshot was taken due to failure in '{}'. Will try to take snapshot after snapshot period {}."",
         actorName,
         snapshotRate,
         failure);
@@ -407,13 +406,8 @@ public final class AsyncSnapshotDirector extends Actor
   }
 
   @Override
-  public void onCommit(final IndexedRaftLogEntry indexedRaftLogEntry) {
-    // is called by the Leader Role and gives the last committed entry, where we
-    // can extract the highest position, which corresponds to the last committed position
-    if (indexedRaftLogEntry.isApplicationEntry()) {
-      final var committedPosition = indexedRaftLogEntry.getApplicationEntry().highestPosition();
-      newPositionCommitted(committedPosition);
-    }
+  public void onCommit(final long committedPosition) {
+    newPositionCommitted(committedPosition);
   }
 
   public void newPositionCommitted(final long currentCommitPosition) {

diff --git a/ionic/components/app/app.ts b/ionic/components/app/app.ts
index 04d8c57..08aab92 100644
--- a/ionic/components/app/app.ts
+++ b/ionic/components/app/app.ts
@@ -3,8 +3,7 @@ import {Title} from 'angular2/platform/browser';
 
 import {Config} from '../../config/config';
 import {ClickBlock} from '../../util/click-block';
-import {Nav} from '../nav/nav';
-import {Tabs} from '../tabs/tabs';
+import {Platform} from '../../platform/platform';
 
 
 /**
@@ -23,8 +22,20 @@ export class IonicApp {
 
   constructor(
     private _config: Config,
-    private _clickBlock: ClickBlock
-  ) {}
+    private _clickBlock: ClickBlock,
+    platform: Platform
+  ) {
+    platform.backButton.subscribe(() => {
+      let activeNav = this.getActiveNav();
+      if (activeNav) {
+        if (activeNav.length() === 1) {
+          platform.exitApp();
+        } else {
+          activeNav.pop();
+        }
+      }
+    });
+  }
 
   /**
    * Sets the document title.
@@ -102,7 +113,7 @@ export class IonicApp {
   /**
    * @private
    */
-  getActiveNav(): Nav | Tabs {
+  getActiveNav(): any {
     var nav = this._rootNav || null;
     var activeChildNav;
 

diff --git a/.circleci/get-deploy-tags.sh b/.circleci/get-deploy-tags.sh
index f80c8cb..7ddfa62 100755
--- a/.circleci/get-deploy-tags.sh
+++ b/.circleci/get-deploy-tags.sh
@@ -20,7 +20,7 @@
 set -euo pipefail
 
 DOCKER_IMAGE_TAG=${1}
-DOCKER_IMAGE=""quay.io/influxdb/fusion""
+DOCKER_IMAGE=""quay.io/influxdb/iox""
 APP_NAME=""IOx""
 
 DOCKER_IMAGE_DIGEST=""$(docker image inspect ""${DOCKER_IMAGE}:${DOCKER_IMAGE_TAG}"" --format '{{ if eq (len .RepoDigests) 1 }}{{index .RepoDigests 0}}{{ end }}')""
",3,"[""323cf81961cdd3748a7ba6ba470ecb13e5374e9f"", ""68278b00450f2679761a2999500f6d87a579376b"", ""6786fd5955b064021f5b6d6a630453351d683fae""]","[""refactor"", ""feat"", ""cicd""]"
"remove unnecessary import | Use arm64v8 postfix for Cube Store :dev build | assist build

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>","diff --git a/transport/src/main/java/io/camunda/zeebe/transport/stream/impl/LogicalId.java b/transport/src/main/java/io/camunda/zeebe/transport/stream/impl/LogicalId.java
index 14c6f30..ebaef60 100644
--- a/transport/src/main/java/io/camunda/zeebe/transport/stream/impl/LogicalId.java
+++ b/transport/src/main/java/io/camunda/zeebe/transport/stream/impl/LogicalId.java
@@ -8,7 +8,6 @@
 package io.camunda.zeebe.transport.stream.impl;
 
 import io.camunda.zeebe.util.buffer.BufferUtil;
-import org.agrona.BitUtil;
 import org.agrona.concurrent.UnsafeBuffer;
 
 /**

diff --git a/.github/workflows/rust-cubestore-master.yml b/.github/workflows/rust-cubestore-master.yml
index 4a84984..bb07cd7 100644
--- a/.github/workflows/rust-cubestore-master.yml
+++ b/.github/workflows/rust-cubestore-master.yml
@@ -115,9 +115,9 @@ jobs:
           if [[ $VERSION =~ ^v[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]]; then
             MINOR=${VERSION%.*}
             MAJOR=${MINOR%.*}
-            TAGS=""$TAGS,${DOCKER_IMAGE}:${MINOR},${DOCKER_IMAGE}:${MAJOR},${DOCKER_IMAGE}:latest""
+            TAGS=""$TAGS,${DOCKER_IMAGE}:${MINOR},${DOCKER_IMAGE}:${MAJOR}""
           elif [ ""${{ github.event_name }}"" = ""push"" ]; then
-            TAGS=""$TAGS,${DOCKER_IMAGE}:build-1${GITHUB_RUN_NUMBER}""
+            TAGS=""$TAGS,${DOCKER_IMAGE}:build-1${GITHUB_RUN_NUMBER}${{ matrix.postfix }}""
           fi
 
           echo ::set-output name=version::${VERSION}

diff --git a/scripts/helmcharts/build_deploy.sh b/scripts/helmcharts/build_deploy.sh
index 4a484f2..f9f8f9f 100644
--- a/scripts/helmcharts/build_deploy.sh
+++ b/scripts/helmcharts/build_deploy.sh
@@ -24,7 +24,7 @@ echo $DOCKER_REPO
     docker login $DOCKER_REPO
     cd ../../backend
     bash build.sh $@
-    cd ../../assist-stats/
+    cd ../assist-stats/
     bash build.sh $@
     cd ../assist
     bash build.sh $@
diff --git a/scripts/helmcharts/build_deploy_parallel.sh b/scripts/helmcharts/build_deploy_parallel.sh
index 47ada0c..cb4e3f4 100644
--- a/scripts/helmcharts/build_deploy_parallel.sh
+++ b/scripts/helmcharts/build_deploy_parallel.sh
@@ -15,7 +15,7 @@ export PUSH_IMAGE=1
 export AWS_DEFAULT_REGION=""eu-central-1""
 export SIGN_KEY=""awskms:///alias/openreplay-container-sign""
 echo $DOCKER_REPO
-[[ -z DOCKER_REPO ]] && {
+[[ -z $DOCKER_REPO ]] && {
     echo Set DOCKER_REPO=""your docker registry""
     exit 1
 } || {
@@ -30,7 +30,8 @@ echo $DOCKER_REPO
     tmux split-window ""cd ../../sourcemap-reader && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux split-window ""cd ../../api && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@ \
       && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_alerts.sh $@ \
-      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@""
+      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@ \
+      && cd ../assist-stats && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux select-layout tiled
 
 }
",3,"[""84529bcb10c6fe02e2c0079d069ab6c6ac7683d6"", ""10bdcb452ff9d2b884d45a9c43a4b8a20fc4a883"", ""1269431c8a3e7549f10fcbbb4b88ff625c8898b3""]","[""refactor"", ""cicd"", ""build""]"
"disable edit/delete if primary key missing

Signed-off-by: Pranav C <pranavxc@gmail.com> | add gitignore.nix to dep update matrix | updated webpack in react","diff --git a/packages/nc-gui/components/project/spreadsheet/components/expandedForm.vue b/packages/nc-gui/components/project/spreadsheet/components/expandedForm.vue
index 5f9841f..c414c8c 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/expandedForm.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/expandedForm.vue
@@ -413,6 +413,9 @@ export default {
 
           await this.reload()
         } else if (Object.keys(updatedObj).length) {
+          if (!id) {
+            return this.$toast.info('Update not allowed for table which doesn\'t have primary Key').goAway(3000)
+          }
           await this.api.update(id, updatedObj, this.oldRow)
         } else {
           return this.$toast.info('No columns to update').goAway(3000)
diff --git a/packages/nc-gui/components/project/spreadsheet/rowsXcDataTable.vue b/packages/nc-gui/components/project/spreadsheet/rowsXcDataTable.vue
index c2b4b81..1b9d6a0 100644
--- a/packages/nc-gui/components/project/spreadsheet/rowsXcDataTable.vue
+++ b/packages/nc-gui/components/project/spreadsheet/rowsXcDataTable.vue
@@ -62,7 +62,15 @@
       <v-spacer class=""h-100"" @dblclick=""debug=true"" />
 
       <debug-metas v-if=""debug"" class=""mr-3"" />
-
+      <v-tooltip bottom>
+        <template #activator=""{on}"">
+          <v-icon v-if=""!isPkAvail"" color=""warning"" small class=""mr-3"" v-on=""on"">
+            mdi-information-outline
+          </v-icon>
+        </template>
+        <span class=""caption"">          Update & Delete not allowed since the table doesn't have any primary key
+        </span>
+      </v-tooltip>
       <lock-menu v-if=""_isUIAllowed('view-type')"" v-model=""viewStatus.type"" />
       <x-btn tooltip=""Reload view data"" outlined small text @click=""reload"">
         <v-icon small class=""mr-1"" color=""grey  darken-3"">
@@ -208,6 +216,7 @@
               :meta=""meta""
               :is-virtual=""selectedView.type === 'vtable'""
               :api=""api""
+              :is-pk-avail=""isPkAvail""
               @onNewColCreation=""onNewColCreation""
               @onCellValueChange=""onCellValueChange""
               @insertNewRow=""insertNewRow""
@@ -631,8 +640,8 @@ export default {
       if (
         !this.meta || (
           (this.meta.hasMany && this.meta.hasMany.length) ||
-        (this.meta.manyToMany && this.meta.manyToMany.length) ||
-        (this.meta.belongsTo && this.meta.belongsTo.length))
+          (this.meta.manyToMany && this.meta.manyToMany.length) ||
+          (this.meta.belongsTo && this.meta.belongsTo.length))
       ) {
         return this.$toast.info('Please delete relations before deleting table.').goAway(3000)
       }
@@ -817,6 +826,10 @@ export default {
 
           const id = this.meta.columns.filter(c => c.pk).map(c => rowObj[c._cn]).join('___')
 
+          if (!id) {
+            return this.$toast.info('Update not allowed for table which doesn\'t have primary Key').goAway(3000)
+          }
+
           const newData = await this.api.update(id, {
             [column._cn]: rowObj[column._cn]
           }, { [column._cn]: oldRow[column._cn] })
@@ -841,6 +854,11 @@ export default {
         const rowObj = this.rowContextMenu.row
         if (!this.rowContextMenu.rowMeta.new) {
           const id = this.meta && this.meta.columns && this.meta.columns.filter(c => c.pk).map(c => rowObj[c._cn]).join('___')
+
+          if (!id) {
+            return this.$toast.info('Delete not allowed for table which doesn\'t have primary Key').goAway(3000)
+          }
+
           await this.api.delete(id)
         }
         this.data.splice(this.rowContextMenu.index, 1)
@@ -859,6 +877,11 @@ export default {
           }
           if (!rowMeta.new) {
             const id = this.meta.columns.filter(c => c.pk).map(c => rowObj[c._cn]).join('___')
+
+            if (!id) {
+              return this.$toast.info('Delete not allowed for table which doesn\'t have primary Key').goAway(3000)
+            }
+
             await this.api.delete(id)
           }
           this.data.splice(row, 1)
@@ -991,6 +1014,9 @@ export default {
     }
   },
   computed: {
+    isPkAvail() {
+      return this.meta && this.meta.columns.some(c => c.pk)
+    },
     isGallery() {
       return this.selectedView && this.selectedView.show_as === 'gallery'
     },
diff --git a/packages/nc-gui/components/project/spreadsheet/views/xcGridView.vue b/packages/nc-gui/components/project/spreadsheet/views/xcGridView.vue
index 5497d05..c198784 100644
--- a/packages/nc-gui/components/project/spreadsheet/views/xcGridView.vue
+++ b/packages/nc-gui/components/project/spreadsheet/views/xcGridView.vue
@@ -27,7 +27,7 @@
             @xcresized=""resizingCol = null""
           >
             <!--            :style=""columnsWidth[col._cn]  ? `min-width:${columnsWidth[col._cn]}; max-width:${columnsWidth[col._cn]}` : ''""
-    -->
+-->
 
             <virtual-header-cell
               v-if=""col.virtual""
@@ -136,13 +136,13 @@
             :key=""row + columnObj.alias""
             class=""cell pointer""
             :class=""{
-              'active' : !isPublicView && selected.col === col && selected.row === row && isEditable ,
+              'active' :!isPublicView && selected.col === col && selected.row === row && isEditable ,
               'primary-column' : primaryValueColumn === columnObj._cn,
               'text-center': isCentrallyAligned(columnObj),
               'required': isRequired(columnObj,rowObj)
             }""
             :data-col=""columnObj.alias""
-            @dblclick=""makeEditable(col,row,columnObj.ai)""
+            @dblclick=""makeEditable(col,row,columnObj.ai,rowMeta)""
             @click=""makeSelected(col,row);""
             @contextmenu=""showRowContextMenu($event,rowObj,rowMeta,row,col, columnObj)""
           >
@@ -162,7 +162,8 @@
 
             <editable-cell
               v-else-if=""
-                !isLocked
+                (isPkAvail ||rowMeta.new) &&
+                  !isLocked
                   && !isPublicView
                   && (editEnabled.col === col && editEnabled.row === row)
                   || enableEditable(columnObj)
@@ -190,11 +191,11 @@
               :db-alias=""nodes.dbAlias""
               :value=""rowObj[columnObj._cn]""
               :sql-ui=""sqlUi""
-              @enableedit=""makeSelected(col,row);makeEditable(col,row,columnObj.ai)""
+              @enableedit=""makeSelected(col,row);makeEditable(col,row,columnObj.ai, rowMeta)""
             />
           </td>
         </tr>
-        <tr v-if=""!isLocked && !isPublicView && isEditable && relationType !== 'bt'"">
+        <tr v-if=""isPkAvail && !isLocked && !isPublicView && isEditable && relationType !== 'bt'"">
           <td :colspan=""visibleColLength + 1"" class=""text-left pointer"" @click=""insertNewRow(true)"">
             <v-tooltip top>
               <template #activator=""{on}"">
@@ -214,7 +215,9 @@
     <!--    <div is=""style"" v-html=""resizeColStyle"" />-->
     <dynamic-style>
       <template v-if=""resizingCol"">
-        [data-col=""{{ resizingCol }}""]{min-width:{{ resizingColWidth }};max-width:{{ resizingColWidth }};width:{{ resizingColWidth }};}
+        [data-col=""{{ resizingCol }}""]{min-width:{{ resizingColWidth }};max-width:{{
+          resizingColWidth
+        }};width:{{ resizingColWidth }};}
       </template>
     </dynamic-style>
   </div>
@@ -261,7 +264,8 @@ export default {
     table: String,
     isVirtual: Boolean,
     isLocked: Boolean,
-    columnsWidth: { type: Object }
+    columnsWidth: { type: Object },
+    isPkAvail: Boolean
   },
   data: () => ({
     resizingCol: null,
@@ -426,6 +430,10 @@ export default {
             return
           }
           if (e.key && e.key.length === 1) {
+            if (!this.isPkAvail && !this.data[this.selected.row].rowMeta.new) {
+              return this.$toast.info('Update not allowed for table which doesn\'t have primary Key').goAway(3000)
+            }
+
             this.$set(this.data[this.selected.row].row, this.availableColumns[this.selected.col]._cn, '')
             this.editEnabled = { ...this.selected }
           }
@@ -466,10 +474,14 @@ export default {
         this.editEnabled = {}
       }
     },
-    makeEditable(col, row) {
+    makeEditable(col, row, _, rowMeta) {
       if (this.isPublicView || !this.isEditable) {
         return
       }
+
+      if (!this.isPkAvail && !rowMeta.new) {
+        return this.$toast.info('Update not allowed for table which doesn\'t have primary Key').goAway(3000)
+      }
       if (this.availableColumns[col].ai) {
         return this.$toast.info('Auto Increment field is not editable').goAway(3000)
       }

diff --git a/.github/workflows/update-deps.yml b/.github/workflows/update-deps.yml
index e0ccd62..1236f58 100644
--- a/.github/workflows/update-deps.yml
+++ b/.github/workflows/update-deps.yml
@@ -13,6 +13,7 @@ jobs:
           - nixpkgs
           - poetry2nix
           - pre-commit-hooks
+          - gitignore.nix
     steps:
       - name: Checkout
         uses: actions/checkout@v2

diff --git a/components/react/package.json b/components/react/package.json
index bbeb9ee..43ddebc 100644
--- a/components/react/package.json
+++ b/components/react/package.json
@@ -114,7 +114,7 @@
     ""ts-loader"": ""^9.2.9"",
     ""ts-node"": ""^10.7.0"",
     ""typescript"": ""^4.7.3"",
-    ""webpack"": ""^5.72.0"",
+    ""webpack"": ""^5.73.0"",
     ""webpack-bundle-analyzer"": ""^4.5.0"",
     ""webpack-cli"": ""^4.9.2"",
     ""webpack-node-externals"": ""^3.0.0""
diff --git a/yarn.lock b/yarn.lock
index a3fdb26..19a0716 100644
--- a/yarn.lock
+++ b/yarn.lock
@@ -25212,7 +25212,7 @@ webpack@^4.38.0, webpack@^4.42.1:
     watchpack ""^1.7.4""
     webpack-sources ""^1.4.1""
 
-webpack@^5.54.0, webpack@^5.71.0, webpack@^5.72.0:
+webpack@^5.54.0, webpack@^5.71.0, webpack@^5.72.0, webpack@^5.73.0:
   version ""5.73.0""
   resolved ""https://registry.yarnpkg.com/webpack/-/webpack-5.73.0.tgz#bbd17738f8a53ee5760ea2f59dce7f3431d35d38""
   integrity sha512-svjudQRPPa0YiOYa2lM/Gacw0r6PvxptHj4FuEKQ2kX05ZLkjbVc5MnPs6its5j7IZljnIqSVo/OsY2X0IpHGA==
",3,"[""4d92f352741b04c8709319dfe5c8419654f3682c"", ""c444fdb9e85ce44c5c0c99addc777dd7b6085153"", ""78c446cbea61af2268b4c4da03a9ad4283f10049""]","[""feat"", ""cicd"", ""build""]"
"xfail on to_parquet and to_csv that use pyarrow write options | Deploy utilities from correct folder

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com> | add workingDirectory option to shell.openExternal() (#15065)

Allows passing `workingDirectory` to the underlying `ShellExecuteW` API on Windows._x000D_
_x000D_
the motivation is that by default `ShellExecute` would use the current working directory, which would get locked on Windows and can prevent autoUpdater from working correctly. We need to be able specify a different `workingDirectory` to prevent this situation.","diff --git a/ibis/backends/tests/test_export.py b/ibis/backends/tests/test_export.py
index 4d536d7..5bb9775 100644
--- a/ibis/backends/tests/test_export.py
+++ b/ibis/backends/tests/test_export.py
@@ -222,18 +222,23 @@ def test_table_to_parquet(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs""), [({""version"": ""1.0""}), ({""version"": ""2.6""})])
-def test_table_to_parquet_writer_kwargs(kwargs, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.NotSupportedError,
+)
+@pytest.mark.parametrize(""version"", [""1.0"", ""2.6""])
+def test_table_to_parquet_writer_kwargs(version, tmp_path, backend, awards_players):
     outparquet = tmp_path / ""out.parquet""
-    awards_players.to_parquet(outparquet, **kwargs)
+    awards_players.to_parquet(outparquet, version=version)
 
     df = pd.read_parquet(outparquet)
 
     backend.assert_frame_equal(awards_players.to_pandas(), df)
 
-    file = pa.parquet.ParquetFile(outparquet)
+    md = pa.parquet.read_metadata(outparquet)
 
-    assert file.metadata.format_version == kwargs[""version""]
+    assert md.format_version == version
 
 
 @pytest.mark.notimpl(
@@ -316,14 +321,20 @@ def test_table_to_csv(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs"", ""delimiter""), [({""write_options"": pcsv.WriteOptions(delimiter="";"")}, "";""), ({""write_options"": pcsv.WriteOptions(delimiter=""\t"")}, ""\t"")])
-def test_table_to_csv_writer_kwargs(kwargs, delimiter, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.ProgrammingError,
+)
+@pytest.mark.parametrize(""delimiter"", ["";"", ""\t""], ids=[""semicolon"", ""tab""])
+def test_table_to_csv_writer_kwargs(delimiter, tmp_path, awards_players):
     outcsv = tmp_path / ""out.csv""
     # avoid pandas NaNonense
     awards_players = awards_players.select(""playerID"", ""awardID"", ""yearID"", ""lgID"")
 
-    awards_players.to_csv(outcsv, **kwargs)
-    pd.read_csv(outcsv, delimiter=delimiter)
+    awards_players.to_csv(outcsv, write_options=pcsv.WriteOptions(delimiter=delimiter))
+    df = pd.read_csv(outcsv, delimiter=delimiter, nrows=1)
+    assert len(df) == 1
 
 
 @pytest.mark.parametrize(

diff --git a/.github/workflows/utilities.yaml b/.github/workflows/utilities.yaml
index 92e130c..afbc850 100644
--- a/.github/workflows/utilities.yaml
+++ b/.github/workflows/utilities.yaml
@@ -43,7 +43,7 @@ jobs:
         PUSH_IMAGE=1 bash build.sh
     - name: Deploy to kubernetes
       run: |
-        cd scripts/helm/
+        cd scripts/helmcharts/
         sed -i ""s#openReplayContainerRegistry.*#openReplayContainerRegistry: \""${{ secrets.OSS_REGISTRY_URL }}\""#g"" vars.yaml
         sed -i ""s#minio_access_key.*#minio_access_key: \""${{ secrets.OSS_MINIO_ACCESS_KEY }}\"" #g"" vars.yaml
         sed -i ""s#minio_secret_key.*#minio_secret_key: \""${{ secrets.OSS_MINIO_SECRET_KEY }}\"" #g"" vars.yaml

diff --git a/atom/browser/atom_browser_client.cc b/atom/browser/atom_browser_client.cc
index 97e5f26..df0774b 100644
--- a/atom/browser/atom_browser_client.cc
+++ b/atom/browser/atom_browser_client.cc
@@ -611,7 +611,7 @@ void OnOpenExternal(const GURL& escaped_url, bool allowed) {
 #else
         escaped_url,
 #endif
-        true);
+        platform_util::OpenExternalOptions());
 }
 
 void HandleExternalProtocolInUI(
diff --git a/atom/common/api/atom_api_shell.cc b/atom/common/api/atom_api_shell.cc
index 1323cd6..7c67c7a 100644
--- a/atom/common/api/atom_api_shell.cc
+++ b/atom/common/api/atom_api_shell.cc
@@ -60,11 +60,12 @@ bool OpenExternal(
     const GURL& url,
 #endif
     mate::Arguments* args) {
-  bool activate = true;
+  platform_util::OpenExternalOptions options;
   if (args->Length() >= 2) {
-    mate::Dictionary options;
-    if (args->GetNext(&options)) {
-      options.Get(""activate"", &activate);
+    mate::Dictionary obj;
+    if (args->GetNext(&obj)) {
+      obj.Get(""activate"", &options.activate);
+      obj.Get(""workingDirectory"", &options.working_dir);
     }
   }
 
@@ -72,13 +73,13 @@ bool OpenExternal(
     base::Callback<void(v8::Local<v8::Value>)> callback;
     if (args->GetNext(&callback)) {
       platform_util::OpenExternal(
-          url, activate,
+          url, options,
           base::Bind(&OnOpenExternalFinished, args->isolate(), callback));
       return true;
     }
   }
 
-  return platform_util::OpenExternal(url, activate);
+  return platform_util::OpenExternal(url, options);
 }
 
 #if defined(OS_WIN)
diff --git a/atom/common/platform_util.h b/atom/common/platform_util.h
index 6fd8405..6686a4f 100644
--- a/atom/common/platform_util.h
+++ b/atom/common/platform_util.h
@@ -8,6 +8,7 @@
 #include <string>
 
 #include ""base/callback_forward.h""
+#include ""base/files/file_path.h""
 #include ""build/build_config.h""
 
 #if defined(OS_WIN)
@@ -16,10 +17,6 @@
 
 class GURL;
 
-namespace base {
-class FilePath;
-}
-
 namespace platform_util {
 
 typedef base::Callback<void(const std::string&)> OpenExternalCallback;
@@ -32,6 +29,11 @@ bool ShowItemInFolder(const base::FilePath& full_path);
 // Must be called from the UI thread.
 bool OpenItem(const base::FilePath& full_path);
 
+struct OpenExternalOptions {
+  bool activate = true;
+  base::FilePath working_dir;
+};
+
 // Open the given external protocol URL in the desktop's default manner.
 // (For example, mailto: URLs in the default mail user agent.)
 bool OpenExternal(
@@ -40,7 +42,7 @@ bool OpenExternal(
 #else
     const GURL& url,
 #endif
-    bool activate);
+    const OpenExternalOptions& options);
 
 // The asynchronous version of OpenExternal.
 void OpenExternal(
@@ -49,7 +51,7 @@ void OpenExternal(
 #else
     const GURL& url,
 #endif
-    bool activate,
+    const OpenExternalOptions& options,
     const OpenExternalCallback& callback);
 
 // Move a file to trash.
diff --git a/atom/common/platform_util_linux.cc b/atom/common/platform_util_linux.cc
index 63ee0bd..f17cbda 100644
--- a/atom/common/platform_util_linux.cc
+++ b/atom/common/platform_util_linux.cc
@@ -80,7 +80,7 @@ bool OpenItem(const base::FilePath& full_path) {
   return XDGOpen(full_path.value(), false);
 }
 
-bool OpenExternal(const GURL& url, bool activate) {
+bool OpenExternal(const GURL& url, const OpenExternalOptions& options) {
   // Don't wait for exit, since we don't want to wait for the browser/email
   // client window to close before returning
   if (url.SchemeIs(""mailto""))
@@ -90,10 +90,10 @@ bool OpenExternal(const GURL& url, bool activate) {
 }
 
 void OpenExternal(const GURL& url,
-                  bool activate,
+                  const OpenExternalOptions& options,
                   const OpenExternalCallback& callback) {
   // TODO(gabriel): Implement async open if callback is specified
-  callback.Run(OpenExternal(url, activate) ? """" : ""Failed to open"");
+  callback.Run(OpenExternal(url, options) ? """" : ""Failed to open"");
 }
 
 bool MoveItemToTrash(const base::FilePath& full_path) {
diff --git a/atom/common/platform_util_mac.mm b/atom/common/platform_util_mac.mm
index b83b1e1..4cda8bf 100644
--- a/atom/common/platform_util_mac.mm
+++ b/atom/common/platform_util_mac.mm
@@ -139,16 +139,16 @@ bool OpenItem(const base::FilePath& full_path) {
                                launchIdentifiers:NULL];
 }
 
-bool OpenExternal(const GURL& url, bool activate) {
+bool OpenExternal(const GURL& url, const OpenExternalOptions& options) {
   DCHECK([NSThread isMainThread]);
   NSURL* ns_url = net::NSURLWithGURL(url);
   if (ns_url)
-    return OpenURL(ns_url, activate).empty();
+    return OpenURL(ns_url, options.activate).empty();
   return false;
 }
 
 void OpenExternal(const GURL& url,
-                  bool activate,
+                  const OpenExternalOptions& options,
                   const OpenExternalCallback& callback) {
   NSURL* ns_url = net::NSURLWithGURL(url);
   if (!ns_url) {
@@ -157,13 +157,13 @@ void OpenExternal(const GURL& url,
   }
 
   __block OpenExternalCallback c = callback;
-  dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0),
-                 ^{
-                   __block std::string error = OpenURL(ns_url, activate);
-                   dispatch_async(dispatch_get_main_queue(), ^{
-                     c.Run(error);
-                   });
-                 });
+  dispatch_async(
+      dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{
+        __block std::string error = OpenURL(ns_url, options.activate);
+        dispatch_async(dispatch_get_main_queue(), ^{
+          c.Run(error);
+        });
+      });
 }
 
 bool MoveItemToTrash(const base::FilePath& full_path) {
diff --git a/atom/common/platform_util_win.cc b/atom/common/platform_util_win.cc
index 34576be..5712200 100644
--- a/atom/common/platform_util_win.cc
+++ b/atom/common/platform_util_win.cc
@@ -294,15 +294,18 @@ bool OpenItem(const base::FilePath& full_path) {
     return ui::win::OpenFileViaShell(full_path);
 }
 
-bool OpenExternal(const base::string16& url, bool activate) {
+bool OpenExternal(const base::string16& url,
+                  const OpenExternalOptions& options) {
   // Quote the input scheme to be sure that the command does not have
   // parameters unexpected by the external program. This url should already
   // have been escaped.
   base::string16 escaped_url = L""\"""" + url + L""\"""";
+  auto working_dir = options.working_dir.value();
 
-  if (reinterpret_cast<ULONG_PTR>(ShellExecuteW(
-          NULL, L""open"", escaped_url.c_str(), NULL, NULL, SW_SHOWNORMAL)) <=
-      32) {
+  if (reinterpret_cast<ULONG_PTR>(
+          ShellExecuteW(nullptr, L""open"", escaped_url.c_str(), nullptr,
+                        working_dir.empty() ? nullptr : working_dir.c_str(),
+                        SW_SHOWNORMAL)) <= 32) {
     // We fail to execute the call. We could display a message to the user.
     // TODO(nsylvain): we should also add a dialog to warn on errors. See
     // bug 1136923.
@@ -312,10 +315,10 @@ bool OpenExternal(const base::string16& url, bool activate) {
 }
 
 void OpenExternal(const base::string16& url,
-                  bool activate,
+                  const OpenExternalOptions& options,
                   const OpenExternalCallback& callback) {
   // TODO(gabriel): Implement async open if callback is specified
-  callback.Run(OpenExternal(url, activate) ? """" : ""Failed to open"");
+  callback.Run(OpenExternal(url, options) ? """" : ""Failed to open"");
 }
 
 bool MoveItemToTrash(const base::FilePath& path) {
diff --git a/docs/api/shell.md b/docs/api/shell.md
index a469f94..b38348a 100644
--- a/docs/api/shell.md
+++ b/docs/api/shell.md
@@ -37,9 +37,10 @@ Open the given file in the desktop's default manner.
 ### `shell.openExternal(url[, options, callback])`
 
 * `url` String - Max 2081 characters on windows, or the function returns false.
-* `options` Object (optional) _macOS_
-  * `activate` Boolean - `true` to bring the opened application to the
-    foreground. The default is `true`.
+* `options` Object (optional)
+  * `activate` Boolean (optional) - `true` to bring the opened application to the
+    foreground. The default is `true`. _macOS_
+  * `workingDirectory` String (optional) - The working directory. _Windows_
 * `callback` Function (optional) _macOS_ - If specified will perform the open asynchronously.
   * `error` Error
 
",3,"[""bedc7950b24c37809e36a585b7985d5aa5e3e458"", ""2ebf04099353ef70395b8c8f5e130f70e1ed0814"", ""a9475f359061fcd6cd53557599fedf0df5e9ee00""]","[""test"", ""cicd"", ""feat""]"
add test for spurious cross join | add documentation to use react-native-paper with CRA (#874) | removed files,"diff --git a/ibis/tests/sql/test_sqlalchemy.py b/ibis/tests/sql/test_sqlalchemy.py
index 4ad32a6..b2e5d72 100644
--- a/ibis/tests/sql/test_sqlalchemy.py
+++ b/ibis/tests/sql/test_sqlalchemy.py
@@ -841,3 +841,63 @@ def test_filter_group_by_agg_with_same_name():
     )
     ex = sa.select([t0]).where(t0.c.bigint_col == 60)
     _check(expr, ex)
+
+
+@pytest.fixture
+def person():
+    return ibis.table(
+        dict(id=""string"", personal=""string"", family=""string""),
+        name=""person"",
+    )
+
+
+@pytest.fixture
+def visited():
+    return ibis.table(
+        dict(id=""int32"", site=""string"", dated=""string""),
+        name=""visited"",
+    )
+
+
+@pytest.fixture
+def survey():
+    return ibis.table(
+        dict(
+            taken=""int32"",
+            person=""string"",
+            quant=""string"",
+            reading=""float32"",
+        ),
+        name=""survey"",
+    )
+
+
+def test_no_cross_join(person, visited, survey):
+    expr = person.join(survey, person.id == survey.person).join(
+        visited,
+        visited.id == survey.taken,
+    )
+
+    context = AlchemyContext(compiler=AlchemyCompiler)
+    _ = AlchemyCompiler.to_sql(expr, context)
+
+    t0 = context.get_ref(person)
+    t1 = context.get_ref(survey)
+    t2 = context.get_ref(visited)
+
+    from_ = t0.join(t1, t0.c.id == t1.c.person).join(t2, t2.c.id == t1.c.taken)
+    ex = sa.select(
+        [
+            t0.c.id.label(""id_x""),
+            t0.c.personal,
+            t0.c.family,
+            t1.c.taken,
+            t1.c.person,
+            t1.c.quant,
+            t1.c.reading,
+            t2.c.id.label(""id_y""),
+            t2.c.site,
+            t2.c.dated,
+        ]
+    ).select_from(from_)
+    _check(expr, ex)

diff --git a/docs/pages/4.react-native-web.md b/docs/pages/4.react-native-web.md
index 69e4e52..8d6ae2a 100644
--- a/docs/pages/4.react-native-web.md
+++ b/docs/pages/4.react-native-web.md
@@ -16,6 +16,63 @@ To install `react-native-web`, run:
 yarn add react-native-web react-dom react-art
 ```
 
+### Using CRA ([Create React App](https://github.com/facebook/create-react-app))
+
+Install [`react-app-rewired`](https://github.com/timarney/react-app-rewired) to override `webpack` configuration:
+
+```sh
+yarn add --dev react-app-rewired
+```
+
+[Configure `babel-loader`](#2-configure-babel-loader) using a new file called `config-overrides.js`:
+
+```js
+module.exports = function override(config, env) {
+  config.module.rules.push({
+    test: /\.js$/,
+    exclude: /node_modules[/\\](?!react-native-paper|react-native-vector-icons|react-native-safe-area-view)/,
+    use: {
+      loader: ""babel-loader"",
+      options: {
+        // Disable reading babel configuration
+        babelrc: false,
+        configFile: false,
+
+        // The configration for compilation
+        presets: [
+          [""@babel/preset-env"", { useBuiltIns: ""usage"" }],
+          ""@babel/preset-react"",
+          ""@babel/preset-flow""
+        ],
+        plugins: [
+          ""@babel/plugin-proposal-class-properties"",
+          ""@babel/plugin-proposal-object-rest-spread""
+        ]
+      }
+    }
+  });
+
+  return config;
+};
+```
+
+Change your script in `package.json`:
+
+```diff
+/* package.json */
+
+  ""scripts"": {
+-   ""start"": ""react-scripts start"",
++   ""start"": ""react-app-rewired start"",
+-   ""build"": ""react-scripts build"",
++   ""build"": ""react-app-rewired build"",
+-   ""test"": ""react-scripts test --env=jsdom"",
++   ""test"": ""react-app-rewired test --env=jsdom""
+}
+```
+
+### Custom webpack setup
+
 To install `webpack`, run:
 
 ```sh

diff --git a/packages/tui/src/widgets/button.rs b/packages/tui/src/widgets/button.rs
index f3ebc79..845a60c 100644
--- a/packages/tui/src/widgets/button.rs
+++ b/packages/tui/src/widgets/button.rs
@@ -32,7 +32,6 @@ pub(crate) fn Button<'a>(cx: Scope<'a, ButtonProps>) -> Element<'a> {
             callback.call(FormData {
                 value: text.to_string(),
                 values: HashMap::new(),
-                files: None,
             });
         }
         state.set(new_state);
diff --git a/packages/tui/src/widgets/checkbox.rs b/packages/tui/src/widgets/checkbox.rs
index 4831172..90c7212 100644
--- a/packages/tui/src/widgets/checkbox.rs
+++ b/packages/tui/src/widgets/checkbox.rs
@@ -56,7 +56,6 @@ pub(crate) fn CheckBox<'a>(cx: Scope<'a, CheckBoxProps>) -> Element<'a> {
                     ""on"".to_string()
                 },
                 values: HashMap::new(),
-                files: None,
             });
         }
         state.set(new_state);
diff --git a/packages/tui/src/widgets/number.rs b/packages/tui/src/widgets/number.rs
index 05cb2d6..93f9edd 100644
--- a/packages/tui/src/widgets/number.rs
+++ b/packages/tui/src/widgets/number.rs
@@ -84,7 +84,6 @@ pub(crate) fn NumbericInput<'a>(cx: Scope<'a, NumbericInputProps>) -> Element<'a
             input_handler.call(FormData {
                 value: text,
                 values: HashMap::new(),
-                files: None,
             });
         }
     };
diff --git a/packages/tui/src/widgets/password.rs b/packages/tui/src/widgets/password.rs
index 7f8455d..d7e978f 100644
--- a/packages/tui/src/widgets/password.rs
+++ b/packages/tui/src/widgets/password.rs
@@ -99,7 +99,6 @@ pub(crate) fn Password<'a>(cx: Scope<'a, PasswordProps>) -> Element<'a> {
                     input_handler.call(FormData{
                         value: text.clone(),
                         values: HashMap::new(),
-                        files: None
                     });
                 }
 
diff --git a/packages/tui/src/widgets/slider.rs b/packages/tui/src/widgets/slider.rs
index 43f0ac7..257c765 100644
--- a/packages/tui/src/widgets/slider.rs
+++ b/packages/tui/src/widgets/slider.rs
@@ -58,7 +58,6 @@ pub(crate) fn Slider<'a>(cx: Scope<'a, SliderProps>) -> Element<'a> {
             oninput.call(FormData {
                 value,
                 values: HashMap::new(),
-                files: None,
             });
         }
     };
diff --git a/packages/tui/src/widgets/textbox.rs b/packages/tui/src/widgets/textbox.rs
index 8628fca..ce0ffcc 100644
--- a/packages/tui/src/widgets/textbox.rs
+++ b/packages/tui/src/widgets/textbox.rs
@@ -95,7 +95,6 @@ pub(crate) fn TextBox<'a>(cx: Scope<'a, TextBoxProps>) -> Element<'a> {
                     input_handler.call(FormData{
                         value: text.clone(),
                         values: HashMap::new(),
-                        files: None
                     });
                 }
 
diff --git a/packages/web/src/dom.rs b/packages/web/src/dom.rs
index 7fa3d20..5037c4d 100644
--- a/packages/web/src/dom.rs
+++ b/packages/web/src/dom.rs
@@ -331,11 +331,7 @@ fn read_input_to_data(target: Element) -> Rc<FormData> {
         }
     }
 
-    Rc::new(FormData {
-        value,
-        values,
-        files: None,
-    })
+    Rc::new(FormData { value, values })
 }
 
 fn walk_event_for_id(event: &web_sys::Event) -> Option<(ElementId, web_sys::Element)> {
",3,"[""8dac3fe5a7a56356ca95547fcf7925bec8d9c1dd"", ""ee7cc5d5a940fba774e715b1f029c6361110b108"", ""a81bbb83d64867f08c4d1be10919ef6806a1bf51""]","[""test"", ""docs"", ""fix""]"
autostart feature fixed,"diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();
",1,"[""bed78248c941d57ad4cc20a455147e186e97c7a1""]","[""fix""]"
fix build | rename ELECTRON_CACHE env variable to electron_config_cache (#21313),"diff --git a/server/Dockerfile b/server/Dockerfile
index 2f203bb..a84c31e 100755
--- a/server/Dockerfile
+++ b/server/Dockerfile
@@ -9,9 +9,11 @@ ENV TZ utc
 WORKDIR /src
 
 COPY package.json /src
+COPY package-lock.json /src
+COPY tsconfig.json /src
 RUN npm install --production --no-optional
 
 COPY public /src/public
 COPY dist /src
 
-CMD [ ""node"", ""./server/index.js"" ]
+CMD [ ""node"", ""-r"", ""tsconfig-paths/register"", ""./server/index.js"" ]
diff --git a/server/package-lock.json b/server/package-lock.json
index 6cacfa2..236f1bb 100644
--- a/server/package-lock.json
+++ b/server/package-lock.json
@@ -2164,8 +2164,7 @@
     ""@types/json5"": {
       ""version"": ""0.0.29"",
       ""resolved"": ""https://registry.npmjs.org/@types/json5/-/json5-0.0.29.tgz"",
-      ""integrity"": ""sha1-7ihweulOEdK4J7y+UnC86n8+ce4="",
-      ""dev"": true
+      ""integrity"": ""sha1-7ihweulOEdK4J7y+UnC86n8+ce4=""
     },
     ""@types/jsonwebtoken"": {
       ""version"": ""8.3.5"",
@@ -9246,8 +9245,7 @@
     ""strip-bom"": {
       ""version"": ""3.0.0"",
       ""resolved"": ""https://registry.npmjs.org/strip-bom/-/strip-bom-3.0.0.tgz"",
-      ""integrity"": ""sha1-IzTBjpx1n3vdVv3vfprj1YjmjtM="",
-      ""dev"": true
+      ""integrity"": ""sha1-IzTBjpx1n3vdVv3vfprj1YjmjtM=""
     },
     ""strip-final-newline"": {
       ""version"": ""2.0.0"",
@@ -9524,7 +9522,6 @@
       ""version"": ""3.9.0"",
       ""resolved"": ""https://registry.npmjs.org/tsconfig-paths/-/tsconfig-paths-3.9.0.tgz"",
       ""integrity"": ""sha512-dRcuzokWhajtZWkQsDVKbWyY+jgcLC5sqJhg2PSgf4ZkH2aHPvaOY8YWGhmjb68b5qqTfasSsDO9k7RUiEmZAw=="",
-      ""dev"": true,
       ""requires"": {
         ""@types/json5"": ""^0.0.29"",
         ""json5"": ""^1.0.1"",
@@ -9536,7 +9533,6 @@
           ""version"": ""1.0.1"",
           ""resolved"": ""https://registry.npmjs.org/json5/-/json5-1.0.1.tgz"",
           ""integrity"": ""sha512-aKS4WQjPenRxiQsC93MNfjx+nbF4PAdYzmd/1JIj8HYzqfbu86beTuNgXDzPknWk0n0uARlyewZo4s++ES36Ow=="",
-          ""dev"": true,
           ""requires"": {
             ""minimist"": ""^1.2.0""
           }
@@ -9544,8 +9540,7 @@
         ""minimist"": {
           ""version"": ""1.2.5"",
           ""resolved"": ""https://registry.npmjs.org/minimist/-/minimist-1.2.5.tgz"",
-          ""integrity"": ""sha512-FM9nNUYrRBAELZQT3xeZQ7fmMOBg6nWNmJKTcgsJeaLstP/UODVpGsr5OhXhhXg6f+qtJ8uiZ+PUxkDWcgIXLw=="",
-          ""dev"": true
+          ""integrity"": ""sha512-FM9nNUYrRBAELZQT3xeZQ7fmMOBg6nWNmJKTcgsJeaLstP/UODVpGsr5OhXhhXg6f+qtJ8uiZ+PUxkDWcgIXLw==""
         }
       }
     },
diff --git a/server/package.json b/server/package.json
index 35426e9..896e9b3 100644
--- a/server/package.json
+++ b/server/package.json
@@ -41,6 +41,7 @@
     ""pino-cloudwatch"": ""0.7.0"",
     ""pino-multi-stream"": ""4.2.0"",
     ""reflect-metadata"": ""0.1.13"",
+    ""tsconfig-paths"": ""3.9.0"",
     ""typeorm"": ""0.2.37""
   },
   ""devDependencies"": {
@@ -69,7 +70,6 @@
     ""pino-pretty"": ""3.6.1"",
     ""ts-jest"": ""27.0.7"",
     ""ts-node-dev"": ""1.1.8"",
-    ""tsconfig-paths"": ""3.9.0"",
     ""typescript"": ""4.3.5""
   },
   ""jest-junit"": {

diff --git a/docs/tutorial/installation.md b/docs/tutorial/installation.md
index d4af120..1a09eea 100644
--- a/docs/tutorial/installation.md
+++ b/docs/tutorial/installation.md
@@ -82,7 +82,7 @@ with the network at all.
 On environments that have been using older versions of Electron, you might find the
 cache also in `~/.electron`.
 
-You can also override the local cache location by providing a `ELECTRON_CACHE`
+You can also override the local cache location by providing a `electron_config_cache`
 environment variable.
 
 The cache contains the version's official zip file as well as a checksum, stored as
",2,"[""a827777f41e90b6332c191d05bae8db525de6f38"", ""f2f52c23b513dd857350f3c163f676d37189d0d3""]","[""build"", ""docs""]"
add link to roadmap,"diff --git a/packages/plugin-core/README.md b/packages/plugin-core/README.md
index 3c25c9b..c7506d4 100644
--- a/packages/plugin-core/README.md
+++ b/packages/plugin-core/README.md
@@ -187,6 +187,10 @@ When the workspace opens, it will show dialogue to install the recommended exten
 
 See [[FAQ]] to answers for common questions.
 
+# Roadmap
+
+Check out our [public roadmap](https://github.com/orgs/dendronhq/projects/1) to see the features we're working on and to vote for what you want to see next. 
+
 
 # Contributing
 
",1,"[""94202f01e44c58bee4419044f8a18ac5f1a50dff""]","[""docs""]"
"added components pages to typedoc output | add ability to get all encoded values | fix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.","diff --git a/core/main/tsconfig.json b/core/main/tsconfig.json
index c4474a7..7916bc5 100644
--- a/core/main/tsconfig.json
+++ b/core/main/tsconfig.json
@@ -96,11 +96,35 @@
     ""particles"": {
       ""groups"": [
         {
-          ""title"": ""Documentation"",
+          ""title"": ""Components"",
           ""pages"": [
             {
-              ""title"": ""My Page"",
-              ""source"": ""./markdown/pages/index.md""
+              ""title"": ""Angular"",
+              ""source"": ""../../components/angular/README.md""
+            },
+            {
+              ""title"": ""React"",
+              ""source"": ""../../components/react/README.md""
+            },
+            {
+              ""title"": ""Vue"",
+              ""source"": ""../../components/vue/README.md""
+            },
+            {
+              ""title"": ""Svelte"",
+              ""source"": ""../../components/svelte/README.md""
+            },
+            {
+              ""title"": ""jQuery"",
+              ""source"": ""../../components/jquery/README.md""
+            },
+            {
+              ""title"": ""Preact"",
+              ""source"": ""../../components/preact/README.md""
+            },
+            {
+              ""title"": ""Inferno"",
+              ""source"": ""../../components/inferno/README.md""
             }
           ]
         }

diff --git a/delorean_mem_qe/src/column.rs b/delorean_mem_qe/src/column.rs
index bc89cb2..b3df18e 100644
--- a/delorean_mem_qe/src/column.rs
+++ b/delorean_mem_qe/src/column.rs
@@ -537,6 +537,22 @@ impl Column {
         }
     }
 
+    /// Materialise all of the encoded values.
+    pub fn all_encoded_values(&self) -> Vector {
+        match self {
+            Column::String(c) => {
+                let now = std::time::Instant::now();
+                let v = c.all_encoded_values();
+                log::debug!(""time getting all encoded values {:?}"", now.elapsed());
+
+                log::debug!(""dictionary {:?}"", c.data.dictionary());
+                Vector::Integer(v)
+            }
+            Column::Float(c) => Vector::Float(c.all_encoded_values()),
+            Column::Integer(c) => Vector::Integer(c.all_encoded_values()),
+        }
+    }
+
     /// Given an encoded value for a row, materialise and return the decoded
     /// version.
     ///
@@ -986,6 +1002,10 @@ impl String {
         self.data.encoded_values(row_ids)
     }
 
+    pub fn all_encoded_values(&self) -> Vec<i64> {
+        self.data.all_encoded_values()
+    }
+
     /// Return the decoded value for an encoded ID.
     ///
     /// Panics if there is no decoded value for the provided id
@@ -1037,6 +1057,10 @@ impl Float {
         self.data.encoded_values(row_ids)
     }
 
+    pub fn all_encoded_values(&self) -> Vec<f64> {
+        self.data.all_encoded_values()
+    }
+
     pub fn scan_from(&self, row_id: usize) -> &[f64] {
         self.data.scan_from(row_id)
     }
@@ -1106,6 +1130,10 @@ impl Integer {
         self.data.encoded_values(row_ids)
     }
 
+    pub fn all_encoded_values(&self) -> Vec<i64> {
+        self.data.all_encoded_values()
+    }
+
     pub fn scan_from(&self, row_id: usize) -> &[i64] {
         self.data.scan_from(row_id)
     }
diff --git a/delorean_mem_qe/src/encoding.rs b/delorean_mem_qe/src/encoding.rs
index d6a865a..4b057cf 100644
--- a/delorean_mem_qe/src/encoding.rs
+++ b/delorean_mem_qe/src/encoding.rs
@@ -68,6 +68,12 @@ where
         self.values(row_ids)
     }
 
+    /// Return all encoded values. For this encoding this is just the decoded
+    /// values
+    pub fn all_encoded_values(&self) -> Vec<T> {
+        self.values.clone()
+    }
+
     // TODO(edd): fix this when added NULL support
     pub fn scan_from_until_some(&self, _row_id: usize) -> Option<T> {
         unreachable!(""to remove"");
@@ -485,6 +491,26 @@ impl DictionaryRLE {
         out
     }
 
+    // values materialises a vector of references to all logical values in the
+    // encoding.
+    pub fn all_values(&mut self) -> Vec<Option<&String>> {
+        let mut out: Vec<Option<&String>> = Vec::with_capacity(self.total as usize);
+
+        // build reverse mapping.
+        let mut idx_value = BTreeMap::new();
+        for (k, v) in &self.entry_index {
+            idx_value.insert(v, k);
+        }
+        assert_eq!(idx_value.len(), self.entry_index.len());
+
+        for (idx, rl) in &self.run_lengths {
+            // TODO(edd): fix unwrap - we know that the value exists in map...
+            let v = idx_value.get(&idx).unwrap().as_ref();
+            out.extend(iter::repeat(v).take(*rl as usize));
+        }
+        out
+    }
+
     /// Return the decoded value for an encoded ID.
     ///
     /// Panics if there is no decoded value for the provided id
@@ -528,22 +554,13 @@ impl DictionaryRLE {
         out
     }
 
-    // values materialises a vector of references to all logical values in the
-    // encoding.
-    pub fn all_values(&mut self) -> Vec<Option<&String>> {
-        let mut out: Vec<Option<&String>> = Vec::with_capacity(self.total as usize);
-
-        // build reverse mapping.
-        let mut idx_value = BTreeMap::new();
-        for (k, v) in &self.entry_index {
-            idx_value.insert(v, k);
-        }
-        assert_eq!(idx_value.len(), self.entry_index.len());
+    // all_encoded_values materialises a vector of all encoded values for the
+    // column.
+    pub fn all_encoded_values(&self) -> Vec<i64> {
+        let mut out: Vec<i64> = Vec::with_capacity(self.total as usize);
 
         for (idx, rl) in &self.run_lengths {
-            // TODO(edd): fix unwrap - we know that the value exists in map...
-            let v = idx_value.get(&idx).unwrap().as_ref();
-            out.extend(iter::repeat(v).take(*rl as usize));
+            out.extend(iter::repeat(*idx as i64).take(*rl as usize));
         }
         out
     }
diff --git a/delorean_mem_qe/src/segment.rs b/delorean_mem_qe/src/segment.rs
index c058df0..f8c5005 100644
--- a/delorean_mem_qe/src/segment.rs
+++ b/delorean_mem_qe/src/segment.rs
@@ -228,7 +228,7 @@ impl Segment {
         group_columns: &[String],
         aggregates: &[(String, AggregateType)],
         window: i64,
-    ) -> BTreeMap<Vec<String>, Vec<(String, Option<column::Aggregate>)>> {
+    ) -> BTreeMap<Vec<i64>, Vec<(&String, &AggregateType, Option<column::Aggregate>)>> {
         // Build a hash table - essentially, scan columns for matching row ids,
         // emitting the encoded value for each column and track those value
         // combinations in a hashmap with running aggregates.
@@ -242,6 +242,10 @@ impl Segment {
             assert_ne!(group_columns[group_columns.len() - 1], ""time"");
         }
 
+        // TODO(edd): Perf - if there is no predicate and we want entire segment
+        // then it will be a lot faster to not build filtered_row_ids and just
+        // get all encoded values for each grouping column...
+
         // filter on predicates and time
         let filtered_row_ids: croaring::Bitmap;
         if let Some(row_ids) = self.filter_by_predicates_eq(time_range, predicates) {
@@ -263,7 +267,12 @@ impl Segment {
         let mut group_column_encoded_values = Vec::with_capacity(group_columns.len());
         for group_column in group_columns {
             if let Some(column) = self.column(&group_column) {
-                let encoded_values = column.encoded_values(&filtered_row_ids_vec);
+                let encoded_values = if filtered_row_ids_vec.len() == self.meta.rows {
+                    column.all_encoded_values()
+                } else {
+                    column.encoded_values(&filtered_row_ids_vec)
+                };
+
                 assert_eq!(
                     filtered_row_ids.cardinality() as usize,
                     encoded_values.len()
@@ -325,10 +334,10 @@ impl Segment {
             .collect::<Vec<_>>();
 
         // hashMap is about 20% faster than BTreeMap in this case
-        let mut hash_table: HashMap<
+        let mut hash_table: BTreeMap<
             Vec<i64>,
             Vec<(&String, &AggregateType, Option<column::Aggregate>)>,
-        > = HashMap::new();
+        > = BTreeMap::new();
 
         let mut aggregate_row: Vec<(&str, Option<column::Scalar>)> =
             std::iter::repeat_with(|| ("""", None))
@@ -406,8 +415,10 @@ impl Segment {
             }
             processed_rows += 1;
         }
+        // println!(""groups: {:?}"", hash_table.len());
         log::debug!(""({:?} rows processed) {:?}"", processed_rows, hash_table);
         BTreeMap::new()
+        // hash_table
     }
 
     pub fn aggregate_by_group_using_sort(
@@ -451,7 +462,11 @@ impl Segment {
         let mut group_column_encoded_values = Vec::with_capacity(group_columns.len());
         for group_column in group_columns {
             if let Some(column) = self.column(&group_column) {
-                let encoded_values = column.encoded_values(&filtered_row_ids_vec);
+                let encoded_values = if filtered_row_ids_vec.len() == self.meta.rows {
+                    column.all_encoded_values()
+                } else {
+                    column.encoded_values(&filtered_row_ids_vec)
+                };
                 assert_eq!(
                     filtered_row_ids.cardinality() as usize,
                     encoded_values.len()
@@ -557,6 +572,10 @@ impl Segment {
             assert_ne!(group_columns[group_columns.len() - 1], ""time"");
         }
 
+        // TODO(edd): Perf - if there is no predicate and we want entire segment
+        // then it will be a lot faster to not build filtered_row_ids and just
+        // get all encoded values for each grouping column...
+
         // filter on predicates and time
         let filtered_row_ids: croaring::Bitmap;
         if let Some(row_ids) = self.filter_by_predicates_eq(time_range, predicates) {
@@ -577,7 +596,11 @@ impl Segment {
         let mut group_column_encoded_values = Vec::with_capacity(group_columns.len());
         for group_column in group_columns {
             if let Some(column) = self.column(&group_column) {
-                let encoded_values = column.encoded_values(&filtered_row_ids_vec);
+                let encoded_values = if filtered_row_ids_vec.len() == self.meta.rows {
+                    column.all_encoded_values()
+                } else {
+                    column.encoded_values(&filtered_row_ids_vec)
+                };
                 assert_eq!(
                     filtered_row_ids.cardinality() as usize,
                     encoded_values.len()
@@ -709,6 +732,7 @@ impl Segment {
             aggregates: group_key_aggregates,
         });
 
+        // println!(""groups: {:?}"", results.len());
         log::debug!(""({:?} rows processed) {:?}"", processed_rows, results);
         // results
         vec![]

diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 
",3,"[""fca2c198c6486c4d586b1af1832be46f19667235"", ""cad5e45208346528ad02cd04dcac863f90faa037"", ""9be725fa3906323d4bc9788f54eccf74109d632b""]","[""docs"", ""feat"", ""fix""]"
"add activatedElementInstanceKeys to modification record | only run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com> | add system get version info Fiddle example (#20536)","diff --git a/protocol-impl/src/test/java/io/camunda/zeebe/protocol/impl/JsonSerializableToJsonTest.java b/protocol-impl/src/test/java/io/camunda/zeebe/protocol/impl/JsonSerializableToJsonTest.java
index 33410da..edd0588 100644
--- a/protocol-impl/src/test/java/io/camunda/zeebe/protocol/impl/JsonSerializableToJsonTest.java
+++ b/protocol-impl/src/test/java/io/camunda/zeebe/protocol/impl/JsonSerializableToJsonTest.java
@@ -787,7 +787,8 @@ final class JsonSerializableToJsonTest {
               }
             }],
             ""elementId"": ""activity""
-          }]
+          }],
+          ""activatedElementInstanceKeys"": []
         }
         """"""
       },
@@ -803,7 +804,8 @@ final class JsonSerializableToJsonTest {
         {
           ""processInstanceKey"": 1,
           ""terminateInstructions"": [],
-          ""activateInstructions"": []
+          ""activateInstructions"": [],
+          ""activatedElementInstanceKeys"": []
         }
         """"""
       },

diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest

diff --git a/docs/fiddles/system/system-information/get-version-information/index.html b/docs/fiddles/system/system-information/get-version-information/index.html
new file mode 100644
index 0000000..0867bc3
--- /dev/null
+++ b/docs/fiddles/system/system-information/get-version-information/index.html
@@ -0,0 +1,26 @@
+<!DOCTYPE html>
+<html>
+  <head>
+    <meta charset=""UTF-8"">
+  </head>
+  <body>
+    <div>
+      <div>
+        <h1>Get version information</h1>
+        <i>Supports: Win, macOS, Linux <span>|</span> Process: Both</i>
+        <div>
+          <div>
+            <button id=""version-info"">View Demo</button>
+            <span id=""got-version-info""></span>
+          </div>
+          <p>The <code>process</code> module is built into Node.js (therefore you can use this in both the main and renderer processes) and in Electron apps this object has a few more useful properties on it.</p>
+          <p>The example below gets the version of Electron in use by the app.</p>
+          <p>See the <a href=""http://electron.atom.io/docs/api/process"">process documentation <span>(opens in new window)</span></a> for more.</p>
+        </div>
+      </div>
+    </div>
+  </body>
+  <script>
+    require('./renderer.js')
+  </script>
+</html>
diff --git a/docs/fiddles/system/system-information/get-version-information/main.js b/docs/fiddles/system/system-information/get-version-information/main.js
new file mode 100644
index 0000000..1f9f917
--- /dev/null
+++ b/docs/fiddles/system/system-information/get-version-information/main.js
@@ -0,0 +1,25 @@
+const { app, BrowserWindow } = require('electron')
+
+let mainWindow = null
+
+function createWindow () {
+  const windowOptions = {
+    width: 600,
+    height: 400,
+    title: 'Get version information',
+    webPreferences: {
+      nodeIntegration: true
+    }
+  }
+
+  mainWindow = new BrowserWindow(windowOptions)
+  mainWindow.loadFile('index.html')
+
+  mainWindow.on('closed', () => {
+    mainWindow = null
+  })
+}
+
+app.on('ready', () => {
+  createWindow()
+})
diff --git a/docs/fiddles/system/system-information/get-version-information/renderer.js b/docs/fiddles/system/system-information/get-version-information/renderer.js
new file mode 100644
index 0000000..40f7f2c
--- /dev/null
+++ b/docs/fiddles/system/system-information/get-version-information/renderer.js
@@ -0,0 +1,8 @@
+const versionInfoBtn = document.getElementById('version-info')
+
+const electronVersion = process.versions.electron
+
+versionInfoBtn.addEventListener('click', () => {
+  const message = `This app is using Electron version: ${electronVersion}`
+  document.getElementById('got-version-info').innerHTML = message
+})
",3,"[""f7cc7b263afeb27eef393b7497db8dad8ebb0518"", ""dbb537a26e388a8d7d17faf131abc30c2f7a84e6"", ""16d4ace80096557fb3fd48396aa09107241c3131""]","[""test"", ""cicd"", ""docs""]"
"updates the readme to improve the readability and contributing sections | only restart if pages directory itself is changed

resolves #429","diff --git a/.github/CONTRIBUTING.md b/.github/CONTRIBUTING.md
index 3c4dd8d..f8b8514 100644
--- a/.github/CONTRIBUTING.md
+++ b/.github/CONTRIBUTING.md
@@ -21,7 +21,8 @@ Contributions are always welcome! Please use the following guidelines when contr
     - `chore` - Catch all or things that have to do with the build system, etc
     - `examples` - Changes to existing example, or a new example
  * The `COMPONENT` is optional, and may be a single file, directory, or logical component. Can be omitted if commit applies globally
-5. Run the tests (`cargo test --no-std-features && cargo test --features yaml`)
+5. Run the tests (`cargo test --features ""yaml unstable""`)
+5. Run the lints (`cargo build --features lints`) (requires a nightly compiler)
 6. `git rebase` into concise commits and remove `--fixup`s (`git rebase -i HEAD~NUM` where `NUM` is number of commits back)
 7. Push your changes back to your fork (`git push origin $your-branch`)
 8. Create a pull request! (You can also create the pull request first, and we'll merge when ready. This a good way to discuss proposed changes.)
diff --git a/README.md b/README.md
index 9e6efce..b74405d 100644
--- a/README.md
+++ b/README.md
@@ -31,7 +31,9 @@ Table of Contents
   * [More Information](#more-information)
     * [Video Tutorials](#video-tutorials)
 * [How to Contribute](#how-to-contribute)
-  * [Running the tests](#running-the-tests)
+  * [Testing Code](#testing-code)
+  * [Linting Code](#linting-code)
+  * [Debugging Code](#debugging-code)
   * [Goals](#goals)
   * [Compatibility Policy](#compatibility-policy)
     * [Minimum Version of Rust](#minimum-version-of-rust)
@@ -43,288 +45,83 @@ Created by [gh-md-toc](https://github.com/ekalinin/github-markdown-toc)
 
 ## What's New
 
-Here's what's new in v2.18.0
+Here's the highlights from v2.0.0 to v2.18.0
 
 * **Completions:**  Adds completion support for Microsoft PowerShell! (Thanks to @Arnavion)
-
-Here's what's new in v2.17.1
-
-* Fixes a bug where using low index multiples was propagated to subcommands
-
-Here's what's new in v2.17.0
-
 * Allows specifying the second to last positional argument as `multiple(true)` (i.e. things such as `mv <files>... <target>`)
 * Adds an `App::get_name` and `App::get_bin_name`
-
-Here's what's new in v2.16.4
-
-* Fixes bug that caused panic on subcommands with aliases
 * Conflicting argument errors are now symetrical, meaning more consistent and better usage suggestions
-* Fixes typo in example `13a_enum_values_automatic`
-* Fixes failing yaml example (#715)
-* Fixes the `debug` feature (#716)
-
-Here's the highlights for v2.16.3
-
-* Fixes a bug where the derived display order isn't propagated
-* **yaml-example:**  fixes some inconsistent args in the example
-
-Here's the highlights for v2.16.2
-
-* Fixes a bug where single quotes are not escaped
-
-Here's the highlights for v2.16.1
-
-* **Help Message:**  fixes a regression bug where args with multiple(true) threw off alignment
-
-Here's the highlights for v2.16.0
-
 * **Completions:**  adds automatic ZSH completion script generation support! :tada: :tada:
-
-Here's a gif of them in action!
-
-![zsh-comppletions](http://i.imgur.com/rwlMbAv.gif)
-
-Here's the highlights for v2.15.0
-
 * **AppSettings:**  adds new setting `AppSettings::AllowNegativeNumbers` which functions like `AllowLeadingHyphen` except only allows undefined negative numbers to pass parsing.
-* Improves some of the documentation of `AppSettings` by moving variants into roughly alphabetical order
-
-Here's the highlights for v2.14.1 (Huge thanks to all the contributors who put in a lot of work this cycle! Especially @tormol @nabijaczleweli and @wdv4758h)
-
 * Stabilize `clap_app!` macro (i.e. no longer need to use `unstable` feature)
-* Fixes a bug that made determining when to auto-wrap long help messages inconsistent
-* Fixes fish completions for nested subcommands
-* Improve documentation around features
-* Reword docs for `ErrorKind` and `App::settings`
-* Fix tests that fail when the `suggestions` feature is disabled
-* Fix the `OsString`-using doc-tests
-* Tag non-rust code blocks as such instead of ignoring them
-* Improve some errors about subcommands
-* Makes sure the doc-tests don't fail before ""missing file"" in YAML tests
 * Deprecate `App::with_defaults`
-* Make lints not enable other nightly-requiring features
-
-Here's the highlights for v2.14.0
-
-* One can now alias arguments either visibly (whichc appears in the help text) or invisibly just like subcommands!
+* One can now alias arguments either visibly (which appears in the help text) or invisibly just like subcommands!
 * The `from_usage` parser now correctly handles non-ascii names / options and help!
-* Fixes a bug in the `require_delimiter` code which caused some incorrect parses
-* Fixes various typos in the docs
-* Various other small performance improvements and enhancements
-
-Here's the highlights for v2.13.0
-
 * **Value Delimiters:**  fixes the confusion around implicitly setting value delimiters. (The default is to *not* use a delimiter unless explicitly set)
-* **Docs:** Updates README.md with new website information and updated video tutorials info
-* **Docs:** Updates the docs about removing implicit `value_delimiter(true)`
-* **Docs:** Adds better examples on using default values
-
-
-Here's the highlights for v2.12.1
-
-* Fixes a regression-bug where the old `{n}` newline char stopped being replaced a properly re-aligned newline
-
-Here's the highlights for v2.12.0
-
 * Changes the default value delimiter rules (i.e. the default is `use_delimiter(false)` *unless* a setting/method that implies multiple values was used) **[Bugfix that *may* ""break"" code]**
  * If code breaks, simply add `Arg::use_delimiter(true)` to the affected args
-* Updates the docs for the `Arg::multiple` method WRT value delimiters and default settings
 * Adds ability to hide the possible values from the help text on a per argument basis, instead of command wide
 * Allows for limiting detected terminal width (i.e. wrap at `x` length, unless the terminal width is *smaller*)
-* Removes some redundant `contains()` checks for minor performance improvements
-* Fixes a bug where valid args aren't recognized with the `AppSettings::AllowLeadingHyphen` setting
 * `clap` now ignores hard newlines in help messages and properly re-aligns text, but still wraps if the term width is too small
-* Makes some minor changes to when next line help is automatically used
 * Adds support for the setting `Arg::require_delimiter` from YAML
-* Removes the verbage about using `'{n}'` to insert newlines in help text from the docs (the normal `\n` can now be used)
-* Documents `AppSetting::DisableVersion`
-
-Here's the highlights for v2.11.3
-
 * `clap` no longer requires one to use `{n}` inside help text to insert a newline that is properly aligned. One can now use the normal `\n`.
 * `clap` now ignores hard newlines in help messages and properly re-aligns text, but still wraps if the term width is too small
-* Supports setting `Arg::require_delimiter` from YAML
-
-Here's the highlights for v2.11.2
-
-* Makes some minor changes to when next line help is automatically used for improved wrapping
-
-Here's the highlights for v2.11.1
-
-* Fixes an issue where settings weren't propogated down through grand-child subcommands
 * Errors can now have custom description
 * Uses `term_size` instead of home-grown solution on Windows
-* Updates deps with some minor bug fixes
-
-
-Here's the highlights for v2.11.0
-
 * Adds the ability to wrap help text intelligently on Windows!
-* Moves docs to [docs.rs!](https://docs.rs/clap/)
-* Fixes some usage strings that contain both args in groups and ones that conflict with each other
-* Uses standard conventions for bash completion files, namely `{bin}.bash-completion`
+* Moves docs to [docs.rs!](https://docs.rs/clap/)!
 * Automatically moves help text to the next line and wraps when term width is determined to be too small, or help text is too long
 * Vastly improves *development* error messages when using YAML
-* Adds `App::with_defaults` to automatically use `crate_authors!` and `crate_version!` macros
-* Other minor improvements and bug fixes
-
-Here's the highlights for v2.10.4
-
-* Fixes a bug where help is wrapped incorrectly and causing a panic with some non-English characters
-
-Here's the highlights for v2.10.3
-
-* Fixes a bug with non-English characters in help text wrapping, where the character is stripped or causes a panic
-* Fixes an issue with `strsim` which caused a panic in some scenarios
 * Adds a shorthand way to ignore help text wrapping and use source formatting (i.e. `App::set_term_width(0)`)
-
-Here's the highlights for v2.10.2
-
-* Fixes a critical bug where the help message is printed twice
-
-Here's the highlights for v2.10.1
-
 * **Help Subcommand:**  fixes misleading usage string when using multi-level subcommmands such as `myprog help subcmd1 subcmd2`
 * **YAML:**  allows using lists or single values with certain arg declarations for increased ergonomics
-
-
-Here's the highlights for v2.10.0
-
-
 * **Fish Shell Completions:**  one can generate a basic fish completions script at compile time!
-* **External SubCommands:**  fixes a bug which now correctly preserves external subcommand name along with args to said command (Minor breaking change that breaks no known real world code)
-* **YAML Documentation:**  fixes example 17's incorrect reference to arg_groups instead of groups
-
-
-Here's the highlights for v2.9.3
-
 * Adds the ability to generate completions to an `io::Write` object
 * Adds an `App::unset_setting` and `App::unset_settings`
-* Fixes bug where only first arg in list of `required_unless_one` is recognized
-* Fixes a typo bug `SubcommandsRequired`->`SubcommandRequired`
-
-
-Here's the highlights for v2.9.2
-
-
-* fixes bug where --help and --version short weren't added to the completion list
-* improves completions allowing multiple bins to have seperate completion files
-
-Here's the highlights for v2.9.0
-
 * **Completions:**  one can now [generate a bash completions](https://docs.rs/clap/2.9.0/clap/struct.App.html#method.gen_completions) script at compile time! These completions work with options using [possible values](https://docs.rs/clap/2.9.0/clap/struct.Arg.html#method.possible_values), [subcommand aliases](https://docs.rs/clap/2.9.0/clap/struct.App.html#method.aliases), and even multiple levels of subcommands
-* Minor bug fixes when using `AppSettings::TrailingVarArg` and `AppSettings::AllowLeadingHyphen`
-
-Here's the highlights for v2.8.0
-
 * **Arg:**  adds new optional setting [`Arg::require_delimiter`](https://docs.rs/clap/2.8.0/clap/struct.Arg.html#method.require_delimiter) which requires val delimiter to parse multiple values
 * The terminal sizing portion has been factored out into a separate crate, [term_size](https://crates.io/crates/term_size)
-* Minor bug fixes
-
-
-Here's the highlights for v2.7.1
-
-* **Options:**
-  *  options using multiple values and delimiters no longer parse additional values after a trailing space (i.e. `prog -o 1,2 file.txt` parses as `1,2` for `-o` and `file.txt` for a positional arg)
-  *  using options using multiple values and with an `=` no longer parse args after the trailing space as values (i.e. `prog -o=1 file.txt` parses as `1` for `-o` and `file.txt` for a positional arg)
-
-Here's the highlights for v2.7.0
-
+* Options using multiple values and delimiters no longer parse additional values after a trailing space (i.e. `prog -o 1,2 file.txt` parses as `1,2` for `-o` and `file.txt` for a positional arg)
+* Using options using multiple values and with an `=` no longer parse args after the trailing space as values (i.e. `prog -o=1 file.txt` parses as `1` for `-o` and `file.txt` for a positional arg)
 * **Usage Strings:**  `[FLAGS]` and `[ARGS]` are no longer blindly added to usage strings, instead only when applicable
 * `arg_enum!`:  allows using more than one meta item, or things like `#[repr(C)]` with `arg_enum!`s
 * `App::print_help`: now prints the same as would have been printed by `--help` or the like
-* **Help Messages:**
- *  prevents invoking `<cmd> help help` and displaying incorrect help message
- *  subcommand help messages requested via `<cmd> help <sub>` now correctly match `<cmd> <sub> --help`
-* **`ArgGroup`s:**
- *  one can now specify groups which require AT LEAST one of the args
- *  allows adding multiple ArgGroups per Arg
- * **Documentation:**  vastly improves `ArgGroup` docs by adding better examples
-* **Documentation:**  fixes a bunch of typos in the documentation
-
-Here's the highlights for v2.6.0
-
+* Prevents invoking `<cmd> help help` and displaying incorrect help message
+* Subcommand help messages requested via `<cmd> help <sub>` now correctly match `<cmd> <sub> --help`
+* One can now specify groups which require AT LEAST one of the args
+* Allows adding multiple ArgGroups per Arg
 * **Global Settings:** One can now set an `AppSetting` which is propogated down through child subcommands
 * **Terminal Wrapping:**  Allows wrapping at specified term width (Even on Windows!) (can now set an absolute width to ""smart"" wrap at)
 * **SubCommands/Aliases:**  adds support for visible aliases for subcommands (i.e. aliases that are dipslayed in the help message)
 * **Subcommands/Aliases:**  when viewing the help of an alias, it now display help of the aliased subcommand
-* Improves the default usage string when only a single positional arg is present
 * Adds new setting to stop delimiting values with `--` or `AppSettings::TrailingVarArg`
-* `App::before_help` and `App::after_help` now correctly wrap
-* Fixes bug where positional args are printed out of order when using templates
-* Fixes bug where one can't override the auto-generated version or help flags
-* Fixes issue where `App::before_help` wasn't printed
-* Fixes a failing windows build
-* Fixes bug where new color settings couldn't be converted from strings
-* Adds missing YAML methods for App and Arg
-* Allows printing version to any io::Write object
-* Removes extra newline from help and version output
-
-Here's what's new in v.2.5.2
-
-*   Removes trailing newlines from help and version output
-*   Allows printing version to any io::Write object
-*   Inter-links all types and pages
-*   Makes all publicly available types viewable in docs
-*   Fixes bug where one can't override version or help flags
-*   Fixes bug where args are printed out of order when using templates
-*   Fixes issue where `App::before_help` wasn't printed properly
-
-Here's what's new in v.2.5.0
-
 * Subcommands now support aliases - think of them as hidden subcommands that dispatch to said subcommand automatically
-
-Here's what's new in v2.4.3
-
-* Bug Fixes
- * Usage strings get de-deuplicated when there are args which are also part ``ArgGroup`s`
- * Fixed times when `ArgGroup`s are duplicated in usage strings
-* Improvements
- * Positional arguments which are part of a group are now formatted in a more readable way (fewer brackets)
- * Positional arguments use the standard `<>` brackets to reduce confusion
- * The default help string for the `help` subcommand has been shortened to fit in 80 columns
-
-Here's the highlights from v2.4.0
-
+* Fixed times when `ArgGroup`s are duplicated in usage strings
 * **Before Help:**  adds support for displaying info before help message
 * **Required Unless:**  adds support for allowing args that are required unless certain other args are present
-* Bug fixes
-
-Here's the highlights from v2.3.0
-
 * **New Help Template Engine!**: Now you have full control over the layout of your help message. Major thanks to @hgrecco
 * **Pull crate Authors from Cargo.toml**: One can now use the `crate_authors!` macro to automatically pull the crate authors from their Cargo.toml file
 * **Colored Help Messages**: Help messages can now be optionally colored (See the `AppSettings::ColoredHelp` setting). Screenshot below.
-* A bunch of bug fixes
-
-Here's the highlights from v2.2.1
-
 * **Help text auto wraps and aligns at for subcommands too!** - Long help strings of subcommands will now properly wrap and align to term width on Linux and OS X. This can be turned off as well.
-* Bug fixes
-
-An example of the optional colored help:
-
-![screenshot](http://i.imgur.com/7fs2h5j.png)
-
-Here's the highlights from v2.2.0
-
 * **Help text auto wraps and aligns at term width!** - Long help strings will now properly wrap and align to term width on Linux and OS X (and presumably Unix too). This can be turned off as well.
 * **Can customize the order of opts, flags, and subcommands in help messages**  - Instead of using the default alphabetical order, you can now re-arrange the order of your args and subcommands in help message. This helps to emphasize more popular or important options.
- * **Can auto-derive the order from declaration order** - Have a bunch of args or subcommmands to re-order? You can now just derive the order from the declaration order!
+* **Can auto-derive the order from declaration order** - Have a bunch of args or subcommmands to re-order? You can now just derive the order from the declaration order!
 * **Help subcommand now accepts other subcommands as arguments!** - Similar to other CLI precedents, the `help` subcommand can now accept other subcommands as arguments to display their help message. i.e. `$ myprog help mysubcmd` (*Note* these can even be nested heavily such as `$ myprog help subcmd1 subcmd2 subcmd3` etc.)
+* **Default Values**: Args can now specify default values
+* **Next Line Help**: Args can have help strings on the line following the argument (useful for long arguments, or those with many values). This can be set command-wide or for individual args
 
-* Other minor bug fixes
+Here's a gif of them in action!
+
+![zsh-comppletions](http://i.imgur.com/rwlMbAv.gif)
 
 An example of the help text wrapping at term width:
 
 ![screenshot](http://i.imgur.com/PAJzJJG.png)
 
-In v2.1.2
+An example of the optional colored help:
+
+![screenshot](http://i.imgur.com/7fs2h5j.png)
 
- * **Default Values**: Args can now specify default values
- * **Next Line Help**: Args can have help strings on the line following the argument (useful for long arguments, or those with many values). This can be set command-wide or for individual args
- * **Documentation Examples**: The examples in the documentation have been vastly improved
 
 For full details, see [CHANGELOG.md](https://github.com/kbknapp/clap-rs/blob/master/CHANGELOG.md)
 
@@ -697,6 +494,7 @@ features = [ ""suggestions"", ""color"" ]
 #### Opt-in features
 
 * **""yaml""**: Enables building CLIs from YAML documents. (builds dependency `yaml-rust`)
+* **""unstable""**: Enables unstable `clap` features that may change from release to release
 
 ### Dependencies Tree
 
@@ -707,6 +505,7 @@ The following graphic depicts `clap`s dependency graph (generated using [cargo-g
  * **Blue** Color: Dev dependency, only used while developing.
 
 ![clap dependencies](clap_dep_graph.png)
+
 ### More Information
 
 You can find complete documentation on the [docs.rs](https://docs.rs/clap/) for this project.
@@ -727,20 +526,65 @@ Another really great way to help is if you find an interesting, or helpful way i
 
 Please read [CONTRIBUTING.md](.github/CONTRIBUTING.md) before you start contributing.
 
+
+### Testing Code
+
 To test with all features both enabled and disabled, you can run theese commands:
 
 ```sh
 $ cargo test --no-default-features
-$ cargo test --features yaml
+$ cargo test --features ""yaml unstable""
 ```
 
-If you have a nightly compiler you can append `--features lints` to both commands
-to get style warnings and code smells; If you get one from code you think is fine,
-you can ignore it by prepending `#[cfg_attr(feature=""lints"", allow(lint_name))]`
-to the function or impl block.
+Alternatively, if you have [`just`](https://github.com/casey/just) installed you can run the prebuilt recipies. *Not* using `just` is prfeclty fine as well, it simply bundles commands automatically.
+
+For example, to test the code, as above simply run:
+
+```sh
+$ just run-tests`
+```
+
+From here on, I will lis the appropriate `cargo` command as well as the `just` command.
+
+Sometimes it's helpful to only run a subset of the tests, which can be done via:
+
+```sh
+$ cargo test --test <test_name>
+
+# Or
+
+$ just run-test <test_name>
+```
 
-If you are debugging (or just trying to understand the code) you can enable the
-""debug"" feature which will trace function calls and brances in some parts of the code.
+### Linting Code
+
+During the CI process `clap` runs against many different lints using [`clippy`](https://github.com/Manishearth/rust-clippy). In order to check if these lints pass on your own computer prior to submitting a PR you'll need a nightly compiler.
+
+In order to check the code for lints run either:
+
+```sh
+$ rustup override add nightly
+$ cargo build --features lints
+$ rustup override remove
+
+# Or
+
+$ just lint
+```
+
+### Debugging Code
+
+Another helpful technique is to see the `clap` debug output while developing features. In order to see the debug output while running the full test suite or individual tests, run:
+
+```sh
+$ cargo test --features debug
+
+# Or for individual tests
+$ cargo test --test <test_name> --features debug
+
+# The corresponding just command for individual debugging tests is:
+$ just debug <test_name>
+```
 
 ### Goals
 

diff --git a/packages/cli/src/commands/dev.ts b/packages/cli/src/commands/dev.ts
index 35d859e..d6d91ed 100644
--- a/packages/cli/src/commands/dev.ts
+++ b/packages/cli/src/commands/dev.ts
@@ -1,4 +1,4 @@
-import { resolve } from 'upath'
+import { resolve, relative } from 'upath'
 import chokidar from 'chokidar'
 import debounce from 'debounce-promise'
 import type { Nuxt } from '@nuxt/kit'
@@ -27,9 +27,9 @@ export default defineNuxtCommand({
     const { loadNuxt, buildNuxt } = requireModule('@nuxt/kit', rootDir) as typeof import('@nuxt/kit')
 
     let currentNuxt: Nuxt
-    const load = async (isRestart: boolean) => {
+    const load = async (isRestart: boolean, reason?: string) => {
       try {
-        const message = `${isRestart ? 'Restarting' : 'Starting'} nuxt...`
+        const message = `${reason ? reason + '. ' : ''}${isRestart ? 'Restarting' : 'Starting'} nuxt...`
         server.setApp(createLoadingHandler(message))
         if (isRestart) {
           console.log(message)
@@ -59,12 +59,8 @@ export default defineNuxtCommand({
     const dLoad = debounce(load, 250)
     const watcher = chokidar.watch([rootDir], { ignoreInitial: true, depth: 1 })
     watcher.on('all', (_event, file) => {
-      // Ignore any changes to files within the Nuxt build directory
-      if (file.includes(currentNuxt.options.buildDir)) {
-        return
-      }
-      if (file.includes('nuxt.config') || file.includes('modules') || file.includes('pages')) {
-        dLoad(true)
+      if (file.match(/nuxt\.config\.(js|ts|mjs|cjs)$|pages$/)) {
+        dLoad(true, `${relative(rootDir, file)} updated`)
       }
     })
 
",2,"[""eb51316cdfdc7258d287ba13b67ef2f42bd2b8f6"", ""cbce777addb3dd118232a9f28db9d425d4c937b2""]","[""docs"", ""fix""]"
use lambda to define backend operations | Downgrade @azure/* deps for Node.sj 10 compability,"diff --git a/ibis/backends/duckdb/registry.py b/ibis/backends/duckdb/registry.py
index 20ffd6f..3f56f2a 100644
--- a/ibis/backends/duckdb/registry.py
+++ b/ibis/backends/duckdb/registry.py
@@ -107,28 +107,13 @@ def _literal(_, op):
     return sa.cast(sa.literal(value), sqla_type)
 
 
-def _array_column(t, op):
-    (arg,) = op.args
-    sqla_type = to_sqla_type(op.output_dtype)
-    return sa.cast(sa.func.list_value(*map(t.translate, arg)), sqla_type)
-
-
 def _neg_idx_to_pos(array, idx):
     if_ = getattr(sa.func, ""if"")
     arg_length = sa.func.array_length(array)
     return if_(idx < 0, arg_length + sa.func.greatest(idx, -arg_length), idx)
 
 
-def _struct_field(t, op):
-    return sa.func.struct_extract(
-        t.translate(op.arg),
-        sa.text(repr(op.field)),
-        type_=to_sqla_type(op.output_dtype),
-    )
-
-
-def _regex_extract(t, op):
-    string, pattern, index = map(t.translate, op.args)
+def _regex_extract(string, pattern, index):
     result = sa.case(
         [
             (
@@ -149,8 +134,7 @@ def _regex_extract(t, op):
     return result
 
 
-def _json_get_item(t, op):
-    left, path = map(t.translate, op.args)
+def _json_get_item(left, path):
     # Workaround for https://github.com/duckdb/duckdb/issues/5063
     # In some situations duckdb silently does the wrong thing if
     # the path is parametrized.
@@ -197,7 +181,12 @@ def _struct_column(t, op):
 
 operation_registry.update(
     {
-        ops.ArrayColumn: _array_column,
+        ops.ArrayColumn: (
+            lambda t, op: sa.cast(
+                sa.func.list_value(*map(t.translate, op.cols)),
+                to_sqla_type(op.output_dtype),
+            )
+        ),
         ops.ArrayConcat: fixed_arity(sa.func.array_concat, 2),
         ops.ArrayRepeat: fixed_arity(
             lambda arg, times: sa.func.flatten(
@@ -222,7 +211,13 @@ operation_registry.update(
         # TODO: map operations, but DuckDB's maps are multimaps
         ops.Modulus: fixed_arity(operator.mod, 2),
         ops.Round: _round,
-        ops.StructField: _struct_field,
+        ops.StructField: (
+            lambda t, op: sa.func.struct_extract(
+                t.translate(op.arg),
+                sa.text(repr(op.field)),
+                type_=to_sqla_type(op.output_dtype),
+            )
+        ),
         ops.TableColumn: _table_column,
         ops.TimestampDiff: fixed_arity(sa.func.age, 2),
         ops.TimestampFromUNIX: _timestamp_from_unix,
@@ -232,7 +227,7 @@ operation_registry.update(
             lambda *_: sa.cast(sa.func.now(), sa.TIMESTAMP),
             0,
         ),
-        ops.RegexExtract: _regex_extract,
+        ops.RegexExtract: fixed_arity(_regex_extract, 3),
         ops.RegexReplace: fixed_arity(
             lambda *args: sa.func.regexp_replace(*args, ""g""), 3
         ),
@@ -255,7 +250,7 @@ operation_registry.update(
         ops.ArgMin: reduction(sa.func.min_by),
         ops.ArgMax: reduction(sa.func.max_by),
         ops.BitwiseXor: fixed_arity(sa.func.xor, 2),
-        ops.JSONGetItem: _json_get_item,
+        ops.JSONGetItem: fixed_arity(_json_get_item, 2),
         ops.RowID: lambda *_: sa.literal_column('rowid'),
         ops.StringToTimestamp: fixed_arity(sa.func.strptime, 2),
     }

diff --git a/package.json b/package.json
index 911f8cd..ac29f54 100644
--- a/package.json
+++ b/package.json
@@ -79,7 +79,13 @@
   ""resolutions"": {
     ""@types/ramda"": ""0.27.40"",
     ""rc-tree"": ""4.1.5"",
+    ""@azure/storage-blob"": ""12.7.0"",
+    ""@azure/core-paging"": ""1.1.3"",
+    ""@azure/logger"": ""1.0.0"",
     ""@azure/core-auth"": ""1.2.0"",
+    ""@azure/core-lro"": ""1.0.5"",
+    ""@azure/core-tracing"": ""1.0.0-preview.10"",
+    ""@azure/core-http"": ""1.2.6"",
     ""testcontainers"": ""7.12.1""
   },
   ""license"": ""MIT""
diff --git a/yarn.lock b/yarn.lock
index 5019f68..99235b5 100644
--- a/yarn.lock
+++ b/yarn.lock
@@ -1144,19 +1144,19 @@
     ""@azure/abort-controller"" ""^1.0.0""
     tslib ""^2.0.0""
 
-""@azure/core-http@^2.0.0"":
-  version ""2.2.2""
-  resolved ""https://registry.yarnpkg.com/@azure/core-http/-/core-http-2.2.2.tgz#573798f087d808d39aa71fd7c52b8d7b89f440da""
-  integrity sha512-V1DdoO9V/sFimKpdWoNBgsE+QUjQgpXYnxrTdUp5RyhsTJjvEVn/HKmTQXIHuLUUo6IyIWj+B+Dg4VaXse9dIA==
+""@azure/core-http@1.2.6"", ""@azure/core-http@^1.2.0"", ""@azure/core-http@^2.0.0"":
+  version ""1.2.6""
+  resolved ""https://registry.yarnpkg.com/@azure/core-http/-/core-http-1.2.6.tgz#9cd508418572d2062fd3175274219438772bdb65""
+  integrity sha512-odtH7UMKtekc5YQ86xg9GlVHNXR6pq2JgJ5FBo7/jbOjNGdBqcrIVrZx2bevXVJz/uUTSx6vUf62gzTXTfqYSQ==
   dependencies:
     ""@azure/abort-controller"" ""^1.0.0""
     ""@azure/core-asynciterator-polyfill"" ""^1.0.0""
     ""@azure/core-auth"" ""^1.3.0""
-    ""@azure/core-tracing"" ""1.0.0-preview.13""
+    ""@azure/core-tracing"" ""1.0.0-preview.11""
     ""@azure/logger"" ""^1.0.0""
     ""@types/node-fetch"" ""^2.5.0""
-    ""@types/tunnel"" ""^0.0.3""
-    form-data ""^4.0.0""
+    ""@types/tunnel"" ""^0.0.1""
+    form-data ""^3.0.0""
     node-fetch ""^2.6.0""
     process ""^0.11.10""
     tough-cookie ""^4.0.0""
@@ -1165,38 +1165,39 @@
     uuid ""^8.3.0""
     xml2js ""^0.4.19""
 
-""@azure/core-lro@^2.2.0"":
-  version ""2.2.1""
-  resolved ""https://registry.yarnpkg.com/@azure/core-lro/-/core-lro-2.2.1.tgz#5527b41037c658d3aefc19d68633e51e53d6e6a3""
-  integrity sha512-HE6PBl+mlKa0eBsLwusHqAqjLc5n9ByxeDo3Hz4kF3B1hqHvRkBr4oMgoT6tX7Hc3q97KfDctDUon7EhvoeHPA==
+""@azure/core-lro@1.0.5"", ""@azure/core-lro@^2.0.0"":
+  version ""1.0.5""
+  resolved ""https://registry.yarnpkg.com/@azure/core-lro/-/core-lro-1.0.5.tgz#856a2cb6a9bec739ee9cde33a27cc28f81ac0522""
+  integrity sha512-0EFCFZxARrIoLWMIRt4vuqconRVIO2Iin7nFBfJiYCCbKp5eEmxutNk8uqudPmG0XFl5YqlVh68/al/vbE5OOg==
   dependencies:
     ""@azure/abort-controller"" ""^1.0.0""
-    ""@azure/core-tracing"" ""1.0.0-preview.13""
-    ""@azure/logger"" ""^1.0.0""
-    tslib ""^2.2.0""
+    ""@azure/core-http"" ""^1.2.0""
+    ""@azure/core-tracing"" ""1.0.0-preview.11""
+    events ""^3.0.0""
+    tslib ""^2.0.0""
 
-""@azure/core-paging@^1.1.1"":
-  version ""1.2.0""
-  resolved ""https://registry.yarnpkg.com/@azure/core-paging/-/core-paging-1.2.0.tgz#3754da429e8687bdc3613c750e79a564582e802b""
-  integrity sha512-ZX1bCjm/MjKPCN6kQD/9GJErYSoKA8YWp6YWoo5EIzcTWlSBLXu3gNaBTUl8usGl+UShiKo7b4Gdy1NSTIlpZg==
+""@azure/core-paging@1.1.3"", ""@azure/core-paging@^1.1.1"":
+  version ""1.1.3""
+  resolved ""https://registry.yarnpkg.com/@azure/core-paging/-/core-paging-1.1.3.tgz#3587c9898a0530cacb64bab216d7318468aa5efc""
+  integrity sha512-his7Ah40ThEYORSpIAwuh6B8wkGwO/zG7gqVtmSE4WAJ46e36zUDXTKReUCLBDc6HmjjApQQxxcRFy5FruG79A==
   dependencies:
     ""@azure/core-asynciterator-polyfill"" ""^1.0.0""
-    tslib ""^2.2.0""
 
-""@azure/core-tracing@1.0.0-preview.13"":
-  version ""1.0.0-preview.13""
-  resolved ""https://registry.yarnpkg.com/@azure/core-tracing/-/core-tracing-1.0.0-preview.13.tgz#55883d40ae2042f6f1e12b17dd0c0d34c536d644""
-  integrity sha512-KxDlhXyMlh2Jhj2ykX6vNEU0Vou4nHr025KoSEiz7cS3BNiHNaZcdECk/DmLkEB0as5T7b/TpRcehJ5yV6NeXQ==
+""@azure/core-tracing@1.0.0-preview.10"", ""@azure/core-tracing@1.0.0-preview.11"", ""@azure/core-tracing@1.0.0-preview.13"":
+  version ""1.0.0-preview.10""
+  resolved ""https://registry.yarnpkg.com/@azure/core-tracing/-/core-tracing-1.0.0-preview.10.tgz#e7060272145dddad4486765030d1b037cd52a8ea""
+  integrity sha512-iIwjtMwQnsxB7cYkugMx+s4W1nfy3+pT/ceo+uW1fv4YDgYe84nh+QP0fEC9IH/3UATLSWbIBemdMHzk2APUrw==
   dependencies:
-    ""@opentelemetry/api"" ""^1.0.1""
-    tslib ""^2.2.0""
+    ""@opencensus/web-types"" ""0.0.7""
+    ""@opentelemetry/api"" ""^0.10.2""
+    tslib ""^2.0.0""
 
-""@azure/logger@^1.0.0"":
-  version ""1.0.3""
-  resolved ""https://registry.yarnpkg.com/@azure/logger/-/logger-1.0.3.tgz#6e36704aa51be7d4a1bae24731ea580836293c96""
-  integrity sha512-aK4s3Xxjrx3daZr3VylxejK3vG5ExXck5WOHDJ8in/k9AqlfIyFMMT1uG7u8mNjX+QRILTIn0/Xgschfh/dQ9g==
+""@azure/logger@1.0.0"", ""@azure/logger@^1.0.0"":
+  version ""1.0.0""
+  resolved ""https://registry.yarnpkg.com/@azure/logger/-/logger-1.0.0.tgz#48b371dfb34288c8797e5c104f6c4fb45bf1772c""
+  integrity sha512-g2qLDgvmhyIxR3JVS8N67CyIOeFRKQlX/llxYJQr1OSGQqM3HTpVP8MjmjcEKbL/OIt2N9C9UFaNQuKOw1laOA==
   dependencies:
-    tslib ""^2.2.0""
+    tslib ""^1.9.3""
 
 ""@azure/ms-rest-azure-env@^2.0.0"":
   version ""2.0.0""
@@ -1227,19 +1228,19 @@
     ""@azure/ms-rest-js"" ""^2.0.4""
     adal-node ""^0.2.2""
 
-""@azure/storage-blob@^12.5.0"":
-  version ""12.8.0""
-  resolved ""https://registry.yarnpkg.com/@azure/storage-blob/-/storage-blob-12.8.0.tgz#97b7ecc6c7b17bcbaf0281c79c16af6f512d6130""
-  integrity sha512-c8+Wz19xauW0bGkTCoqZH4dYfbtBniPiGiRQOn1ca6G5jsjr4azwaTk9gwjVY8r3vY2Taf95eivLzipfIfiS4A==
+""@azure/storage-blob@12.7.0"", ""@azure/storage-blob@^12.5.0"":
+  version ""12.7.0""
+  resolved ""https://registry.yarnpkg.com/@azure/storage-blob/-/storage-blob-12.7.0.tgz#f17f278000a46bca516e5864d846cd8fa57d6d7d""
+  integrity sha512-7YEWEx03Us/YBxthzBv788R7jokwpCD5KcIsvtE5xRaijNX9o80KXpabhEwLR9DD9nmt/AlU/c1R+aXydgCduQ==
   dependencies:
     ""@azure/abort-controller"" ""^1.0.0""
     ""@azure/core-http"" ""^2.0.0""
-    ""@azure/core-lro"" ""^2.2.0""
+    ""@azure/core-lro"" ""^2.0.0""
     ""@azure/core-paging"" ""^1.1.1""
     ""@azure/core-tracing"" ""1.0.0-preview.13""
     ""@azure/logger"" ""^1.0.0""
     events ""^3.0.0""
-    tslib ""^2.2.0""
+    tslib ""^2.0.0""
 
 ""@babel/cli@^7.5.5"":
   version ""7.16.0""
@@ -2888,9 +2889,9 @@
   integrity sha512-82cpyJyKRoQoRi+14ibCeGPu0CwypgtBAdBhq1WfvagpCZNKqwXbKwXllYSMG91DhmG4jt9gN8eP6lGOtozuaw==
 
 ""@google-cloud/bigquery@^5.6.0"":
-  version ""5.9.1""
-  resolved ""https://registry.yarnpkg.com/@google-cloud/bigquery/-/bigquery-5.9.1.tgz#96cee86fa0caef4a7e1470efde9295bc09f5981f""
-  integrity sha512-80pMzhAC299CSiXW9TvR8AARLaPRDeQg8pSAvrVcLXcUkx1hWvVx2m94nBZ4KUoZb4LVWIHHYhvFB6XvIcxqjw==
+  version ""5.9.2""
+  resolved ""https://registry.yarnpkg.com/@google-cloud/bigquery/-/bigquery-5.9.2.tgz#d53eac984fdd256d31be490762157e5f6c5b82c3""
+  integrity sha512-lJiMsSekcnhrzzR9e48yx8iOx+ElP3r/wOoionXL6eDPbA41RgP12if5NmMqHZzfWdKlWV2plspEPrbjhJAzCw==
   dependencies:
     ""@google-cloud/common"" ""^3.1.0""
     ""@google-cloud/paginator"" ""^3.0.0""
@@ -4831,11 +4832,28 @@
   resolved ""https://registry.yarnpkg.com/@oozcitak/util/-/util-8.3.8.tgz#10f65fe1891fd8cde4957360835e78fd1936bfdd""
   integrity sha512-T8TbSnGsxo6TDBJx/Sgv/BlVJL3tshxZP7Aq5R1mSnM5OcHY2dQaxLMu2+E8u3gN0MLOzdjurqN4ZRVuzQycOQ==
 
-""@opentelemetry/api@^1.0.0"", ""@opentelemetry/api@^1.0.1"":
+""@opencensus/web-types@0.0.7"":
+  version ""0.0.7""
+  resolved ""https://registry.yarnpkg.com/@opencensus/web-types/-/web-types-0.0.7.tgz#4426de1fe5aa8f624db395d2152b902874f0570a""
+  integrity sha512-xB+w7ZDAu3YBzqH44rCmG9/RlrOmFuDPt/bpf17eJr8eZSrLt7nc7LnWdxM9Mmoj/YKMHpxRg28txu3TcpiL+g==
+
+""@opentelemetry/api@^0.10.2"":
+  version ""0.10.2""
+  resolved ""https://registry.yarnpkg.com/@opentelemetry/api/-/api-0.10.2.tgz#9647b881f3e1654089ff7ea59d587b2d35060654""
+  integrity sha512-GtpMGd6vkzDMYcpu2t9LlhEgMy/SzBwRnz48EejlRArYqZzqSzAsKmegUK7zHgl+EOIaK9mKHhnRaQu3qw20cA==
+  dependencies:
+    ""@opentelemetry/context-base"" ""^0.10.2""
+
+""@opentelemetry/api@^1.0.0"":
   version ""1.0.3""
   resolved ""https://registry.yarnpkg.com/@opentelemetry/api/-/api-1.0.3.tgz#13a12ae9e05c2a782f7b5e84c3cbfda4225eaf80""
   integrity sha512-puWxACExDe9nxbBB3lOymQFrLYml2dVOrd7USiVRnSbgXE+KwBu+HxFvxrzfqsiSda9IWsXJG1ef7C1O2/GmKQ==
 
+""@opentelemetry/context-base@^0.10.2"":
+  version ""0.10.2""
+  resolved ""https://registry.yarnpkg.com/@opentelemetry/context-base/-/context-base-0.10.2.tgz#55bea904b2b91aa8a8675df9eaba5961bddb1def""
+  integrity sha512-hZNKjKOYsckoOEgBziGMnBcX0M7EtstnCmwz5jZUOUYwlZ+/xxX6z3jPu1XVO2Jivk0eLfuP9GP+vFD49CMetw==
+
 ""@opentelemetry/semantic-conventions@^0.24.0"":
   version ""0.24.0""
   resolved ""https://registry.yarnpkg.com/@opentelemetry/semantic-conventions/-/semantic-conventions-0.24.0.tgz#1028ef0e0923b24916158d80d2ddfd67ea8b6740""
@@ -5564,9 +5582,9 @@
   integrity sha1-7ihweulOEdK4J7y+UnC86n8+ce4=
 
 ""@types/jsonwebtoken@^8.5.0"":
-  version ""8.5.5""
-  resolved ""https://registry.yarnpkg.com/@types/jsonwebtoken/-/jsonwebtoken-8.5.5.tgz#da5f2f4baee88f052ef3e4db4c1a0afb46cff22c""
-  integrity sha512-OGqtHQ7N5/Ap/TUwO6IgHDuLiAoTmHhGpNvgkCm/F4N6pKzx/RBSfr2OXZSwC6vkfnsEdb6+7DNZVtiXiwdwFw==
+  version ""8.5.6""
+  resolved ""https://registry.yarnpkg.com/@types/jsonwebtoken/-/jsonwebtoken-8.5.6.tgz#1913e5a61e70a192c5a444623da4901a7b1a9d42""
+  integrity sha512-+P3O/xC7nzVizIi5VbF34YtqSonFsdnbXBnWUCYRiKOi1f9gA4sEFvXkrGr/QVV23IbMYvcoerI7nnhDUiWXRQ==
   dependencies:
     ""@types/node"" ""*""
 
@@ -5753,18 +5771,18 @@
     ""@types/react"" ""*""
 
 ""@types/react@*"", ""@types/react@^17.0.3"":
-  version ""17.0.34""
-  resolved ""https://registry.yarnpkg.com/@types/react/-/react-17.0.34.tgz#797b66d359b692e3f19991b6b07e4b0c706c0102""
-  integrity sha512-46FEGrMjc2+8XhHXILr+3+/sTe3OfzSPU9YGKILLrUYbQ1CLQC9Daqo1KzENGXAWwrFwiY0l4ZbF20gRvgpWTg==
+  version ""17.0.35""
+  resolved ""https://registry.yarnpkg.com/@types/react/-/react-17.0.35.tgz#217164cf830267d56cd1aec09dcf25a541eedd4c""
+  integrity sha512-r3C8/TJuri/SLZiiwwxQoLAoavaczARfT9up9b4Jr65+ErAUX3MIkU0oMOQnrpfgHme8zIqZLX7O5nnjm5Wayw==
   dependencies:
     ""@types/prop-types"" ""*""
     ""@types/scheduler"" ""*""
     csstype ""^3.0.2""
 
 ""@types/react@^16.9.41"":
-  version ""16.14.20""
-  resolved ""https://registry.yarnpkg.com/@types/react/-/react-16.14.20.tgz#ff6e932ad71d92c27590e4a8667c7a53a7d0baad""
-  integrity sha512-SV7TaVc8e9E/5Xuv6TIyJ5VhQpZoVFJqX6IZgj5HZoFCtIDCArE3qXkcHlc6O/Ud4UwcMoX+tlvDA95YrKdLgA==
+  version ""16.14.21""
+  resolved ""https://registry.yarnpkg.com/@types/react/-/react-16.14.21.tgz#35199b21a278355ec7a3c40003bd6a334bd4ae4a""
+  integrity sha512-rY4DzPKK/4aohyWiDRHS2fotN5rhBSK6/rz1X37KzNna9HJyqtaGAbq9fVttrEPWF5ywpfIP1ITL8Xi2QZn6Eg==
   dependencies:
     ""@types/prop-types"" ""*""
     ""@types/scheduler"" ""*""
@@ -5950,10 +5968,10 @@
   resolved ""https://registry.yarnpkg.com/@types/tough-cookie/-/tough-cookie-4.0.1.tgz#8f80dd965ad81f3e1bc26d6f5c727e132721ff40""
   integrity sha512-Y0K95ThC3esLEYD6ZuqNek29lNX2EM1qxV8y2FTLUB0ff5wWrk7az+mLrnNFUnaXcgKye22+sFBRXOgpPILZNg==
 
-""@types/tunnel@^0.0.3"":
-  version ""0.0.3""
-  resolved ""https://registry.yarnpkg.com/@types/tunnel/-/tunnel-0.0.3.tgz#f109e730b072b3136347561fc558c9358bb8c6e9""
-  integrity sha512-sOUTGn6h1SfQ+gbgqC364jLFBw2lnFqkgF3q0WovEHRLMrVD1sd5aufqi/aJObLekJO+Aq5z646U4Oxy6shXMA==
+""@types/tunnel@^0.0.1"":
+  version ""0.0.1""
+  resolved ""https://registry.yarnpkg.com/@types/tunnel/-/tunnel-0.0.1.tgz#0d72774768b73df26f25df9184273a42da72b19c""
+  integrity sha512-AOqu6bQu5MSWwYvehMXLukFHnupHrpZ8nvgae5Ggie9UwzDR1CCwoXgSSWNZJuyOlCdfdsWMA5F2LlmvyoTv8A==
   dependencies:
     ""@types/node"" ""*""
 
@@ -5999,9 +6017,9 @@
     source-map ""^0.6.1""
 
 ""@types/webpack@^4"", ""@types/webpack@^4.0.0"", ""@types/webpack@^4.41.8"":
-  version ""4.41.31""
-  resolved ""https://registry.yarnpkg.com/@types/webpack/-/webpack-4.41.31.tgz#c35f252a3559ddf9c85c0d8b0b42019025e581aa""
-  integrity sha512-/i0J7sepXFIp1ZT7FjUGi1eXMCg8HCCzLJEQkKsOtbJFontsJLolBcDC+3qxn5pPwiCt1G0ZdRmYRzNBtvpuGQ==
+  version ""4.41.32""
+  resolved ""https://registry.yarnpkg.com/@types/webpack/-/webpack-4.41.32.tgz#a7bab03b72904070162b2f169415492209e94212""
+  integrity sha512-cb+0ioil/7oz5//7tZUSwbrSAN/NWHrQylz5cW8G0dWTcF/g+/dSdMlKVZspBYuMAN1+WnwHrkxiRrLcwd0Heg==
   dependencies:
     ""@types/node"" ""*""
     ""@types/tapable"" ""^1""
@@ -7624,9 +7642,9 @@ autoprefixer@^9.6.1, autoprefixer@^9.6.5, autoprefixer@^9.8.6:
     postcss-value-parser ""^4.1.0""
 
 aws-sdk@^2.404.0, aws-sdk@^2.787.0, aws-sdk@^2.819.0, aws-sdk@^2.878.0:
-  version ""2.1028.0""
-  resolved ""https://registry.yarnpkg.com/aws-sdk/-/aws-sdk-2.1028.0.tgz#ce076076174afa9bd311406b8186ea90163e3331""
-  integrity sha512-OmR0NcpU8zsDcUOZhM+eZ6CzlUFtuaEuRyjm6mxDO0KI7lJAp7/NzB6tcellRrgWxL+NO7b5TSxi+m28qu5ocQ==
+  version ""2.1029.0""
+  resolved ""https://registry.yarnpkg.com/aws-sdk/-/aws-sdk-2.1029.0.tgz#702d4d6092adcf0ceaf37ae0da6fee07a71f39dd""
+  integrity sha512-nCmaMPkJr3EATXaeqR3JeNC0GTDH2lJZ3Xq/ZCAW+yrfaPQWv8HqJJHBCNGtmk3FmcCoxc7ed/gEB8XSl0tocA==
   dependencies:
     buffer ""4.9.2""
     events ""1.1.1""
@@ -8596,11 +8614,16 @@ bytes@3.0.0:
   resolved ""https://registry.yarnpkg.com/bytes/-/bytes-3.0.0.tgz#d32815404d689699f85a4ea4fa8755dd13a96048""
   integrity sha1-0ygVQE1olpn4Wk6k+odV3ROpYEg=
 
-bytes@3.1.0, bytes@^3.1.0:
+bytes@3.1.0:
   version ""3.1.0""
   resolved ""https://registry.yarnpkg.com/bytes/-/bytes-3.1.0.tgz#f6cf7933a360e0588fa9fde85651cdc7f805d1f6""
   integrity sha512-zauLjrfCG+xvoyaqLoV8bLVXXNGC4JqlxFCutSDWA6fJrTo2ZuvLYTqZ7aHBLZSMOopbzwv8f+wZcVzfVTI2Dg==
 
+bytes@^3.1.0:
+  version ""3.1.1""
+  resolved ""https://registry.yarnpkg.com/bytes/-/bytes-3.1.1.tgz#3f018291cb4cbad9accb6e6970bca9c8889e879a""
+  integrity sha512-dWe4nWO/ruEOY7HkUJ5gFt1DCFV9zPRoJr8pV0/ASQermOZjtq8jMjOprC0Kd10GLN+l7xaUPvxzJFWtxGu8Fg==
+
 cacache@15.0.3:
   version ""15.0.3""
   resolved ""https://registry.yarnpkg.com/cacache/-/cacache-15.0.3.tgz#2225c2d1dd8e872339950d6a39c051e0e9334392""
@@ -11359,9 +11382,9 @@ ejs@^2.6.1:
   integrity sha512-7vmuyh5+kuUyJKePhQfRQBhXV5Ce+RnaeeQArKu1EAMpL3WbgMt5WG6uQZpEVvYSSsxMXRKOewtDk9RaTKXRlA==
 
 electron-to-chromium@^1.3.564, electron-to-chromium@^1.3.896:
-  version ""1.3.896""
-  resolved ""https://registry.yarnpkg.com/electron-to-chromium/-/electron-to-chromium-1.3.896.tgz#4a94efe4870b1687eafd5c378198a49da06e8a1b""
-  integrity sha512-NcGkBVXePiuUrPLV8IxP43n1EOtdg+dudVjrfVEUd/bOqpQUFZ2diL5PPYzbgEhZFEltdXV3AcyKwGnEQ5lhMA==
+  version ""1.3.899""
+  resolved ""https://registry.yarnpkg.com/electron-to-chromium/-/electron-to-chromium-1.3.899.tgz#4d7d040e73def3d5f5bd6b8a21049025dce6fce0""
+  integrity sha512-w16Dtd2zl7VZ4N4Db+FIa7n36sgPGCKjrKvUUmp5ialsikvcQLjcJR9RWnlYNxIyEHLdHaoIZEqKsPxU9MdyBg==
 
 elegant-spinner@^1.0.1:
   version ""1.0.1""
@@ -12887,15 +12910,6 @@ form-data@^3.0.0:
     combined-stream ""^1.0.8""
     mime-types ""^2.1.12""
 
-form-data@^4.0.0:
-  version ""4.0.0""
-  resolved ""https://registry.yarnpkg.com/form-data/-/form-data-4.0.0.tgz#93919daeaf361ee529584b9b31664dc12c9fa452""
-  integrity sha512-ETEklSGi5t0QMZuiXoA/Q6vcnxcLQP5vdugSpuAyi6SVGi2clPPp+xgEhuMaHC+zGgn31Kd235W35f7Hykkaww==
-  dependencies:
-    asynckit ""^0.4.0""
-    combined-stream ""^1.0.8""
-    mime-types ""^2.1.12""
-
 form-data@~2.3.2:
   version ""2.3.3""
   resolved ""https://registry.yarnpkg.com/form-data/-/form-data-2.3.3.tgz#dcce52c05f644f298c6a7ab936bd724ceffbf3a6""
@@ -21198,11 +21212,13 @@ proto-list@~1.2.1:
   integrity sha1-IS1b/hMYMGpCD2QCuOJv85ZHqEk=
 
 proto3-json-serializer@^0.1.5:
-  version ""0.1.5""
-  resolved ""https://registry.yarnpkg.com/proto3-json-serializer/-/proto3-json-serializer-0.1.5.tgz#c619769a59dc7fd8adf4e6c5060b9bf3039c8304""
-  integrity sha512-G395jcZkgNXNeS+6FGqd09TsXeoCs9wmBWByDiwFy7Yd7HD8pyfyvf6q+rGh7PhT4AshRpG4NowzoKYUtkNjKg==
+  version ""0.1.6""
+  resolved ""https://registry.yarnpkg.com/proto3-json-serializer/-/proto3-json-serializer-0.1.6.tgz#67cf3b8d5f4c8bebfc410698ad3b1ed64da39c7b""
+  integrity sha512-tGbV6m6Kad8NqxMh5hw87euPS0YoZSAOIfvR01zYkQV8Gpx1V/8yU/0gCKCvfCkhAJsjvzzhnnsdQxA1w7PSog==
+  dependencies:
+    protobufjs ""^6.11.2""
 
-protobufjs@6.11.2, protobufjs@^6.10.0:
+protobufjs@6.11.2, protobufjs@^6.10.0, protobufjs@^6.11.2:
   version ""6.11.2""
   resolved ""https://registry.yarnpkg.com/protobufjs/-/protobufjs-6.11.2.tgz#de39fabd4ed32beaa08e9bb1e30d08544c1edf8b""
   integrity sha512-4BQJoPooKJl2G9j3XftkIXjoC9C0Av2NOrWmbLWT1vH32GcSUHjM0Arra6UfTsVyfMAuFzaLucXn1sadxJydAw==
",2,"[""5d14de6722eb34c6604a124f6f11cb711f16bd44"", ""5ef4fd29a4cef69c6c348dd25156934df041f183""]","[""refactor"", ""build""]"
"simplyfy statement | initialize threejs objects in defaultRef, to fix undefined type errors","diff --git a/src/Object/Merge.ts b/src/Object/Merge.ts
index 1f48efb..06caad1 100644
--- a/src/Object/Merge.ts
+++ b/src/Object/Merge.ts
@@ -96,9 +96,11 @@ type ChooseMergeDeep<OK, O1K, K extends Key, OOK extends Key, style extends Merg
 @hidden
 */
 export type _MergeDeep<O, O1, K extends Key, OOK extends Key, style extends MergeStyle> =
-    Or<Extends<[O], [never]>, Extends<[O1], [never]>> extends 1 // filter never
+    [O] extends [never]
     ? MergeProp<O, O1, K, OOK, style>
-    : LibStyle<ChooseMergeDeep<NoList<O>, NoList<O1>, K, OOK, style>, O, O1, style>
+    : [O1] extends [never]
+      ? MergeProp<O, O1, K, OOK, style>
+      : LibStyle<ChooseMergeDeep<NoList<O>, NoList<O1>, K, OOK, style>, O, O1, style>
 
 /**
 @hidden
diff --git a/src/Object/Patch.ts b/src/Object/Patch.ts
index 2d73784..2c8bd42 100644
--- a/src/Object/Patch.ts
+++ b/src/Object/Patch.ts
@@ -89,9 +89,11 @@ type ChoosePatchDeep<OK, O1K, K extends Key, OOK extends Key, style extends Merg
 @hidden
 */
 export type _PatchDeep<O, O1, K extends Key, OOK extends Key, style extends MergeStyle> =
-    Or<Extends<[O], [never]>, Extends<[O1], [never]>> extends 1 // filter never
+    [O] extends [never]
     ? PatchProp<O, O1, K, OOK>
-    : LibStyle<ChoosePatchDeep<NoList<O>, NoList<O1>, K, OOK, style>, O, O1, style>
+    : [O1] extends [never]
+      ? PatchProp<O, O1, K, OOK>
+      : LibStyle<ChoosePatchDeep<NoList<O>, NoList<O1>, K, OOK, style>, O, O1, style>
 
 /**
 @hidden

diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number
",2,"[""f86944ff00b970d7e2da48abbff43e58bdf29b99"", ""2561f4ade46fc9d59f289f328cc77733a6443697""]","[""refactor"", ""fix""]"
fix typos (#90) | skip flaky test,"diff --git a/README.md b/README.md
index de15ac5..5ad8b47 100755
--- a/README.md
+++ b/README.md
@@ -16,13 +16,13 @@ content that will be loaded, similar to Facebook cards loaders.
 
 ## Features
 
-* :gear: **Complety customizable:** you can change the colors, speed and sizes;
+* :gear: **Completely customizable:** you can change the colors, speed and sizes;
 * :pencil2: **Create your own loading:** use the
   [create-react-content-loader](https://danilowoz.github.io/create-react-content-loader/) to create
-  your customs loadings easily;
+  your custom loadings easily;
 * :ok_hand: **You can use right now:** there are a lot of presets to use the loader, see the
   [options](#options);
-* :rocket: **Perfomance:** react-content-loader uses pure SVG to work, so it's works without any extra scritpt,
+* :rocket: **Performance:** react-content-loader uses pure SVG to work, so it works without any extra scripts,
   canvas, etc;
 
 ## Usage

diff --git a/test/browser-pool/browser-pool.test.ts b/test/browser-pool/browser-pool.test.ts
index 9f21322..7a011b5 100644
--- a/test/browser-pool/browser-pool.test.ts
+++ b/test/browser-pool/browser-pool.test.ts
@@ -128,7 +128,8 @@ describe.each([
             expect(page.close).toBeDefined();
         });
 
-        test('should allow early aborting in case of outer timeout', async () => {
+        // TODO: this test is very flaky in the CI
+        test.skip('should allow early aborting in case of outer timeout', async () => {
             const timeout = browserPool.operationTimeoutMillis;
             browserPool.operationTimeoutMillis = 500;
             // @ts-expect-error mocking private method
",2,"[""88257ee720ed8ba136d49087c0d31373e8397dd5"", ""e2e8ad25854bd1e7cdbc7f50b50bbd99e04ad47d""]","[""docs"", ""test""]"
"updated test to use rows for action items

references #279 | remove deprecated settings

Removes deprecated ZEEBE_HOST environment variable, and removes
unnecessary log level environment variable, since it's already the
default in the log file | fix scroll behavior in navigation","diff --git a/ionic/components/card/test/advanced/main.html b/ionic/components/card/test/advanced/main.html
index 7c56a7d..c19ea12 100644
--- a/ionic/components/card/test/advanced/main.html
+++ b/ionic/components/card/test/advanced/main.html
@@ -19,16 +19,20 @@
       </p>
     </ion-card-content>
 
-    <ion-item>
-      <button clear item-left>
-        <icon star></icon>
-        Star
-      </button>
-      <button clear item-right class=""activated"">
-        <icon share></icon>
-        Share.activated
-      </button>
-    </ion-item>
+    <ion-row no-padding>
+      <ion-col>
+        <button clear small>
+          <icon star></icon>
+          Star
+        </button>
+      </ion-col>
+      <ion-col text-right>
+        <button clear small class=""activated"">
+          <icon share></icon>
+          Share.activated
+        </button>
+      </ion-col>
+    </ion-row>
 
   </ion-card>
 
@@ -51,19 +55,24 @@
       <p>Hello. I am a paragraph.</p>
     </ion-card-content>
 
-    <ion-item>
-      <button clear item-left danger class=""activated"">
-        <icon star></icon>
-        Favorite.activated
-      </button>
-      <button clear item-left danger>
-        <icon musical-notes></icon>
-        Listen
-      </button>
-      <ion-note item-right>
-        Right Note
-      </ion-note>
-    </ion-item>
+    <ion-row center no-padding>
+      <ion-col width-75>
+        <button clear small danger class=""activated"">
+          <icon star></icon>
+          Favorite.activated
+        </button>
+        <button clear small danger>
+          <icon musical-notes></icon>
+          Listen
+        </button>
+      </ion-col>
+      <ion-col text-right>
+        <button clear small>
+          <icon share></icon>
+          Share
+        </button>
+      </ion-col>
+    </ion-row>
   </ion-card>
 
   <ion-card>
@@ -76,20 +85,27 @@
       This card was breaking the border radius.
     </ion-card-content>
 
-    <ion-item>
-      <button clear item-left dark>
-        <icon star></icon>
-        Favorite
-      </button>
-      <button clear item-right dark>
-        <icon musical-notes></icon>
-        Listen
-      </button>
-      <button clear item-right dark>
-        <icon share-alt></icon>
-        Share
-      </button>
-    </ion-item>
+    <ion-row text-center no-padding>
+      <ion-col>
+        <button clear small dark>
+          <icon star></icon>
+          Favorite
+        </button>
+      </ion-col>
+
+      <ion-col>
+        <button clear small dark>
+          <icon musical-notes></icon>
+          Listen
+        </button>
+      </ion-col>
+      <ion-col>
+        <button clear small dark>
+          <icon share-alt></icon>
+          Share
+        </button>
+      </ion-col>
+    </ion-row>
 
   </ion-card>
 

diff --git a/Dockerfile b/Dockerfile
index 6762a39..7f380cd 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -34,7 +34,6 @@ RUN wget -O - https://github.com/jvm-profiling-tools/async-profiler/releases/dow
 FROM ${APP_ENV} as app
 
 ENV ZB_HOME=/usr/local/zeebe \
-    ZEEBE_LOG_LEVEL=info \
     ZEEBE_BROKER_GATEWAY_NETWORK_HOST=0.0.0.0 \
     ZEEBE_STANDALONE_GATEWAY=false
 ENV PATH ""${ZB_HOME}/bin:${PATH}""
diff --git a/docker/utils/startup.sh b/docker/utils/startup.sh
index bc8d2fc..0fcde2b 100755
--- a/docker/utils/startup.sh
+++ b/docker/utils/startup.sh
@@ -1,17 +1,14 @@
 #!/bin/bash -xeu
 
-# legacy support
-# This environment variable was used to set the gatewway cluster host in standalone and embedded mode.
-# Now, there are two dedicated environment variables for the two different deployment scenarios.
-export ZEEBE_HOST=${ZEEBE_HOST:-$(hostname -i)}
-# Legacy support
+HOST=$(hostname -i)
 
 if [ ""$ZEEBE_STANDALONE_GATEWAY"" = ""true"" ]; then
-    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_GATEWAY_NETWORK_HOST=${ZEEBE_GATEWAY_NETWORK_HOST:-${HOST}}
+    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${HOST}}
 
     exec /usr/local/zeebe/bin/gateway
 else
-    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${HOST}}
     export ZEEBE_BROKER_GATEWAY_CLUSTER_HOST=${ZEEBE_BROKER_GATEWAY_CLUSTER_HOST:-${ZEEBE_BROKER_NETWORK_HOST}}
 
     exec /usr/local/zeebe/bin/broker

diff --git a/website/layouts/Base.tsx b/website/layouts/Base.tsx
index 5959fd2..08d5674 100644
--- a/website/layouts/Base.tsx
+++ b/website/layouts/Base.tsx
@@ -90,12 +90,21 @@ function SidebarItem({
 type SidebarNodeWrapper = {
   children: React.ReactNode,
   node: Sitemap,
-  elementRef: React.MutableRefObject<HTMLLIElement | null>;
+  isActive: boolean;
 };
 
-function SidebarNodeWrapper({ children, node, elementRef }: SidebarNodeWrapper) {
+function SidebarNodeWrapper({ children, node, isActive }: SidebarNodeWrapper) {
+  const { asPath } = useRouter();
+  const nodeRef = useRef<HTMLLIElement | null>(null);
+
+  useEffect(() => {
+    if (isActive) {
+      nodeRef.current?.scrollIntoView({ behavior: 'smooth', block: 'nearest', inline: 'start' });
+    }
+  }, [asPath]);
+
   if (node.resource?.label) {
-    return <li ref={elementRef}>{children}</li>;
+    return <li ref={nodeRef}>{children}</li>;
   }
 
   return <>{children}</>;
@@ -109,14 +118,12 @@ type SidebarNodeProps = {
 
 function SidebarNode({ node, level, isNodeActive }: SidebarNodeProps) {
   const { asPath } = useRouter();
-  const nodeWrapperRef = useRef<HTMLLIElement | null>(null);
   const isFirstLevel = level === 1;
   const initialIsExpanded = !isFirstLevel || hasActiveChild(node);
   const [isExpanded, setIsExpanded] = useState(initialIsExpanded);
 
   useEffect(() => {
     setIsExpanded(initialIsExpanded);
-    nodeWrapperRef.current?.scrollIntoView({ behavior: 'smooth', block: 'nearest', inline: 'start' });
   }, [asPath]);
 
   const id = node.resource?.label?.toLowerCase().replace(/\s/g, '-');
@@ -136,7 +143,7 @@ function SidebarNode({ node, level, isNodeActive }: SidebarNodeProps) {
   }
 
   return (
-    <SidebarNodeWrapper node={node} elementRef={nodeWrapperRef}>
+    <SidebarNodeWrapper node={node} isActive={isNodeActive(node)}>
       <>
         {node.resource?.label ? (
           <SidebarItem
",3,"[""19feaea1885eb015759b5c7a5d785521f2b8a212"", ""e4a11fd5c34942ba12737f1c8c084489428ee274"", ""4b5604063fcb8ff457bcb61fdbea85c6b3a5c620""]","[""test"", ""build"", ""fix""]"
"use lambda to define backend operations | fix netty dependency

netty-bom 4.1.70 contains the changes from pull request
https://github.com/netty/netty/pull/11798, which moved the classes out
of the native modules to make sure the same classes don't end up on the
classpath multiple times. For us it means that we need to depend on both
the native and classes modules. However, since we don't use the native
module directly (only classes that were moved to this classes module),
we need to force the dependency plugin to consider the native module as
used. | skip flaky test","diff --git a/ibis/backends/duckdb/registry.py b/ibis/backends/duckdb/registry.py
index 20ffd6f..3f56f2a 100644
--- a/ibis/backends/duckdb/registry.py
+++ b/ibis/backends/duckdb/registry.py
@@ -107,28 +107,13 @@ def _literal(_, op):
     return sa.cast(sa.literal(value), sqla_type)
 
 
-def _array_column(t, op):
-    (arg,) = op.args
-    sqla_type = to_sqla_type(op.output_dtype)
-    return sa.cast(sa.func.list_value(*map(t.translate, arg)), sqla_type)
-
-
 def _neg_idx_to_pos(array, idx):
     if_ = getattr(sa.func, ""if"")
     arg_length = sa.func.array_length(array)
     return if_(idx < 0, arg_length + sa.func.greatest(idx, -arg_length), idx)
 
 
-def _struct_field(t, op):
-    return sa.func.struct_extract(
-        t.translate(op.arg),
-        sa.text(repr(op.field)),
-        type_=to_sqla_type(op.output_dtype),
-    )
-
-
-def _regex_extract(t, op):
-    string, pattern, index = map(t.translate, op.args)
+def _regex_extract(string, pattern, index):
     result = sa.case(
         [
             (
@@ -149,8 +134,7 @@ def _regex_extract(t, op):
     return result
 
 
-def _json_get_item(t, op):
-    left, path = map(t.translate, op.args)
+def _json_get_item(left, path):
     # Workaround for https://github.com/duckdb/duckdb/issues/5063
     # In some situations duckdb silently does the wrong thing if
     # the path is parametrized.
@@ -197,7 +181,12 @@ def _struct_column(t, op):
 
 operation_registry.update(
     {
-        ops.ArrayColumn: _array_column,
+        ops.ArrayColumn: (
+            lambda t, op: sa.cast(
+                sa.func.list_value(*map(t.translate, op.cols)),
+                to_sqla_type(op.output_dtype),
+            )
+        ),
         ops.ArrayConcat: fixed_arity(sa.func.array_concat, 2),
         ops.ArrayRepeat: fixed_arity(
             lambda arg, times: sa.func.flatten(
@@ -222,7 +211,13 @@ operation_registry.update(
         # TODO: map operations, but DuckDB's maps are multimaps
         ops.Modulus: fixed_arity(operator.mod, 2),
         ops.Round: _round,
-        ops.StructField: _struct_field,
+        ops.StructField: (
+            lambda t, op: sa.func.struct_extract(
+                t.translate(op.arg),
+                sa.text(repr(op.field)),
+                type_=to_sqla_type(op.output_dtype),
+            )
+        ),
         ops.TableColumn: _table_column,
         ops.TimestampDiff: fixed_arity(sa.func.age, 2),
         ops.TimestampFromUNIX: _timestamp_from_unix,
@@ -232,7 +227,7 @@ operation_registry.update(
             lambda *_: sa.cast(sa.func.now(), sa.TIMESTAMP),
             0,
         ),
-        ops.RegexExtract: _regex_extract,
+        ops.RegexExtract: fixed_arity(_regex_extract, 3),
         ops.RegexReplace: fixed_arity(
             lambda *args: sa.func.regexp_replace(*args, ""g""), 3
         ),
@@ -255,7 +250,7 @@ operation_registry.update(
         ops.ArgMin: reduction(sa.func.min_by),
         ops.ArgMax: reduction(sa.func.max_by),
         ops.BitwiseXor: fixed_arity(sa.func.xor, 2),
-        ops.JSONGetItem: _json_get_item,
+        ops.JSONGetItem: fixed_arity(_json_get_item, 2),
         ops.RowID: lambda *_: sa.literal_column('rowid'),
         ops.StringToTimestamp: fixed_arity(sa.func.strptime, 2),
     }

diff --git a/atomix/cluster/pom.xml b/atomix/cluster/pom.xml
index a477873..b6db695 100644
--- a/atomix/cluster/pom.xml
+++ b/atomix/cluster/pom.xml
@@ -69,6 +69,10 @@
     </dependency>
     <dependency>
       <groupId>io.netty</groupId>
+      <artifactId>netty-transport-classes-epoll</artifactId>
+    </dependency>
+    <dependency>
+      <groupId>io.netty</groupId>
       <artifactId>netty-transport-native-epoll</artifactId>
       <classifier>linux-x86_64</classifier>
     </dependency>
@@ -278,6 +282,7 @@
             <dependency>uk.co.real-logic:sbe-tool</dependency>
             <dependency>net.jqwik:jqwik</dependency>
             <dependency>io.netty:netty-tcnative-boringssl-static</dependency>
+            <dependency>io.netty:netty-transport-native-epoll</dependency>
           </usedDependencies>
         </configuration>
       </plugin>

diff --git a/test/browser-pool/browser-pool.test.ts b/test/browser-pool/browser-pool.test.ts
index 9f21322..7a011b5 100644
--- a/test/browser-pool/browser-pool.test.ts
+++ b/test/browser-pool/browser-pool.test.ts
@@ -128,7 +128,8 @@ describe.each([
             expect(page.close).toBeDefined();
         });
 
-        test('should allow early aborting in case of outer timeout', async () => {
+        // TODO: this test is very flaky in the CI
+        test.skip('should allow early aborting in case of outer timeout', async () => {
             const timeout = browserPool.operationTimeoutMillis;
             browserPool.operationTimeoutMillis = 500;
             // @ts-expect-error mocking private method
",3,"[""5d14de6722eb34c6604a124f6f11cb711f16bd44"", ""f00a4d3e307b89842250358ee432e6800bb24362"", ""e2e8ad25854bd1e7cdbc7f50b50bbd99e04ad47d""]","[""refactor"", ""build"", ""test""]"
update drone,"diff --git a/.drone.yml b/.drone.yml
index 53e3329..306516b 100644
--- a/.drone.yml
+++ b/.drone.yml
@@ -21,10 +21,10 @@ steps:
         from_secret: docker_username
       password:
         from_secret: docker_password
-      tags: pg
+      tags: latest
     when: 
       branch:
-        - pg
+        - master
       event: 
         - push
   - 
@@ -40,14 +40,14 @@ steps:
       port: 22
       script: 
         - ""sleep 10""
-        - ""docker pull rsschool/api:pg""
+        - ""docker pull rsschool/api:latest""
         - ""docker-compose stop api""
         - ""docker-compose rm -f api""
         - ""docker-compose up -d api""
         - ""docker system prune -f""
     when: 
       branch: 
-        - pg
+        - master
       event: 
         - push
 volumes:
",1,"[""88129ee45b1d49bc4ff887f3b488464cc7097e29""]","[""build""]"
right side menus | fix error spacing,"diff --git a/ionic/components/menu/menu-types.scss b/ionic/components/menu/menu-types.scss
index dbbfdda..5e4f990 100644
--- a/ionic/components/menu/menu-types.scss
+++ b/ionic/components/menu/menu-types.scss
@@ -35,3 +35,7 @@ ion-menu[type=overlay] {
     }
   }
 }
+
+ion-menu[type=overlay][side=right] {
+  left: 8px;
+}
diff --git a/ionic/components/menu/menu-types.ts b/ionic/components/menu/menu-types.ts
index 360aeb4..0666a38 100644
--- a/ionic/components/menu/menu-types.ts
+++ b/ionic/components/menu/menu-types.ts
@@ -10,7 +10,7 @@ import {Animation} from 'ionic/animations/animation';
  */
 export class MenuType {
 
-  constructor(menu: Menu) {
+  constructor() {
     this.open = new Animation();
     this.close = new Animation();
   }
@@ -88,16 +88,17 @@ class MenuRevealType extends MenuType {
     let duration = 250;
 
     let openedX = (menu.width() * (menu.side == 'right' ? -1 : 1)) + 'px';
+    let closedX = '0px'
 
     this.open.easing(easing).duration(duration);
     this.close.easing(easing).duration(duration);
 
     let contentOpen = new Animation(menu.getContentElement());
-    contentOpen.fromTo(TRANSLATE_X, CENTER, openedX);
+    contentOpen.fromTo(TRANSLATE_X, closedX, openedX);
     this.open.add(contentOpen);
 
     let contentClose = new Animation(menu.getContentElement());
-    contentClose.fromTo(TRANSLATE_X, openedX, CENTER);
+    contentClose.fromTo(TRANSLATE_X, openedX, closedX);
     this.close.add(contentClose);
   }
 }
@@ -117,13 +118,23 @@ class MenuOverlayType extends MenuType {
     let duration = 250;
     let backdropOpacity = 0.5;
 
-    let closedX = (menu.width() * (menu.side == 'right' ? 1 : -1)) + 'px';
+    let closedX, openedX;
+    if (menu.side == 'right') {
+      // right side
+      closedX = menu.platform.width() + 'px';
+      openedX = (menu.platform.width() - menu.width() - 8) + 'px';
+
+    } else {
+      // left side
+      closedX = -menu.width() + 'px';
+      openedX = '8px';
+    }
 
     this.open.easing(easing).duration(duration);
     this.close.easing(easing).duration(duration);
 
     let menuOpen = new Animation(menu.getMenuElement());
-    menuOpen.fromTo(TRANSLATE_X, closedX, '8px');
+    menuOpen.fromTo(TRANSLATE_X, closedX, openedX);
     this.open.add(menuOpen);
 
     let backdropOpen = new Animation(menu.getBackdropElement());
@@ -131,7 +142,7 @@ class MenuOverlayType extends MenuType {
     this.open.add(backdropOpen);
 
     let menuClose = new Animation(menu.getMenuElement());
-    menuClose.fromTo(TRANSLATE_X, '8px', closedX);
+    menuClose.fromTo(TRANSLATE_X, openedX, closedX);
     this.close.add(menuClose);
 
     let backdropClose = new Animation(menu.getBackdropElement());
@@ -144,4 +155,3 @@ Menu.register('overlay', MenuOverlayType);
 
 const OPACITY = 'opacity';
 const TRANSLATE_X = 'translateX';
-const CENTER = '0px';
diff --git a/ionic/components/menu/menu.ts b/ionic/components/menu/menu.ts
index d911b2e..e980069 100644
--- a/ionic/components/menu/menu.ts
+++ b/ionic/components/menu/menu.ts
@@ -4,6 +4,7 @@ import {Ion} from '../ion';
 import {IonicApp} from '../app/app';
 import {IonicConfig} from '../../config/config';
 import {IonicComponent} from '../../config/annotations';
+import {IonicPlatform} from '../../platform/platform';
 import * as gestures from  './menu-gestures';
 
 
@@ -35,10 +36,16 @@ import * as gestures from  './menu-gestures';
 })
 export class Menu extends Ion {
 
-  constructor(app: IonicApp, elementRef: ElementRef, config: IonicConfig) {
+  constructor(
+    app: IonicApp,
+    elementRef: ElementRef,
+    config: IonicConfig,
+    platform: IonicPlatform
+  ) {
     super(elementRef, config);
-
     this.app = app;
+    this.platform = platform;
+
     this.opening = new EventEmitter('opening');
     this.isOpen = false;
     this._disableTime = 0;
@@ -46,9 +53,9 @@ export class Menu extends Ion {
 
   onInit() {
     super.onInit();
-    this.contentElement = (this.content instanceof Node) ? this.content : this.content.getNativeElement();
+    this._cntEle = (this.content instanceof Node) ? this.content : this.content.getNativeElement();
 
-    if (!this.contentElement) {
+    if (!this._cntEle) {
       return console.error('Menu: must have a [content] element to listen for drag events on. Example:\n\n<ion-menu [content]=""content""></ion-menu>\n\n<ion-content #content></ion-content>');
     }
 
@@ -61,8 +68,8 @@ export class Menu extends Ion {
     this._initGesture();
     this._initType(this.type);
 
-    this.contentElement.classList.add('menu-content');
-    this.contentElement.classList.add('menu-content-' + this.type);
+    this._cntEle.classList.add('menu-content');
+    this._cntEle.classList.add('menu-content-' + this.type);
 
     let self = this;
     this.onContentClick = function(ev) {
@@ -161,11 +168,11 @@ export class Menu extends Ion {
 
     this.isOpen = isOpen;
 
-    this.contentElement.classList[isOpen ? 'add' : 'remove']('menu-content-open');
+    this._cntEle.classList[isOpen ? 'add' : 'remove']('menu-content-open');
 
-    this.contentElement.removeEventListener('click', this.onContentClick);
+    this._cntEle.removeEventListener('click', this.onContentClick);
     if (isOpen) {
-      this.contentElement.addEventListener('click', this.onContentClick);
+      this._cntEle.addEventListener('click', this.onContentClick);
 
     } else {
       this.getNativeElement().classList.remove('show-menu');
@@ -220,7 +227,7 @@ export class Menu extends Ion {
    * @return {Element} The Menu's associated content element.
    */
   getContentElement() {
-    return this.contentElement;
+    return this._cntEle;
   }
 
   /**
@@ -239,7 +246,7 @@ export class Menu extends Ion {
     this.app.unregister(this.id);
     this._gesture && this._gesture.destroy();
     this._type && this._type.onDestroy();
-    this.contentElement = null;
+    this._cntEle = null;
   }
 
 }
diff --git a/ionic/components/menu/test/basic/index.ts b/ionic/components/menu/test/basic/index.ts
index 698cec4..65952ff 100644
--- a/ionic/components/menu/test/basic/index.ts
+++ b/ionic/components/menu/test/basic/index.ts
@@ -36,9 +36,9 @@ class E2EApp {
     ];
   }
 
-  openPage(menu, page) {
+  openPage(page) {
     // close the menu when clicking a link from the menu
-    menu.close();
+    this.app.getComponent('leftMenu').close();
 
     // Reset the content nav to have just this page
     // we wouldn't want the back button to show in this scenario
diff --git a/ionic/components/menu/test/basic/main.html b/ionic/components/menu/test/basic/main.html
index 9bdeb5c..4905ae6 100644
--- a/ionic/components/menu/test/basic/main.html
+++ b/ionic/components/menu/test/basic/main.html
@@ -1,4 +1,4 @@
-<ion-menu #menu [content]=""content"">
+<ion-menu [content]=""content"" id=""leftMenu"">
 
   <ion-toolbar secondary>
     <ion-title>Left Menu</ion-title>
@@ -8,11 +8,35 @@
 
     <ion-list>
 
-      <button ion-item *ng-for=""#p of pages"" (click)=""openPage(menu, p)"">
+      <button ion-item *ng-for=""#p of pages"" (click)=""openPage(p)"">
         {{p.title}}
       </button>
 
-      <button ion-item menu-toggle no-forward-icon class=""e2eCloseMenu"">
+      <button ion-item menu-toggle=""leftMenu"" no-forward-icon class=""e2eCloseMenu"">
+        Close Menu
+      </button>
+
+    </ion-list>
+  </ion-content>
+
+</ion-menu>
+
+
+<ion-menu side=""right"" [content]=""content"" id=""rightMenu"">
+
+  <ion-toolbar secondary>
+    <ion-title>Right Menu</ion-title>
+  </ion-toolbar>
+
+  <ion-content>
+
+    <ion-list>
+
+      <button ion-item *ng-for=""#p of pages"" (click)=""openPage(p)"">
+        {{p.title}}
+      </button>
+
+      <button ion-item menu-toggle=""rightMenu"" no-forward-icon class=""e2eCloseMenu"">
         Close Menu
       </button>
 
diff --git a/ionic/components/menu/test/basic/page1.html b/ionic/components/menu/test/basic/page1.html
index 1881d9e..2bc5c79 100644
--- a/ionic/components/menu/test/basic/page1.html
+++ b/ionic/components/menu/test/basic/page1.html
@@ -1,7 +1,7 @@
 
 <ion-navbar *navbar>
 
-  <a menu-toggle>
+  <a menu-toggle=""leftMenu"">
     <icon menu></icon>
   </a>
 
@@ -21,19 +21,23 @@
     </button>
   </ion-nav-items>
 
-  <a menu-toggle secondary>
+  <a menu-toggle=""rightMenu"" secondary>
     <icon menu></icon>
   </a>
 
 </ion-navbar>
 
 
-<ion-content #content padding>
+<ion-content padding>
 
   <h3>Page 1</h3>
 
   <p>
-    <button class=""e2eContentToggleMenu"" menu-toggle>Toggle Menu</button>
+    <button class=""e2eContentToggleMenu"" menu-toggle=""leftMenu"">Toggle Left Menu</button>
+  </p>
+
+  <p>
+    <button class=""e2eContentToggleMenu"" menu-toggle=""rightMenu"">Toggle Right Menu</button>
   </p>
 
   <f></f><f></f><f></f><f></f><f></f><f></f><f></f><f></f>
diff --git a/ionic/components/menu/test/basic/page2.html b/ionic/components/menu/test/basic/page2.html
index 9801c4f..098f3e1 100644
--- a/ionic/components/menu/test/basic/page2.html
+++ b/ionic/components/menu/test/basic/page2.html
@@ -1,7 +1,7 @@
 
 <ion-navbar *navbar>
 
-  <a menu-toggle>
+  <a menu-toggle=""leftMenu"">
     <icon menu></icon>
   </a>
 
@@ -11,12 +11,12 @@
 
 </ion-navbar>
 
-<ion-content #content padding>
+<ion-content padding>
 
   <h3>Page 2</h3>
 
   <p>
-    <button menu-toggle class=""e2eContentToggleMenu"">Toggle Menu</button>
+    <button menu-toggle=""leftMenu"" class=""e2eContentToggleMenu"">Toggle Left Menu</button>
   </p>
 
   <p>
diff --git a/ionic/components/menu/test/basic/page3.html b/ionic/components/menu/test/basic/page3.html
index a2d65e2..079a3e9 100644
--- a/ionic/components/menu/test/basic/page3.html
+++ b/ionic/components/menu/test/basic/page3.html
@@ -1,7 +1,7 @@
 
 <ion-navbar *navbar>
 
-  <a menu-toggle>
+  <a menu-toggle=""leftMenu"">
     <icon menu></icon>
   </a>
 
@@ -12,12 +12,12 @@
 </ion-navbar>
 
 
-<ion-content #content padding>
+<ion-content padding>
 
   <h3>Page 3</h3>
 
   <p>
-    <button menu-toggle>Toggle Menu</button>
+    <button menu-toggle=""leftMenu"">Toggle Left Menu</button>
   </p>
 
   <f></f><f></f><f></f><f></f><f></f><f></f><f></f><f></f>
diff --git a/ionic/components/toolbar/modes/md.scss b/ionic/components/toolbar/modes/md.scss
index 984e758..339169a 100644
--- a/ionic/components/toolbar/modes/md.scss
+++ b/ionic/components/toolbar/modes/md.scss
@@ -43,6 +43,12 @@ $toolbar-md-button-font-size:        1.4rem !default;
     }
   }
 
+  [menu-toggle][secondary],
+  [menu-toggle][secondary].activated {
+    margin: 0 2px;
+    min-width: 28px;
+  }
+
 }
 
 ion-title {

diff --git a/cmd/infracost/main.go b/cmd/infracost/main.go
index 425aef1..fcc9eb5 100644
--- a/cmd/infracost/main.go
+++ b/cmd/infracost/main.go
@@ -149,7 +149,7 @@ Example:
 			}
 
 			if appErr.Error() != """" {
-				fmt.Fprintf(os.Stderr, ""\n%s\n"", color.HiRedString(appErr.Error()))
+				fmt.Fprintf(os.Stderr, ""%s\n"", color.HiRedString(appErr.Error()))
 			}
 		}
 
",2,"[""1a60540f2bcda48d33f015e31f3728ac2c59a159"", ""c623b3622058b913290120b06ccdc779a4e4413d""]","[""feat"", ""fix""]"
"101: fix import key cmd

Signed-off-by: Sam Alba <sam.alba@gmail.com> | [gn] fix include_dirs ordering error | Adjust test scenario

With the new version of the FEEL engine, a non-existing variable results in `null`. Previously, the evaluation failed
with an error.

To keep the semantics of the test cases, create the incident by failing the job.","diff --git a/docs/learn/101-use.md b/docs/learn/101-use.md
index 283c1c1..2ec10f9 100644
--- a/docs/learn/101-use.md
+++ b/docs/learn/101-use.md
@@ -41,8 +41,7 @@ cd ./examples/todoapp
 The example app contains encrypted secrets and other pre-configured inputs, here is how to decrypt them:
 
 ```sh
-curl -sfL https://releases.dagger.io/examples/key.txt >> ~/.config/dagger/keys.txt
-dagger input list
+dagger input list || curl -sfL https://releases.dagger.io/examples/key.txt >> ~/.config/dagger/keys.txt
 ```
 
 **Step 4**: Deploy!

diff --git a/BUILD.gn b/BUILD.gn
index 11adaa7..ed64b17 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -240,6 +240,14 @@ static_library(""electron_lib"") {
     ""brightray"",
     ""build/node"",
   ]
+  include_dirs = [
+    ""chromium_src"",
+    ""."",
+    ""$target_gen_dir"",
+    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
+    # API of blink, then delete this include dir.
+    ""//third_party/WebKit/Source"",
+  ]
   if (enable_desktop_capturer) {
     deps += [ ""//third_party/webrtc/modules/desktop_capture"" ]
   }
@@ -275,14 +283,6 @@ static_library(""electron_lib"") {
     # Disable warnings for g_settings_list_schemas.
     ""GLIB_DISABLE_DEPRECATION_WARNINGS"",
   ]
-  include_dirs = [
-    ""chromium_src"",
-    ""."",
-    ""$target_gen_dir"",
-    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
-    # API of blink, then delete this include dir.
-    ""//third_party/WebKit/Source"",
-  ]
   if (is_component_build) {
     defines += [
       # Import V8 symbols from shared library (node.dll / libnode.so)

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
index c0a3472..6a9389b 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
@@ -759,7 +759,7 @@ public final class ProcessExecutionCleanStateTest {
         .withXmlResource(
             Bpmn.createExecutableProcess(PROCESS_ID)
                 .startEvent()
-                .serviceTask(""task"", t -> t.zeebeJobType(""test"").zeebeOutputExpression(""x"", ""y""))
+                .serviceTask(""task"", t -> t.zeebeJobType(""test""))
                 .endEvent()
                 .done())
         .deploy();
@@ -768,7 +768,7 @@ public final class ProcessExecutionCleanStateTest {
     final var processInstanceKey =
         engineRule.processInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    engineRule.job().ofInstance(processInstanceKey).withType(""test"").complete();
+    engineRule.job().ofInstance(processInstanceKey).withType(""test"").withRetries(0).fail();
 
     RecordingExporter.incidentRecords(IncidentIntent.CREATED)
         .withProcessInstanceKey(processInstanceKey)
",3,"[""2b01808ec86fe9d8b4a93141a1b7f95e11fd6010"", ""c44cf88a6ec54e5ddd99d8348bcc57b301ec7945"", ""f411e58cd510f8a2b980b2f1932003a0c0e9f8f3""]","[""docs"", ""build"", ""test""]"
remove unused branches and ignore envrc file | Introduce timediff fn (stub) | typo,"diff --git a/.github/workflows/ibis-backends-cloud.yml b/.github/workflows/ibis-backends-cloud.yml
index 2003e8e..7c7fd26 100644
--- a/.github/workflows/ibis-backends-cloud.yml
+++ b/.github/workflows/ibis-backends-cloud.yml
@@ -5,9 +5,12 @@ on:
     # Skip the backend suite if all changes are in the docs directory
     paths-ignore:
       - ""docs/**""
+      - ""**/*.md""
+      - ""**/*.qmd""
+      - ""codecov.yml""
+      - "".envrc""
     branches:
       - master
-      - quarto
 
 permissions:
   # this allows extractions/setup-just to list releases for `just` at a higher
diff --git a/.github/workflows/ibis-backends-skip-helper.yml b/.github/workflows/ibis-backends-skip-helper.yml
index 5d5f3f7..0471994 100644
--- a/.github/workflows/ibis-backends-skip-helper.yml
+++ b/.github/workflows/ibis-backends-skip-helper.yml
@@ -9,20 +9,20 @@ on:
       - ""**/*.md""
       - ""**/*.qmd""
       - ""codecov.yml""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     paths:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
       - ""codecov.yml""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 jobs:
   test_backends:
diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index 4a1cae9..30e6c1a 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -8,10 +8,10 @@ on:
       - ""**/*.md""
       - ""**/*.qmd""
       - ""codecov.yml""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     # Skip the backend suite if all changes are docs
     paths-ignore:
@@ -19,10 +19,10 @@ on:
       - ""**/*.md""
       - ""**/*.qmd""
       - ""codecov.yml""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 permissions:
diff --git a/.github/workflows/ibis-docs-lint.yml b/.github/workflows/ibis-docs-lint.yml
index 1adda11..b528a30 100644
--- a/.github/workflows/ibis-docs-lint.yml
+++ b/.github/workflows/ibis-docs-lint.yml
@@ -5,12 +5,10 @@ on:
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 concurrency:
diff --git a/.github/workflows/ibis-main-skip-helper.yml b/.github/workflows/ibis-main-skip-helper.yml
index a5fdc6f..0fb5dea 100644
--- a/.github/workflows/ibis-main-skip-helper.yml
+++ b/.github/workflows/ibis-main-skip-helper.yml
@@ -8,19 +8,19 @@ on:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     paths:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 jobs:
   test_core:
diff --git a/.github/workflows/ibis-main.yml b/.github/workflows/ibis-main.yml
index aa31436..0b1536a 100644
--- a/.github/workflows/ibis-main.yml
+++ b/.github/workflows/ibis-main.yml
@@ -7,20 +7,20 @@ on:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     # Skip the test suite if all changes are in the docs directory
     paths-ignore:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 permissions:
diff --git a/.github/workflows/ibis-tpch-queries-skip-helper.yml b/.github/workflows/ibis-tpch-queries-skip-helper.yml
index 1f1c0bc..f10fb8d 100644
--- a/.github/workflows/ibis-tpch-queries-skip-helper.yml
+++ b/.github/workflows/ibis-tpch-queries-skip-helper.yml
@@ -6,19 +6,19 @@ on:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     paths:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 concurrency:
diff --git a/.github/workflows/ibis-tpch-queries.yml b/.github/workflows/ibis-tpch-queries.yml
index b4f8a48..9e65a61 100644
--- a/.github/workflows/ibis-tpch-queries.yml
+++ b/.github/workflows/ibis-tpch-queries.yml
@@ -6,19 +6,19 @@ on:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     paths-ignore:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 concurrency:
diff --git a/.github/workflows/nix-skip-helper.yml b/.github/workflows/nix-skip-helper.yml
index 677b4d7..e0ab8f7 100644
--- a/.github/workflows/nix-skip-helper.yml
+++ b/.github/workflows/nix-skip-helper.yml
@@ -9,19 +9,19 @@ on:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     paths:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 jobs:
diff --git a/.github/workflows/nix.yml b/.github/workflows/nix.yml
index f2dd3f0..7ea9e26 100644
--- a/.github/workflows/nix.yml
+++ b/.github/workflows/nix.yml
@@ -6,19 +6,19 @@ on:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     paths-ignore:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 concurrency:

diff --git a/rust/Cargo.lock b/rust/Cargo.lock
index b42616f..4795eb6 100644
--- a/rust/Cargo.lock
+++ b/rust/Cargo.lock
@@ -1287,7 +1287,7 @@ dependencies = [
 [[package]]
 name = ""datafusion""
 version = ""5.1.0""
-source = ""git+https://github.com/cube-js/arrow-datafusion.git?rev=8df4132b83d896a0d3db5c82a4eaaa3eaa285d15#8df4132b83d896a0d3db5c82a4eaaa3eaa285d15""
+source = ""git+https://github.com/cube-js/arrow-datafusion.git?rev=868f3c4de13d13cda84cee33475b9782b94fa60c#868f3c4de13d13cda84cee33475b9782b94fa60c""
 dependencies = [
  ""ahash 0.7.4"",
  ""arrow 6.0.0"",
diff --git a/rust/cubesql/Cargo.toml b/rust/cubesql/Cargo.toml
index 3cb386a..9aef494 100644
--- a/rust/cubesql/Cargo.toml
+++ b/rust/cubesql/Cargo.toml
@@ -9,7 +9,7 @@ documentation = ""https://cube.dev/docs""
 homepage = ""https://cube.dev""
 
 [dependencies]
-datafusion = { git = 'https://github.com/cube-js/arrow-datafusion.git', rev = ""8df4132b83d896a0d3db5c82a4eaaa3eaa285d15"", default-features = false, features = [""unicode_expressions""] }
+datafusion = { git = 'https://github.com/cube-js/arrow-datafusion.git', rev = ""868f3c4de13d13cda84cee33475b9782b94fa60c"", default-features = false, features = [""unicode_expressions""] }
 anyhow = ""1.0""
 thiserror = ""1.0""
 cubeclient = { path = ""../cubeclient"" }
diff --git a/rust/cubesql/src/compile/engine/df/intervals.rs b/rust/cubesql/src/compile/engine/df/intervals.rs
new file mode 100644
index 0000000..9e6cb7e
--- /dev/null
+++ b/rust/cubesql/src/compile/engine/df/intervals.rs
@@ -0,0 +1,51 @@
+#[macro_export]
+macro_rules! make_string_interval_year_month {
+    ($array: ident, $row: ident) => {{
+        let s = if $array.is_null($row) {
+            ""NULL"".to_string()
+        } else {
+            let interval = $array.value($row) as f64;
+            let years = (interval / 12_f64).floor();
+            let month = interval - (years * 12_f64);
+
+            format!(
+                ""{} years {} mons 0 days 0 hours 0 mins 0.00 secs"",
+                years, month,
+            )
+        };
+
+        s
+    }};
+}
+
+#[macro_export]
+macro_rules! make_string_interval_day_time {
+    ($array: ident, $row: ident) => {{
+        let s = if $array.is_null($row) {
+            ""NULL"".to_string()
+        } else {
+            let value: u64 = $array.value($row) as u64;
+
+            let days_parts: i32 = ((value & 0xFFFFFFFF00000000) >> 32) as i32;
+            let milliseconds_part: i32 = (value & 0xFFFFFFFF) as i32;
+
+            let secs = milliseconds_part / 1000;
+            let mins = secs / 60;
+            let hours = mins / 60;
+
+            let secs = secs - (mins * 60);
+            let mins = mins - (hours * 60);
+
+            format!(
+                ""0 years 0 mons {} days {} hours {} mins {}.{:02} secs"",
+                days_parts,
+                hours,
+                mins,
+                secs,
+                (milliseconds_part % 1000),
+            )
+        };
+
+        s
+    }};
+}
diff --git a/rust/cubesql/src/compile/engine/df/mod.rs b/rust/cubesql/src/compile/engine/df/mod.rs
index a19a970..3097523 100644
--- a/rust/cubesql/src/compile/engine/df/mod.rs
+++ b/rust/cubesql/src/compile/engine/df/mod.rs
@@ -1 +1,2 @@
 pub mod coerce;
+pub mod intervals;
diff --git a/rust/cubesql/src/compile/engine/udf.rs b/rust/cubesql/src/compile/engine/udf.rs
index 55b8bc1..0e160b3 100644
--- a/rust/cubesql/src/compile/engine/udf.rs
+++ b/rust/cubesql/src/compile/engine/udf.rs
@@ -1,14 +1,19 @@
 use std::any::type_name;
 use std::sync::Arc;
 
+
 use datafusion::{
     arrow::{
         array::{
             ArrayRef, BooleanArray, BooleanBuilder, GenericStringArray, Int32Builder,
-            PrimitiveArray, StringBuilder, UInt32Builder,
+            IntervalDayTimeBuilder, PrimitiveArray, StringBuilder,
+            UInt32Builder,
         },
         compute::cast,
-        datatypes::{DataType, Int64Type},
+        datatypes::{
+            DataType, Int64Type, IntervalUnit, TimeUnit,
+            TimestampNanosecondType,
+        },
     },
     error::DataFusionError,
     logical_plan::create_udf,
@@ -399,3 +404,63 @@ pub fn create_convert_tz_udf() -> ScalarUDF {
         &fun,
     )
 }
+
+pub fn create_timediff_udf() -> ScalarUDF {
+    let fun = make_scalar_function(move |args: &[ArrayRef]| {
+        assert!(args.len() == 2);
+
+        let left_dt = &args[0];
+        let right_dt = &args[1];
+
+        let left_date = match left_dt.data_type() {
+            DataType::Timestamp(TimeUnit::Nanosecond, _) => {
+                let arr = downcast_primitive_arg!(left_dt, ""left_dt"", TimestampNanosecondType);
+                let ts = arr.value(0);
+
+                // NaiveDateTime::from_timestamp(ts, 0)
+                ts
+            }
+            _ => {
+                return Err(DataFusionError::Execution(format!(
+                    ""left_dt argument must be a Timestamp, actual: {}"",
+                    left_dt.data_type()
+                )));
+            }
+        };
+
+        let right_date = match right_dt.data_type() {
+            DataType::Timestamp(TimeUnit::Nanosecond, _) => {
+                let arr = downcast_primitive_arg!(right_dt, ""right_dt"", TimestampNanosecondType);
+                arr.value(0)
+            }
+            _ => {
+                return Err(DataFusionError::Execution(format!(
+                    ""right_dt argument must be a Timestamp, actual: {}"",
+                    right_dt.data_type()
+                )));
+            }
+        };
+
+        let diff = right_date - left_date;
+        if diff != 0 {
+            return Err(DataFusionError::NotImplemented(format!(
+                ""timediff is not implemented, it's stub""
+            )));
+        }
+
+        let mut interal_arr = IntervalDayTimeBuilder::new(1);
+        interal_arr.append_value(diff)?;
+
+        Ok(Arc::new(interal_arr.finish()) as ArrayRef)
+    });
+
+    let return_type: ReturnTypeFunction =
+        Arc::new(move |_| Ok(Arc::new(DataType::Interval(IntervalUnit::DayTime))));
+
+    ScalarUDF::new(
+        ""timediff"",
+        &Signature::any(2, Volatility::Immutable),
+        &return_type,
+        &fun,
+    )
+}
diff --git a/rust/cubesql/src/compile/mod.rs b/rust/cubesql/src/compile/mod.rs
index a88da57..6121aa0 100644
--- a/rust/cubesql/src/compile/mod.rs
+++ b/rust/cubesql/src/compile/mod.rs
@@ -32,8 +32,8 @@ use self::engine::context::SystemVar;
 use self::engine::provider::CubeContext;
 use self::engine::udf::{
     create_connection_id_udf, create_convert_tz_udf, create_current_user_udf, create_db_udf,
-    create_if_udf, create_instr_udf, create_isnull_udf, create_least_udf, create_user_udf,
-    create_version_udf,
+    create_if_udf, create_instr_udf, create_isnull_udf, create_least_udf, create_timediff_udf,
+    create_user_udf, create_version_udf,
 };
 use self::parser::parse_sql_to_statement;
 
@@ -1450,6 +1450,7 @@ impl QueryPlanner {
         ctx.register_udf(create_if_udf());
         ctx.register_udf(create_least_udf());
         ctx.register_udf(create_convert_tz_udf());
+        ctx.register_udf(create_timediff_udf());
 
         let state = ctx.state.lock().unwrap().clone();
         let cube_ctx = CubeContext::new(&state, &self.context.cubes);
@@ -3226,6 +3227,25 @@ mod tests {
     }
 
     #[tokio::test]
+    async fn test_timediff() -> Result<(), CubeError> {
+        assert_eq!(
+            execute_df_query(
+                ""select \
+                    timediff('1994-11-26T13:25:00.000Z'::timestamp, '1994-11-26T13:25:00.000Z'::timestamp) as r1
+                "".to_string()
+            )
+            .await?,
+            ""+------------------------------------------------+\n\
+            | r1                                             |\n\
+            +------------------------------------------------+\n\
+            | 0 years 0 mons 0 days 0 hours 0 mins 0.00 secs |\n\
+            +------------------------------------------------+""
+        );
+
+        Ok(())
+    }
+
+    #[tokio::test]
     async fn test_metabase() -> Result<(), CubeError> {
         assert_eq!(
             execute_df_query(
diff --git a/rust/cubesql/src/mysql/dataframe.rs b/rust/cubesql/src/mysql/dataframe.rs
index fa246aa..2443458 100644
--- a/rust/cubesql/src/mysql/dataframe.rs
+++ b/rust/cubesql/src/mysql/dataframe.rs
@@ -3,9 +3,10 @@ use std::fmt::{self, Debug, Formatter};
 use chrono::{SecondsFormat, TimeZone, Utc};
 use comfy_table::{Cell, Table};
 use datafusion::arrow::array::{
-    Array, Float64Array, Int32Array, Int64Array, StringArray, TimestampMicrosecondArray,
-    UInt32Array,
+    Array, Float64Array, Int32Array, Int64Array, IntervalDayTimeArray, IntervalYearMonthArray,
+    StringArray, TimestampMicrosecondArray, UInt32Array,
 };
+use datafusion::arrow::datatypes::IntervalUnit;
 use datafusion::arrow::{
     array::{BooleanArray, TimestampNanosecondArray, UInt64Array},
     datatypes::{DataType, TimeUnit},
@@ -15,6 +16,7 @@ use log::{error, warn};
 use msql_srv::{ColumnFlags, ColumnType};
 
 use crate::{compile::builder::CompiledQueryFieldMeta, CubeError};
+use crate::{make_string_interval_day_time, make_string_interval_year_month};
 
 #[derive(Clone, Debug)]
 pub struct Column {
@@ -309,6 +311,7 @@ pub fn arrow_to_column_type(arrow_type: DataType) -> Result<ColumnType, CubeErro
         DataType::Binary => Ok(ColumnType::MYSQL_TYPE_BLOB),
         DataType::Utf8 | DataType::LargeUtf8 => Ok(ColumnType::MYSQL_TYPE_STRING),
         DataType::Timestamp(_, _) => Ok(ColumnType::MYSQL_TYPE_STRING),
+        DataType::Interval(_) => Ok(ColumnType::MYSQL_TYPE_STRING),
         DataType::Float16 | DataType::Float64 => Ok(ColumnType::MYSQL_TYPE_DOUBLE),
         DataType::Boolean => Ok(ColumnType::MYSQL_TYPE_TINY),
         DataType::Int8
@@ -402,6 +405,24 @@ pub fn batch_to_dataframe(batches: &Vec<RecordBatch>) -> Result<DataFrame, CubeE
                         });
                     }
                 }
+                DataType::Interval(IntervalUnit::DayTime) => {
+                    let a = array
+                        .as_any()
+                        .downcast_ref::<IntervalDayTimeArray>()
+                        .unwrap();
+                    for i in 0..num_rows {
+                        rows[i].push(TableValue::String(make_string_interval_day_time!(a, i)));
+                    }
+                }
+                DataType::Interval(IntervalUnit::YearMonth) => {
+                    let a = array
+                        .as_any()
+                        .downcast_ref::<IntervalYearMonthArray>()
+                        .unwrap();
+                    for i in 0..num_rows {
+                        rows[i].push(TableValue::String(make_string_interval_year_month!(a, i)));
+                    }
+                }
                 DataType::Boolean => {
                     let a = array.as_any().downcast_ref::<BooleanArray>().unwrap();
                     for i in 0..num_rows {

diff --git a/README.md b/README.md
index b823d75..53f265d 100644
--- a/README.md
+++ b/README.md
@@ -74,7 +74,7 @@ With oclif you can create 2 different CLI types, single and multi.
 
 Single CLIs are like `ls` or `cat`. They can accept arguments and flags. Single CLIs can optionally be just be a single file.
 
-Multi CLIs are like `git` or `heroku`. They have subcommands that are themselves single CLIs commands. In the `package.json` there is a field `oclif.commands` that points to a directory. This directory contains all the subcommands for the CLI. For example, if you wanted a CLI called `mycli` with the commands `mycli create` and `mycli destroy`, you would have a project like the following:
+Multi CLIs are like `git` or `heroku`. They have subcommands that are themselves single CLI commands. In the `package.json` there is a field `oclif.commands` that points to a directory. This directory contains all the subcommands for the CLI. For example, if you wanted a CLI called `mycli` with the commands `mycli create` and `mycli destroy`, you would have a project like the following:
 
 ```
 package.json
",3,"[""d0c6476df61b9c6ab07b87e1724ea7c5318595bb"", ""29dfb9716298c5a579c0ffba6742e13a29325670"", ""06c12fb603e3a38eca0340a92719ee59d34a9f47""]","[""cicd"", ""feat"", ""docs""]"
do not use scripts and binaries from the libcc repo | remove sync ts check,"diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |

diff --git a/config/webpack.config.prod.js b/config/webpack.config.prod.js
index 8b23fba..58a4c17 100644
--- a/config/webpack.config.prod.js
+++ b/config/webpack.config.prod.js
@@ -251,7 +251,7 @@ module.exports = {
   plugins: [
     argv.notypecheck
     ? null
-    : new ForkTsCheckerWebpackPlugin({tslint: true, async: false}),
+    : new ForkTsCheckerWebpackPlugin({tslint: true}),
     // Makes some environment variables available in index.html.
     // The public URL is available as %PUBLIC_URL% in index.html, e.g.:
     // <link rel=""shortcut icon"" href=""%PUBLIC_URL%/favicon.ico"">
",2,"[""45837af24a33308a70a3454f0f650f9fe728e272"", ""411be831591b2ea15ca9138eaf8db81f51b5101e""]","[""cicd"", ""build""]"
add riscv64gc-unknown-linux-gnu | use new freespace config for disk space recory test | add ability to get all encoded values,"diff --git a/.github/workflows/linux-riscv64.yaml b/.github/workflows/linux-riscv64.yaml
new file mode 100644
index 0000000..8da3d41
--- /dev/null
+++ b/.github/workflows/linux-riscv64.yaml
@@ -0,0 +1,53 @@
+name: Linux-riscv64
+
+env:
+  DEBUG: 'napi:*'
+
+concurrency:
+  group: ${{ github.workflow }}-${{ github.ref }}
+  cancel-in-progress: true
+
+on:
+  push:
+    branches:
+      - main
+  pull_request:
+
+jobs:
+  build:
+    name: stable - riscv64-unknown-linux-gnu - node@18
+    runs-on: ubuntu-latest
+
+    steps:
+      - uses: actions/checkout@v3
+
+      - name: Setup node
+        uses: actions/setup-node@v3
+        with:
+          node-version: 18
+          cache: 'yarn'
+
+      - name: Install
+        uses: dtolnay/rust-toolchain@stable
+        with:
+          toolchain: stable
+          targets: riscv64gc-unknown-linux-gnu
+
+      - name: Cache cargo
+        uses: actions/cache@v3
+        with:
+          path: |
+            ~/.cargo/registry
+            ~/.cargo/git
+          key: stable-linux-riscv64-gnu-node@18-cargo-cache
+
+      - name: Install dependencies
+        run: |
+          sudo apt-get update
+          sudo apt-get install -y gcc-riscv64-linux-gnu
+          yarn config set --json supportedArchitectures.cpu '[""current"", ""riscv64""]'
+          yarn config set supportedArchitectures.libc ""glibc""
+          yarn install --immutable --mode=skip-build
+
+      - name: Cross build native tests
+        run: yarn build:test -- --target riscv64gc-unknown-linux-gnu
diff --git a/cli/src/api/templates/ci-template.ts b/cli/src/api/templates/ci-template.ts
index 783aa41..ee1dfdc 100644
--- a/cli/src/api/templates/ci-template.ts
+++ b/cli/src/api/templates/ci-template.ts
@@ -94,6 +94,14 @@ jobs:
           - host: windows-latest
             target: 'aarch64-pc-windows-msvc'
             build: yarn build --platform --target aarch64-pc-windows-msvc
+          - host: ubuntu-latest
+            target: 'riscv64gc-unknown-linux-gnu'
+            setup: |
+              sudo apt-get update
+              sudo apt-get install gcc-riscv64-linux-gnu -y
+            build: |
+              yarn build --platform --target riscv64gc-unknown-linux-gnu
+              riscv64-linux-gnu-strip *.node
 
     name: stable - \${{ matrix.settings.target }} - node@18
     runs-on: \${{ matrix.settings.host }}
diff --git a/cli/src/utils/ci.ts b/cli/src/utils/ci.ts
index 3084bb3..d77148d 100644
--- a/cli/src/utils/ci.ts
+++ b/cli/src/utils/ci.ts
@@ -99,4 +99,13 @@ export const CIConfig: Partial<
     ],
     test: false,
   },
+  'riscv64gc-unknown-linux-gnu': {
+    host: 'ubuntu-latest',
+    build_setup: [
+      'sudo apt-get update',
+      'sudo apt-get install g++-riscv64-linux-gnu gcc-riscv64-linux-gnu -y',
+    ],
+    // No official nodejs docker image for riscv64
+    test: false,
+  },
 }

diff --git a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/health/DiskSpaceRecoveryIT.java b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/health/DiskSpaceRecoveryIT.java
index 0854323..bfc7b7e 100644
--- a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/health/DiskSpaceRecoveryIT.java
+++ b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/health/DiskSpaceRecoveryIT.java
@@ -47,7 +47,8 @@ final class DiskSpaceRecoveryIT {
           .withZeebeData(volume)
           .withEnv(""ZEEBE_BROKER_DATA_LOGSEGMENTSIZE"", ""1MB"")
           .withEnv(""ZEEBE_BROKER_NETWORK_MAXMESSAGESIZE"", ""1MB"")
-          .withEnv(""ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK"", ""0.5"");
+          .withEnv(""ZEEBE_BROKER_DATA_DISK_FREESPACE_PROCESSING"", ""10MB"")
+          .withEnv(""ZEEBE_BROKER_DATA_DISK_FREESPACE_REPLICATION"", ""1MB"");
 
   private ZeebeClient client;
 
@@ -127,7 +128,9 @@ final class DiskSpaceRecoveryIT {
         ContainerEngine.builder()
             .withDebugReceiverPort(SocketUtil.getNextAddress().getPort())
             .withContainer(
-                container.withEnv(""ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK"", ""0.0001""))
+                container
+                    .withEnv(""ZEEBE_BROKER_DATA_DISK_FREESPACE_PROCESSING"", ""16MB"")
+                    .withEnv(""ZEEBE_BROKER_DATA_DISK_FREESPACE_REPLICATION"", ""10MB""))
             .build();
 
     @BeforeEach

diff --git a/delorean_mem_qe/src/column.rs b/delorean_mem_qe/src/column.rs
index bc89cb2..b3df18e 100644
--- a/delorean_mem_qe/src/column.rs
+++ b/delorean_mem_qe/src/column.rs
@@ -537,6 +537,22 @@ impl Column {
         }
     }
 
+    /// Materialise all of the encoded values.
+    pub fn all_encoded_values(&self) -> Vector {
+        match self {
+            Column::String(c) => {
+                let now = std::time::Instant::now();
+                let v = c.all_encoded_values();
+                log::debug!(""time getting all encoded values {:?}"", now.elapsed());
+
+                log::debug!(""dictionary {:?}"", c.data.dictionary());
+                Vector::Integer(v)
+            }
+            Column::Float(c) => Vector::Float(c.all_encoded_values()),
+            Column::Integer(c) => Vector::Integer(c.all_encoded_values()),
+        }
+    }
+
     /// Given an encoded value for a row, materialise and return the decoded
     /// version.
     ///
@@ -986,6 +1002,10 @@ impl String {
         self.data.encoded_values(row_ids)
     }
 
+    pub fn all_encoded_values(&self) -> Vec<i64> {
+        self.data.all_encoded_values()
+    }
+
     /// Return the decoded value for an encoded ID.
     ///
     /// Panics if there is no decoded value for the provided id
@@ -1037,6 +1057,10 @@ impl Float {
         self.data.encoded_values(row_ids)
     }
 
+    pub fn all_encoded_values(&self) -> Vec<f64> {
+        self.data.all_encoded_values()
+    }
+
     pub fn scan_from(&self, row_id: usize) -> &[f64] {
         self.data.scan_from(row_id)
     }
@@ -1106,6 +1130,10 @@ impl Integer {
         self.data.encoded_values(row_ids)
     }
 
+    pub fn all_encoded_values(&self) -> Vec<i64> {
+        self.data.all_encoded_values()
+    }
+
     pub fn scan_from(&self, row_id: usize) -> &[i64] {
         self.data.scan_from(row_id)
     }
diff --git a/delorean_mem_qe/src/encoding.rs b/delorean_mem_qe/src/encoding.rs
index d6a865a..4b057cf 100644
--- a/delorean_mem_qe/src/encoding.rs
+++ b/delorean_mem_qe/src/encoding.rs
@@ -68,6 +68,12 @@ where
         self.values(row_ids)
     }
 
+    /// Return all encoded values. For this encoding this is just the decoded
+    /// values
+    pub fn all_encoded_values(&self) -> Vec<T> {
+        self.values.clone()
+    }
+
     // TODO(edd): fix this when added NULL support
     pub fn scan_from_until_some(&self, _row_id: usize) -> Option<T> {
         unreachable!(""to remove"");
@@ -485,6 +491,26 @@ impl DictionaryRLE {
         out
     }
 
+    // values materialises a vector of references to all logical values in the
+    // encoding.
+    pub fn all_values(&mut self) -> Vec<Option<&String>> {
+        let mut out: Vec<Option<&String>> = Vec::with_capacity(self.total as usize);
+
+        // build reverse mapping.
+        let mut idx_value = BTreeMap::new();
+        for (k, v) in &self.entry_index {
+            idx_value.insert(v, k);
+        }
+        assert_eq!(idx_value.len(), self.entry_index.len());
+
+        for (idx, rl) in &self.run_lengths {
+            // TODO(edd): fix unwrap - we know that the value exists in map...
+            let v = idx_value.get(&idx).unwrap().as_ref();
+            out.extend(iter::repeat(v).take(*rl as usize));
+        }
+        out
+    }
+
     /// Return the decoded value for an encoded ID.
     ///
     /// Panics if there is no decoded value for the provided id
@@ -528,22 +554,13 @@ impl DictionaryRLE {
         out
     }
 
-    // values materialises a vector of references to all logical values in the
-    // encoding.
-    pub fn all_values(&mut self) -> Vec<Option<&String>> {
-        let mut out: Vec<Option<&String>> = Vec::with_capacity(self.total as usize);
-
-        // build reverse mapping.
-        let mut idx_value = BTreeMap::new();
-        for (k, v) in &self.entry_index {
-            idx_value.insert(v, k);
-        }
-        assert_eq!(idx_value.len(), self.entry_index.len());
+    // all_encoded_values materialises a vector of all encoded values for the
+    // column.
+    pub fn all_encoded_values(&self) -> Vec<i64> {
+        let mut out: Vec<i64> = Vec::with_capacity(self.total as usize);
 
         for (idx, rl) in &self.run_lengths {
-            // TODO(edd): fix unwrap - we know that the value exists in map...
-            let v = idx_value.get(&idx).unwrap().as_ref();
-            out.extend(iter::repeat(v).take(*rl as usize));
+            out.extend(iter::repeat(*idx as i64).take(*rl as usize));
         }
         out
     }
diff --git a/delorean_mem_qe/src/segment.rs b/delorean_mem_qe/src/segment.rs
index c058df0..f8c5005 100644
--- a/delorean_mem_qe/src/segment.rs
+++ b/delorean_mem_qe/src/segment.rs
@@ -228,7 +228,7 @@ impl Segment {
         group_columns: &[String],
         aggregates: &[(String, AggregateType)],
         window: i64,
-    ) -> BTreeMap<Vec<String>, Vec<(String, Option<column::Aggregate>)>> {
+    ) -> BTreeMap<Vec<i64>, Vec<(&String, &AggregateType, Option<column::Aggregate>)>> {
         // Build a hash table - essentially, scan columns for matching row ids,
         // emitting the encoded value for each column and track those value
         // combinations in a hashmap with running aggregates.
@@ -242,6 +242,10 @@ impl Segment {
             assert_ne!(group_columns[group_columns.len() - 1], ""time"");
         }
 
+        // TODO(edd): Perf - if there is no predicate and we want entire segment
+        // then it will be a lot faster to not build filtered_row_ids and just
+        // get all encoded values for each grouping column...
+
         // filter on predicates and time
         let filtered_row_ids: croaring::Bitmap;
         if let Some(row_ids) = self.filter_by_predicates_eq(time_range, predicates) {
@@ -263,7 +267,12 @@ impl Segment {
         let mut group_column_encoded_values = Vec::with_capacity(group_columns.len());
         for group_column in group_columns {
             if let Some(column) = self.column(&group_column) {
-                let encoded_values = column.encoded_values(&filtered_row_ids_vec);
+                let encoded_values = if filtered_row_ids_vec.len() == self.meta.rows {
+                    column.all_encoded_values()
+                } else {
+                    column.encoded_values(&filtered_row_ids_vec)
+                };
+
                 assert_eq!(
                     filtered_row_ids.cardinality() as usize,
                     encoded_values.len()
@@ -325,10 +334,10 @@ impl Segment {
             .collect::<Vec<_>>();
 
         // hashMap is about 20% faster than BTreeMap in this case
-        let mut hash_table: HashMap<
+        let mut hash_table: BTreeMap<
             Vec<i64>,
             Vec<(&String, &AggregateType, Option<column::Aggregate>)>,
-        > = HashMap::new();
+        > = BTreeMap::new();
 
         let mut aggregate_row: Vec<(&str, Option<column::Scalar>)> =
             std::iter::repeat_with(|| ("""", None))
@@ -406,8 +415,10 @@ impl Segment {
             }
             processed_rows += 1;
         }
+        // println!(""groups: {:?}"", hash_table.len());
         log::debug!(""({:?} rows processed) {:?}"", processed_rows, hash_table);
         BTreeMap::new()
+        // hash_table
     }
 
     pub fn aggregate_by_group_using_sort(
@@ -451,7 +462,11 @@ impl Segment {
         let mut group_column_encoded_values = Vec::with_capacity(group_columns.len());
         for group_column in group_columns {
             if let Some(column) = self.column(&group_column) {
-                let encoded_values = column.encoded_values(&filtered_row_ids_vec);
+                let encoded_values = if filtered_row_ids_vec.len() == self.meta.rows {
+                    column.all_encoded_values()
+                } else {
+                    column.encoded_values(&filtered_row_ids_vec)
+                };
                 assert_eq!(
                     filtered_row_ids.cardinality() as usize,
                     encoded_values.len()
@@ -557,6 +572,10 @@ impl Segment {
             assert_ne!(group_columns[group_columns.len() - 1], ""time"");
         }
 
+        // TODO(edd): Perf - if there is no predicate and we want entire segment
+        // then it will be a lot faster to not build filtered_row_ids and just
+        // get all encoded values for each grouping column...
+
         // filter on predicates and time
         let filtered_row_ids: croaring::Bitmap;
         if let Some(row_ids) = self.filter_by_predicates_eq(time_range, predicates) {
@@ -577,7 +596,11 @@ impl Segment {
         let mut group_column_encoded_values = Vec::with_capacity(group_columns.len());
         for group_column in group_columns {
             if let Some(column) = self.column(&group_column) {
-                let encoded_values = column.encoded_values(&filtered_row_ids_vec);
+                let encoded_values = if filtered_row_ids_vec.len() == self.meta.rows {
+                    column.all_encoded_values()
+                } else {
+                    column.encoded_values(&filtered_row_ids_vec)
+                };
                 assert_eq!(
                     filtered_row_ids.cardinality() as usize,
                     encoded_values.len()
@@ -709,6 +732,7 @@ impl Segment {
             aggregates: group_key_aggregates,
         });
 
+        // println!(""groups: {:?}"", results.len());
         log::debug!(""({:?} rows processed) {:?}"", processed_rows, results);
         // results
         vec![]
",3,"[""173553c0372e66e03bdab19e0e6c2dd44daa14a0"", ""672cd2b9775fb6dac2d522cb3f4469db47c0556b"", ""cad5e45208346528ad02cd04dcac863f90faa037""]","[""cicd"", ""test"", ""feat""]"
"convert to record | path correction

Signed-off-by: Pranav C <pranavxc@gmail.com> | add `to_sql`

Co-authored-by: Gil Forsyth <gforsyth@users.noreply.github.com>","diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
index cc998c6..65c8550 100755
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
@@ -167,13 +167,8 @@ public final class ExporterDirectorDistributionTest {
    * <p>This makes sure that even if we miss one export position event, we distribute the event
    * later again, which makes tests less flaky.
    */
-  private static final class ClockShifter implements ConditionEvaluationListener<Void> {
-
-    private final ControlledActorClock clock;
-
-    public ClockShifter(final ControlledActorClock clock) {
-      this.clock = clock;
-    }
+  private record ClockShifter(ControlledActorClock clock)
+      implements ConditionEvaluationListener<Void> {
 
     @Override
     public void conditionEvaluated(final EvaluatedCondition<Void> condition) {

diff --git a/packages/nocodb-nest/src/modules/test/TestResetService/resetMetaSakilaSqliteProject.ts b/packages/nocodb-nest/src/modules/test/TestResetService/resetMetaSakilaSqliteProject.ts
index 3afce9b..8425b00 100644
--- a/packages/nocodb-nest/src/modules/test/TestResetService/resetMetaSakilaSqliteProject.ts
+++ b/packages/nocodb-nest/src/modules/test/TestResetService/resetMetaSakilaSqliteProject.ts
@@ -1,11 +1,9 @@
 import { promises as fs } from 'fs';
 import axios from 'axios';
+import path from 'path'
 
 const sqliteFilePath = (parallelId: string) => {
-  const rootDir = __dirname.replace(
-    '/src/modules/test/TestResetService',
-    '',
-  );
+  const rootDir = process.cwd()
 
   return `${rootDir}/test_sakila_${parallelId}.db`;
 };
@@ -78,10 +76,10 @@ const deleteSqliteFileIfExists = async (parallelId: string) => {
 };
 
 const seedSakilaSqliteFile = async (parallelId: string) => {
-  const testsDir = __dirname.replace(
-    '/src/modules/test/TestResetService',
-    '/tests',
-  );
+  const testsDir =  path.join(
+    process.cwd(),
+    'tests'
+  );;
 
   await fs.copyFile(
     `${testsDir}/sqlite-sakila-db/sakila.db`,
diff --git a/packages/nocodb-nest/src/modules/test/TestResetService/resetMysqlSakilaProject.ts b/packages/nocodb-nest/src/modules/test/TestResetService/resetMysqlSakilaProject.ts
index 6bcd3f1..e4ed112 100644
--- a/packages/nocodb-nest/src/modules/test/TestResetService/resetMysqlSakilaProject.ts
+++ b/packages/nocodb-nest/src/modules/test/TestResetService/resetMysqlSakilaProject.ts
@@ -1,4 +1,5 @@
 import { promises as fs } from 'fs';
+import path from 'path';
 import axios from 'axios';
 import { knex } from 'knex';
 import Audit from '../../../models/Audit';
@@ -85,10 +86,7 @@ const resetSakilaMysql = async (
   parallelId: string,
   isEmptyProject: boolean,
 ) => {
-  const testsDir = __dirname.replace(
-    '/src/modules/test/TestResetService',
-    '/tests',
-  );
+  const testsDir = path.join(process.cwd(), '/tests');
 
   try {
     await knex.raw(`DROP DATABASE test_sakila_${parallelId}`);
diff --git a/packages/nocodb-nest/src/modules/test/TestResetService/resetPgSakilaProject.ts b/packages/nocodb-nest/src/modules/test/TestResetService/resetPgSakilaProject.ts
index 1a042c3..73923ef 100644
--- a/packages/nocodb-nest/src/modules/test/TestResetService/resetPgSakilaProject.ts
+++ b/packages/nocodb-nest/src/modules/test/TestResetService/resetPgSakilaProject.ts
@@ -1,6 +1,7 @@
 import { promises as fs } from 'fs';
 import axios from 'axios';
 import { knex } from 'knex';
+import path from 'path'
 import Audit from '../../../models/Audit';
 import type Project from '../../../models/Project';
 
@@ -78,8 +79,8 @@ const isSakilaPgToBeReset = async (parallelId: string, project?: Project) => {
 };
 
 const resetSakilaPg = async (parallelId: string, isEmptyProject: boolean) => {
-  const testsDir = __dirname.replace(
-    '/src/modules/test/TestResetService',
+  const testsDir = path.join(
+    process.cwd(),
     '/tests',
   );
 

diff --git a/docs/api/expressions/top_level.md b/docs/api/expressions/top_level.md
index efaffbd..34b529e 100644
--- a/docs/api/expressions/top_level.md
+++ b/docs/api/expressions/top_level.md
@@ -28,7 +28,7 @@ These methods and objects are available directly in the `ibis` module.
 ::: ibis.or_
 ::: ibis.param
 ::: ibis.show_sql
-::: ibis.sql
+::: ibis.to_sql
 ::: ibis.random
 ::: ibis.range_window
 ::: ibis.row_number
",3,"[""3346331a963766c8193170fb130adad2e658ada2"", ""974e033a3ca7484290a04201ee33856a25da0942"", ""e2821a56c7d867b8b591f1777019843a2ffca797""]","[""refactor"", ""fix"", ""docs""]"
create mock img server,"diff --git a/scripts/gulp/tasks/test.ts b/scripts/gulp/tasks/test.ts
index 8014b12..d10c1aa 100644
--- a/scripts/gulp/tasks/test.ts
+++ b/scripts/gulp/tasks/test.ts
@@ -26,12 +26,18 @@ task('test.imageserver', () => {
   function handleRequest(req, res) {
     const urlParse = url.parse(req.url, true);
 
+    res.setHeader('Access-Control-Allow-Origin', '*');
+    res.setHeader('Access-Control-Allow-Methods', 'GET');
+    res.setHeader('Connection', 'keep-alive');
+    res.setHeader('Age', '0');
+    res.setHeader('cache-control', 'no-store');
+
     if (urlParse.pathname === '/reset') {
       console.log('Image Server Reset');
       console.log('---------------------------');
       requestedUrls.length = 0;
       start = Date.now();
-      res.setHeader('Access-Control-Allow-Origin', '*');
+      res.setHeader('Content-Type', 'text/plain');
       res.end('reset');
       return;
     }
@@ -48,9 +54,8 @@ task('test.imageserver', () => {
 
     setTimeout(() => {
       res.setHeader('Content-Type', 'image/svg+xml');
-      res.setHeader('Access-Control-Allow-Origin', '*');
       res.end(`<svg xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink""
-                   style=""background-color: ${color}; width: ${width}px; height: ${height}px;"">
+                   viewBox=""0 0 ${width} ${height}"" style=""background-color: ${color};"">
                  <text x=""5"" y=""22"" style=""font-family: Courier; font-size: 24px"">${id}</text>
                </svg>`);
     }, delay);
",1,"[""32b76173a259ea1993298289b436cf10c1e800bf""]","[""test""]"
restructure ClusterTopology to track completed change,"diff --git a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
index e4ffc70..07707fe 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
@@ -150,12 +150,12 @@ public class TopologyChangeCoordinatorImpl implements TopologyChangeCoordinator 
       final ClusterTopology updatedTopology,
       final TopologyChangeAppliersImpl topologyChangeSimulator,
       final ActorFuture<ClusterTopology> simulationCompleted) {
-    if (!updatedTopology.changes().hasPendingChanges()) {
+    if (!updatedTopology.hasPendingChanges()) {
       simulationCompleted.complete(updatedTopology);
       return;
     }
 
-    final var operation = updatedTopology.changes().nextPendingOperation();
+    final var operation = updatedTopology.nextPendingOperation();
     final OperationApplier applier = topologyChangeSimulator.getApplier(operation);
     final var result = applier.init(updatedTopology);
     if (result.isLeft()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
index a521721..1f89665 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
@@ -23,7 +23,6 @@ import io.camunda.zeebe.topology.protocol.Requests.ChangeStatus;
 import io.camunda.zeebe.topology.protocol.Topology;
 import io.camunda.zeebe.topology.protocol.Topology.CompletedChange;
 import io.camunda.zeebe.topology.protocol.Topology.MemberState;
-import io.camunda.zeebe.topology.protocol.Topology.PendingChange;
 import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterChangePlan.CompletedOperation;
 import io.camunda.zeebe.topology.state.ClusterTopology;
@@ -98,10 +97,17 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             .map(e -> Map.entry(MemberId.from(e.getKey()), decodeMemberState(e.getValue())))
             .collect(Collectors.toMap(Entry::getKey, Entry::getValue));
 
-    final var changes = decodeChangePlan(encodedClusterTopology.getChanges());
+    final Optional<io.camunda.zeebe.topology.state.CompletedChange> completedChange =
+        encodedClusterTopology.hasLastChange()
+            ? Optional.of(decodeCompletedChange(encodedClusterTopology.getLastChange()))
+            : Optional.empty();
+    final Optional<ClusterChangePlan> currentChange =
+        encodedClusterTopology.hasCurrentChange()
+            ? Optional.of(decodeChangePlan(encodedClusterTopology.getCurrentChange()))
+            : Optional.empty();
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        encodedClusterTopology.getVersion(), members, changes);
+        encodedClusterTopology.getVersion(), members, completedChange, currentChange);
   }
 
   private Topology.ClusterTopology encodeClusterTopology(
@@ -110,12 +116,19 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
         clusterTopology.members().entrySet().stream()
             .collect(Collectors.toMap(e -> e.getKey().id(), e -> encodeMemberState(e.getValue())));
 
-    final var encodedChangePlan = encodeChangePlan(clusterTopology.changes());
-    return Topology.ClusterTopology.newBuilder()
-        .setVersion(clusterTopology.version())
-        .putAllMembers(members)
-        .setChanges(encodedChangePlan)
-        .build();
+    final var builder =
+        Topology.ClusterTopology.newBuilder()
+            .setVersion(clusterTopology.version())
+            .putAllMembers(members);
+
+    clusterTopology
+        .lastChange()
+        .ifPresent(lastChange -> builder.setLastChange(encodeCompletedChange(lastChange)));
+    clusterTopology
+        .changes()
+        .ifPresent(changePlan -> builder.setCurrentChange(encodeChangePlan(changePlan)));
+
+    return builder.build();
   }
 
   private io.camunda.zeebe.topology.state.MemberState decodeMemberState(
@@ -207,17 +220,28 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private Topology.ClusterChangePlan encodeChangePlan(final ClusterChangePlan changes) {
-    final var builder = Topology.ClusterChangePlan.newBuilder().setVersion(changes.version());
-    if (changes.ongoingChange().isPresent()) {
-      builder.setPendingChange(encodePendingChange(changes.ongoingChange().get()));
-    } else if (changes.lastChange().isPresent()) {
-      builder.setCompletedChange(encodeCompletedChange(changes.lastChange().get()));
-    }
+    final var builder =
+        Topology.ClusterChangePlan.newBuilder()
+            .setVersion(changes.version())
+            .setId(changes.id())
+            .setStatus(fromTopologyChangeStatus(changes.status()))
+            .setStartedAt(
+                Timestamp.newBuilder()
+                    .setSeconds(changes.startedAt().getEpochSecond())
+                    .setNanos(changes.startedAt().getNano())
+                    .build());
+    changes
+        .pendingOperations()
+        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
+    changes
+        .completedOperations()
+        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
+
     return builder.build();
   }
 
   private CompletedChange encodeCompletedChange(
-      final ClusterChangePlan.CompletedChange completedChange) {
+      final io.camunda.zeebe.topology.state.CompletedChange completedChange) {
     final var builder = Topology.CompletedChange.newBuilder();
     builder
         .setId(completedChange.id())
@@ -236,27 +260,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
     return builder.build();
   }
 
-  private Topology.PendingChange encodePendingChange(
-      final ClusterChangePlan.PendingChange pendingChange) {
-    final var builder = Topology.PendingChange.newBuilder();
-    builder
-        .setId(pendingChange.id())
-        .setStatus(fromTopologyChangeStatus(pendingChange.status()))
-        .setStartedAt(
-            Timestamp.newBuilder()
-                .setSeconds(pendingChange.startedAt().getEpochSecond())
-                .setNanos(pendingChange.startedAt().getNano())
-                .build());
-    pendingChange
-        .pendingOperations()
-        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
-    pendingChange
-        .completedOperations()
-        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
-
-    return builder.build();
-  }
-
   private Topology.TopologyChangeOperation encodeOperation(
       final io.camunda.zeebe.topology.state.TopologyChangeOperation operation) {
     final var builder =
@@ -298,22 +301,31 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private ClusterChangePlan decodeChangePlan(final Topology.ClusterChangePlan clusterChangePlan) {
+
     final var version = clusterChangePlan.getVersion();
-    final Optional<ClusterChangePlan.PendingChange> pendingChange =
-        clusterChangePlan.hasPendingChange()
-            ? Optional.of(decodePendingChange(clusterChangePlan.getPendingChange()))
-            : Optional.empty();
-    final Optional<ClusterChangePlan.CompletedChange> completedChange =
-        clusterChangePlan.hasCompletedChange()
-            ? Optional.of(decodeCompletedChange(clusterChangePlan.getCompletedChange()))
-            : Optional.empty();
+    final var pendingOperations =
+        clusterChangePlan.getPendingOperationsList().stream()
+            .map(this::decodeOperation)
+            .collect(Collectors.toList());
+    final var completedOperations =
+        clusterChangePlan.getCompletedOperationsList().stream()
+            .map(this::decodeCompletedOperation)
+            .collect(Collectors.toList());
 
-    return new ClusterChangePlan(version, completedChange, pendingChange);
+    return new ClusterChangePlan(
+        clusterChangePlan.getId(),
+        clusterChangePlan.getVersion(),
+        toChangeStatus(clusterChangePlan.getStatus()),
+        Instant.ofEpochSecond(
+            clusterChangePlan.getStartedAt().getSeconds(),
+            clusterChangePlan.getStartedAt().getNanos()),
+        completedOperations,
+        pendingOperations);
   }
 
-  private ClusterChangePlan.CompletedChange decodeCompletedChange(
+  private io.camunda.zeebe.topology.state.CompletedChange decodeCompletedChange(
       final CompletedChange completedChange) {
-    return new ClusterChangePlan.CompletedChange(
+    return new io.camunda.zeebe.topology.state.CompletedChange(
         completedChange.getId(),
         toChangeStatus(completedChange.getStatus()),
         Instant.ofEpochSecond(
@@ -323,25 +335,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             completedChange.getCompletedAt().getNanos()));
   }
 
-  private ClusterChangePlan.PendingChange decodePendingChange(final PendingChange pendingChange) {
-    final var pendingOperations =
-        pendingChange.getPendingOperationsList().stream()
-            .map(this::decodeOperation)
-            .collect(Collectors.toList());
-    final var completedOperations =
-        pendingChange.getCompletedOperationsList().stream()
-            .map(this::decodeCompletedOperation)
-            .collect(Collectors.toList());
-
-    return new ClusterChangePlan.PendingChange(
-        pendingChange.getId(),
-        toChangeStatus(pendingChange.getStatus()),
-        Instant.ofEpochSecond(
-            pendingChange.getStartedAt().getSeconds(), pendingChange.getStartedAt().getNanos()),
-        completedOperations,
-        pendingOperations);
-  }
-
   private TopologyChangeOperation decodeOperation(
       final Topology.TopologyChangeOperation topologyChangeOperation) {
     if (topologyChangeOperation.hasPartitionJoin()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
index 49ed70f..97a29ba 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
@@ -11,7 +11,6 @@ import io.atomix.cluster.MemberId;
 import java.time.Instant;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Optional;
 
 /**
  * Represents the ongoing cluster topology changes. The pendingOperations are executed sequentially.
@@ -23,50 +22,32 @@ import java.util.Optional;
  * gossip update out of order.
  */
 public record ClusterChangePlan(
-    int version, Optional<CompletedChange> lastChange, Optional<PendingChange> ongoingChange) {
-  public static ClusterChangePlan empty() {
-    return new ClusterChangePlan(0, Optional.empty(), Optional.empty());
-  }
+    long id,
+    int version,
+    Status status,
+    Instant startedAt,
+    List<CompletedOperation> completedOperations,
+    List<TopologyChangeOperation> pendingOperations) {
 
   public static ClusterChangePlan init(
       final long id, final List<TopologyChangeOperation> operations) {
     return new ClusterChangePlan(
-        1,
-        Optional.empty(),
-        Optional.of(
-            new PendingChange(
-                id, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations))));
+        id, 1, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations));
   }
 
   /** To be called when the first operation is completed. */
   ClusterChangePlan advance() {
     // List#subList hold on to the original list. Make a copy to prevent a potential memory leak.
-    final PendingChange pendingChange = ongoingChange.orElseThrow();
-    final List<TopologyChangeOperation> pendingOperations = pendingChange.pendingOperations();
     final var nextPendingOperations =
         List.copyOf(pendingOperations.subList(1, pendingOperations.size()));
-    final var newCompletedOperations = new ArrayList<>(pendingChange.completedOperations());
+    final var newCompletedOperations = new ArrayList<>(completedOperations);
     newCompletedOperations.add(new CompletedOperation(pendingOperations.get(0), Instant.now()));
     return new ClusterChangePlan(
-        version + 1,
-        lastChange,
-        Optional.of(
-            new PendingChange(
-                pendingChange.id(),
-                pendingChange.status(),
-                pendingChange.startedAt(),
-                newCompletedOperations,
-                nextPendingOperations)));
+        id, version + 1, status, startedAt(), newCompletedOperations, nextPendingOperations);
   }
 
-  ClusterChangePlan completed() {
-    final var pendingChange = ongoingChange.orElseThrow();
-    return new ClusterChangePlan(
-        0, // reset version
-        Optional.of(
-            new CompletedChange(
-                pendingChange.id(), Status.COMPLETED, pendingChange.startedAt(), Instant.now())),
-        Optional.empty());
+  CompletedChange completed() {
+    return new CompletedChange(id, Status.COMPLETED, startedAt(), Instant.now());
   }
 
   public ClusterChangePlan merge(final ClusterChangePlan other) {
@@ -81,35 +62,22 @@ public record ClusterChangePlan(
   }
 
   public boolean hasPendingChangesFor(final MemberId memberId) {
-    if (ongoingChange.isEmpty()) {
-      return false;
-    }
-    final var pendingOperations = ongoingChange.get().pendingOperations();
     return !pendingOperations.isEmpty() && pendingOperations.get(0).memberId().equals(memberId);
   }
 
   public TopologyChangeOperation nextPendingOperation() {
-    return ongoingChange.orElseThrow().pendingOperations().get(0);
+    return pendingOperations().get(0);
   }
 
   public boolean hasPendingChanges() {
-    return ongoingChange.isPresent() && !ongoingChange.get().pendingOperations().isEmpty();
+    return !pendingOperations().isEmpty();
   }
 
-  public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
-
-  public record PendingChange(
-      long id,
-      Status status,
-      Instant startedAt,
-      List<CompletedOperation> completedOperations,
-      List<TopologyChangeOperation> pendingOperations) {}
-
   public record CompletedOperation(TopologyChangeOperation operation, Instant completedAt) {}
 
   public enum Status {
     IN_PROGRESS,
     COMPLETED,
-    FAILED
+    FAILED;
   }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
index 544118a..3494832 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
@@ -12,6 +12,8 @@ import io.atomix.cluster.MemberId;
 import io.camunda.zeebe.topology.state.MemberState.State;
 import java.util.List;
 import java.util.Map;
+import java.util.Map.Entry;
+import java.util.NoSuchElementException;
 import java.util.Objects;
 import java.util.Optional;
 import java.util.function.UnaryOperator;
@@ -32,12 +34,15 @@ import java.util.stream.Stream;
  * <p>This class is immutable. Each mutable methods returns a new instance with the updated state.
  */
 public record ClusterTopology(
-    long version, Map<MemberId, MemberState> members, ClusterChangePlan changes) {
+    long version,
+    Map<MemberId, MemberState> members,
+    Optional<CompletedChange> lastChange,
+    Optional<ClusterChangePlan> changes) {
 
   private static final int UNINITIALIZED_VERSION = -1;
 
   public static ClusterTopology uninitialized() {
-    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public boolean isUninitialized() {
@@ -45,7 +50,7 @@ public record ClusterTopology(
   }
 
   public static ClusterTopology init() {
-    return new ClusterTopology(0, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(0, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public ClusterTopology addMember(final MemberId memberId, final MemberState state) {
@@ -58,7 +63,7 @@ public record ClusterTopology(
 
     final var newMembers =
         ImmutableMap.<MemberId, MemberState>builder().putAll(members).put(memberId, state).build();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   /**
@@ -96,7 +101,7 @@ public record ClusterTopology(
     }
 
     final var newMembers = mapBuilder.buildKeepingLast();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   public ClusterTopology startTopologyChange(final List<TopologyChangeOperation> operations) {
@@ -110,7 +115,10 @@ public record ClusterTopology(
     } else {
       final long newVersion = version + 1;
       return new ClusterTopology(
-          newVersion, members, ClusterChangePlan.init(newVersion, operations));
+          newVersion,
+          members,
+          lastChange,
+          Optional.of(ClusterChangePlan.init(newVersion, operations)));
     }
   }
 
@@ -130,20 +138,28 @@ public record ClusterTopology(
     } else {
       final var mergedMembers =
           Stream.concat(members.entrySet().stream(), other.members().entrySet().stream())
-              .collect(
-                  Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, MemberState::merge));
+              .collect(Collectors.toMap(Entry::getKey, Entry::getValue, MemberState::merge));
 
-      final var mergedChanges = changes.merge(other.changes);
-      return new ClusterTopology(version, ImmutableMap.copyOf(mergedMembers), mergedChanges);
+      final Optional<ClusterChangePlan> mergedChanges =
+          Stream.of(changes, other.changes)
+              .flatMap(Optional::stream)
+              .reduce(ClusterChangePlan::merge);
+
+      return new ClusterTopology(
+          version, ImmutableMap.copyOf(mergedMembers), lastChange, mergedChanges);
     }
   }
 
+  public boolean hasPendingChanges() {
+    return changes.isPresent() && changes.orElseThrow().hasPendingChanges();
+  }
+
   /**
    * @return true if the next operation in pending changes is applicable for the given memberId,
    *     otherwise returns false.
    */
   private boolean hasPendingChangesFor(final MemberId memberId) {
-    return changes.hasPendingChangesFor(memberId);
+    return changes.isPresent() && changes.get().hasPendingChangesFor(memberId);
   }
 
   /**
@@ -157,7 +173,7 @@ public record ClusterTopology(
     if (!hasPendingChangesFor(memberId)) {
       return Optional.empty();
     }
-    return Optional.of(changes.nextPendingOperation());
+    return Optional.of(changes.orElseThrow().nextPendingOperation());
   }
 
   /**
@@ -179,7 +195,9 @@ public record ClusterTopology(
       throw new IllegalStateException(
           ""Expected to advance the topology change, but there is no pending change"");
     }
-    final ClusterTopology result = new ClusterTopology(version, members, changes.advance());
+    final ClusterTopology result =
+        new ClusterTopology(
+            version, members, lastChange, Optional.of(changes.orElseThrow().advance()));
 
     if (!result.hasPendingChanges()) {
       // The last change has been applied. Clean up the members that are marked as LEFT in the
@@ -194,7 +212,9 @@ public record ClusterTopology(
               .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
 
       // Increment the version so that other members can merge by overwriting their local topology.
-      return new ClusterTopology(result.version() + 1, currentMembers, changes.completed());
+      final var completedChange = changes.orElseThrow().completed();
+      return new ClusterTopology(
+          result.version() + 1, currentMembers, Optional.of(completedChange), Optional.empty());
     }
 
     return result;
@@ -208,10 +228,6 @@ public record ClusterTopology(
     return members().get(memberId);
   }
 
-  public boolean hasPendingChanges() {
-    return changes.hasPendingChanges();
-  }
-
   public int clusterSize() {
     return (int)
         members.entrySet().stream()
@@ -226,4 +242,11 @@ public record ClusterTopology(
     return (int)
         members.values().stream().flatMap(m -> m.partitions().keySet().stream()).distinct().count();
   }
+
+  public TopologyChangeOperation nextPendingOperation() {
+    if (!hasPendingChanges()) {
+      throw new NoSuchElementException();
+    }
+    return changes.orElseThrow().nextPendingOperation();
+  }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
new file mode 100644
index 0000000..7031e88
--- /dev/null
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
@@ -0,0 +1,13 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.topology.state;
+
+import io.camunda.zeebe.topology.state.ClusterChangePlan.Status;
+import java.time.Instant;
+
+public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
index 5861c7c..ef94a1f 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
@@ -10,13 +10,13 @@ package io.camunda.zeebe.topology.util;
 import io.atomix.cluster.MemberId;
 import io.atomix.primitive.partition.PartitionId;
 import io.atomix.primitive.partition.PartitionMetadata;
-import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterTopology;
 import io.camunda.zeebe.topology.state.MemberState;
 import io.camunda.zeebe.topology.state.PartitionState;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Optional;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -42,7 +42,7 @@ public final class TopologyUtil {
     }
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        0, Map.copyOf(memberStates), ClusterChangePlan.empty());
+        0, Map.copyOf(memberStates), Optional.empty(), Optional.empty());
   }
 
   public static Set<PartitionMetadata> getPartitionDistributionFrom(
",1,"[""3cca5c314ad6feeffbfe1f14cf49ebd0fd9a95a2""]","[""refactor""]"
change min checked results for score calculation | Fix Cube Store build on Windows | get ip from forwarded header,"diff --git a/server/src/services/courseService.ts b/server/src/services/courseService.ts
index 89633f4..10bfc55 100644
--- a/server/src/services/courseService.ts
+++ b/server/src/services/courseService.ts
@@ -580,8 +580,7 @@ export async function getTaskSolutionCheckers(courseTaskId: number, minCheckedCo
     .createQueryBuilder('tsr')
     .select('tsr.""studentId"", ROUND(AVG(tsr.score)) as ""score""')
     .where(qb => {
-      // query students with 3 checked tasks
-
+      // query students who checked enough tasks
       const query = qb
         .subQuery()
         .select('r.""checkerId""')
@@ -600,7 +599,7 @@ export async function getTaskSolutionCheckers(courseTaskId: number, minCheckedCo
     })
     .andWhere('tsr.""courseTaskId"" = :courseTaskId', { courseTaskId })
     .groupBy('tsr.""studentId""')
-    .having(`COUNT(tsr.id) >= :count`, { count: minCheckedCount })
+    .having(`COUNT(tsr.id) >= :count`, { count: minCheckedCount - 1 })
     .getRawMany();
 
   return records.map(record => ({ studentId: record.studentId, score: Number(record.score) }));

diff --git a/.github/workflows/publish.yml b/.github/workflows/publish.yml
index a986501..db33097 100644
--- a/.github/workflows/publish.yml
+++ b/.github/workflows/publish.yml
@@ -409,7 +409,7 @@ jobs:
         run: vcpkg integrate install; vcpkg install openssl:x64-windows
       - name: Instal LLVM for Windows
         if: ${{ startsWith(matrix.os, 'windows') }}
-        run: choco install -y llvm --version 9.0.1
+        run: choco install -y --force llvm --version 9.0.1
       - name: Set Env Variables for Windows
         uses: allenevans/set-env@v2.0.0
         if: ${{ startsWith(matrix.os, 'windows') }}
diff --git a/.github/workflows/rust.yml b/.github/workflows/rust.yml
index d45cdf9..8d87ed6 100644
--- a/.github/workflows/rust.yml
+++ b/.github/workflows/rust.yml
@@ -158,7 +158,7 @@ jobs:
         run: vcpkg integrate install; vcpkg install openssl:x64-windows
       - name: Instal LLVM for Windows
         if: ${{ startsWith(matrix.os, 'windows') }}
-        run: choco install -y llvm --version 9.0.1
+        run: choco install -y --force llvm --version 9.0.1
       - name: Set Env Variables for Windows
         uses: allenevans/set-env@v2.0.0
         if: ${{ startsWith(matrix.os, 'windows') }}

diff --git a/kousa/lib/broth/socket_handler.ex b/kousa/lib/broth/socket_handler.ex
index d142135..5828f30 100644
--- a/kousa/lib/broth/socket_handler.ex
+++ b/kousa/lib/broth/socket_handler.ex
@@ -22,7 +22,7 @@ defmodule Broth.SocketHandler do
   ## initialization boilerplate
 
   @impl true
-  def init(request = %{peer: {ip, _reverse_port}}, _state) do
+  def init(request, _state) do
     props = :cowboy_req.parse_qs(request)
 
     compression =
@@ -37,10 +37,16 @@ defmodule Broth.SocketHandler do
         _ -> :json
       end
 
+    ip =
+      case request.headers do
+        %{""x-forwarded-for"" => v} -> v
+        _ -> nil
+      end
+
     state = %__MODULE__{
       awaiting_init: true,
       user_id: nil,
-      ip: IP.to_string(ip),
+      ip: ip,
       encoding: encoding,
       compression: compression,
       callers: get_callers(request)
diff --git a/kousa/test/_support/ws_client.ex b/kousa/test/_support/ws_client.ex
index aeca704..125da17 100644
--- a/kousa/test/_support/ws_client.ex
+++ b/kousa/test/_support/ws_client.ex
@@ -19,7 +19,9 @@ defmodule BrothTest.WsClient do
 
     @api_url
     |> Path.join(""socket"")
-    |> WebSockex.start_link(__MODULE__, nil, extra_headers: [{""user-agent"", ancestors}])
+    |> WebSockex.start_link(__MODULE__, nil,
+      extra_headers: [{""user-agent"", ancestors}, {""x-forwarded-for"", ""127.0.0.1""}]
+    )
   end
 
   ###########################################################################
",3,"[""fd849bd08363df60dbc8b9b6d55bac4f5ace88f4"", ""e34bb04baac7574e67bc566d13dea72092e0cfa3"", ""2f5718743a830d40ddf272ad46f253dbb6d08cff""]","[""docs"", ""cicd"", ""fix""]"
selenium java 4.8.1 | add test for clickhouse-specific `create_table` parameters,"diff --git a/pom.xml b/pom.xml
index f792f3c..477224a 100644
--- a/pom.xml
+++ b/pom.xml
@@ -60,8 +60,8 @@
         <codehaus-groovy.version>3.0.11</codehaus-groovy.version>
         <jython.version>2.7.0</jython.version>
         <docker-java.version>3.2.14</docker-java.version>
-        <selenium.version>4.8.0</selenium.version>
-        <jmeter-plugins-webdriver.version>4.8.0</jmeter-plugins-webdriver.version>
+        <selenium.version>4.8.1</selenium.version>
+        <jmeter-plugins-webdriver.version>4.8.1</jmeter-plugins-webdriver.version>
         <opentelemetry.version>1.22.0</opentelemetry.version>
         <oracle-database.version>19.7.0.0</oracle-database.version>
         <zookeeper.version>3.8.0</zookeeper.version>

diff --git a/ibis/backends/clickhouse/tests/test_client.py b/ibis/backends/clickhouse/tests/test_client.py
index 678683d..c4e2aec 100644
--- a/ibis/backends/clickhouse/tests/test_client.py
+++ b/ibis/backends/clickhouse/tests/test_client.py
@@ -224,6 +224,21 @@ def test_create_table_data(con, data, engine, temp_table):
     assert len(t.execute()) == 3
 
 
+def test_create_table_with_properties(con, temp_table):
+    data = pd.DataFrame({""a"": list(""abcde"" * 20), ""b"": [1, 2, 3, 4, 5] * 20})
+    n = len(data)
+    t = con.create_table(
+        temp_table,
+        data,
+        schema=ibis.schema(dict(a=""string"", b=""!uint32"")),
+        order_by=[""a"", ""b""],
+        partition_by=[""a""],
+        sample_by=[""b""],
+        settings={""allow_nullable_key"": ""1""},
+    )
+    assert t.count().execute() == n
+
+
 @pytest.mark.parametrize(
     ""engine"",
     [
",2,"[""66f907f2d6ff0956bb5215518678bc79cab83c17"", ""7e1ece7d3fd41d1e3ee38e479c119494bb269966""]","[""build"", ""test""]"
"Template using kube api version

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com> | verify the replay mode

* write a test to verify the different replay modes | change notice from 'danger' > 'info'

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>","diff --git a/.github/workflows/api-ee.yaml b/.github/workflows/api-ee.yaml
index c014f34..2a12e0d 100644
--- a/.github/workflows/api-ee.yaml
+++ b/.github/workflows/api-ee.yaml
@@ -8,7 +8,7 @@ on:
         default: 'false'
   push:
     branches:
-      - dev
+      - test_ci
     paths:
       - ee/api/**
       - api/**
@@ -112,7 +112,8 @@ jobs:
         # Deploy command
         kubectl config set-context --namespace=app --current
         kubectl config get-contexts
-        helm template openreplay -n app openreplay -f vars.yaml -f /tmp/image_override.yaml --set ingress-nginx.enabled=false --set skipMigration=true --no-hooks | kubectl apply -f -
+        k_version=$(kubectl version --short 2>/dev/null | awk '/Server/{print $NF}')
+        helm template openreplay -n app openreplay -f vars.yaml -f /tmp/image_override.yaml --set ingress-nginx.enabled=false --set skipMigration=true --no-hooks --kube-version=$k_version | kubectl apply -f -
       env:
         DOCKER_REPO: ${{ secrets.EE_REGISTRY_URL }}
         # We're not passing -ee flag, because helm will add that.

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/ContinuouslyReplayTest.java b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/ContinuouslyReplayTest.java
index 167444c..7494014 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/ContinuouslyReplayTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/ContinuouslyReplayTest.java
@@ -11,6 +11,9 @@ import io.camunda.zeebe.engine.state.ZbColumnFamilies;
 import io.camunda.zeebe.engine.util.EngineRule;
 import io.camunda.zeebe.engine.util.ListLogStorage;
 import io.camunda.zeebe.model.bpmn.Bpmn;
+import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
+import io.camunda.zeebe.protocol.record.value.BpmnElementType;
+import io.camunda.zeebe.test.util.record.RecordingExporter;
 import org.assertj.core.api.SoftAssertions;
 import org.awaitility.Awaitility;
 import org.junit.Rule;
@@ -27,16 +30,22 @@ public class ContinuouslyReplayTest {
   @Rule public final EngineRule processing = EngineRule.withSharedStorage(sharedStorage);
 
   @Test
-  public void shouldEndUpWithTheSameState() {
+  public void shouldBuildTheSameStateOnProcessingAndReplay() {
     // given
-
-    // when
     processing
         .deployment()
-        .withXmlResource(Bpmn.createExecutableProcess().startEvent().endEvent().done())
+        .withXmlResource(Bpmn.createExecutableProcess(""process"").startEvent().endEvent().done())
         .deploy();
 
+    // when
+    final var processInstanceKey = processing.processInstance().ofBpmnProcessId(""process"").create();
+
     // then
+    RecordingExporter.processInstanceRecords(ProcessInstanceIntent.ELEMENT_COMPLETED)
+        .withProcessInstanceKey(processInstanceKey)
+        .withElementType(BpmnElementType.PROCESS)
+        .await();
+
     assertStates();
   }
 
diff --git a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
new file mode 100644
index 0000000..9dd9f4c
--- /dev/null
+++ b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
@@ -0,0 +1,121 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.engine.processing.streamprocessor;
+
+import static io.camunda.zeebe.engine.util.RecordToWrite.command;
+import static io.camunda.zeebe.engine.util.RecordToWrite.event;
+import static io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent.ACTIVATE_ELEMENT;
+import static io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent.ELEMENT_ACTIVATING;
+import static org.assertj.core.api.Assertions.assertThat;
+import static org.mockito.ArgumentMatchers.any;
+import static org.mockito.ArgumentMatchers.anyLong;
+import static org.mockito.ArgumentMatchers.eq;
+import static org.mockito.Mockito.inOrder;
+import static org.mockito.Mockito.never;
+import static org.mockito.Mockito.timeout;
+
+import io.camunda.zeebe.engine.processing.streamprocessor.StreamProcessor.Phase;
+import io.camunda.zeebe.engine.state.EventApplier;
+import io.camunda.zeebe.engine.util.Records;
+import io.camunda.zeebe.engine.util.StreamProcessorRule;
+import io.camunda.zeebe.protocol.impl.record.value.processinstance.ProcessInstanceRecord;
+import io.camunda.zeebe.protocol.record.ValueType;
+import org.junit.Rule;
+import org.junit.Test;
+import org.mockito.InOrder;
+import org.mockito.Mock;
+import org.mockito.junit.MockitoJUnit;
+import org.mockito.junit.MockitoRule;
+import org.mockito.verification.VerificationWithTimeout;
+
+public final class StreamProcessorReplayModeTest {
+
+  private static final long TIMEOUT_MILLIS = 2_000L;
+  private static final VerificationWithTimeout TIMEOUT = timeout(TIMEOUT_MILLIS);
+
+  private static final int PARTITION_ID = 1;
+
+  private static final ProcessInstanceRecord RECORD = Records.processInstance(1);
+
+  @Rule
+  public final StreamProcessorRule replayUntilEnd =
+      new StreamProcessorRule(PARTITION_ID).withReplayMode(ReplayMode.UNTIL_END);
+
+  @Rule
+  public final StreamProcessorRule replayContinuously =
+      new StreamProcessorRule(PARTITION_ID).withReplayMode(ReplayMode.CONTINUOUSLY);
+
+  @Rule public MockitoRule mockitoRule = MockitoJUnit.rule();
+
+  @Mock private TypedRecordProcessor<?> typedRecordProcessor;
+  @Mock private EventApplier eventApplier;
+
+  @Test
+  public void shouldReplayUntilEnd() {
+    // given
+    replayUntilEnd.writeBatch(
+        command().processInstance(ACTIVATE_ELEMENT, RECORD),
+        event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
+
+    // when
+    startStreamProcessor(replayUntilEnd);
+
+    replayUntilEnd.writeBatch(
+        command().processInstance(ACTIVATE_ELEMENT, RECORD),
+        event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
+
+    // then
+    final InOrder inOrder = inOrder(typedRecordProcessor, eventApplier);
+    inOrder.verify(eventApplier, TIMEOUT).applyState(anyLong(), eq(ELEMENT_ACTIVATING), any());
+    inOrder.verify(typedRecordProcessor, TIMEOUT.times(1)).onRecovered(any());
+    inOrder
+        .verify(typedRecordProcessor, TIMEOUT)
+        .processRecord(anyLong(), any(), any(), any(), any());
+    inOrder.verifyNoMoreInteractions();
+
+    assertThat(getCurrentPhase(replayUntilEnd)).isEqualTo(Phase.PROCESSING);
+  }
+
+  @Test
+  public void shouldReplayContinuously() {
+    // given
+    replayContinuously.writeBatch(
+        command().processInstance(ACTIVATE_ELEMENT, RECORD),
+        event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
+
+    // when
+    startStreamProcessor(replayContinuously);
+
+    replayContinuously.writeBatch(
+        command().processInstance(ACTIVATE_ELEMENT, RECORD),
+        event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
+
+    // then
+    final InOrder inOrder = inOrder(typedRecordProcessor, eventApplier);
+    inOrder
+        .verify(eventApplier, TIMEOUT.times(2))
+        .applyState(anyLong(), eq(ELEMENT_ACTIVATING), any());
+    inOrder.verify(typedRecordProcessor, never()).onRecovered(any());
+    inOrder.verifyNoMoreInteractions();
+
+    assertThat(getCurrentPhase(replayContinuously)).isEqualTo(Phase.REPROCESSING);
+  }
+
+  private void startStreamProcessor(final StreamProcessorRule streamProcessorRule) {
+    streamProcessorRule
+        .withEventApplierFactory(zeebeState -> eventApplier)
+        .startTypedStreamProcessor(
+            (processors, context) ->
+                processors.onCommand(
+                    ValueType.PROCESS_INSTANCE, ACTIVATE_ELEMENT, typedRecordProcessor));
+  }
+
+  private Phase getCurrentPhase(final StreamProcessorRule streamProcessorRule) {
+    return streamProcessorRule.getStreamProcessor(PARTITION_ID).getCurrentPhase().join();
+  }
+}
diff --git a/engine/src/test/java/io/camunda/zeebe/engine/util/EngineRule.java b/engine/src/test/java/io/camunda/zeebe/engine/util/EngineRule.java
index f626ed4..cf07b5c 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/util/EngineRule.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/util/EngineRule.java
@@ -101,7 +101,6 @@ public final class EngineRule extends ExternalResource {
       new Int2ObjectHashMap<>();
 
   private long lastProcessedPosition = -1L;
-  private ReplayMode replayMode;
 
   private EngineRule(final int partitionCount) {
     this(partitionCount, null);
@@ -176,7 +175,7 @@ public final class EngineRule extends ExternalResource {
   }
 
   public EngineRule withReplayMode(final ReplayMode replayMode) {
-    this.replayMode = replayMode;
+    environmentRule.withReplayMode(replayMode);
     return this;
   }
 
@@ -194,7 +193,6 @@ public final class EngineRule extends ExternalResource {
               (processingContext) ->
                   EngineProcessors.createEngineProcessors(
                           processingContext
-                              .replayMode(replayMode)
                               .onProcessedListener(
                                   record -> {
                                     lastProcessedPosition = record.getPosition();
diff --git a/engine/src/test/java/io/camunda/zeebe/engine/util/StreamProcessorRule.java b/engine/src/test/java/io/camunda/zeebe/engine/util/StreamProcessorRule.java
index ab44773..1f9fe26 100755
--- a/engine/src/test/java/io/camunda/zeebe/engine/util/StreamProcessorRule.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/util/StreamProcessorRule.java
@@ -10,6 +10,7 @@ package io.camunda.zeebe.engine.util;
 import static io.camunda.zeebe.engine.util.StreamProcessingComposite.getLogName;
 
 import io.camunda.zeebe.db.ZeebeDbFactory;
+import io.camunda.zeebe.engine.processing.streamprocessor.ReplayMode;
 import io.camunda.zeebe.engine.processing.streamprocessor.StreamProcessor;
 import io.camunda.zeebe.engine.processing.streamprocessor.TypedRecord;
 import io.camunda.zeebe.engine.processing.streamprocessor.TypedRecordProcessorFactory;
@@ -64,6 +65,7 @@ public final class StreamProcessorRule implements TestRule {
   private TestStreams streams;
   private StreamProcessingComposite streamProcessingComposite;
   private ListLogStorage sharedStorage = null;
+  private ReplayMode replayMode = ReplayMode.UNTIL_END;
 
   public StreamProcessorRule() {
     this(new TemporaryFolder());
@@ -125,6 +127,11 @@ public final class StreamProcessorRule implements TestRule {
     return this;
   }
 
+  public StreamProcessorRule withReplayMode(final ReplayMode replayMode) {
+    this.replayMode = replayMode;
+    return this;
+  }
+
   public LogStreamRecordWriter getLogStreamRecordWriter(final int partitionId) {
     return streamProcessingComposite.getLogStreamRecordWriter(partitionId);
   }
@@ -317,6 +324,7 @@ public final class StreamProcessorRule implements TestRule {
     @Override
     protected void before() {
       streams = new TestStreams(tempFolder, closeables, actorSchedulerRule.get());
+      streams.withReplayMode(replayMode);
 
       int partitionId = startPartitionId;
       for (int i = 0; i < partitionCount; i++) {
diff --git a/engine/src/test/java/io/camunda/zeebe/engine/util/TestStreams.java b/engine/src/test/java/io/camunda/zeebe/engine/util/TestStreams.java
index 18696b2..176c405 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/util/TestStreams.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/util/TestStreams.java
@@ -17,6 +17,7 @@ import static org.mockito.Mockito.when;
 
 import io.camunda.zeebe.db.ZeebeDb;
 import io.camunda.zeebe.db.ZeebeDbFactory;
+import io.camunda.zeebe.engine.processing.streamprocessor.ReplayMode;
 import io.camunda.zeebe.engine.processing.streamprocessor.StreamProcessor;
 import io.camunda.zeebe.engine.processing.streamprocessor.TypedEventRegistry;
 import io.camunda.zeebe.engine.processing.streamprocessor.TypedRecord;
@@ -79,6 +80,7 @@ public final class TestStreams {
   private boolean snapshotWasTaken = false;
 
   private Function<MutableZeebeState, EventApplier> eventApplierFactory = EventAppliers::new;
+  private ReplayMode replayMode = ReplayMode.UNTIL_END;
 
   public TestStreams(
       final TemporaryFolder dataDirectory,
@@ -107,6 +109,10 @@ public final class TestStreams {
     this.eventApplierFactory = eventApplierFactory;
   }
 
+  public void withReplayMode(final ReplayMode replayMode) {
+    this.replayMode = replayMode;
+  }
+
   public CommandResponseWriter getMockedResponseWriter() {
     return mockCommandResponseWriter;
   }
@@ -252,6 +258,7 @@ public final class TestStreams {
             .onProcessedListener(mockOnProcessedListener)
             .streamProcessorFactory(factory)
             .eventApplierFactory(eventApplierFactory)
+            .replayMode(replayMode)
             .build();
     final var openFuture = streamProcessor.openAsync(false);
 

diff --git a/packages/noco-docs/docs/030.workspaces/040.actions-on-workspace.md b/packages/noco-docs/docs/030.workspaces/040.actions-on-workspace.md
index 17a1d85..b8c3f52 100644
--- a/packages/noco-docs/docs/030.workspaces/040.actions-on-workspace.md
+++ b/packages/noco-docs/docs/030.workspaces/040.actions-on-workspace.md
@@ -20,7 +20,7 @@ To update the workspace name:
 ## Delete workspace
 If you determine that a workspace is no longer necessary, you have the option to permanently remove it from your settings. Deleting a workspace will delete all the bases and data associated with it.
 
-:::danger
+:::info
 **This action cannot be undone.**
 :::
 
diff --git a/packages/noco-docs/docs/040.bases/070.actions-on-base.md b/packages/noco-docs/docs/040.bases/070.actions-on-base.md
index b8e5723..7207971 100644
--- a/packages/noco-docs/docs/040.bases/070.actions-on-base.md
+++ b/packages/noco-docs/docs/040.bases/070.actions-on-base.md
@@ -69,7 +69,7 @@ To duplicate a base, you can follow these straightforward steps:
 
 If you determine that a base is no longer necessary, you have the option to permanently remove it from your workspace. Deleting a base will delete all the tables and data associated with it.
 
-:::danger
+:::info
 **This action cannot be undone.**
 :::
 
diff --git a/packages/noco-docs/docs/050.tables/060.actions-on-table.md b/packages/noco-docs/docs/050.tables/060.actions-on-table.md
index 3cf03d3..8ae9ade 100644
--- a/packages/noco-docs/docs/050.tables/060.actions-on-table.md
+++ b/packages/noco-docs/docs/050.tables/060.actions-on-table.md
@@ -46,7 +46,7 @@ A new table will be generated, mirroring the original table's schema and content
 
 ## Delete table
 
-:::danger
+:::info
 **This action cannot be undone.**
 :::
 
diff --git a/packages/noco-docs/docs/070.fields/060.actions-on-field.md b/packages/noco-docs/docs/070.fields/060.actions-on-field.md
index 600c6fd..fe2cfa8 100644
--- a/packages/noco-docs/docs/070.fields/060.actions-on-field.md
+++ b/packages/noco-docs/docs/070.fields/060.actions-on-field.md
@@ -83,7 +83,7 @@ New field will be created to the right of the original field.
 New field will be created to the left of the original field.
 
 ### Delete field
-:::danger
+:::info
 **This action cannot be undone.**
 :::
 
diff --git a/packages/noco-docs/docs/080.records/070.actions-on-record.md b/packages/noco-docs/docs/080.records/070.actions-on-record.md
index a9245ff..6d4774a 100644
--- a/packages/noco-docs/docs/080.records/070.actions-on-record.md
+++ b/packages/noco-docs/docs/080.records/070.actions-on-record.md
@@ -54,8 +54,8 @@ On the bulk update modal,
 5. Click on the `Bulk Update all` button
 6. A confirmation dialog will be displayed. Click on `Confirm` to update the records.
 
-:::danger
-This operation cannot be undone.
+:::info
+**This action cannot be undone.**
 :::
 
 ![Bulk Update](/img/v2/records/bulk-update-1.png)
diff --git a/packages/noco-docs/docs/090.views/090.actions-on-view.md b/packages/noco-docs/docs/090.views/090.actions-on-view.md
index c6c6ab2..7d23959 100644
--- a/packages/noco-docs/docs/090.views/090.actions-on-view.md
+++ b/packages/noco-docs/docs/090.views/090.actions-on-view.md
@@ -41,7 +41,7 @@ The view context menu provides a set of tools to interact with the view. The vie
 
 ## Delete view
 
-:::danger
+:::info
 **This action cannot be undone.**
 :::
 
",3,"[""c3531347fe5a4cc82d426db195026a5bdad15e7a"", ""48d5d573886e9fdd0cca1cea47112c4a2f6edf52"", ""2ba752d45350a676babe553dd68f019af81b512b""]","[""cicd"", ""test"", ""docs""]"
add unit test for query API | use ng2 loadNextToLocation,"diff --git a/gateway/src/test/java/io/camunda/zeebe/gateway/api/util/StubbedBrokerClient.java b/gateway/src/test/java/io/camunda/zeebe/gateway/api/util/StubbedBrokerClient.java
index 2d2d084..38261ad 100644
--- a/gateway/src/test/java/io/camunda/zeebe/gateway/api/util/StubbedBrokerClient.java
+++ b/gateway/src/test/java/io/camunda/zeebe/gateway/api/util/StubbedBrokerClient.java
@@ -25,6 +25,7 @@ import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.CompletableFuture;
+import java.util.concurrent.TimeUnit;
 import java.util.function.Consumer;
 
 public final class StubbedBrokerClient implements BrokerClient {
@@ -67,7 +68,15 @@ public final class StubbedBrokerClient implements BrokerClient {
   @Override
   public <T> CompletableFuture<BrokerResponse<T>> sendRequestWithRetry(
       final BrokerRequest<T> request, final Duration requestTimeout) {
-    throw new UnsupportedOperationException(""not implemented"");
+    final CompletableFuture<BrokerResponse<T>> result = new CompletableFuture<>();
+
+    sendRequestWithRetry(
+        request,
+        (key, response) ->
+            result.complete(new BrokerResponse<>(response, Protocol.decodePartitionId(key), key)),
+        result::completeExceptionally);
+
+    return result.orTimeout(requestTimeout.toNanos(), TimeUnit.NANOSECONDS);
   }
 
   @Override
diff --git a/gateway/src/test/java/io/camunda/zeebe/gateway/query/QueryApiTest.java b/gateway/src/test/java/io/camunda/zeebe/gateway/query/QueryApiTest.java
new file mode 100644
index 0000000..ec9ec80
--- /dev/null
+++ b/gateway/src/test/java/io/camunda/zeebe/gateway/query/QueryApiTest.java
@@ -0,0 +1,91 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.gateway.query;
+
+import static org.assertj.core.api.Assertions.assertThat;
+
+import io.camunda.zeebe.gateway.api.util.GatewayTest;
+import io.camunda.zeebe.gateway.cmd.BrokerErrorException;
+import io.camunda.zeebe.gateway.impl.broker.response.BrokerError;
+import io.camunda.zeebe.gateway.impl.broker.response.BrokerErrorResponse;
+import io.camunda.zeebe.gateway.impl.broker.response.BrokerResponse;
+import io.camunda.zeebe.gateway.query.impl.QueryApiImpl;
+import io.camunda.zeebe.protocol.Protocol;
+import io.camunda.zeebe.protocol.record.ErrorCode;
+import java.time.Duration;
+import java.util.concurrent.CompletionStage;
+import java.util.concurrent.ExecutionException;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.junit.runners.Parameterized;
+import org.junit.runners.Parameterized.Parameter;
+import org.junit.runners.Parameterized.Parameters;
+
+@RunWith(Parameterized.class)
+public final class QueryApiTest extends GatewayTest {
+  @Parameter(0)
+  public String name;
+
+  @Parameter(1)
+  public Querier querier;
+
+  @Parameters(name = ""{index}: {0}"")
+  public static Object[][] queries() {
+    return new Object[][] {
+      new Object[] {""getBpmnProcessIdForProcess"", (Querier) QueryApi::getBpmnProcessIdFromProcess},
+      new Object[] {
+        ""getBpmnProcessIdForProcessInstance"",
+        (Querier) QueryApi::getBpmnProcessIdFromProcessInstance
+      },
+      new Object[] {""getBpmnProcessIdForProcessJob"", (Querier) QueryApi::getBpmnProcessIdFromJob},
+    };
+  }
+
+  @Test
+  public void shouldGetBpmnProcessId() {
+    // given
+    final var key = Protocol.encodePartitionId(1, 1);
+    final var api = new QueryApiImpl(brokerClient);
+    final var timeout = Duration.ofSeconds(5);
+    final var stub = new QueryStub(new BrokerResponse<>(""myProcess"", 1, 1));
+    stub.registerWith(brokerClient);
+
+    // when
+    final var result = querier.query(api, key, timeout);
+
+    // then
+    assertThat(result).succeedsWithin(timeout).isEqualTo(""myProcess"");
+  }
+
+  @Test
+  public void shouldCompleteExceptionallyOnError() {
+    // given
+    final var key = Protocol.encodePartitionId(1, 1);
+    final var api = new QueryApiImpl(brokerClient);
+    final var timeout = Duration.ofSeconds(5);
+    final var stub =
+        new QueryStub(
+            new BrokerErrorResponse<>(
+                new BrokerError(ErrorCode.PARTITION_LEADER_MISMATCH, ""Leader mismatch"")));
+    stub.registerWith(brokerClient);
+
+    // when
+    final var result = querier.query(api, key, timeout);
+
+    // then
+    assertThat(result)
+        .failsWithin(timeout)
+        .withThrowableOfType(ExecutionException.class)
+        .havingRootCause()
+        .isInstanceOf(BrokerErrorException.class);
+  }
+
+  private interface Querier {
+    CompletionStage<String> query(final QueryApi api, final long key, final Duration timeout);
+  }
+}
diff --git a/gateway/src/test/java/io/camunda/zeebe/gateway/query/QueryStub.java b/gateway/src/test/java/io/camunda/zeebe/gateway/query/QueryStub.java
new file mode 100644
index 0000000..2f8334e
--- /dev/null
+++ b/gateway/src/test/java/io/camunda/zeebe/gateway/query/QueryStub.java
@@ -0,0 +1,31 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.gateway.query;
+
+import io.camunda.zeebe.gateway.api.util.StubbedBrokerClient;
+import io.camunda.zeebe.gateway.api.util.StubbedBrokerClient.RequestStub;
+import io.camunda.zeebe.gateway.impl.broker.response.BrokerResponse;
+import io.camunda.zeebe.gateway.query.impl.BrokerExecuteQuery;
+
+final class QueryStub implements RequestStub<BrokerExecuteQuery, BrokerResponse<String>> {
+  private final BrokerResponse<String> response;
+
+  public QueryStub(final BrokerResponse<String> response) {
+    this.response = response;
+  }
+
+  @Override
+  public void registerWith(final StubbedBrokerClient gateway) {
+    gateway.registerHandler(BrokerExecuteQuery.class, this);
+  }
+
+  @Override
+  public BrokerResponse<String> handle(final BrokerExecuteQuery request) throws Exception {
+    return response;
+  }
+}

diff --git a/ionic/components/nav/nav-controller.ts b/ionic/components/nav/nav-controller.ts
index 8e23c4c..37ac0f4 100644
--- a/ionic/components/nav/nav-controller.ts
+++ b/ionic/components/nav/nav-controller.ts
@@ -527,41 +527,13 @@ export class NavController extends Ion {
    * @private
    * TODO
    */
-  createViewComponentRef(type, hostProtoViewRef, viewContainer, viewCtrlBindings) {
-    let bindings = this.bindings.concat(viewCtrlBindings);
-
-    // the same guts as DynamicComponentLoader.loadNextToLocation
-    var hostViewRef =
-        viewContainer.createHostView(hostProtoViewRef, viewContainer.length, bindings);
-    var newLocation = this._viewManager.getHostElement(hostViewRef);
-    var component = this._viewManager.getComponent(newLocation);
-
-    var dispose = () => {
-      var index = viewContainer.indexOf(hostViewRef);
-      if (index !== -1) {
-        viewContainer.remove(index);
-      }
-    };
-
-    // TODO: make-shift ComponentRef_, this is pretty much going to
-    // break in future versions of ng2, keep an eye on it
-    return {
-      location: newLocation,
-      instance: component,
-      dispose: dispose
-    };
-  }
-
-  /**
-   * @private
-   * TODO
-   */
-  getBindings(viewCtrl) {
-    // create bindings to this ViewController and its NavParams
-    return this.bindings.concat(Injector.resolve([
+  loadNextToAnchor(type, location, viewCtrl) {
+    let bindings = this.bindings.concat(Injector.resolve([
       bind(ViewController).toValue(viewCtrl),
       bind(NavParams).toValue(viewCtrl.params),
     ]));
+
+    return this._loader.loadNextToLocation(type, location, bindings);
   }
 
   /**
diff --git a/ionic/components/nav/nav.ts b/ionic/components/nav/nav.ts
index a98a4ef..063eeb9 100644
--- a/ionic/components/nav/nav.ts
+++ b/ionic/components/nav/nav.ts
@@ -192,65 +192,70 @@ export class Nav extends NavController {
     if (structure.tabs) {
       // the component being loaded is an <ion-tabs>
       // Tabs is essentially a pane, cuz it has its own navbar and content containers
-      let contentContainerRef = this._viewManager.getViewContainer(this.anchorElementRef());
-      let viewComponentRef = this.createViewComponentRef(componentType, hostProtoViewRef, contentContainerRef, this.getBindings(viewCtrl));
-      viewComponentRef.instance._paneView = true;
+      this.loadNextToAnchor(componentType, this.anchorElementRef(), viewCtrl).then(componentRef => {
 
-      viewCtrl.disposals.push(() => {
-        viewComponentRef.dispose();
-      });
+        componentRef.instance._paneView = true;
+
+        viewCtrl.disposals.push(() => {
+          componentRef.dispose();
+        });
+
+        viewCtrl.onReady().then(() => {
+          done();
+        });
 
-      viewCtrl.onReady().then(() => {
-        done();
       });
 
     } else {
       // normal ion-view going into pane
       this.getPane(structure, viewCtrl, (pane) => {
         // add the content of the view into the pane's content area
-        let viewComponentRef = this.createViewComponentRef(componentType, hostProtoViewRef, pane.contentContainerRef, this.getBindings(viewCtrl));
-        viewCtrl.disposals.push(() => {
-          viewComponentRef.dispose();
+        this.loadNextToAnchor(componentType, pane.contentAnchorRef, viewCtrl).then(componentRef => {
 
-          // remove the pane if there are no view items left
-          pane.totalViews--;
-          if (pane.totalViews === 0) {
-            pane.dispose && pane.dispose();
-          }
-        });
+          viewCtrl.disposals.push(() => {
+            componentRef.dispose();
 
-        // count how many ViewControllers are in this pane
-        pane.totalViews++;
+            // remove the pane if there are no view items left
+            pane.totalViews--;
+            if (pane.totalViews === 0) {
+              pane.dispose && pane.dispose();
+            }
+          });
 
-        // a new ComponentRef has been created
-        // set the ComponentRef's instance to this ViewController
-        viewCtrl.setInstance(viewComponentRef.instance);
+          // count how many ViewControllers are in this pane
+          pane.totalViews++;
 
-        // remember the ElementRef to the content that was just created
-        viewCtrl.viewElementRef(viewComponentRef.location);
+          // a new ComponentRef has been created
+          // set the ComponentRef's instance to this ViewController
+          viewCtrl.setInstance(componentRef.instance);
 
-        // get the NavController's container for navbars, which is
-        // the place this NavController will add each ViewController's navbar
-        let navbarContainerRef = pane.navbarContainerRef;
+          // remember the ElementRef to the content that was just created
+          viewCtrl.viewElementRef(componentRef.location);
 
-        // get this ViewController's navbar TemplateRef, which may not
-        // exist if the ViewController's template didn't have an <ion-navbar *navbar>
-        let navbarTemplateRef = viewCtrl.getNavbarTemplateRef();
+          // get the NavController's container for navbars, which is
+          // the place this NavController will add each ViewController's navbar
+          let navbarContainerRef = pane.navbarContainerRef;
 
-        // create the navbar view if the pane has a navbar container, and the
-        // ViewController's instance has a navbar TemplateRef to go to inside of it
-        if (navbarContainerRef && navbarTemplateRef) {
-          let navbarView = navbarContainerRef.createEmbeddedView(navbarTemplateRef, -1);
+          // get this ViewController's navbar TemplateRef, which may not
+          // exist if the ViewController's template didn't have an <ion-navbar *navbar>
+          let navbarTemplateRef = viewCtrl.getNavbarTemplateRef();
 
-          viewCtrl.disposals.push(() => {
-            let index = navbarContainerRef.indexOf(navbarView);
-            if (index > -1) {
-              navbarContainerRef.remove(index);
-            }
-          });
-        }
+          // create the navbar view if the pane has a navbar container, and the
+          // ViewController's instance has a navbar TemplateRef to go to inside of it
+          if (navbarContainerRef && navbarTemplateRef) {
+            let navbarView = navbarContainerRef.createEmbeddedView(navbarTemplateRef, -1);
+
+            viewCtrl.disposals.push(() => {
+              let index = navbarContainerRef.indexOf(navbarView);
+              if (index > -1) {
+                navbarContainerRef.remove(index);
+              }
+            });
+          }
+
+          done();
+        });
 
-        done();
       });
     }
   }
@@ -273,7 +278,7 @@ export class Nav extends NavController {
 
     } else {
       // create a new nav pane
-      this._loader.loadNextToLocation(Pane, this.anchorElementRef(), this.getBindings(viewCtrl)).then(componentRef => {
+      this._loader.loadNextToLocation(Pane, this.anchorElementRef(), this.bindings).then(componentRef => {
 
         // get the pane reference
         pane = this.newPane;
@@ -354,17 +359,6 @@ export class Nav extends NavController {
 
 /**
  * @private
- * TODO
- * @param  {TODO} elementBinder TODO
- * @param  {TODO} id            TODO
- * @return {TODO}               TODO
- */
-function isComponent(elementBinder, id) {
-  return (elementBinder && elementBinder.componentDirective && elementBinder.componentDirective.metadata.id == id);
-}
-
-/**
- * @private
  */
 @Directive({selector: 'template[pane-anchor]'})
 class NavPaneAnchor {
@@ -393,9 +387,9 @@ class NavBarAnchor {
 class ContentAnchor {
   constructor(
     @Host() @Inject(forwardRef(() => Pane)) pane: Pane,
-    viewContainerRef: ViewContainerRef
+    elementRef: ElementRef
   ) {
-    pane.contentContainerRef = viewContainerRef;
+    pane.contentAnchorRef = elementRef;
   }
 }
 
diff --git a/ionic/components/tabs/tab.ts b/ionic/components/tabs/tab.ts
index aa21cad..af5d190 100644
--- a/ionic/components/tabs/tab.ts
+++ b/ionic/components/tabs/tab.ts
@@ -153,40 +153,44 @@ export class Tab extends NavController {
 
   loadContainer(componentType, hostProtoViewRef, viewCtrl, done) {
 
-    let viewComponentRef = this.createViewComponentRef(componentType, hostProtoViewRef, this.contentContainerRef, this.getBindings(viewCtrl));
-    viewCtrl.disposals.push(() => {
-      viewComponentRef.dispose();
-    });
+    this.loadNextToAnchor(componentType, this.contentAnchorRef, viewCtrl).then(componentRef => {
 
-    // a new ComponentRef has been created
-    // set the ComponentRef's instance to this ViewController
-    viewCtrl.setInstance(viewComponentRef.instance);
+      viewCtrl.disposals.push(() => {
+        componentRef.dispose();
+      });
 
-    // remember the ElementRef to the content that was just created
-    viewCtrl.viewElementRef(viewComponentRef.location);
+      // a new ComponentRef has been created
+      // set the ComponentRef's instance to this ViewController
+      viewCtrl.setInstance(componentRef.instance);
 
-    // get the NavController's container for navbars, which is
-    // the place this NavController will add each ViewController's navbar
-    let navbarContainerRef = this.tabs.navbarContainerRef;
+      // remember the ElementRef to the content that was just created
+      viewCtrl.viewElementRef(componentRef.location);
 
-    // get this ViewController's navbar TemplateRef, which may not
-    // exist if the ViewController's template didn't have an <ion-navbar *navbar>
-    let navbarTemplateRef = viewCtrl.getNavbarTemplateRef();
+      // get the NavController's container for navbars, which is
+      // the place this NavController will add each ViewController's navbar
+      let navbarContainerRef = this.tabs.navbarContainerRef;
 
-    // create the navbar view if the pane has a navbar container, and the
-    // ViewController's instance has a navbar TemplateRef to go to inside of it
-    if (navbarContainerRef && navbarTemplateRef) {
-      let navbarView = navbarContainerRef.createEmbeddedView(navbarTemplateRef, -1);
+      // get this ViewController's navbar TemplateRef, which may not
+      // exist if the ViewController's template didn't have an <ion-navbar *navbar>
+      let navbarTemplateRef = viewCtrl.getNavbarTemplateRef();
 
-      viewCtrl.disposals.push(() => {
-        let index = navbarContainerRef.indexOf(navbarView);
-        if (index > -1) {
-          navbarContainerRef.remove(index);
-        }
-      });
-    }
+      // create the navbar view if the pane has a navbar container, and the
+      // ViewController's instance has a navbar TemplateRef to go to inside of it
+      if (navbarContainerRef && navbarTemplateRef) {
+        let navbarView = navbarContainerRef.createEmbeddedView(navbarTemplateRef, -1);
+
+        viewCtrl.disposals.push(() => {
+          let index = navbarContainerRef.indexOf(navbarView);
+          if (index > -1) {
+            navbarContainerRef.remove(index);
+          }
+        });
+      }
+
+      done();
+
+    });
 
-    done();
   }
 
 }
@@ -194,10 +198,7 @@ export class Tab extends NavController {
 
 @Directive({selector: 'template[content-anchor]'})
 class TabContentAnchor {
-  constructor(
-    @Host() tab: Tab,
-    viewContainerRef: ViewContainerRef
-  ) {
-    tab.contentContainerRef = viewContainerRef;
+  constructor(@Host() tab: Tab, elementRef: ElementRef) {
+    tab.contentAnchorRef = elementRef;
   }
 }
",2,"[""bed86aeae8dad2dd6371635cd24bf8ef3db80361"", ""085ee958c48d695ba50822d8767d615fd9e887fa""]","[""test"", ""refactor""]"
avoid cancelling jobs | repository creation | [gn] fix include_dirs ordering error,"diff --git a/.github/workflows/ibis-backends-cloud.yml b/.github/workflows/ibis-backends-cloud.yml
index 321708e..b990984 100644
--- a/.github/workflows/ibis-backends-cloud.yml
+++ b/.github/workflows/ibis-backends-cloud.yml
@@ -29,7 +29,9 @@ jobs:
     name: ${{ matrix.backend.title }} python-${{ matrix.python-version }}
     # only a single bigquery or snowflake run at a time, otherwise test data is
     # clobbered by concurrent runs
-    concurrency: ${{ matrix.backend.name }}
+    concurrency:
+      group: ${{ matrix.backend.name }}
+      cancel-in-progress: false
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false

diff --git a/server/src/services/repository.service.ts b/server/src/services/repository.service.ts
index 3869c98..d675b30 100644
--- a/server/src/services/repository.service.ts
+++ b/server/src/services/repository.service.ts
@@ -19,6 +19,8 @@ export class RepositoryService {
       return;
     }
 
+    await this.createTeam(this.github, this.getTeamName(course), course.id);
+
     const studentRepo = getCustomRepository(StudentRepository);
     const students = await studentRepo.findActiveByCourseId(this.courseId);
 
@@ -31,8 +33,8 @@ export class RepositoryService {
         if (mentorGithubId) {
           await this.inviteMentor(mentorGithubId, course);
         }
-        await this.addTeamToRepository(this.github, course, student.githubId);
       }
+      await this.addTeamToRepository(this.github, course, student.githubId);
       if (record?.repository) {
         result.push({ repository: record.repository });
       }

diff --git a/BUILD.gn b/BUILD.gn
index 11adaa7..ed64b17 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -240,6 +240,14 @@ static_library(""electron_lib"") {
     ""brightray"",
     ""build/node"",
   ]
+  include_dirs = [
+    ""chromium_src"",
+    ""."",
+    ""$target_gen_dir"",
+    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
+    # API of blink, then delete this include dir.
+    ""//third_party/WebKit/Source"",
+  ]
   if (enable_desktop_capturer) {
     deps += [ ""//third_party/webrtc/modules/desktop_capture"" ]
   }
@@ -275,14 +283,6 @@ static_library(""electron_lib"") {
     # Disable warnings for g_settings_list_schemas.
     ""GLIB_DISABLE_DEPRECATION_WARNINGS"",
   ]
-  include_dirs = [
-    ""chromium_src"",
-    ""."",
-    ""$target_gen_dir"",
-    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
-    # API of blink, then delete this include dir.
-    ""//third_party/WebKit/Source"",
-  ]
   if (is_component_build) {
     defines += [
       # Import V8 symbols from shared library (node.dll / libnode.so)
",3,"[""19514bc68624a964c63fc217f163f7b11f3dfe82"", ""87d5d4e55ab7149b593d29410f1fe426ba2447d4"", ""c44cf88a6ec54e5ddd99d8348bcc57b301ec7945""]","[""cicd"", ""fix"", ""build""]"
increment failing test retries | pass absolute burnchain block height to pox sync watchdog so we correctly infer ibd status,"diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 

diff --git a/testnet/stacks-node/src/run_loop/neon.rs b/testnet/stacks-node/src/run_loop/neon.rs
index 677749b..dc4a7bd 100644
--- a/testnet/stacks-node/src/run_loop/neon.rs
+++ b/testnet/stacks-node/src/run_loop/neon.rs
@@ -411,7 +411,6 @@ impl RunLoop {
 
         let mut burnchain_height = sortition_db_height;
         let mut num_sortitions_in_last_cycle = 1;
-        let mut learned_burnchain_height = false;
 
         // prepare to fetch the first reward cycle!
         target_burnchain_block_height = burnchain_height + pox_constants.reward_cycle_length as u64;
@@ -439,18 +438,16 @@ impl RunLoop {
                 break;
             }
 
+            let remote_chain_height = burnchain.get_headers_height();
+
             // wait for the p2p state-machine to do at least one pass
-            debug!(""Wait until we reach steady-state before processing more burnchain blocks..."");
+            debug!(""Wait until we reach steady-state before processing more burnchain blocks (chain height is {}, we are at {})..."", remote_chain_height, burnchain_height);
 
             // wait until it's okay to process the next sortitions
             let ibd = match pox_watchdog.pox_sync_wait(
                 &burnchain_config,
                 &burnchain_tip,
-                if learned_burnchain_height {
-                    Some(burnchain_height)
-                } else {
-                    None
-                },
+                Some(remote_chain_height),
                 num_sortitions_in_last_cycle,
             ) {
                 Ok(ibd) => ibd,
@@ -478,7 +475,6 @@ impl RunLoop {
                     };
 
                 // *now* we know the burnchain height
-                learned_burnchain_height = true;
                 burnchain_tip = next_burnchain_tip;
                 burnchain_height = cmp::min(burnchain_height + 1, target_burnchain_block_height);
 
",2,"[""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57"", ""5b70e008c57efc89da4061f9adb7d0491b2ea644""]","[""cicd"", ""fix""]"
"deploy dmn using java client

This test is an acceptance test that verifies that the java client can
deploy a dmn decision model using the newDeployCommand client method.

It verifies that the model was resource was parsed and deployed,
resulting in a response that contains metadata of the deployed decision
requirements graph and the decisions it contains. | Add the select function for logicflow | refactor to get ride of cloneDeep","diff --git a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/client/command/CreateDeploymentTest.java b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/client/command/CreateDeploymentTest.java
index f36465b..6b6ab48 100644
--- a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/client/command/CreateDeploymentTest.java
+++ b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/client/command/CreateDeploymentTest.java
@@ -67,6 +67,49 @@ public final class CreateDeploymentTest {
   }
 
   @Test
+  public void shouldDeployDecisionModel() {
+    // given
+    final String resourceName = ""dmn/drg-force-user.dmn"";
+
+    // when
+    final DeploymentEvent result =
+        CLIENT_RULE
+            .getClient()
+            .newDeployCommand()
+            .addResourceFromClasspath(resourceName)
+            .send()
+            .join();
+
+    // then
+    assertThat(result.getKey()).isPositive();
+    assertThat(result.getDecisionRequirements()).hasSize(1);
+    assertThat(result.getDecisions()).hasSize(2);
+
+    final var decisionRequirements = result.getDecisionRequirements().get(0);
+    assertThat(decisionRequirements.getDmnDecisionRequirementsId()).isEqualTo(""force_users"");
+    assertThat(decisionRequirements.getDmnDecisionRequirementsName()).isEqualTo(""Force Users"");
+    assertThat(decisionRequirements.getVersion()).isEqualTo(1);
+    assertThat(decisionRequirements.getDecisionRequirementsKey()).isPositive();
+    assertThat(decisionRequirements.getResourceName()).isEqualTo(resourceName);
+
+    final var decision1 = result.getDecisions().get(0);
+    assertThat(decision1.getDmnDecisionId()).isEqualTo(""jedi_or_sith"");
+    assertThat(decision1.getDmnDecisionName()).isEqualTo(""Jedi or Sith"");
+    assertThat(decision1.getVersion()).isEqualTo(1);
+    assertThat(decision1.getDecisionKey()).isPositive();
+    assertThat(decision1.getDmnDecisionRequirementsId()).isEqualTo(""force_users"");
+    assertThat(decision1.getDecisionRequirementsKey()).isPositive();
+
+    final var decision2 = result.getDecisions().get(1);
+    assertThat(decision2.getDmnDecisionId()).isEqualTo(""force_user"");
+    assertThat(decision2.getDmnDecisionName()).isEqualTo(""Which force user?"");
+    assertThat(decision2.getVersion()).isEqualTo(1);
+    assertThat(decision2.getDecisionKey()).isPositive();
+    assertThat(decision2.getDmnDecisionRequirementsId()).isEqualTo(""force_users"");
+    assertThat(decision2.getDecisionRequirementsKey()).isPositive();
+  }
+
+  @Test
   public void shouldRejectDeployIfProcessIsInvalid() {
     // given
     final BpmnModelInstance process =
diff --git a/qa/integration-tests/src/test/resources/dmn/drg-force-user.dmn b/qa/integration-tests/src/test/resources/dmn/drg-force-user.dmn
new file mode 100644
index 0000000..8d55c55
--- /dev/null
+++ b/qa/integration-tests/src/test/resources/dmn/drg-force-user.dmn
@@ -0,0 +1,144 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<definitions xmlns=""https://www.omg.org/spec/DMN/20191111/MODEL/"" xmlns:dmndi=""https://www.omg.org/spec/DMN/20191111/DMNDI/"" xmlns:dc=""http://www.omg.org/spec/DMN/20180521/DC/"" xmlns:biodi=""http://bpmn.io/schema/dmn/biodi/2.0"" xmlns:di=""http://www.omg.org/spec/DMN/20180521/DI/"" id=""force_users"" name=""Force Users""  namespace=""http://camunda.org/schema/1.0/dmn"" exporter=""Camunda Modeler"" exporterVersion=""4.12.0"">
+  <decision id=""jedi_or_sith"" name=""Jedi or Sith"">
+    <decisionTable id=""DecisionTable_14n3bxx"">
+      <input id=""Input_1"" label=""Lightsaber color"" biodi:width=""192"">
+        <inputExpression id=""InputExpression_1"" typeRef=""string"">
+          <text>lightsaberColor</text>
+        </inputExpression>
+      </input>
+      <output id=""Output_1"" label=""Jedi or Sith"" name=""jedi_or_sith"" typeRef=""string"" biodi:width=""192"">
+        <outputValues id=""UnaryTests_0hj346a"">
+          <text>""Jedi"",""Sith""</text>
+        </outputValues>
+      </output>
+      <rule id=""DecisionRule_0zumznl"">
+        <inputEntry id=""UnaryTests_0leuxqi"">
+          <text>""blue""</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_0c9vpz8"">
+          <text>""Jedi""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_1utwb1e"">
+        <inputEntry id=""UnaryTests_1v3sd4m"">
+          <text>""green""</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_0tgh8k1"">
+          <text>""Jedi""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_1bwgcym"">
+        <inputEntry id=""UnaryTests_0n1ewm3"">
+          <text>""red""</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_19xnlkw"">
+          <text>""Sith""</text>
+        </outputEntry>
+      </rule>
+    </decisionTable>
+  </decision>
+  <decision id=""force_user"" name=""Which force user?"">
+    <informationRequirement id=""InformationRequirement_1o8esai"">
+      <requiredDecision href=""#jedi_or_sith"" />
+    </informationRequirement>
+    <decisionTable id=""DecisionTable_07g94t1"" hitPolicy=""FIRST"">
+      <input id=""InputClause_0qnqj25"" label=""Jedi or Sith"">
+        <inputExpression id=""LiteralExpression_00lcyt5"" typeRef=""string"">
+          <text>jedi_or_sith</text>
+        </inputExpression>
+        <inputValues id=""UnaryTests_1xjidd8"">
+          <text>""Jedi"",""Sith""</text>
+        </inputValues>
+      </input>
+      <input id=""InputClause_0k64hys"" label=""Body height"">
+        <inputExpression id=""LiteralExpression_0ib6fnk"" typeRef=""number"">
+          <text>height</text>
+        </inputExpression>
+      </input>
+      <output id=""OutputClause_0hhe1yo"" label=""Force user"" name=""force_user"" typeRef=""string"" />
+      <rule id=""DecisionRule_13zidc5"">
+        <inputEntry id=""UnaryTests_056skcq"">
+          <text>""Jedi""</text>
+        </inputEntry>
+        <inputEntry id=""UnaryTests_0l4xksq"">
+          <text>&gt; 190</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_0hclhw3"">
+          <text>""Mace Windu""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_0uin2hk"">
+        <description></description>
+        <inputEntry id=""UnaryTests_16maepk"">
+          <text>""Jedi""</text>
+        </inputEntry>
+        <inputEntry id=""UnaryTests_0rv0nwf"">
+          <text>&gt; 180</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_0t82c11"">
+          <text>""Obi-Wan Kenobi""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_0mpio0p"">
+        <inputEntry id=""UnaryTests_09eicyc"">
+          <text>""Jedi""</text>
+        </inputEntry>
+        <inputEntry id=""UnaryTests_1bekl8k"">
+          <text>&lt; 70</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_0brx3vt"">
+          <text>""Yoda""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_06paffx"">
+        <inputEntry id=""UnaryTests_1baiid4"">
+          <text>""Sith""</text>
+        </inputEntry>
+        <inputEntry id=""UnaryTests_0fcdq0i"">
+          <text>&gt; 200</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_02oibi4"">
+          <text>""Darth Vader""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_1ua4pcl"">
+        <inputEntry id=""UnaryTests_1s1h3nm"">
+          <text>""Sith""</text>
+        </inputEntry>
+        <inputEntry id=""UnaryTests_1pnvw8p"">
+          <text>&gt; 170</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_1w1n2rc"">
+          <text>""Darth Sidius""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_00ew25e"">
+        <inputEntry id=""UnaryTests_07uxyug"">
+          <text></text>
+        </inputEntry>
+        <inputEntry id=""UnaryTests_1he6fym"">
+          <text></text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_07i3sc8"">
+          <text>""unknown""</text>
+        </outputEntry>
+      </rule>
+    </decisionTable>
+  </decision>
+  <dmndi:DMNDI>
+    <dmndi:DMNDiagram>
+      <dmndi:DMNShape dmnElementRef=""jedi_or_sith"">
+        <dc:Bounds height=""80"" width=""180"" x=""160"" y=""280"" />
+      </dmndi:DMNShape>
+      <dmndi:DMNShape id=""DMNShape_1sb3tre"" dmnElementRef=""force_user"">
+        <dc:Bounds height=""80"" width=""180"" x=""280"" y=""80"" />
+      </dmndi:DMNShape>
+      <dmndi:DMNEdge id=""DMNEdge_0gt1p1u"" dmnElementRef=""InformationRequirement_1o8esai"">
+        <di:waypoint x=""250"" y=""280"" />
+        <di:waypoint x=""370"" y=""180"" />
+        <di:waypoint x=""370"" y=""160"" />
+      </dmndi:DMNEdge>
+    </dmndi:DMNDiagram>
+  </dmndi:DMNDI>
+</definitions>

diff --git a/packages/core/src/LogicFlow.tsx b/packages/core/src/LogicFlow.tsx
index 0d913b7..dcc59b3 100644
--- a/packages/core/src/LogicFlow.tsx
+++ b/packages/core/src/LogicFlow.tsx
@@ -276,6 +276,12 @@ export default class LogicFlow {
     this.translate(-TRANSLATE_X, -TRANSLATE_Y);
   }
   /**
+   * 
+   */
+  select(id: string) {
+    this.graphModel.selectElementById(id);
+  }
+  /**
    * 
    * @param focusOnArgs idtypeid
    */
diff --git a/packages/core/src/model/GraphModel.ts b/packages/core/src/model/GraphModel.ts
index 94d0899..10280a9 100644
--- a/packages/core/src/model/GraphModel.ts
+++ b/packages/core/src/model/GraphModel.ts
@@ -481,6 +481,13 @@ class GraphModel {
     this.selectElement?.setSelected(true);
   }
 
+  @action
+  selectElementById(id: string) {
+    this.selectElement?.setSelected(false);
+    this.selectElement = this.getElement(id) as BaseNodeModel | BaseEdgeModel;
+    this.selectElement?.setSelected(true);
+  }
+
   /*  */
   @action
   changeEdgeType(type: string): void {

diff --git a/config/webpack.config.prod.js b/config/webpack.config.prod.js
index 3d2e5a6..e5219bd 100644
--- a/config/webpack.config.prod.js
+++ b/config/webpack.config.prod.js
@@ -56,7 +56,7 @@ const extractTextPluginOptions = shouldUseRelativeAssetPaths
 const entries = fs.readdirSync(paths.appSrc)
   .filter(name => !name.startsWith('_'))
   .map(name => ({name, dirPath: path.join(paths.appSrc, name)}))
-  .filter(({name, dirPath}) => !/^assets|components|manifest|typings$/.test(name) && fs.lstatSync(dirPath).isDirectory())
+  .filter(({name, dirPath}) => !/^assets|components|manifest|typings|app-config$/.test(name) && fs.lstatSync(dirPath).isDirectory())
 
 // This is the production configuration.
 // It compiles slowly and is focused on producing a fast and minimal bundle.
diff --git a/src/app-config/context-menus.ts b/src/app-config/context-menus.ts
new file mode 100644
index 0000000..a733b01
--- /dev/null
+++ b/src/app-config/context-menus.ts
@@ -0,0 +1,27 @@
+export function getAllContextMenus () {
+  const allContextMenus = {
+    google_page_translate: 'x',
+    youdao_page_translate: 'x',
+    google_search: 'https://www.google.com/#newwindow=1&q=%s',
+    baidu_search: 'https://www.baidu.com/s?ie=utf-8&wd=%s',
+    bing_search: 'https://www.bing.com/search?q=%s',
+    google_translate: 'https://translate.google.cn/#auto/zh-CN/%s',
+    etymonline: 'http://www.etymonline.com/index.php?search=%s',
+    merriam_webster: 'http://www.merriam-webster.com/dictionary/%s',
+    oxford: 'http://www.oxforddictionaries.com/us/definition/english/%s',
+    cambridge: 'http://dictionary.cambridge.org/spellcheck/english-chinese-simplified/?q=%s',
+    youdao: 'http://dict.youdao.com/w/%s',
+    dictcn: 'https://dict.eudic.net/dicts/en/%s',
+    iciba: 'http://www.iciba.com/%s',
+    liangan: 'https://www.moedict.tw/~%s',
+    guoyu: 'https://www.moedict.tw/%s',
+    longman_business: 'http://www.ldoceonline.com/search/?q=%s',
+    bing_dict: 'https://cn.bing.com/dict/?q=%s'
+  }
+
+  // Just for type check. Keys in allContextMenus are useful so no actual assertion
+  // tslint:disable-next-line:no-unused-expression
+  allContextMenus as { [id: string]: string }
+
+  return allContextMenus
+}
diff --git a/src/app-config/dicts.ts b/src/app-config/dicts.ts
new file mode 100644
index 0000000..905d2de
--- /dev/null
+++ b/src/app-config/dicts.ts
@@ -0,0 +1,398 @@
+import { DeepReadonly } from '@/typings/helpers'
+
+export function getALlDicts () {
+  const allDicts = {
+    bing: {
+      /**
+       * Full content page to jump to when user clicks the title.
+       * %s will be replaced with the current word.
+       * %z will be replaced with the traditional Chinese version of the current word.
+       */
+      page: 'https://cn.bing.com/dict/search?q=%s',
+      /**
+       * If set to true, the dict start searching automatically.
+       * Otherwise it'll only start seaching when user clicks the unfold button.
+       * Default MUST be true and let user decide.
+       */
+      defaultUnfold: true,
+      /**
+       * This is the default height when the dict first renders the result.
+       * If the content height is greater than the preferred height,
+       * the preferred height is used and a mask with a view-more button is shown.
+       * Otherwise the content height is used.
+       */
+      preferredHeight: 240,
+      /**
+       * Only start searching if the selection contains the language.
+       * Better set default to true and let user decide.
+       */
+      selectionLang: {
+        eng: true,
+        chs: true
+      },
+      /** Optional dict custom options. Can only be boolean or number. */
+      options: {
+        tense: true,
+        phsym: true,
+        cdef: true,
+        related: true,
+        sentence: 4
+      }
+    },
+    business: {
+      /**
+       * Full content page to jump to when user clicks the title.
+       * %s will be replaced with the current word.
+       * %z will be replaced with the traditional Chinese version of the current word
+       */
+      page: 'http://www.ldoceonline.com/search/?q=%s',
+      /**
+       * If set to true, the dict start searching automatically.
+       * Otherwise it'll only start seaching when user clicks the unfold button.
+       * Default MUST be true and let user decide.
+       */
+      defaultUnfold: true,
+      /**
+       * This is the default height when the dict first renders the result.
+       * If the content height is greater than the preferred height,
+       * the preferred height is used and a mask with a view-more button is shown.
+       * Otherwise the content height is used.
+       */
+      preferredHeight: 265,
+      /**
+       * Only start searching if the selection contains the language.
+       * Better set default to true and let user decide.
+       */
+      selectionLang: {
+        eng: true,
+        chs: true
+      }
+    },
+    cobuild: {
+      /**
+       * Full content page to jump to when user clicks the title.
+       * %s will be replaced with the current word.
+       * %z will be replaced with the traditional Chinese version of the current word
+       */
+      page: 'https://www.collinsdictionary.com/dictionary/%s',
+      /**
+       * If set to true, the dict start searching automatically.
+       * Otherwise it'll only start seaching when user clicks the unfold button.
+       * Default MUST be true and let user decide.
+       */
+      defaultUnfold: true,
+      /**
+       * This is the default height when the dict first renders the result.
+       * If the content height is greater than the preferred height,
+       * the preferred height is used and a mask with a view-more button is shown.
+       * Otherwise the content height is used.
+       */
+      preferredHeight: 300,
+      /**
+       * Only start searching if the selection contains the language.
+       * Better set default to true and let user decide.
+       */
+      selectionLang: {
+        eng: true,
+        chs: true
+      },
+      /** Optional dict custom options. Can only be boolean or number. */
+      options: {
+        sentence: 4
+      }
+    },
+    dictcn: {
+      /**
+       * Full content page to jump to when user clicks the title.
+       * %s will be replaced with the current word.
+       * %z will be replaced with the traditional Chinese version of the current word
+       */
+      page: 'http://dict.cn/%s',
+      /**
+       * If set to true, the dict start searching automatically.
+       * Otherwise it'll only start seaching when user clicks the unfold button.
+       * Default MUST be true and let user decide.
+       */
+      defaultUnfold: true,
+      /**
+       * This is the default height when the dict first renders the result.
+       * If the content height is greater than the preferred height,
+       * the preferred height is used and a mask with a view-more button is shown.
+       * Otherwise the content height is used.
+       */
+      preferredHeight: 300,
+      /**
+       * Only start searching if the selection contains the language.
+       * Better set default to true and let user decide.
+       */
+      selectionLang: {
+        eng: true,
+        chs: true
+      },
+      /** Optional dict custom options. Can only be boolean or number. */
+      options: {
+        chart: true,
+        etym: true
+      }
+    },
+    etymonline: {
+      /**
+       * Full content page to jump to when user clicks the title.
+       * %s will be replaced with the current word.
+       * %z will be replaced with the traditional Chinese version of the current word
+       */
+      page: 'http://www.etymonline.com/search?q=%s',
+      /**
+       * If set to true, the dict start searching automatically.
+       * Otherwise it'll only start seaching when user clicks the unfold button.
+       * Default MUST be true and let user decide.
+       */
+      defaultUnfold: true,
+      /**
+       * This is the default height when the dict first renders the result.
+       * If the content height is greater than the preferred height,
+       * the preferred height is used and a mask with a view-more button is shown.
+       * Otherwise the content height is used.
+       */
+      preferredHeight: 265,
+      /**
+       * Only start searching if the selection contains the language.
+       * Better set default to true and let user decide.
+       */
+      selectionLang: {
+        eng: true,
+        chs: true
+      },
+      /** Optional dict custom options. Can only be boolean or number. */
+      options: {
+        resultnum: 2
+      }
+    },
+    google: {
+      /**
+       * Full content page to jump to when user clicks the title.
+       * %s will be replaced with the current word.
+       * %z will be replaced with the traditional Chinese version of the current word
+       */
+      page: 'https://translate.google.com/#auto/zh-CN/%s',
+      /**
+       * If set to true, the dict start searching automatically.
+       * Otherwise it'll only start seaching when user clicks the unfold button.
+       * Default MUST be true and let user decide.
+       */
+      defaultUnfold: true,
+      /**
+       * This is the default height when the dict first renders the result.
+       * If the content height is greater than the preferred height,
+       * the preferred height is used and a mask with a view-more button is shown.
+       * Otherwise the content height is used.
+       */
+      preferredHeight: 110,
+      /**
+       * Only start searching if the selection contains the language.
+       * Better set default to true and let user decide.
+       */
+      selectionLang: {
+        eng: true,
+        chs: true
+      }
+    },
+    guoyu: {
+      /**
+       * Full content page to jump to when user clicks the title.
+       * %s will be replaced with the current word.
+       * %z will be replaced with the traditional Chinese version of the current word
+       */
+      page: 'https://www.moedict.tw/%z',
+      /**
+       * If set to true, the dict start searching automatically.
+       * Otherwise it'll only start seaching when user clicks the unfold button.
+       * Default MUST be true and let user decide.
+       */
+      defaultUnfold: true,
+      /**
+       * This is the default height when the dict first renders the result.
+       * If the content height is greater than the preferred height,
+       * the preferred height is used and a mask with a view-more button is shown.
+       * Otherwise the content height is used.
+       */
+      preferredHeight: 265,
+      /**
+       * Only start searching if the selection contains the language.
+       * Better set default to true and let user decide.
+       */
+      selectionLang: {
+        eng: true,
+        chs: true
+      }
+    },
+    liangan: {
+      /**
+       * Full content page to jump to when user clicks the title.
+       * %s will be replaced with the current word.
+       * %z will be replaced with the traditional Chinese version of the current word
+       */
+      page: 'https://www.moedict.tw/~%z',
+      /**
+       * If set to true, the dict start searching automatically.
+       * Otherwise it'll only start seaching when user clicks the unfold button.
+       * Default MUST be true and let user decide.
+       */
+      defaultUnfold: true,
+      /**
+       * This is the default height when the dict first renders the result.
+       * If the content height is greater than the preferred height,
+       * the preferred height is used and a mask with a view-more button is shown.
+       * Otherwise the content height is used.
+       */
+      preferredHeight: 265,
+      /**
+       * Only start searching if the selection contains the language.
+       * Better set default to true and let user decide.
+       */
+      selectionLang: {
+        eng: true,
+        chs: true
+      }
+    },
+    macmillan: {
+      /**
+       * Full content page to jump to when user clicks the title.
+       * %s will be replaced with the current word.
+       * %z will be replaced with the traditional Chinese version of the current word
+       */
+      page: 'http://www.macmillandictionary.com/dictionary/british/%s',
+      /**
+       * If set to true, the dict start searching automatically.
+       * Otherwise it'll only start seaching when user clicks the unfold button.
+       * Default MUST be true and let user decide.
+       */
+      defaultUnfold: true,
+      /**
+       * This is the default height when the dict first renders the result.
+       * If the content height is greater than the preferred height,
+       * the preferred height is used and a mask with a view-more button is shown.
+       * Otherwise the content height is used.
+       */
+      preferredHeight: 265,
+      /**
+       * Only start searching if the selection contains the language.
+       * Better set default to true and let user decide.
+       */
+      selectionLang: {
+        eng: true,
+        chs: true
+      }
+    },
+    urban: {
+      /**
+       * Full content page to jump to when user clicks the title.
+       * %s will be replaced with the current word.
+       * %z will be replaced with the traditional Chinese version of the current word
+       */
+      page: 'http://www.urbandictionary.com/define.php?term=%s',
+      /**
+       * If set to true, the dict start searching automatically.
+       * Otherwise it'll only start seaching when user clicks the unfold button.
+       * Default MUST be true and let user decide.
+       */
+      defaultUnfold: true,
+      /**
+       * This is the default height when the dict first renders the result.
+       * If the content height is greater than the preferred height,
+       * the preferred height is used and a mask with a view-more button is shown.
+       * Otherwise the content height is used.
+       */
+      preferredHeight: 180,
+      /**
+       * Only start searching if the selection contains the language.
+       * Better set default to true and let user decide.
+       */
+      selectionLang: {
+        eng: true,
+        chs: true
+      },
+      /** Optional dict custom options. Can only be boolean or number. */
+      options: {
+        resultnum: 4
+      }
+    },
+    vocabulary: {
+      /**
+       * Full content page to jump to when user clicks the title.
+       * %s will be replaced with the current word.
+       * %z will be replaced with the traditional Chinese version of the current word
+       */
+      page: 'https://www.vocabulary.com/dictionary/%s',
+      /**
+       * If set to true, the dict start searching automatically.
+       * Otherwise it'll only start seaching when user clicks the unfold button.
+       * Default MUST be true and let user decide.
+       */
+      defaultUnfold: true,
+      /**
+       * This is the default height when the dict first renders the result.
+       * If the content height is greater than the preferred height,
+       * the preferred height is used and a mask with a view-more button is shown.
+       * Otherwise the content height is used.
+       */
+      preferredHeight: 180,
+      /**
+       * Only start searching if the selection contains the language.
+       * Better set default to true and let user decide.
+       */
+      selectionLang: {
+        eng: true,
+        chs: true
+      }
+    },
+    zdic: {
+      /**
+       * Full content page to jump to when user clicks the title.
+       * %s will be replaced with the current word.
+       * %z will be replaced with the traditional Chinese version of the current word
+       */
+      page: 'http://www.zdic.net/search/?c=1&q=%s',
+      /**
+       * If set to true, the dict start searching automatically.
+       * Otherwise it'll only start seaching when user clicks the unfold button.
+       * Default MUST be true and let user decide.
+       */
+      defaultUnfold: true,
+      /**
+       * This is the default height when the dict first renders the result.
+       * If the content height is greater than the preferred height,
+       * the preferred height is used and a mask with a view-more button is shown.
+       * Otherwise the content height is used.
+       */
+      preferredHeight: 400,
+      /**
+       * Only start searching if the selection contains the language.
+       * Better set default to true and let user decide.
+       */
+      selectionLang: {
+        eng: true,
+        chs: true
+      }
+    },
+  }
+
+  // Just for type check. Keys in allDicts are useful so no actual assertion
+  // tslint:disable-next-line:no-unused-expression
+  allDicts as {
+    [id: string]: {
+      page: string
+      defaultUnfold: boolean
+      preferredHeight: number
+      selectionLang: {
+        eng: boolean
+        chs: boolean
+      }
+      options?: {
+        [option: string]: number | boolean
+      }
+    }
+  }
+
+  return allDicts
+}
diff --git a/src/app-config/index.ts b/src/app-config/index.ts
index 350cd8f..879a312 100644
--- a/src/app-config/index.ts
+++ b/src/app-config/index.ts
@@ -1,5 +1,6 @@
-import cloneDeep from 'lodash/cloneDeep'
-import { DeepReadonly } from './typings/helpers'
+import { DeepReadonly } from '@/typings/helpers'
+import { getALlDicts } from './dicts'
+import { getAllContextMenus } from './context-menus'
 
 const langUI = (browser.i18n.getUILanguage() || 'en').replace('-', '_')
 const langCode = /^zh_CN|zh_TW|en$/.test(langUI)
@@ -8,220 +9,11 @@ const langCode = /^zh_CN|zh_TW|en$/.test(langUI)
     : langUI
   : 'en'
 
-const allDicts = {
-  bing: {
-    page: 'https://cn.bing.com/dict/search?q=%s',
-    defaultUnfold: true,
-    preferredHeight: 240,
-    selectionLang: {
-      eng: true,
-      chs: true
-    },
-    options: {
-      tense: true,
-      phsym: true,
-      cdef: true,
-      related: true,
-      sentence: 4
-    }
-  },
-  business: {
-    page: 'http://www.ldoceonline.com/search/?q=%s',
-    defaultUnfold: true,
-    preferredHeight: 265,
-    selectionLang: {
-      eng: true,
-      chs: true
-    }
-  },
-  cobuild: {
-    page: 'https://www.collinsdictionary.com/dictionary/%s',
-    defaultUnfold: true,
-    preferredHeight: 300,
-    selectionLang: {
-      eng: true,
-      chs: true
-    },
-    options: {
-      sentence: 4
-    }
-  },
-  dictcn: {
-    page: 'http://dict.cn/%s',
-    defaultUnfold: true,
-    preferredHeight: 300,
-    selectionLang: {
-      eng: true,
-      chs: true
-    },
-    options: {
-      chart: true,
-      etym: true
-    }
-  },
-  etymonline: {
-    page: 'http://www.etymonline.com/search?q=%s',
-    defaultUnfold: true,
-    preferredHeight: 265,
-    selectionLang: {
-      eng: true,
-      chs: true
-    },
-    options: {
-      resultnum: 2
-    }
-  },
-  eudic: {
-    page: 'https://dict.eudic.net/dicts/en/%s',
-    defaultUnfold: true,
-    preferredHeight: 265,
-    selectionLang: {
-      eng: true,
-      chs: true
-    }
-  },
-  google: {
-    page: 'https://translate.google.com/#auto/zh-CN/%s',
-    defaultUnfold: true,
-    preferredHeight: 110,
-    selectionLang: {
-      eng: true,
-      chs: true
-    }
-  },
-  guoyu: {
-    page: 'https://www.moedict.tw/%z',
-    defaultUnfold: true,
-    preferredHeight: 265,
-    selectionLang: {
-      eng: true,
-      chs: true
-    }
-  },
-  howjsay: {
-    page: 'http://www.howjsay.com/index.php?word=%s',
-    defaultUnfold: true,
-    preferredHeight: 265,
-    selectionLang: {
-      eng: true,
-      chs: true
-    },
-    options: {
-      related: true
-    }
-  },
-  liangan: {
-    page: 'https://www.moedict.tw/~%z',
-    defaultUnfold: true,
-    preferredHeight: 265,
-    selectionLang: {
-      eng: true,
-      chs: true
-    }
-  },
-  macmillan: {
-    page: 'http://www.macmillandictionary.com/dictionary/british/%s',
-    defaultUnfold: true,
-    preferredHeight: 265,
-    selectionLang: {
-      eng: true,
-      chs: true
-    }
-  },
-  urban: {
-    page: 'http://www.urbandictionary.com/define.php?term=%s',
-    defaultUnfold: true,
-    preferredHeight: 180,
-    selectionLang: {
-      eng: true,
-      chs: true
-    },
-    options: {
-      resultnum: 4
-    }
-  },
-  vocabulary: {
-    page: 'https://www.vocabulary.com/dictionary/%s',
-    defaultUnfold: true,
-    preferredHeight: 180,
-    selectionLang: {
-      eng: true,
-      chs: true
-    }
-  },
-  wordreference: {
-    page: 'http://www.wordreference.com/definition/%s',
-    defaultUnfold: true,
-    preferredHeight: 180,
-    selectionLang: {
-      eng: true,
-      chs: true
-    },
-    options: {
-      etym: true,
-      idiom: true
-    }
-  },
-  zdic: {
-    page: 'http://www.zdic.net/search/?c=1&q=%s',
-    defaultUnfold: true,
-    preferredHeight: 400,
-    selectionLang: {
-      eng: true,
-      chs: true
-    }
-  },
-}
-
-// Just for type check. Keys in allDicts are useful so no actual assertion
-// tslint:disable-next-line:no-unused-expression
-allDicts as {
-  [id: string]: {
-    /** url for the complete result */
-    page: string
-    /** lazy load */
-    defaultUnfold: boolean
-    /** content below the preferrred height will be hidden by default */
-    preferredHeight: number
-    /** only search when the selection contains the language */
-    selectionLang: {
-      eng: boolean
-      chs: boolean
-    }
-    /** other options */
-    options?: {
-      [option: string]: number | boolean
-    }
-  }
-}
-
-export type DictID = keyof typeof allDicts
-
-const allContextMenus = {
-  google_page_translate: 'x',
-  youdao_page_translate: 'x',
-  google_search: 'https://www.google.com/#newwindow=1&q=%s',
-  baidu_search: 'https://www.baidu.com/s?ie=utf-8&wd=%s',
-  bing_search: 'https://www.bing.com/search?q=%s',
-  google_translate: 'https://translate.google.cn/#auto/zh-CN/%s',
-  etymonline: 'http://www.etymonline.com/index.php?search=%s',
-  merriam_webster: 'http://www.merriam-webster.com/dictionary/%s',
-  oxford: 'http://www.oxforddictionaries.com/us/definition/english/%s',
-  cambridge: 'http://dictionary.cambridge.org/spellcheck/english-chinese-simplified/?q=%s',
-  youdao: 'http://dict.youdao.com/w/%s',
-  dictcn: 'https://dict.eudic.net/dicts/en/%s',
-  iciba: 'http://www.iciba.com/%s',
-  liangan: 'https://www.moedict.tw/~%s',
-  guoyu: 'https://www.moedict.tw/%s',
-  longman_business: 'http://www.ldoceonline.com/search/?q=%s',
-  bing_dict: 'https://cn.bing.com/dict/?q=%s'
-}
-
-// Just for type check. Keys in allContextMenus are useful so no actual assertion
-// tslint:disable-next-line:no-unused-expression
-allContextMenus as { [id: string]: string }
+export type DictConfigsMutable = ReturnType<typeof getALlDicts>
+export type DictConfigs = DeepReadonly<DictConfigsMutable>
+export type DictID = keyof DictConfigsMutable
 
-export type ContextMenuDictID = keyof typeof allContextMenus
+export type ContextMenuDictID = keyof ReturnType<typeof getAllContextMenus>
 
 export const enum TCDirection {
   center,
@@ -238,10 +30,6 @@ export const enum TCDirection {
 /** '' means no preload */
 export type PreloadSource = '' | 'clipboard' | 'selection'
 
-export type DictConfigs = DeepReadonly<DictConfigsMutable>
-
-export type DictConfigsMutable = typeof allDicts
-
 export type AppConfig = DeepReadonly<AppConfigMutable>
 
 export interface AppConfigMutable {
@@ -418,7 +206,7 @@ export function appConfigFactory (): AppConfig {
       },
       en: {
         dict: '',
-        list: ['bing', 'dictcn', 'howjsay', 'macmillan', 'eudic', 'urban'],
+        list: ['bing', 'dictcn', 'macmillan', 'urban'],
         accent: 'uk' as ('us' | 'uk')
       }
     },
@@ -426,11 +214,11 @@ export function appConfigFactory (): AppConfig {
     dicts: {
       selected: ['bing', 'urban', 'vocabulary', 'dictcn'],
       // settings of each dict will be auto-generated
-      all: cloneDeep(allDicts)
+      all: getALlDicts()
     },
     contextMenus: {
       selected: ['oxford', 'google_translate', 'merriam_webster', 'cambridge', 'google_search', 'google_page_translate', 'youdao_page_translate'],
-      all: cloneDeep(allContextMenus)
+      all: getAllContextMenus()
     }
   }
 }
",3,"[""73eac947689e3fc6b53bf626a6b4604056166d6e"", ""6ae067153cd2608018fd3da76bd6d00a08da4b3a"", ""d986b530775edd8ef1f4e445a5d4b0016f409722""]","[""test"", ""feat"", ""refactor""]"
"added changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284 | i18n for Time Picker | update dependencies","diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')

diff --git a/packages/nc-gui/components/cell/TimePicker.vue b/packages/nc-gui/components/cell/TimePicker.vue
index 619ab45..7f66828 100644
--- a/packages/nc-gui/components/cell/TimePicker.vue
+++ b/packages/nc-gui/components/cell/TimePicker.vue
@@ -38,6 +38,8 @@ const isTimeInvalid = ref(false)
 
 const dateFormat = isMysql(column.value.base_id) ? 'YYYY-MM-DD HH:mm:ss' : 'YYYY-MM-DD HH:mm:ssZ'
 
+const { t } = useI18n()
+
 const localState = computed({
   get() {
     if (!modelValue) {
@@ -89,11 +91,11 @@ watch(
 
 const placeholder = computed(() => {
   if (isEditColumn.value && (modelValue === '' || modelValue === null)) {
-    return '(Optional)'
+    return t('labels.optional')
   } else if (modelValue === null && showNull.value) {
-    return 'NULL'
+    return t('general.null')
   } else if (isTimeInvalid.value) {
-    return 'Invalid time'
+    return t('msg.invalidTime')
   } else {
     return ''
   }

diff --git a/example/exp.json b/example/exp.json
index ea820f9..b838093 100644
--- a/example/exp.json
+++ b/example/exp.json
@@ -1,8 +1,8 @@
 {
-  ""name"": ""react-native-paper-example"",
+  ""name"": ""React Native Paper Example"",
   ""description"": ""Example for React Native Paper"",
   ""slug"": ""react-native-paper-example"",
-  ""sdkVersion"": ""10.0.0"",
+  ""sdkVersion"": ""11.0.0"",
   ""version"": ""1.0.0"",
   ""orientation"": ""portrait"",
   ""primaryColor"": ""#cccccc"",
diff --git a/example/package.json b/example/package.json
index c4d049a..7e2baeb 100644
--- a/example/package.json
+++ b/example/package.json
@@ -6,10 +6,10 @@
   ""private"": true,
   ""main"": ""main.js"",
   ""dependencies"": {
-    ""@exponent/ex-navigation"": ""^1.7.0"",
-    ""exponent"": ""^10.0.4"",
+    ""@exponent/ex-navigation"": ""^2.0.0"",
+    ""exponent"": ""^11.0.2"",
     ""react"": ""~15.3.2"",
-    ""react-native"": ""github:exponentjs/react-native#sdk-10.1.2"",
+    ""react-native"": ""github:exponentjs/react-native#sdk-11.0.3"",
     ""react-native-paper"": ""file:../"",
     ""react-native-vector-icons"": ""git+https://github.com/exponentjs/react-native-vector-icons.git""
   }
diff --git a/package.json b/package.json
index 65afbbc..326ab48 100644
--- a/package.json
+++ b/package.json
@@ -27,17 +27,17 @@
     ""react-native-vector-icons"": ""*""
   },
   ""devDependencies"": {
-    ""babel-eslint"": ""^7.0.0"",
-    ""eslint"": ""^3.8.1"",
+    ""babel-eslint"": ""^7.1.0"",
+    ""eslint"": ""^3.9.1"",
     ""eslint-plugin-babel"": ""^3.3.0"",
-    ""eslint-plugin-import"": ""^2.0.1"",
-    ""eslint-plugin-react"": ""^6.4.1"",
+    ""eslint-plugin-import"": ""^2.2.0"",
+    ""eslint-plugin-react"": ""^6.6.0"",
     ""eslint-plugin-react-native"": ""^2.0.0"",
     ""flow-bin"": ""^0.32.0"",
     ""react"": ""latest"",
     ""react-native"": ""latest""
   },
   ""dependencies"": {
-    ""color"": ""^0.11.3""
+    ""color"": ""^0.11.4""
   }
 }
",3,"[""aca23027da1295c78fdf42ba9687d8ccc88784d7"", ""48806e3675c7b18327e7629827454d7c29be25a9"", ""ecc481f9f501aa34b41e06e7bbdde6e79f8ca1bb""]","[""docs"", ""fix"", ""build""]"
use `regexp_instr != 0` instead of `REGEXP` keyword | add postgres-driver typings,"diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(

diff --git a/packages/cubejs-postgres-driver/driver/index.d.ts b/packages/cubejs-postgres-driver/driver/index.d.ts
new file mode 100644
index 0000000..47dcada
--- /dev/null
+++ b/packages/cubejs-postgres-driver/driver/index.d.ts
@@ -0,0 +1,8 @@
+import { PoolConfig } from ""pg"";
+
+declare module ""@cubejs-backend/postgres-driver"" {
+  class PostgresDriver {
+    constructor(options?: PoolConfig);
+  }
+  export = PostgresDriver;
+}
diff --git a/packages/cubejs-postgres-driver/package.json b/packages/cubejs-postgres-driver/package.json
index 9db5a20..1e9a236 100644
--- a/packages/cubejs-postgres-driver/package.json
+++ b/packages/cubejs-postgres-driver/package.json
@@ -12,6 +12,7 @@
     ""node"": "">=8.11.1""
   },
   ""main"": ""driver/PostgresDriver.js"",
+  ""typings"": ""driver/index.d.ts"",
   ""scripts"": {
     ""lint"": ""eslint **/*.js""
   },
",2,"[""06e2be4e2019b6fa714e1fcb34485860ef1ede79"", ""364d9bf18b2ce73c04d5ec3a70aefa3e6b83cc12""]","[""fix"", ""feat""]"
export a modal transition preset,"diff --git a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
index f1066a1..ae93dca 100644
--- a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
+++ b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
@@ -79,3 +79,8 @@ export const DefaultTransition = Platform.select({
       ? FadeFromBottomAndroid
       : WipeFromBottomAndroid,
 });
+
+export const ModalTransition = Platform.select({
+  ios: ModalSlideFromBottomIOS,
+  default: DefaultTransition,
+});
diff --git a/packages/stack/src/views/Stack/Stack.tsx b/packages/stack/src/views/Stack/Stack.tsx
index cf1719c..47c1abf 100755
--- a/packages/stack/src/views/Stack/Stack.tsx
+++ b/packages/stack/src/views/Stack/Stack.tsx
@@ -14,7 +14,7 @@ import { Props as HeaderContainerProps } from '../Header/HeaderContainer';
 import StackItem from './StackItem';
 import {
   DefaultTransition,
-  ModalSlideFromBottomIOS,
+  ModalTransition,
 } from '../../TransitionConfigs/TransitionPresets';
 import { forNoAnimation } from '../../TransitionConfigs/HeaderStyleInterpolators';
 import {
@@ -301,9 +301,7 @@ export default class Stack extends React.Component<Props, State> {
     const focusedOptions = descriptors[focusedRoute.key].options;
 
     let defaultTransitionPreset =
-      mode === 'modal' && Platform.OS === 'ios'
-        ? ModalSlideFromBottomIOS
-        : DefaultTransition;
+      mode === 'modal' ? ModalTransition : DefaultTransition;
 
     if (headerMode === 'screen') {
       defaultTransitionPreset = {
",1,"[""535708ae50aecb452560a23356fd396f99ef13a2""]","[""refactor""]"
create dashboards from imported templates | add a branch name to Slack notifications (#14793) | also make dependents when running smoke tests,"diff --git a/CHANGELOG.md b/CHANGELOG.md
index 590f5ea..bd74e95 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -1,6 +1,7 @@
 ## v2.0.0-alpha.6 [unreleased]
 
 ### Features
+1. [12496](https://github.com/influxdata/influxdb/pull/12496): Add ability to import a dashboard
 
 ### Bug Fixes
 
diff --git a/ui/src/dashboards/actions/v2/index.ts b/ui/src/dashboards/actions/v2/index.ts
index ad0d13d..35babc7 100644
--- a/ui/src/dashboards/actions/v2/index.ts
+++ b/ui/src/dashboards/actions/v2/index.ts
@@ -16,6 +16,7 @@ import {
   removeDashboardLabels as removeDashboardLabelsAJAX,
   updateView as updateViewAJAX,
 } from 'src/dashboards/apis/v2'
+import {client} from 'src/utils/api'
 
 // Actions
 import {notify} from 'src/shared/actions/notifications'
@@ -25,6 +26,10 @@ import {
   DeleteTimeRangeAction,
 } from 'src/dashboards/actions/v2/ranges'
 import {setView, SetViewAction} from 'src/dashboards/actions/v2/views'
+import {
+  importDashboardSucceeded,
+  importDashboardFailed,
+} from 'src/shared/copy/notifications'
 
 // Utils
 import {
@@ -38,7 +43,7 @@ import * as copy from 'src/shared/copy/notifications'
 // Types
 import {RemoteDataState} from 'src/types'
 import {PublishNotificationAction} from 'src/types/actions/notifications'
-import {CreateCell} from '@influxdata/influx'
+import {CreateCell, IDashboardTemplate} from '@influxdata/influx'
 import {Dashboard, NewView, Cell} from 'src/types/v2'
 import {ILabel} from '@influxdata/influx'
 
@@ -201,6 +206,19 @@ export const getDashboardsAsync = () => async (
   }
 }
 
+export const createDashboardFromTemplate = (
+  template: IDashboardTemplate,
+  orgID: string
+) => async dispatch => {
+  try {
+    await client.dashboards.createFromTemplate(template, orgID)
+
+    dispatch(notify(importDashboardSucceeded()))
+  } catch (error) {
+    dispatch(notify(importDashboardFailed(error)))
+  }
+}
+
 export const importDashboardAsync = (dashboard: Dashboard) => async (
   dispatch: Dispatch<Action>
 ): Promise<void> => {
diff --git a/ui/src/dashboards/components/ImportDashboardOverlay.tsx b/ui/src/dashboards/components/ImportDashboardOverlay.tsx
index 37ef80b..84216c3 100644
--- a/ui/src/dashboards/components/ImportDashboardOverlay.tsx
+++ b/ui/src/dashboards/components/ImportDashboardOverlay.tsx
@@ -1,70 +1,80 @@
+// Libraries
 import React, {PureComponent} from 'react'
 import _ from 'lodash'
+import {connect} from 'react-redux'
 
-import Container from 'src/clockface/components/overlays/OverlayContainer'
-import Heading from 'src/clockface/components/overlays/OverlayHeading'
-import Body from 'src/clockface/components/overlays/OverlayBody'
-import DragAndDrop from 'src/shared/components/DragAndDrop'
+// Constants
 import {dashboardImportFailed} from 'src/shared/copy/notifications'
 
-import {Dashboard} from 'src/types/v2'
-import {Notification} from 'src/types/notifications'
+// Actions
+import {notify as notifyAction} from 'src/shared/actions/notifications'
+import {getDashboardsAsync} from 'src/dashboards/actions/v2'
 
-interface Props {
+// Types
+import ImportOverlay from 'src/shared/components/ImportOverlay'
+import {createDashboardFromTemplate as createDashboardFromTemplateAction} from 'src/dashboards/actions/v2'
+
+interface OwnProps {
   onDismissOverlay: () => void
-  onImportDashboard: (dashboard: Dashboard) => void
-  notify: (message: Notification) => void
+  orgID: string
+  isVisible: boolean
+}
+interface DispatchProps {
+  notify: typeof notifyAction
+  createDashboardFromTemplate: typeof createDashboardFromTemplateAction
+  populateDashboards: typeof getDashboardsAsync
 }
+
+type Props = OwnProps & DispatchProps
+
 class ImportDashboardOverlay extends PureComponent<Props> {
   constructor(props: Props) {
     super(props)
   }
 
   public render() {
-    const {onDismissOverlay} = this.props
+    const {isVisible, onDismissOverlay} = this.props
 
     return (
-      <Container maxWidth={800}>
-        <Heading title=""Import Dashboard"" onDismiss={onDismissOverlay} />
-        <Body>
-          <DragAndDrop
-            submitText=""Upload Dashboard""
-            fileTypesToAccept={this.validFileExtension}
-            handleSubmit={this.handleUploadDashboard}
-          />
-        </Body>
-      </Container>
+      <ImportOverlay
+        isVisible={isVisible}
+        onDismissOverlay={onDismissOverlay}
+        resourceName=""Dashboard""
+        onSubmit={this.handleUploadDashboard}
+      />
     )
   }
 
-  private get validFileExtension(): string {
-    return '.json'
-  }
-
-  private handleUploadDashboard = (
-    uploadContent: string,
-    fileName: string
-  ): void => {
-    const {notify, onImportDashboard, onDismissOverlay} = this.props
-    const fileExtensionRegex = new RegExp(`${this.validFileExtension}$`)
-    if (!fileName.match(fileExtensionRegex)) {
-      notify(dashboardImportFailed('Please import a JSON file'))
-      return
-    }
+  private handleUploadDashboard = async (
+    uploadContent: string
+  ): Promise<void> => {
+    const {
+      notify,
+      createDashboardFromTemplate,
+      onDismissOverlay,
+      populateDashboards,
+      orgID,
+    } = this.props
 
     try {
-      const {dashboard} = JSON.parse(uploadContent)
+      const template = JSON.parse(uploadContent)
 
-      if (!_.isEmpty(dashboard)) {
-        onImportDashboard(dashboard)
-        onDismissOverlay()
-      } else {
-        notify(dashboardImportFailed('No dashboard found in file'))
-      }
+      await createDashboardFromTemplate(template, orgID)
+      await populateDashboards()
+
+      onDismissOverlay()
     } catch (error) {
       notify(dashboardImportFailed(error))
     }
   }
 }
+const mdtp: DispatchProps = {
+  notify: notifyAction,
+  createDashboardFromTemplate: createDashboardFromTemplateAction,
+  populateDashboards: getDashboardsAsync,
+}
 
-export default ImportDashboardOverlay
+export default connect<{}, DispatchProps, OwnProps>(
+  null,
+  mdtp
+)(ImportDashboardOverlay)
diff --git a/ui/src/dashboards/components/dashboard_index/DashboardsIndex.tsx b/ui/src/dashboards/components/dashboard_index/DashboardsIndex.tsx
index d6b299f..1ff7f47 100644
--- a/ui/src/dashboards/components/dashboard_index/DashboardsIndex.tsx
+++ b/ui/src/dashboards/components/dashboard_index/DashboardsIndex.tsx
@@ -2,15 +2,15 @@
 import React, {PureComponent} from 'react'
 import {InjectedRouter} from 'react-router'
 import {connect} from 'react-redux'
-import {isEmpty} from 'lodash'
+import {get} from 'lodash'
 
 // Components
 import DashboardsIndexContents from 'src/dashboards/components/dashboard_index/DashboardsIndexContents'
 import {Page} from 'src/pageLayout'
 import SearchWidget from 'src/shared/components/search_widget/SearchWidget'
 import AddResourceDropdown from 'src/shared/components/AddResourceDropdown'
-import ImportOverlay from 'src/shared/components/ImportOverlay'
 import ExportOverlay from 'src/shared/components/ExportOverlay'
+import ImportDashboardOverlay from 'src/dashboards/components/ImportDashboardOverlay'
 
 // APIs
 import {createDashboard, cloneDashboard} from 'src/dashboards/apis/v2/'
@@ -32,10 +32,7 @@ import {DEFAULT_DASHBOARD_NAME} from 'src/dashboards/constants/index'
 import {
   dashboardSetDefaultFailed,
   dashboardCreateFailed,
-  dashboardImported,
-  dashboardImportFailed,
 } from 'src/shared/copy/notifications'
-import {cantImportInvalidResource} from 'src/shared/copy/v2/notifications'
 
 // Types
 import {Notification} from 'src/types/notifications'
@@ -197,24 +194,6 @@ class DashboardIndex extends PureComponent<Props, State> {
     this.props.handleDeleteDashboard(dashboard)
   }
 
-  private handleImportDashboard = async (
-    importString: string
-  ): Promise<void> => {
-    const {notify} = this.props
-    try {
-      const resource = JSON.parse(importString)
-
-      if (isEmpty(resource)) {
-        notify(cantImportInvalidResource('Dashboard'))
-        return
-      }
-      this.handleToggleImportOverlay()
-      notify(dashboardImported())
-    } catch (error) {
-      notify(dashboardImportFailed(error))
-    }
-  }
-
   private handleFilterDashboards = (searchTerm: string): void => {
     this.setState({searchTerm})
   }
@@ -229,13 +208,13 @@ class DashboardIndex extends PureComponent<Props, State> {
 
   private get importOverlay(): JSX.Element {
     const {isImportingDashboard} = this.state
+    const {orgs} = this.props
 
     return (
-      <ImportOverlay
-        isVisible={isImportingDashboard}
-        resourceName=""Dashboard""
+      <ImportDashboardOverlay
         onDismissOverlay={this.handleToggleImportOverlay}
-        onSubmit={this.handleImportDashboard}
+        orgID={get(orgs, '0.id', '')}
+        isVisible={isImportingDashboard}
       />
     )
   }
diff --git a/ui/src/organizations/components/Dashboards.tsx b/ui/src/organizations/components/Dashboards.tsx
index 08c8402..90c2514 100644
--- a/ui/src/organizations/components/Dashboards.tsx
+++ b/ui/src/organizations/components/Dashboards.tsx
@@ -6,13 +6,10 @@ import _ from 'lodash'
 
 // Components
 import DashboardsIndexContents from 'src/dashboards/components/dashboard_index/DashboardsIndexContents'
-import {OverlayTechnology, Input, Tabs} from 'src/clockface'
+import {Input, Tabs} from 'src/clockface'
 import {Button, ComponentColor, IconFont} from '@influxdata/clockface'
 import ImportDashboardOverlay from 'src/dashboards/components/ImportDashboardOverlay'
 
-// Utils
-import {getDeep} from 'src/utils/wrappers'
-
 // APIs
 import {createDashboard, cloneDashboard} from 'src/dashboards/apis/v2/'
 
@@ -39,7 +36,7 @@ import {DEFAULT_DASHBOARD_NAME} from 'src/dashboards/constants/index'
 
 // Types
 import {Notification} from 'src/types/notifications'
-import {Links, Cell, Dashboard, AppState, Organization} from 'src/types/v2'
+import {Links, Dashboard, AppState, Organization} from 'src/types/v2'
 
 // Decorators
 import {ErrorHandling} from 'src/shared/decorators/errors'
@@ -205,46 +202,20 @@ class Dashboards extends PureComponent<Props, State> {
     this.props.handleDeleteDashboard(dashboard)
   }
 
-  private handleImportDashboard = async (
-    dashboard: Dashboard
-  ): Promise<void> => {
-    const defaultCell = {
-      x: 0,
-      y: 0,
-      w: 4,
-      h: 4,
-    }
-
-    const name = _.get(dashboard, 'name', DEFAULT_DASHBOARD_NAME)
-    const cellsWithDefaultsApplied = getDeep<Cell[]>(
-      dashboard,
-      'cells',
-      []
-    ).map(c => ({...defaultCell, ...c}))
-
-    await this.props.handleImportDashboard({
-      ...dashboard,
-      name,
-      cells: cellsWithDefaultsApplied,
-    })
-  }
-
   private handleToggleOverlay = (): void => {
     this.setState({isImportingDashboard: !this.state.isImportingDashboard})
   }
 
   private get renderImportOverlay(): JSX.Element {
-    const {notify} = this.props
     const {isImportingDashboard} = this.state
+    const {orgs} = this.props
 
     return (
-      <OverlayTechnology visible={isImportingDashboard}>
-        <ImportDashboardOverlay
-          onDismissOverlay={this.handleToggleOverlay}
-          onImportDashboard={this.handleImportDashboard}
-          notify={notify}
-        />
-      </OverlayTechnology>
+      <ImportDashboardOverlay
+        onDismissOverlay={this.handleToggleOverlay}
+        orgID={_.get(orgs, '0.id', '')}
+        isVisible={isImportingDashboard}
+      />
     )
   }
 }
diff --git a/ui/src/shared/components/ImportOverlay.tsx b/ui/src/shared/components/ImportOverlay.tsx
index 10f1d50..476fa70 100644
--- a/ui/src/shared/components/ImportOverlay.tsx
+++ b/ui/src/shared/components/ImportOverlay.tsx
@@ -10,6 +10,7 @@ import {
   OverlayHeading,
   OverlayFooter,
   Radio,
+  ComponentStatus,
 } from 'src/clockface'
 import {Button, ComponentColor} from '@influxdata/clockface'
 
@@ -93,6 +94,7 @@ export default class ImportOverlay extends PureComponent<Props, State> {
           submitText=""Upload""
           handleSubmit={this.handleSetImportContent}
           submitOnDrop={true}
+          submitOnUpload={true}
           onCancel={this.clearImportContent}
         />
       )
@@ -110,18 +112,21 @@ export default class ImportOverlay extends PureComponent<Props, State> {
   private get submitButton(): JSX.Element {
     const {resourceName} = this.props
     const {selectedImportOption, importContent} = this.state
-    if (
+    const isEnabled =
       selectedImportOption === ImportOption.Paste ||
       (selectedImportOption === ImportOption.Upload && importContent)
-    ) {
-      return (
-        <Button
-          text={`Import JSON as ${resourceName}`}
-          onClick={this.submit}
-          color={ComponentColor.Primary}
-        />
-      )
-    }
+    const status = isEnabled
+      ? ComponentStatus.Default
+      : ComponentStatus.Disabled
+
+    return (
+      <Button
+        text={`Import JSON as ${resourceName}`}
+        onClick={this.submit}
+        color={ComponentColor.Primary}
+        status={status}
+      />
+    )
   }
 
   private submit = () => {
diff --git a/ui/src/shared/copy/notifications.ts b/ui/src/shared/copy/notifications.ts
index 4492078..86700e2 100644
--- a/ui/src/shared/copy/notifications.ts
+++ b/ui/src/shared/copy/notifications.ts
@@ -799,9 +799,18 @@ export const importTaskSucceeded = (): Notification => ({
 })
 
 export const importTaskFailed = (error: string): Notification => ({
-  ...defaultSuccessNotification,
+  ...defaultErrorNotification,
   message: `Failed to import task: ${error}`,
 })
+export const importDashboardSucceeded = (): Notification => ({
+  ...defaultSuccessNotification,
+  message: `Successfully imported dashboard.`,
+})
+
+export const importDashboardFailed = (error: string): Notification => ({
+  ...defaultErrorNotification,
+  message: `Failed to import dashboard: ${error}`,
+})
 
 // Labels
 export const getLabelsFailed = (): Notification => ({

diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'

diff --git a/.github/workflows/os-smoke-test.yml b/.github/workflows/os-smoke-test.yml
index 194d108..7e41493 100644
--- a/.github/workflows/os-smoke-test.yml
+++ b/.github/workflows/os-smoke-test.yml
@@ -56,5 +56,7 @@ jobs:
         uses: JesseTG/rm@v1.0.2
         with:
           path: /Users/runner/.m2/repository/uk/co/real-logic/sbe-tool
+      - name: Build relevant modules
+        run: mvn -B -am -pl qa/integration-tests package -DskipTests -DskipChecks -T1C
       - name: Run smoke test
         run: mvn -B -pl qa/integration-tests verify -P smoke-test -DskipUTs -DskipChecks
",3,"[""9114362b39f5194209cd0b330af7076333f3db77"", ""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da"", ""2236b37bd671fdb71313cbc6ebd7633f0effba34""]","[""feat"", ""cicd"", ""build""]"
make jq use compact json for rebase branch query | [gn win] link comctl32.lib to fix component build | svg helper,"diff --git a/.github/workflows/ibis-rebase-nightly.yml b/.github/workflows/ibis-rebase-nightly.yml
index 0e284b0..4a3ec7a 100644
--- a/.github/workflows/ibis-rebase-nightly.yml
+++ b/.github/workflows/ibis-rebase-nightly.yml
@@ -22,7 +22,7 @@ jobs:
               | cut -d ' ' -f2 \
               | grep -P '\d+\.x\.x' \
               | xargs printf '""%s""' \
-              | jq -s '{branch: .}')
+              | jq -rcMs '{branch: .}')
 
           echo ""::set-output name=matrix::$branches""
 

diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]

diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index 0f9cb63..ff5e5f0 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -1,4 +1,4 @@
-import { className, m, ns, style } from '../m';
+import { className, m, ns, svg, style } from '../m';
 import { VNode, VProps } from '../structs';
 
 const h = (tag: string, props?: VProps, ...children: VNode[]) =>
@@ -173,6 +173,28 @@ describe('.m', () => {
     });
   });
 
+  it('should attach ns to props using svg helper', () => {
+    const vnode = {
+      tag: 'svg',
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    expect(svg(vnode)).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
+
   it('should move key to distinct property', () => {
     expect(h('div', { key: 'foo' }, 'foo', h('div'))).toEqual({
       tag: 'div',
",3,"[""4638dcdf7011e8e42d11fde04f068f22ee20fa1d"", ""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0"", ""4aa3e4c438742ef0fe694ffaf6a181874366d777""]","[""cicd"", ""build"", ""test""]"
"unset DOCKER_HOST set to swarm by jenkins

- fixes issue where old images are pushed to registry | added changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284","diff --git a/.ci/docker.dsl b/.ci/docker.dsl
index 4768cb8..9f6a4c9 100644
--- a/.ci/docker.dsl
+++ b/.ci/docker.dsl
@@ -8,6 +8,9 @@ def dockerHubUpload =
 '''\
 #!/bin/bash -xeu
 
+# clear docker host env set by jenkins job
+unset DOCKER_HOST
+
 VERSION=${RELEASE_VERSION}
 
 if [ ""${RELEASE_VERSION}"" = ""SNAPSHOT"" ]; then
@@ -26,9 +29,6 @@ docker login --username ${DOCKER_HUB_USERNAME} --password ${DOCKER_HUB_PASSWORD}
 docker push camunda/zeebe:${RELEASE_VERSION}
 
 if [ ""${IS_LATEST}"" = ""true"" ]; then
-    # to make sure we can tag latest, there were problems before
-    docker rmi camunda/zeebe:latest
-
     docker tag -f camunda/zeebe:${RELEASE_VERSION} camunda/zeebe:latest
     docker push camunda/zeebe:latest
 fi

diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')
",2,"[""8b18a58969ed2adf2df2a8bfe91aedacad3868f5"", ""aca23027da1295c78fdf42ba9687d8ccc88784d7""]","[""cicd"", ""docs""]"
explain `ChunkOrder` query test scenario | simplify loadFiles code,"diff --git a/query_tests/src/scenarios.rs b/query_tests/src/scenarios.rs
index f0e352b..86df0e9 100644
--- a/query_tests/src/scenarios.rs
+++ b/query_tests/src/scenarios.rs
@@ -1170,6 +1170,21 @@ impl DbSetup for ChunkOrder {
             .clear_lifecycle_action()
             .unwrap();
 
+        // Now we have the the following chunks (same partition and table):
+        //
+        // | ID | order | tag: region | field: user | time |
+        // | -- | ----- | ----------- | ----------- | ---- |
+        // |  1 |     1 | ""west""      |           2 | 100  |
+        // |  2 |     0 | ""west""      |           1 | 100  |
+        //
+        // The result after deduplication should be:
+        //
+        // | tag: region | field: user | time |
+        // | ----------- | ----------- | ---- |
+        // | ""west""      |           2 | 100  |
+        //
+        // So the query engine must use `order` as a primary key to sort chunks, NOT `id`.
+
         let scenario = DbScenario {
             scenario_name: ""chunks where chunk ID alone cannot be used for ordering"".into(),
             db,

diff --git a/frontend/app/player/web/network/loadFiles.ts b/frontend/app/player/web/network/loadFiles.ts
index ec174fc..d164333 100644
--- a/frontend/app/player/web/network/loadFiles.ts
+++ b/frontend/app/player/web/network/loadFiles.ts
@@ -1,43 +1,33 @@
 import APIClient from 'App/api_client';
 
-const NO_NTH_FILE = ""nnf""
-const NO_UNPROCESSED_FILES = ""nuf""
+const NO_FILE_OK = ""No-file-but-this-is-ok""
+const NO_BACKUP_FILE = ""No-efs-file""
 
 export const loadFiles = (
   urls: string[],
   onData: (data: Uint8Array) => void,
 ): Promise<void> => {
-  const firstFileURL = urls[0]
-  urls = urls.slice(1)
-  if (!firstFileURL) {
+  if (!urls.length) {
     return Promise.reject(""No urls provided"")
   }
-  return window.fetch(firstFileURL)
-  .then(r => {
-    return processAPIStreamResponse(r, true)
-  })
-  .then(onData)
-  .then(() =>
-    urls.reduce((p, url) =>
-      p.then(() =>
-        window.fetch(url)
-        .then(r => {
-          return processAPIStreamResponse(r, false)
-        })
-        .then(onData)
-      ),
-      Promise.resolve(),
-    )
+  return urls.reduce((p, url, index) =>
+    p.then(() =>
+      window.fetch(url)
+      .then(r => {
+        return processAPIStreamResponse(r, index===0)
+      })
+      .then(onData)
+    ),
+    Promise.resolve(),
   )
   .catch(e => {
-    if (e === NO_NTH_FILE) {
+    if (e === NO_FILE_OK) {
       return
     }
     throw e
   })
 }
 
-
 export async function requestEFSDom(sessionId: string) {
   return await requestEFSMobFile(sessionId + ""/dom.mob"")
 }
@@ -50,21 +40,18 @@ async function requestEFSMobFile(filename: string) {
   const api = new APIClient()
   const res = await api.fetch('/unprocessed/' + filename)
   if (res.status >= 400) {
-    throw NO_UNPROCESSED_FILES
+    throw NO_BACKUP_FILE
   }
   return await processAPIStreamResponse(res, false)
 }
 
-const processAPIStreamResponse = (response: Response, isFirstFile: boolean) => {
+const processAPIStreamResponse = (response: Response, canBeMissed: boolean) => {
   return new Promise<ArrayBuffer>((res, rej) => {
-    if (response.status === 404 && !isFirstFile) {
-      return rej(NO_NTH_FILE)
+    if (response.status === 404 && canBeMissed) {
+      return rej(NO_FILE_OK)
     }
     if (response.status >= 400) {
-      return rej(
-        isFirstFile ? `no start file. status code ${ response.status }`
-        : `Bad endfile status code ${response.status}`
-      )
+      return rej(`Bad file status code ${response.status}. Url: ${response.url}`)
     }
     res(response.arrayBuffer())
   }).then(buffer => new Uint8Array(buffer))
",2,"[""9a60af7fa3b480e2e04bacd646112cad9aaab6d7"", ""983fef55ef08ca2ca25349bb2d5bdff10ecf89f4""]","[""docs"", ""refactor""]"
add documentation to use react-native-paper with CRA (#874) | run pyspark tests in parallel,"diff --git a/docs/pages/4.react-native-web.md b/docs/pages/4.react-native-web.md
index 69e4e52..8d6ae2a 100644
--- a/docs/pages/4.react-native-web.md
+++ b/docs/pages/4.react-native-web.md
@@ -16,6 +16,63 @@ To install `react-native-web`, run:
 yarn add react-native-web react-dom react-art
 ```
 
+### Using CRA ([Create React App](https://github.com/facebook/create-react-app))
+
+Install [`react-app-rewired`](https://github.com/timarney/react-app-rewired) to override `webpack` configuration:
+
+```sh
+yarn add --dev react-app-rewired
+```
+
+[Configure `babel-loader`](#2-configure-babel-loader) using a new file called `config-overrides.js`:
+
+```js
+module.exports = function override(config, env) {
+  config.module.rules.push({
+    test: /\.js$/,
+    exclude: /node_modules[/\\](?!react-native-paper|react-native-vector-icons|react-native-safe-area-view)/,
+    use: {
+      loader: ""babel-loader"",
+      options: {
+        // Disable reading babel configuration
+        babelrc: false,
+        configFile: false,
+
+        // The configration for compilation
+        presets: [
+          [""@babel/preset-env"", { useBuiltIns: ""usage"" }],
+          ""@babel/preset-react"",
+          ""@babel/preset-flow""
+        ],
+        plugins: [
+          ""@babel/plugin-proposal-class-properties"",
+          ""@babel/plugin-proposal-object-rest-spread""
+        ]
+      }
+    }
+  });
+
+  return config;
+};
+```
+
+Change your script in `package.json`:
+
+```diff
+/* package.json */
+
+  ""scripts"": {
+-   ""start"": ""react-scripts start"",
++   ""start"": ""react-app-rewired start"",
+-   ""build"": ""react-scripts build"",
++   ""build"": ""react-app-rewired build"",
+-   ""test"": ""react-scripts test --env=jsdom"",
++   ""test"": ""react-app-rewired test --env=jsdom""
+}
+```
+
+### Custom webpack setup
+
 To install `webpack`, run:
 
 ```sh

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index e23088e..9708157 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -202,11 +202,11 @@ jobs:
         run: poetry install --without dev --without docs --extras ${{ matrix.backend.name }} --extras geospatial
 
       - name: ""run parallel tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name != 'pyspark' && matrix.backend.name != 'impala'
+        if: matrix.backend.name != 'impala'
         run: just ci-check -m ${{ matrix.backend.name }} --numprocesses auto --dist=loadgroup
 
       - name: ""run serial tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name == 'pyspark' || matrix.backend.name == 'impala'
+        if: matrix.backend.name == 'impala'
         run: just ci-check -m ${{ matrix.backend.name }}
         env:
           IBIS_TEST_NN_HOST: localhost
",2,"[""ee7cc5d5a940fba774e715b1f029c6361110b108"", ""4cbbd2552ba0de273e1dfe7d453c5b3efed751a3""]","[""docs"", ""cicd""]"
do not query all networks,"diff --git a/src/environment/windows_win32.go b/src/environment/windows_win32.go
index be0c7b5..b90e0ff 100644
--- a/src/environment/windows_win32.go
+++ b/src/environment/windows_win32.go
@@ -203,7 +203,6 @@ func (env *ShellEnvironment) getConnections() []*Connection {
 	var pIFTable2 *MIN_IF_TABLE2
 	_, _, _ = hGetIfTable2.Call(uintptr(unsafe.Pointer(&pIFTable2)))
 
-	SSIDs, _ := env.getAllWifiSSID()
 	networks := make([]*Connection, 0)
 
 	for i := 0; i < int(pIFTable2.NumEntries); i++ {
@@ -220,11 +219,13 @@ func (env *ShellEnvironment) getConnections() []*Connection {
 		}
 
 		var connectionType ConnectionType
+		var ssid string
 		switch networkInterface.Type {
 		case 6:
 			connectionType = ETHERNET
 		case 71:
 			connectionType = WIFI
+			ssid = env.getWiFiSSID(networkInterface.InterfaceGUID)
 		case 237, 234, 244:
 			connectionType = CELLULAR
 		}
@@ -243,10 +244,7 @@ func (env *ShellEnvironment) getConnections() []*Connection {
 			Name:         description, // we want a relatable name, alias isn't that
 			TransmitRate: networkInterface.TransmitLinkSpeed,
 			ReceiveRate:  networkInterface.ReceiveLinkSpeed,
-		}
-
-		if SSID, OK := SSIDs[network.Name]; OK {
-			network.SSID = SSID
+			SSID:         ssid,
 		}
 
 		networks = append(networks, network)
@@ -322,13 +320,21 @@ type MIB_IF_ROW2 struct { //nolint: revive
 	OutQLen            uint64
 }
 
-func (env *ShellEnvironment) getAllWifiSSID() (map[string]string, error) {
+var (
+	wlanapi             = syscall.NewLazyDLL(""wlanapi.dll"")
+	hWlanOpenHandle     = wlanapi.NewProc(""WlanOpenHandle"")
+	hWlanCloseHandle    = wlanapi.NewProc(""WlanCloseHandle"")
+	hWlanQueryInterface = wlanapi.NewProc(""WlanQueryInterface"")
+)
+
+func (env *ShellEnvironment) getWiFiSSID(guid windows.GUID) string {
+	// Query wifi connection state
 	var pdwNegotiatedVersion uint32
 	var phClientHandle uint32
 	e, _, err := hWlanOpenHandle.Call(uintptr(uint32(2)), uintptr(unsafe.Pointer(nil)), uintptr(unsafe.Pointer(&pdwNegotiatedVersion)), uintptr(unsafe.Pointer(&phClientHandle)))
 	if e != 0 {
 		env.Log(Error, ""getAllWifiSSID"", err.Error())
-		return nil, err
+		return """"
 	}
 
 	// defer closing handle
@@ -336,42 +342,11 @@ func (env *ShellEnvironment) getAllWifiSSID() (map[string]string, error) {
 		_, _, _ = hWlanCloseHandle.Call(uintptr(phClientHandle), uintptr(unsafe.Pointer(nil)))
 	}()
 
-	ssid := make(map[string]string)
-	// list interfaces
-	var interfaceList *WLAN_INTERFACE_INFO_LIST
-	e, _, err = hWlanEnumInterfaces.Call(uintptr(phClientHandle), uintptr(unsafe.Pointer(nil)), uintptr(unsafe.Pointer(&interfaceList)))
-	if e != 0 {
-		env.Log(Error, ""getAllWifiSSID"", err.Error())
-		return nil, err
-	}
-
-	// use first interface that is connected
-	numberOfInterfaces := int(interfaceList.dwNumberOfItems)
-	infoSize := unsafe.Sizeof(interfaceList.InterfaceInfo[0])
-	for i := 0; i < numberOfInterfaces; i++ {
-		network := (*WLAN_INTERFACE_INFO)(unsafe.Pointer(uintptr(unsafe.Pointer(&interfaceList.InterfaceInfo[0])) + uintptr(i)*infoSize))
-		if network.isState == 1 {
-			wifiInterface := strings.TrimRight(string(utf16.Decode(network.strInterfaceDescription[:])), ""\x00"")
-			ssid[wifiInterface] = env.getWiFiSSID(network, phClientHandle)
-		}
-	}
-	return ssid, nil
-}
-
-var (
-	wlanapi             = syscall.NewLazyDLL(""wlanapi.dll"")
-	hWlanOpenHandle     = wlanapi.NewProc(""WlanOpenHandle"")
-	hWlanCloseHandle    = wlanapi.NewProc(""WlanCloseHandle"")
-	hWlanEnumInterfaces = wlanapi.NewProc(""WlanEnumInterfaces"")
-	hWlanQueryInterface = wlanapi.NewProc(""WlanQueryInterface"")
-)
-
-func (env *ShellEnvironment) getWiFiSSID(network *WLAN_INTERFACE_INFO, clientHandle uint32) string {
-	// Query wifi connection state
 	var dataSize uint16
 	var wlanAttr *WLAN_CONNECTION_ATTRIBUTES
-	e, _, _ := hWlanQueryInterface.Call(uintptr(clientHandle),
-		uintptr(unsafe.Pointer(&network.InterfaceGuid)),
+
+	e, _, _ = hWlanQueryInterface.Call(uintptr(phClientHandle),
+		uintptr(unsafe.Pointer(&guid)),
 		uintptr(7), // wlan_intf_opcode_current_connection
 		uintptr(unsafe.Pointer(nil)),
 		uintptr(unsafe.Pointer(&dataSize)),
@@ -389,18 +364,6 @@ func (env *ShellEnvironment) getWiFiSSID(network *WLAN_INTERFACE_INFO, clientHan
 	return string(ssid.ucSSID[0:ssid.uSSIDLength])
 }
 
-type WLAN_INTERFACE_INFO_LIST struct { //nolint: revive
-	dwNumberOfItems uint32
-	dwIndex         uint32 //nolint: unused
-	InterfaceInfo   [256]WLAN_INTERFACE_INFO
-}
-
-type WLAN_INTERFACE_INFO struct { //nolint: revive
-	InterfaceGuid           syscall.GUID //nolint: revive
-	strInterfaceDescription [256]uint16
-	isState                 uint32
-}
-
 type WLAN_CONNECTION_ATTRIBUTES struct { //nolint: revive
 	isState                   uint32      //nolint: unused
 	wlanConnectionMode        uint32      //nolint: unused
",1,"[""8a9a022baa15befc325f87892c6bdae25b35bc33""]","[""refactor""]"
verify checkpoint listeners are notified,"diff --git a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
index c44f724..8b3ad83 100644
--- a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
+++ b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
@@ -27,6 +27,7 @@ import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.RecordType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.nio.file.Path;
+import java.util.concurrent.atomic.AtomicLong;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -175,4 +176,69 @@ final class CheckpointRecordsProcessorTest {
     assertThat(state.getCheckpointId()).isEqualTo(checkpointId);
     assertThat(state.getCheckpointPosition()).isEqualTo(checkpointPosition);
   }
+
+  @Test
+  void shouldNotifyListenerWhenNewCheckpointCreated() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 2;
+    final long checkpointPosition = 20;
+    final CheckpointRecord value = new CheckpointRecord().setCheckpointId(checkpointId);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition, 0, CheckpointIntent.CREATE, RecordType.COMMAND, value);
+
+    // when
+    processor.process(record, resultBuilder);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerWhenReplayed() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 3;
+    final long checkpointPosition = 10;
+    final CheckpointRecord value =
+        new CheckpointRecord()
+            .setCheckpointId(checkpointId)
+            .setCheckpointPosition(checkpointPosition);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition + 1,
+            checkpointPosition,
+            CheckpointIntent.CREATED,
+            RecordType.EVENT,
+            value);
+
+    // when
+    processor.replay(record);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerOnInit() {
+    // given
+    final var context = new Context(zeebedb, zeebedb.createContext());
+    processor = new CheckpointRecordsProcessor(backupManager);
+    final long checkpointId = 3;
+    final long checkpointPosition = 30;
+    state.setCheckpointInfo(checkpointId, checkpointPosition);
+
+    // when
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+    processor.init(context);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
 }
",1,"[""e0198f74b81da3663144cfe1d971939319f82a0f""]","[""test""]"
Add the select function for logicflow | missing transformation for T | add react ecosystem,"diff --git a/packages/core/src/LogicFlow.tsx b/packages/core/src/LogicFlow.tsx
index 0d913b7..dcc59b3 100644
--- a/packages/core/src/LogicFlow.tsx
+++ b/packages/core/src/LogicFlow.tsx
@@ -276,6 +276,12 @@ export default class LogicFlow {
     this.translate(-TRANSLATE_X, -TRANSLATE_Y);
   }
   /**
+   * 
+   */
+  select(id: string) {
+    this.graphModel.selectElementById(id);
+  }
+  /**
    * 
    * @param focusOnArgs idtypeid
    */
diff --git a/packages/core/src/model/GraphModel.ts b/packages/core/src/model/GraphModel.ts
index 94d0899..10280a9 100644
--- a/packages/core/src/model/GraphModel.ts
+++ b/packages/core/src/model/GraphModel.ts
@@ -481,6 +481,13 @@ class GraphModel {
     this.selectElement?.setSelected(true);
   }
 
+  @action
+  selectElementById(id: string) {
+    this.selectElement?.setSelected(false);
+    this.selectElement = this.getElement(id) as BaseNodeModel | BaseEdgeModel;
+    this.selectElement?.setSelected(true);
+  }
+
   /*  */
   @action
   changeEdgeType(type: string): void {

diff --git a/src/Tuple/Merge.ts b/src/Tuple/Merge.ts
index dfa7ce5..5ba44b7 100644
--- a/src/Tuple/Merge.ts
+++ b/src/Tuple/Merge.ts
@@ -30,7 +30,7 @@ type _MergeFlat<O extends object, O1P extends object> = {
 }
 
 type MergeDeep<T extends any[], T1 extends any[]> =
-    TupleOf<Compute<_MergeDeep<T, Omit<ObjectOf<T1>, keyof T>, ObjectOf<T1>>>>
+    TupleOf<Compute<_MergeDeep<ObjectOf<T>, Omit<ObjectOf<T1>, keyof T>, ObjectOf<T1>>>>
     // same principle as above, but with a little tweak
     // we keep the original `O1` to know if we can merge
     // => if `O` and `O1` have `object` fields of same name

diff --git a/package.json b/package.json
index 1ba8c4f..d1de9a0 100644
--- a/package.json
+++ b/package.json
@@ -36,14 +36,19 @@
     ""@types/node"": ""^9.3.0"",
     ""@types/react"": ""^16.0.34"",
     ""@types/react-dom"": ""^16.0.3"",
+    ""@types/react-motion"": ""^0.0.25"",
     ""bootstrap-sass"": ""^3.3.7"",
     ""highcharts"": ""^6.0.4"",
     ""html2canvas"": ""^1.0.0-alpha.9"",
+    ""immer"": ""^1.2.1"",
     ""lodash"": ""^4.17.4"",
     ""moment"": ""^2.20.1"",
     ""normalize.css"": ""^8.0.0"",
-    ""react"": ""^16.2.0"",
-    ""react-dom"": ""^16.2.0"",
+    ""react"": ""^16.3.1"",
+    ""react-dom"": ""^16.3.1"",
+    ""react-motion"": ""^0.5.2"",
+    ""react-redux"": ""^5.0.7"",
+    ""redux"": ""^3.7.2"",
     ""rxjs"": ""^5.5.6"",
     ""vue"": ""^2.5.13"",
     ""vue-plugin-webextension-i18n"": ""^0.1.0"",
diff --git a/yarn.lock b/yarn.lock
index c8898d8..5d0fc9f 100644
--- a/yarn.lock
+++ b/yarn.lock
@@ -187,6 +187,12 @@
     ""@types/node"" ""*""
     ""@types/react"" ""*""
 
+""@types/react-motion@^0.0.25"":
+  version ""0.0.25""
+  resolved ""https://registry.npmjs.org/@types/react-motion/-/react-motion-0.0.25.tgz#2445745ee8e8e6149faa47a36ff6b0d4c21dbf94""
+  dependencies:
+    ""@types/react"" ""*""
+
 ""@types/react@*"", ""@types/react@^16.0.34"":
   version ""16.0.40""
   resolved ""https://registry.npmjs.org/@types/react/-/react-16.0.40.tgz#caabc2296886f40b67f6fc80f0f3464476461df9""
@@ -3837,6 +3843,10 @@ hoek@4.x.x:
   version ""4.2.1""
   resolved ""https://registry.npmjs.org/hoek/-/hoek-4.2.1.tgz#9634502aa12c445dd5a7c5734b572bb8738aacbb""
 
+hoist-non-react-statics@^2.5.0:
+  version ""2.5.0""
+  resolved ""https://registry.npmjs.org/hoist-non-react-statics/-/hoist-non-react-statics-2.5.0.tgz#d2ca2dfc19c5a91c5a6615ce8e564ef0347e2a40""
+
 home-or-tmp@^2.0.0:
   version ""2.0.0""
   resolved ""https://registry.npmjs.org/home-or-tmp/-/home-or-tmp-2.0.0.tgz#e36c3f2d2cae7d746a857e38d18d5f32a7882db8""
@@ -4004,6 +4014,10 @@ ignore@^3.3.5:
   version ""3.3.7""
   resolved ""https://registry.npmjs.org/ignore/-/ignore-3.3.7.tgz#612289bfb3c220e186a58118618d5be8c1bab021""
 
+immer@^1.2.1:
+  version ""1.2.1""
+  resolved ""https://registry.npmjs.org/immer/-/immer-1.2.1.tgz#96e2ae29cdfc428f28120b832701931b92fa597c""
+
 import-local@^1.0.0:
   version ""1.0.0""
   resolved ""https://registry.npmjs.org/import-local/-/import-local-1.0.0.tgz#5e4ffdc03f4fe6c009c6729beb29631c2f8227bc""
@@ -4104,7 +4118,7 @@ interpret@^1.0.0:
   version ""1.1.0""
   resolved ""https://registry.npmjs.org/interpret/-/interpret-1.1.0.tgz#7ed1b1410c6a0e0f78cf95d3b8440c63f78b8614""
 
-invariant@^2.2.2:
+invariant@^2.0.0, invariant@^2.2.2:
   version ""2.2.4""
   resolved ""https://registry.npmjs.org/invariant/-/invariant-2.2.4.tgz#610f3c92c9359ce1db616e538008d23ff35158e6""
   dependencies:
@@ -5040,6 +5054,10 @@ locate-path@^2.0.0:
     p-locate ""^2.0.0""
     path-exists ""^3.0.0""
 
+lodash-es@^4.17.5, lodash-es@^4.2.1:
+  version ""4.17.8""
+  resolved ""https://registry.npmjs.org/lodash-es/-/lodash-es-4.17.8.tgz#6fa8c8c5d337481df0bdf1c0d899d42473121e45""
+
 lodash._reinterpolate@~3.0.0:
   version ""3.0.0""
   resolved ""https://registry.npmjs.org/lodash._reinterpolate/-/lodash._reinterpolate-3.0.0.tgz#0ccf2d89166af03b3663c796538b75ac6e114d9d""
@@ -5149,7 +5167,7 @@ lodash@4.17.2:
   version ""4.17.2""
   resolved ""https://registry.npmjs.org/lodash/-/lodash-4.17.2.tgz#34a3055babe04ce42467b607d700072c7ff6bf42""
 
-lodash@4.x, lodash@^4.0.0, lodash@^4.13.1, lodash@^4.14.0, lodash@^4.16.3, lodash@^4.17.2, lodash@^4.17.3, lodash@^4.17.4, lodash@^4.2.0, lodash@^4.2.1, lodash@^4.3.0, lodash@~4.17.4:
+lodash@4.x, lodash@^4.0.0, lodash@^4.13.1, lodash@^4.14.0, lodash@^4.16.3, lodash@^4.17.2, lodash@^4.17.3, lodash@^4.17.4, lodash@^4.17.5, lodash@^4.2.0, lodash@^4.2.1, lodash@^4.3.0, lodash@~4.17.4:
   version ""4.17.5""
   resolved ""https://registry.npmjs.org/lodash/-/lodash-4.17.5.tgz#99a92d65c0272debe8c96b6057bc8fbfa3bed511""
 
@@ -6467,7 +6485,7 @@ promise@^7.1.1:
   dependencies:
     asap ""~2.0.3""
 
-prop-types@^15.6.0:
+prop-types@^15.5.8, prop-types@^15.6.0:
   version ""15.6.1""
   resolved ""https://registry.npmjs.org/prop-types/-/prop-types-15.6.1.tgz#36644453564255ddda391191fb3a125cbdf654ca""
   dependencies:
@@ -6574,7 +6592,7 @@ quick-lru@^1.0.0:
   version ""1.1.0""
   resolved ""https://registry.npmjs.org/quick-lru/-/quick-lru-1.1.0.tgz#4360b17c61136ad38078397ff11416e186dcfbb8""
 
-raf@3.4.0:
+raf@3.4.0, raf@^3.1.0:
   version ""3.4.0""
   resolved ""https://registry.npmjs.org/raf/-/raf-3.4.0.tgz#a28876881b4bc2ca9117d4138163ddb80f781575""
   dependencies:
@@ -6645,9 +6663,9 @@ react-dev-utils@^5.0.0:
     strip-ansi ""3.0.1""
     text-table ""0.2.0""
 
-react-dom@^16.2.0:
-  version ""16.2.0""
-  resolved ""https://registry.npmjs.org/react-dom/-/react-dom-16.2.0.tgz#69003178601c0ca19b709b33a83369fe6124c044""
+react-dom@^16.3.1:
+  version ""16.3.1""
+  resolved ""https://registry.npmjs.org/react-dom/-/react-dom-16.3.1.tgz#6a3c90a4fb62f915bdbcf6204422d93a7d4ca573""
   dependencies:
     fbjs ""^0.8.16""
     loose-envify ""^1.1.0""
@@ -6658,9 +6676,28 @@ react-error-overlay@^4.0.0:
   version ""4.0.0""
   resolved ""https://registry.npmjs.org/react-error-overlay/-/react-error-overlay-4.0.0.tgz#d198408a85b4070937a98667f500c832f86bd5d4""
 
-react@^16.2.0:
-  version ""16.2.0""
-  resolved ""https://registry.npmjs.org/react/-/react-16.2.0.tgz#a31bd2dab89bff65d42134fa187f24d054c273ba""
+react-motion@^0.5.2:
+  version ""0.5.2""
+  resolved ""https://registry.npmjs.org/react-motion/-/react-motion-0.5.2.tgz#0dd3a69e411316567927917c6626551ba0607316""
+  dependencies:
+    performance-now ""^0.2.0""
+    prop-types ""^15.5.8""
+    raf ""^3.1.0""
+
+react-redux@^5.0.7:
+  version ""5.0.7""
+  resolved ""https://registry.npmjs.org/react-redux/-/react-redux-5.0.7.tgz#0dc1076d9afb4670f993ffaef44b8f8c1155a4c8""
+  dependencies:
+    hoist-non-react-statics ""^2.5.0""
+    invariant ""^2.0.0""
+    lodash ""^4.17.5""
+    lodash-es ""^4.17.5""
+    loose-envify ""^1.1.0""
+    prop-types ""^15.6.0""
+
+react@^16.3.1:
+  version ""16.3.1""
+  resolved ""https://registry.npmjs.org/react/-/react-16.3.1.tgz#4a2da433d471251c69b6033ada30e2ed1202cfd8""
   dependencies:
     fbjs ""^0.8.16""
     loose-envify ""^1.1.0""
@@ -6788,6 +6825,15 @@ reduce-function-call@^1.0.1:
   dependencies:
     balanced-match ""^0.4.2""
 
+redux@^3.7.2:
+  version ""3.7.2""
+  resolved ""https://registry.npmjs.org/redux/-/redux-3.7.2.tgz#06b73123215901d25d065be342eb026bc1c8537b""
+  dependencies:
+    lodash ""^4.2.1""
+    lodash-es ""^4.2.1""
+    loose-envify ""^1.1.0""
+    symbol-observable ""^1.0.3""
+
 regenerate@^1.2.1:
   version ""1.3.3""
   resolved ""https://registry.npmjs.org/regenerate/-/regenerate-1.3.3.tgz#0c336d3980553d755c39b586ae3b20aa49c82b7f""
@@ -7811,6 +7857,10 @@ symbol-observable@1.0.1:
   version ""1.0.1""
   resolved ""https://registry.npmjs.org/symbol-observable/-/symbol-observable-1.0.1.tgz#8340fc4702c3122df5d22288f88283f513d3fdd4""
 
+symbol-observable@^1.0.3:
+  version ""1.2.0""
+  resolved ""https://registry.npmjs.org/symbol-observable/-/symbol-observable-1.2.0.tgz#c22688aed4eab3cdc2dfeacbb561660560a00804""
+
 symbol-tree@^3.2.2:
   version ""3.2.2""
   resolved ""https://registry.npmjs.org/symbol-tree/-/symbol-tree-3.2.2.tgz#ae27db38f660a7ae2e1c3b7d1bc290819b8519e6""
",3,"[""6ae067153cd2608018fd3da76bd6d00a08da4b3a"", ""c4d9e5023fa0f88ba283b37da27677ceda1cbfbb"", ""7e04a5e829d7416e312ac342a00a11787745753b""]","[""feat"", ""fix"", ""build""]"
render-svg | convert to record | pass absolute burnchain block height to pox sync watchdog so we correctly infer ibd status,"diff --git a/package.json b/package.json
index 3f8e5fa..cc4e398 100644
--- a/package.json
+++ b/package.json
@@ -42,6 +42,7 @@
     ""rollup"": ""^2.34.2"",
     ""rollup-plugin-copy"": ""^3.3.0"",
     ""rollup-plugin-dts"": ""^2.0.0"",
+    ""rollup-plugin-terser"": ""^7.0.2"",
     ""rollup-plugin-typescript2"": ""^0.29.0"",
     ""ts-jest"": ""^26.4.4"",
     ""tsup"": ""^3.10.1"",
diff --git a/packages/renderer-svg/package.json b/packages/renderer-svg/package.json
index fa9c049..6a0654c 100644
--- a/packages/renderer-svg/package.json
+++ b/packages/renderer-svg/package.json
@@ -1,16 +1,27 @@
 {
-  ""name"": ""shiki-renderer-svg"",
+  ""name"": ""@antfu/shiki-renderer-svg"",
   ""version"": ""0.2.0"",
   ""description"": ""SVG renderer for shiki"",
   ""author"": ""Pine Wu <octref@gmail.com>"",
   ""homepage"": ""https://github.com/octref/shiki/tree/master/packages/renderer-svg"",
   ""license"": ""MIT"",
-  ""main"": ""dist/index.js"",
-  ""types"": ""dist/index.d.ts"",
   ""repository"": {
     ""type"": ""git"",
     ""url"": ""git+https://github.com/shikijs/shiki.git""
   },
+  ""main"": ""dist/index.js"",
+  ""module"": ""dist/index.mjs"",
+  ""types"": ""dist/index.d.ts"",
+  ""unpkg"": ""dist/index.iife.min.js"",
+  ""jsdelivr"": ""dist/index.iife.min.js"",
+  ""files"": [
+    ""dist""
+  ],
+  ""scripts"": {
+    ""prepublishOnly"": ""npm run build"",
+    ""build"": ""rollup -c"",
+    ""watch"": ""rollup -c -w""
+  },
   ""dependencies"": {
     ""puppeteer"": ""^5.2.1""
   },
diff --git a/packages/renderer-svg/rollup.config.js b/packages/renderer-svg/rollup.config.js
new file mode 100644
index 0000000..d4e45ce
--- /dev/null
+++ b/packages/renderer-svg/rollup.config.js
@@ -0,0 +1,67 @@
+import { nodeResolve } from '@rollup/plugin-node-resolve'
+import commonjs from '@rollup/plugin-commonjs'
+import dts from 'rollup-plugin-dts'
+import typescript from 'rollup-plugin-typescript2'
+import replace from '@rollup/plugin-replace'
+import { terser } from 'rollup-plugin-terser'
+
+const external = ['shiki', 'puppeteer']
+
+export default [
+  {
+    input: 'src/index.ts',
+    external,
+    output: [
+      {
+        file: 'dist/index.js',
+        format: 'cjs'
+      },
+      {
+        file: 'dist/index.mjs',
+        format: 'esm'
+      }
+    ],
+    plugins: [
+      replace({
+        __BROWSER__: JSON.stringify(false)
+      }),
+      typescript(),
+      nodeResolve(),
+      commonjs()
+    ]
+  },
+  {
+    input: 'src/index.ts',
+    output: [
+      {
+        file: 'dist/index.iife.js',
+        format: 'iife',
+        name: 'ShikiRenderSVG'
+      },
+      {
+        file: 'dist/index.iife.min.js',
+        format: 'iife',
+        name: 'ShikiRenderSVG',
+        plugins: [terser()]
+      }
+    ],
+    plugins: [
+      replace({
+        __BROWSER__: JSON.stringify(true)
+      }),
+      typescript(),
+      nodeResolve(),
+      commonjs()
+    ]
+  },
+  {
+    input: 'src/index.ts',
+    output: [
+      {
+        file: 'dist/index.d.ts',
+        format: 'es'
+      }
+    ],
+    plugins: [dts()]
+  }
+]
diff --git a/packages/renderer-svg/src/global.d.ts b/packages/renderer-svg/src/global.d.ts
new file mode 100644
index 0000000..08c128f
--- /dev/null
+++ b/packages/renderer-svg/src/global.d.ts
@@ -0,0 +1 @@
+declare var __BROWSER__: boolean
diff --git a/packages/renderer-svg/src/index.ts b/packages/renderer-svg/src/index.ts
index ae77136..8f92312 100644
--- a/packages/renderer-svg/src/index.ts
+++ b/packages/renderer-svg/src/index.ts
@@ -1,4 +1,4 @@
-import { IThemedToken } from 'shiki'
+import type { IThemedToken } from 'shiki'
 import { measureMonospaceTypeface } from './measureMonospaceTypeface'
 
 interface SVGRendererOptions {
diff --git a/packages/renderer-svg/src/measureMonospaceTypeface.ts b/packages/renderer-svg/src/measureMonospaceTypeface.ts
index e28a1ff..6ab834d 100644
--- a/packages/renderer-svg/src/measureMonospaceTypeface.ts
+++ b/packages/renderer-svg/src/measureMonospaceTypeface.ts
@@ -1,58 +1,61 @@
-import puppeteer from 'puppeteer'
+function measureFont(fontName: string, fontSize: number) {
+  /**
+   * Measure `M` for width
+   */
+  var c = document.createElement('canvas')
+  var ctx = c.getContext('2d')!
+  ctx.font = `${fontSize}px ""${fontName}""`
 
-export async function measureMonospaceTypeface(
-  fontName: string,
-  fontSize: number
-): Promise<{ width: number; height: number }> {
-  const browser = await puppeteer.launch({ headless: true })
-  const page = await browser.newPage()
-  const measurement = await page.evaluate(measureFont, fontName, fontSize)
-  await browser.close()
-  return measurement
+  const capMMeasurement = ctx.measureText('M')
 
-  function measureFont(fontName: string, fontSize: number) {
-    /**
-     * Measure `M` for width
-     */
-    var c = document.createElement('canvas')
-    var ctx = c.getContext('2d')!
-    ctx.font = `${fontSize}px ""${fontName}""`
-
-    const capMMeasurement = ctx.measureText('M')
+  /**
+   * Measure A-Z, a-z for height
+   * A - 65
+   * Z - 90
+   * a - 97
+   * z - 122
+   */
+  const characters = []
+  for (let i = 65; i <= 90; i++) {
+    characters.push(String.fromCharCode(i))
+  }
+  for (let i = 97; i <= 122; i++) {
+    characters.push(String.fromCharCode(i))
+  }
 
-    /**
-     * Measure A-Z, a-z for height
-     * A - 65
-     * Z - 90
-     * a - 97
-     * z - 122
-     */
-    const characters = []
-    for (let i = 65; i <= 90; i++) {
-      characters.push(String.fromCharCode(i))
+  let highC, lowC
+  let highestAscent = 0
+  let lowestDescent = 0
+  characters.forEach(c => {
+    const m = ctx.measureText(c)
+    if (m.actualBoundingBoxAscent > highestAscent) {
+      highestAscent = m.actualBoundingBoxAscent
+      highC = c
     }
-    for (let i = 97; i <= 122; i++) {
-      characters.push(String.fromCharCode(i))
+    if (m.actualBoundingBoxDescent > lowestDescent) {
+      lowestDescent = m.actualBoundingBoxDescent
+      lowC = c
     }
+  })
 
-    let highC, lowC
-    let highestAscent = 0
-    let lowestDescent = 0
-    characters.forEach(c => {
-      const m = ctx.measureText(c)
-      if (m.actualBoundingBoxAscent > highestAscent) {
-        highestAscent = m.actualBoundingBoxAscent
-        highC = c
-      }
-      if (m.actualBoundingBoxDescent > lowestDescent) {
-        lowestDescent = m.actualBoundingBoxDescent
-        lowC = c
-      }
-    })
+  return {
+    width: capMMeasurement.width,
+    height: highestAscent + lowestDescent
+  }
+}
 
-    return {
-      width: capMMeasurement.width,
-      height: highestAscent + lowestDescent
-    }
+export async function measureMonospaceTypeface(
+  fontName: string,
+  fontSize: number
+): Promise<{ width: number; height: number }> {
+  if (__BROWSER__) {
+    return measureFont(fontName, fontSize)
+  } else {
+    const puppeteer = await import('puppeteer')
+    const browser = await puppeteer.launch({ headless: true })
+    const page = await browser.newPage()
+    const measurement = await page.evaluate(measureFont, fontName, fontSize)
+    await browser.close()
+    return measurement
   }
 }
diff --git a/packages/renderer-svg/tsconfig.json b/packages/renderer-svg/tsconfig.json
index 3613212..bc50ce3 100644
--- a/packages/renderer-svg/tsconfig.json
+++ b/packages/renderer-svg/tsconfig.json
@@ -1,9 +1,10 @@
 {
-  ""extends"": ""../../tsconfig.json"",
   ""compilerOptions"": {
-    ""composite"": true,
-    ""rootDir"": ""src"",
-    ""outDir"": ""dist"",
-    ""lib"": [""dom""]
+    ""module"": ""esnext"",
+    ""target"": ""es2017"",
+    ""esModuleInterop"": true,
+    ""moduleResolution"": ""node"",
+    ""lib"": [""esnext"", ""DOM""],
+    ""sourceMap"": true
   }
 }
diff --git a/packages/shiki/rollup.config.js b/packages/shiki/rollup.config.js
index b8ba9e3..9078ea2 100644
--- a/packages/shiki/rollup.config.js
+++ b/packages/shiki/rollup.config.js
@@ -4,6 +4,7 @@ import dts from 'rollup-plugin-dts'
 import typescript from 'rollup-plugin-typescript2'
 import copy from 'rollup-plugin-copy'
 import replace from '@rollup/plugin-replace'
+import { terser } from 'rollup-plugin-terser'
 import { version } from './package.json'
 
 const external = ['onigasm', 'vscode-textmate']
@@ -22,7 +23,14 @@ export default [
         format: 'esm'
       }
     ],
-    plugins: [typescript(), nodeResolve(), commonjs()]
+    plugins: [
+      replace({
+        __BROWSER__: JSON.stringify(false)
+      }),
+      typescript(),
+      nodeResolve(),
+      commonjs()
+    ]
   },
   {
     input: 'src/index.ts',
@@ -58,7 +66,15 @@ export default [
         ]
       }
     ],
-    plugins: [typescript(), nodeResolve(), commonjs()]
+    plugins: [
+      replace({
+        __BROWSER__: JSON.stringify(true)
+      }),
+      typescript(),
+      nodeResolve(),
+      commonjs(),
+      terser()
+    ]
   },
   {
     input: 'src/index.ts',
diff --git a/packages/shiki/src/global.d.ts b/packages/shiki/src/global.d.ts
new file mode 100644
index 0000000..08c128f
--- /dev/null
+++ b/packages/shiki/src/global.d.ts
@@ -0,0 +1 @@
+declare var __BROWSER__: boolean
diff --git a/packages/shiki/src/loader.ts b/packages/shiki/src/loader.ts
index 934cfbd..d9c3128 100644
--- a/packages/shiki/src/loader.ts
+++ b/packages/shiki/src/loader.ts
@@ -5,11 +5,16 @@ import type { ILanguageRegistration, IShikiTheme } from './types'
 export const isBrowser = typeof window !== 'undefined' && typeof window.document !== 'undefined'
 
 let CDN_ROOT = '__CDN_ROOT__'
+let ONIGASM_WASM = ''
 
 export function setCDN(root: string) {
   CDN_ROOT = root
 }
 
+export function setOnigasmWASM(path: string) {
+  ONIGASM_WASM = path
+}
+
 let _onigasmPromise: Promise<IOnigLib> = null
 
 export async function getOnigasm(): Promise<IOnigLib> {
@@ -17,7 +22,7 @@ export async function getOnigasm(): Promise<IOnigLib> {
     let loader: Promise<any>
 
     if (isBrowser) {
-      loader = Onigasm.loadWASM(_resolvePath('onigasm.wasm', 'dist/'))
+      loader = Onigasm.loadWASM(ONIGASM_WASM || _resolvePath('onigasm.wasm', 'dist/'))
     } else {
       const path = require('path')
       const onigasmPath = path.join(require.resolve('onigasm'), '../onigasm.wasm')
diff --git a/yarn.lock b/yarn.lock
index c143969..dfd7540 100644
--- a/yarn.lock
+++ b/yarn.lock
@@ -2487,6 +2487,11 @@ combined-stream@^1.0.6, combined-stream@~1.0.6:
   dependencies:
     delayed-stream ""~1.0.0""
 
+commander@^2.20.0, commander@~2.20.3:
+  version ""2.20.3""
+  resolved ""https://registry.yarnpkg.com/commander/-/commander-2.20.3.tgz#fd485e84c03eb4881c20722ba48035e8531aeb33""
+  integrity sha512-GpVkmM8vF2vQUkj2LvZmD35JxeJOLCwJ9cUkugyk2nuhbv3+mJvpLYYt+0+USMxE+oj+ey/lJEnhZw75x/OMcQ==
+
 commander@^4.0.0:
   version ""4.1.1""
   resolved ""https://registry.yarnpkg.com/commander/-/commander-4.1.1.tgz#9fd602bd936294e9e9ef46a3f4d6964044b18068""
@@ -2497,11 +2502,6 @@ commander@^6.2.0:
   resolved ""https://registry.yarnpkg.com/commander/-/commander-6.2.0.tgz#b990bfb8ac030aedc6d11bc04d1488ffef56db75""
   integrity sha512-zP4jEKbe8SHzKJYQmq8Y9gYjtO/POJLgIdKgV7B9qNmABVFVc+ctqSX6iXh4mCpJfRBOabiZ2YKPg8ciDw6C+Q==
 
-commander@~2.20.3:
-  version ""2.20.3""
-  resolved ""https://registry.yarnpkg.com/commander/-/commander-2.20.3.tgz#fd485e84c03eb4881c20722ba48035e8531aeb33""
-  integrity sha512-GpVkmM8vF2vQUkj2LvZmD35JxeJOLCwJ9cUkugyk2nuhbv3+mJvpLYYt+0+USMxE+oj+ey/lJEnhZw75x/OMcQ==
-
 commondir@^1.0.1:
   version ""1.0.1""
   resolved ""https://registry.yarnpkg.com/commondir/-/commondir-1.0.1.tgz#ddd800da0c66127393cca5950ea968a3aaf1253b""
@@ -4799,7 +4799,7 @@ jest-watcher@^26.6.2:
     jest-util ""^26.6.2""
     string-length ""^4.0.1""
 
-jest-worker@^26.6.2:
+jest-worker@^26.2.1, jest-worker@^26.6.2:
   version ""26.6.2""
   resolved ""https://registry.yarnpkg.com/jest-worker/-/jest-worker-26.6.2.tgz#7f72cbc4d643c365e27b9fd775f9d0eaa9c7a8ed""
   integrity sha512-KWYVV1c4i+jbMpaBC+U++4Va0cp8OisU185o73T1vo99hqi7w8tSJfUXYswwqqrjzwxa6KpRK54WhPvwf5w6PQ==
@@ -6444,6 +6444,13 @@ quick-lru@^4.0.1:
   resolved ""https://registry.yarnpkg.com/quick-lru/-/quick-lru-4.0.1.tgz#5b8878f113a58217848c6482026c73e1ba57727f""
   integrity sha512-ARhCpm70fzdcvNQfPoy49IaanKkTlRWF2JMzqhcJbhSFRZv7nPTvZJdcY7301IPmvW+/p0RgIWnQDLJxifsQ7g==
 
+randombytes@^2.1.0:
+  version ""2.1.0""
+  resolved ""https://registry.yarnpkg.com/randombytes/-/randombytes-2.1.0.tgz#df6f84372f0270dc65cdf6291349ab7a473d4f2a""
+  integrity sha512-vYl3iOX+4CKUWuxGi9Ukhie6fsqXqS9FE2Zaic4tNFD2N2QQaXOMFbuKK4QmDHC0JO6B1Zp41J0LpT0oR68amQ==
+  dependencies:
+    safe-buffer ""^5.1.0""
+
 react-is@^17.0.1:
   version ""17.0.1""
   resolved ""https://registry.yarnpkg.com/react-is/-/react-is-17.0.1.tgz#5b3531bd76a645a4c9fb6e693ed36419e3301339""
@@ -6812,6 +6819,16 @@ rollup-plugin-dts@^2.0.0:
   optionalDependencies:
     ""@babel/code-frame"" ""^7.10.4""
 
+rollup-plugin-terser@^7.0.2:
+  version ""7.0.2""
+  resolved ""https://registry.yarnpkg.com/rollup-plugin-terser/-/rollup-plugin-terser-7.0.2.tgz#e8fbba4869981b2dc35ae7e8a502d5c6c04d324d""
+  integrity sha512-w3iIaU4OxcF52UUXiZNsNeuXIMDvFrr+ZXK6bFZ0Q60qyVfq4uLptoS4bbq3paG3x216eQllFZX7zt6TIImguQ==
+  dependencies:
+    ""@babel/code-frame"" ""^7.10.4""
+    jest-worker ""^26.2.1""
+    serialize-javascript ""^4.0.0""
+    terser ""^5.0.0""
+
 rollup-plugin-typescript2@^0.29.0:
   version ""0.29.0""
   resolved ""https://registry.yarnpkg.com/rollup-plugin-typescript2/-/rollup-plugin-typescript2-0.29.0.tgz#b7ad83f5241dbc5bdf1e98d9c3fca005ffe39e1a""
@@ -6873,7 +6890,7 @@ safe-buffer@^5.0.1, safe-buffer@^5.1.1, safe-buffer@^5.1.2, safe-buffer@~5.1.0, 
   resolved ""https://registry.yarnpkg.com/safe-buffer/-/safe-buffer-5.1.2.tgz#991ec69d296e0313747d59bdfd2b745c35f8828d""
   integrity sha512-Gd2UZBJDkXlY7GbJxfsE8/nvKkUEU1G38c1siN6QP6a9PT9MmHB8GnpscSmMJSoF8LOIrt8ud/wPtojys4G6+g==
 
-safe-buffer@^5.2.0, safe-buffer@~5.2.0:
+safe-buffer@^5.1.0, safe-buffer@^5.2.0, safe-buffer@~5.2.0:
   version ""5.2.1""
   resolved ""https://registry.yarnpkg.com/safe-buffer/-/safe-buffer-5.2.1.tgz#1eaf9fa9bdb1fdd4ec75f58f9cdb4e6b7827eec6""
   integrity sha512-rp3So07KcdmmKbGvgaNxQSJr7bGVSVk5S9Eq1F+ppbRo70+YeaDxkw5Dd8NPN+GD6bjnYm2VuPuCXmpuYvmCXQ==
@@ -6937,6 +6954,13 @@ semver@^6.0.0, semver@^6.2.0, semver@^6.3.0:
   resolved ""https://registry.yarnpkg.com/semver/-/semver-6.3.0.tgz#ee0a64c8af5e8ceea67687b133761e1becbd1d3d""
   integrity sha512-b39TBaTSfV6yBrapU89p5fKekE2m/NwnDocOVruQFS1/veMgdzuPcnOM34M6CwxW8jH/lxEa5rBoDeUwu5HHTw==
 
+serialize-javascript@^4.0.0:
+  version ""4.0.0""
+  resolved ""https://registry.yarnpkg.com/serialize-javascript/-/serialize-javascript-4.0.0.tgz#b525e1238489a5ecfc42afacc3fe99e666f4b1aa""
+  integrity sha512-GaNA54380uFefWghODBWEGisLZFj00nS5ACs6yHa9nLqlLpVLO8ChDGeKRjZnV4Nh4n0Qi7nhYZD/9fCPzEqkw==
+  dependencies:
+    randombytes ""^2.1.0""
+
 set-blocking@^2.0.0, set-blocking@~2.0.0:
   version ""2.0.0""
   resolved ""https://registry.yarnpkg.com/set-blocking/-/set-blocking-2.0.0.tgz#045f9782d011ae9a6803ddd382b24392b3d890f7""
@@ -7140,7 +7164,7 @@ source-map-resolve@^0.5.0:
     source-map-url ""^0.4.0""
     urix ""^0.1.0""
 
-source-map-support@^0.5.6:
+source-map-support@^0.5.6, source-map-support@~0.5.19:
   version ""0.5.19""
   resolved ""https://registry.yarnpkg.com/source-map-support/-/source-map-support-0.5.19.tgz#a98b62f86dcaf4f67399648c085291ab9e8fed61""
   integrity sha512-Wonm7zOCIJzBGQdB+thsPar0kYuCIzYvxZwlBa87yi/Mdjv7Tip2cyVbLj5o0cFPN4EVkuTwb3GDDyUx2DGnGw==
@@ -7163,7 +7187,7 @@ source-map@^0.6.0, source-map@^0.6.1, source-map@~0.6.1:
   resolved ""https://registry.yarnpkg.com/source-map/-/source-map-0.6.1.tgz#74722af32e9614e9c287a8d0bbde48b5e2f1a263""
   integrity sha512-UjgapumWlbMhkBgzT7Ykc5YXUT46F0iKu8SGXq0bcwP5dz/h0Plj6enJqjz1Zbq2l5WaqYnrVbwWOWMyF3F47g==
 
-source-map@^0.7.3:
+source-map@^0.7.3, source-map@~0.7.2:
   version ""0.7.3""
   resolved ""https://registry.yarnpkg.com/source-map/-/source-map-0.7.3.tgz#5302f8169031735226544092e64981f751750383""
   integrity sha512-CkCj6giN3S+n9qrYiBTX5gystlENnRW5jZeNLHpe6aue+SrHcG5VYwujhW9s4dY31mEGsxBDrHR6oI69fTXsaQ==
@@ -7552,6 +7576,15 @@ terminal-link@^2.0.0:
     ansi-escapes ""^4.2.1""
     supports-hyperlinks ""^2.0.0""
 
+terser@^5.0.0:
+  version ""5.5.1""
+  resolved ""https://registry.yarnpkg.com/terser/-/terser-5.5.1.tgz#540caa25139d6f496fdea056e414284886fb2289""
+  integrity sha512-6VGWZNVP2KTUcltUQJ25TtNjx/XgdDsBDKGt8nN0MpydU36LmbPPcMBd2kmtZNNGVVDLg44k7GKeHHj+4zPIBQ==
+  dependencies:
+    commander ""^2.20.0""
+    source-map ""~0.7.2""
+    source-map-support ""~0.5.19""
+
 test-exclude@^6.0.0:
   version ""6.0.0""
   resolved ""https://registry.yarnpkg.com/test-exclude/-/test-exclude-6.0.0.tgz#04a8698661d805ea6fa293b6cb9e63ac044ef15e""

diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
index cc998c6..65c8550 100755
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
@@ -167,13 +167,8 @@ public final class ExporterDirectorDistributionTest {
    * <p>This makes sure that even if we miss one export position event, we distribute the event
    * later again, which makes tests less flaky.
    */
-  private static final class ClockShifter implements ConditionEvaluationListener<Void> {
-
-    private final ControlledActorClock clock;
-
-    public ClockShifter(final ControlledActorClock clock) {
-      this.clock = clock;
-    }
+  private record ClockShifter(ControlledActorClock clock)
+      implements ConditionEvaluationListener<Void> {
 
     @Override
     public void conditionEvaluated(final EvaluatedCondition<Void> condition) {

diff --git a/testnet/stacks-node/src/run_loop/neon.rs b/testnet/stacks-node/src/run_loop/neon.rs
index 677749b..dc4a7bd 100644
--- a/testnet/stacks-node/src/run_loop/neon.rs
+++ b/testnet/stacks-node/src/run_loop/neon.rs
@@ -411,7 +411,6 @@ impl RunLoop {
 
         let mut burnchain_height = sortition_db_height;
         let mut num_sortitions_in_last_cycle = 1;
-        let mut learned_burnchain_height = false;
 
         // prepare to fetch the first reward cycle!
         target_burnchain_block_height = burnchain_height + pox_constants.reward_cycle_length as u64;
@@ -439,18 +438,16 @@ impl RunLoop {
                 break;
             }
 
+            let remote_chain_height = burnchain.get_headers_height();
+
             // wait for the p2p state-machine to do at least one pass
-            debug!(""Wait until we reach steady-state before processing more burnchain blocks..."");
+            debug!(""Wait until we reach steady-state before processing more burnchain blocks (chain height is {}, we are at {})..."", remote_chain_height, burnchain_height);
 
             // wait until it's okay to process the next sortitions
             let ibd = match pox_watchdog.pox_sync_wait(
                 &burnchain_config,
                 &burnchain_tip,
-                if learned_burnchain_height {
-                    Some(burnchain_height)
-                } else {
-                    None
-                },
+                Some(remote_chain_height),
                 num_sortitions_in_last_cycle,
             ) {
                 Ok(ibd) => ibd,
@@ -478,7 +475,6 @@ impl RunLoop {
                     };
 
                 // *now* we know the burnchain height
-                learned_burnchain_height = true;
                 burnchain_tip = next_burnchain_tip;
                 burnchain_height = cmp::min(burnchain_height + 1, target_burnchain_block_height);
 
",3,"[""ace6b981c8098a68092d4a10e75daae7b8bfee9b"", ""3346331a963766c8193170fb130adad2e658ada2"", ""5b70e008c57efc89da4061f9adb7d0491b2ea644""]","[""feat"", ""refactor"", ""fix""]"
"do not pin time in tests but only skip ahead

related to #573","diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
index 636cd21..76afff7 100644
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
@@ -15,7 +15,9 @@
  */
 package io.zeebe.broker.it.startup;
 
-import static io.zeebe.broker.it.util.TopicEventRecorder.*;
+import static io.zeebe.broker.it.util.TopicEventRecorder.incidentEvent;
+import static io.zeebe.broker.it.util.TopicEventRecorder.taskEvent;
+import static io.zeebe.broker.it.util.TopicEventRecorder.wfInstanceEvent;
 import static io.zeebe.test.util.TestUtil.doRepeatedly;
 import static io.zeebe.test.util.TestUtil.waitUntil;
 import static org.assertj.core.api.Assertions.assertThat;
@@ -24,11 +26,18 @@ import java.io.File;
 import java.io.InputStream;
 import java.nio.charset.StandardCharsets;
 import java.time.Duration;
-import java.time.Instant;
 import java.util.Collections;
 import java.util.List;
 import java.util.regex.Pattern;
 
+import org.assertj.core.util.Files;
+import org.junit.After;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.ExpectedException;
+import org.junit.rules.RuleChain;
+import org.junit.rules.TemporaryFolder;
+
 import io.zeebe.broker.clustering.ClusterServiceNames;
 import io.zeebe.broker.it.ClientRule;
 import io.zeebe.broker.it.EmbeddedBrokerRule;
@@ -38,7 +47,9 @@ import io.zeebe.client.ZeebeClient;
 import io.zeebe.client.clustering.impl.TopicLeader;
 import io.zeebe.client.clustering.impl.TopologyResponse;
 import io.zeebe.client.cmd.ClientCommandRejectedException;
-import io.zeebe.client.event.*;
+import io.zeebe.client.event.DeploymentEvent;
+import io.zeebe.client.event.TaskEvent;
+import io.zeebe.client.event.WorkflowInstanceEvent;
 import io.zeebe.model.bpmn.Bpmn;
 import io.zeebe.model.bpmn.instance.WorkflowDefinition;
 import io.zeebe.raft.Raft;
@@ -48,9 +59,6 @@ import io.zeebe.test.util.TestFileUtil;
 import io.zeebe.test.util.TestUtil;
 import io.zeebe.transport.SocketAddress;
 import io.zeebe.util.time.ClockUtil;
-import org.assertj.core.util.Files;
-import org.junit.*;
-import org.junit.rules.*;
 
 public class BrokerRecoveryTest
 {
@@ -360,17 +368,12 @@ public class BrokerRecoveryTest
         waitUntil(() -> !recordingTaskHandler.getHandledTasks().isEmpty());
 
         // when
-        restartBroker(() ->
-        {
-            final Instant now = ClockUtil.getCurrentTime();
-            ClockUtil.setCurrentTime(now.plusSeconds(60));
-        });
+        restartBroker(() -> ClockUtil.addTime(Duration.ofSeconds(60)));
 
         // wait until stream processor and scheduler process the lock task event which is not re-processed on recovery
         doRepeatedly(() ->
         {
-            final Instant now = ClockUtil.getCurrentTime();
-            ClockUtil.setCurrentTime(now.plusSeconds(60));
+            ClockUtil.addTime(Duration.ofSeconds(60)); // retriggers lock expiration check in broker
             return null;
         }).until(t -> eventRecorder.hasTaskEvent(taskEvent(""LOCK_EXPIRED"")));
 
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRestartTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRestartTest.java
index 5ff1301..0ffe98d 100644
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRestartTest.java
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRestartTest.java
@@ -15,7 +15,9 @@
  */
 package io.zeebe.broker.it.startup;
 
-import static io.zeebe.broker.it.util.TopicEventRecorder.*;
+import static io.zeebe.broker.it.util.TopicEventRecorder.incidentEvent;
+import static io.zeebe.broker.it.util.TopicEventRecorder.taskEvent;
+import static io.zeebe.broker.it.util.TopicEventRecorder.wfInstanceEvent;
 import static io.zeebe.test.util.TestUtil.waitUntil;
 import static org.assertj.core.api.Assertions.assertThat;
 
@@ -23,11 +25,18 @@ import java.io.File;
 import java.io.InputStream;
 import java.nio.charset.StandardCharsets;
 import java.time.Duration;
-import java.time.Instant;
 import java.util.Collections;
 import java.util.List;
 import java.util.regex.Pattern;
 
+import org.junit.After;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.experimental.categories.Category;
+import org.junit.rules.ExpectedException;
+import org.junit.rules.RuleChain;
+import org.junit.rules.TemporaryFolder;
+
 import io.zeebe.broker.clustering.ClusterServiceNames;
 import io.zeebe.broker.it.ClientRule;
 import io.zeebe.broker.it.EmbeddedBrokerRule;
@@ -37,7 +46,9 @@ import io.zeebe.client.ZeebeClient;
 import io.zeebe.client.clustering.impl.TopicLeader;
 import io.zeebe.client.clustering.impl.TopologyResponse;
 import io.zeebe.client.cmd.ClientCommandRejectedException;
-import io.zeebe.client.event.*;
+import io.zeebe.client.event.DeploymentEvent;
+import io.zeebe.client.event.TaskEvent;
+import io.zeebe.client.event.WorkflowInstanceEvent;
 import io.zeebe.model.bpmn.Bpmn;
 import io.zeebe.model.bpmn.instance.WorkflowDefinition;
 import io.zeebe.raft.Raft;
@@ -47,9 +58,6 @@ import io.zeebe.test.util.TestFileUtil;
 import io.zeebe.test.util.TestUtil;
 import io.zeebe.transport.SocketAddress;
 import io.zeebe.util.time.ClockUtil;
-import org.junit.*;
-import org.junit.experimental.categories.Category;
-import org.junit.rules.*;
 
 public class BrokerRestartTest
 {
@@ -360,11 +368,7 @@ public class BrokerRestartTest
         waitUntil(() -> !recordingTaskHandler.getHandledTasks().isEmpty());
 
         // when
-        restartBroker(() ->
-        {
-            final Instant now = ClockUtil.getCurrentTime();
-            ClockUtil.setCurrentTime(now.plusSeconds(60));
-        });
+        restartBroker(() -> ClockUtil.addTime(Duration.ofSeconds(60)));
 
         waitUntil(() -> eventRecorder.hasTaskEvent(taskEvent(""LOCK_EXPIRED"")));
         recordingTaskHandler.clear();
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/task/TaskSubscriptionTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/task/TaskSubscriptionTest.java
index 49b527d..a322fbe 100644
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/task/TaskSubscriptionTest.java
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/task/TaskSubscriptionTest.java
@@ -353,7 +353,7 @@ public class TaskSubscriptionTest
         waitUntil(() -> taskHandler.getHandledTasks().size() == 1);
 
         // when
-        ClockUtil.setCurrentTime(Instant.now().plus(Duration.ofMinutes(5)));
+        ClockUtil.addTime(Duration.ofMinutes(5));
 
         // then
         waitUntil(() -> taskHandler.getHandledTasks().size() == 2);
",1,"[""7ece3a9a16780dc6c633bbd903d36ce0aefd6a8a""]","[""test""]"
add tests,"diff --git a/Cargo.lock b/Cargo.lock
index 84d5d07..6ad05da 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -293,6 +293,7 @@ version = ""0.1.0""
 dependencies = [
  ""git-cliff-core"",
  ""log"",
+ ""pretty_assertions"",
  ""pretty_env_logger"",
  ""structopt"",
 ]
diff --git a/git-cliff-core/src/lib.rs b/git-cliff-core/src/lib.rs
index 3b18ba0..a560c94 100644
--- a/git-cliff-core/src/lib.rs
+++ b/git-cliff-core/src/lib.rs
@@ -1,6 +1,8 @@
 //! Highly customizable Changelog Generator
 #![warn(missing_docs, clippy::unwrap_used)]
 
+/// Export regex crate.
+pub use regex;
 /// Git commit.
 pub mod commit;
 /// Config file parser.
diff --git a/git-cliff/Cargo.toml b/git-cliff/Cargo.toml
index 41eb2e9..cc64b37 100644
--- a/git-cliff/Cargo.toml
+++ b/git-cliff/Cargo.toml
@@ -20,3 +20,6 @@ log = ""0.4.14""
 version = ""0.3""
 default-features = false
 features = [""suggestions"", ""color"", ""wrap_help""]
+
+[dev-dependencies]
+pretty_assertions = ""0.7""
diff --git a/git-cliff/src/changelog.rs b/git-cliff/src/changelog.rs
index 3f9e994..23ea186 100644
--- a/git-cliff/src/changelog.rs
+++ b/git-cliff/src/changelog.rs
@@ -115,3 +115,171 @@ impl<'a> Changelog<'a> {
 		Ok(())
 	}
 }
+
+#[cfg(test)]
+mod test {
+	use super::*;
+	use git_cliff_core::config::{
+		ChangelogConfig,
+		CommitParser,
+		GitConfig,
+	};
+	use git_cliff_core::regex::Regex;
+	use pretty_assertions::assert_eq;
+	use std::str;
+	#[test]
+	fn changelog_generator() -> Result<()> {
+		let config = Config {
+			changelog: ChangelogConfig {
+				header: Some(String::from(""# Changelog"")),
+				body:   String::from(
+					r#""{% if version %}
+				## Release [{{ version }}] - {{ timestamp | date(format=""%Y-%m-%d"") }}
+				({{ commit_id }}){% else %}
+				## Unreleased{% endif %}
+				{% for group, commits in commits | group_by(attribute=""group"") %}
+				### {{ group }}{% for group, commits in commits | group_by(attribute=""scope"") %}
+				#### {{ group }}{% for commit in commits %}
+				- {{ commit.message }}{% endfor %}
+				{% endfor %}{% endfor %}""#,
+				)
+				.replace(""				"", """"),
+				footer: Some(String::from(""------------"")),
+			},
+			git:       GitConfig {
+				conventional_commits: true,
+				commit_parsers:       Some(vec![
+					CommitParser {
+						message: Regex::new(""feat*"").ok(),
+						body:    None,
+						group:   Some(String::from(""New features"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new(""fix*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Bug Fixes"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new("".*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Other"")),
+						skip:    None,
+					},
+				]),
+				filter_commits:       Some(false),
+				tag_pattern:          String::new(),
+				skip_tags:            Regex::new(""v3.*"").ok(),
+			},
+		};
+		let test_release = Release {
+			version:   Some(String::from(""v1.0.0"")),
+			commits:   vec![
+				Commit::new(
+					String::from(""0bc123""),
+					String::from(""feat(app): add cool features""),
+				),
+				Commit::new(
+					String::from(""0werty""),
+					String::from(""style(ui): make good stuff""),
+				),
+				Commit::new(
+					String::from(""0w3rty""),
+					String::from(""fix(ui): fix more stuff""),
+				),
+				Commit::new(
+					String::from(""0jkl12""),
+					String::from(""chore(app): do nothing""),
+				),
+			],
+			commit_id: Some(String::from(""0bc123"")),
+			timestamp: 50000000,
+			previous:  None,
+		};
+		let releases = vec![
+			test_release.clone(),
+			Release {
+				version: Some(String::from(""v3.0.0"")),
+				commits: vec![Commit::new(
+					String::from(""n0thin""),
+					String::from(""feat(xyz): skip commit""),
+				)],
+				..Release::default()
+			},
+			Release {
+				version:   None,
+				commits:   vec![
+					Commit::new(
+						String::from(""abc123""),
+						String::from(""feat(app): add xyz""),
+					),
+					Commit::new(
+						String::from(""abc124""),
+						String::from(""docs(app): document zyx""),
+					),
+					Commit::new(String::from(""def789""), String::from(""merge #4"")),
+					Commit::new(
+						String::from(""qwerty""),
+						String::from(""fix(app): fix abc""),
+					),
+					Commit::new(
+						String::from(""hjkl12""),
+						String::from(""chore(ui): do boring stuff""),
+					),
+				],
+				commit_id: None,
+				timestamp: 1000,
+				previous:  Some(Box::new(test_release)),
+			},
+		];
+		let changelog = Changelog::new(releases, &config)?;
+		let mut out = Vec::new();
+		changelog.generate(&mut out)?;
+		assert_eq!(
+			String::from(
+				r#""# Changelog
+
+			## Unreleased
+
+			### Bug Fixes
+			#### app
+			- fix abc
+
+			### New features
+			#### app
+			- add xyz
+
+			### Other
+			#### app
+			- document zyx
+
+			#### ui
+			- do boring stuff
+
+			## Release [v1.0.0] - 1971-08-02
+			(0bc123)
+
+			### Bug Fixes
+			#### ui
+			- fix more stuff
+
+			### New features
+			#### app
+			- add cool features
+
+			### Other
+			#### app
+			- do nothing
+
+			#### ui
+			- make good stuff
+			------------
+			""#
+			)
+			.replace(""			"", """"),
+			str::from_utf8(&out).unwrap()
+		);
+		Ok(())
+	}
+}
",1,"[""8ee0611fbf0cd89abe7ae588f22e6ecb843598ea""]","[""test""]"
Fix windows build,"diff --git a/src/fs/mounts/mod.rs b/src/fs/mounts/mod.rs
index a7f8188..662e2f5 100644
--- a/src/fs/mounts/mod.rs
+++ b/src/fs/mounts/mod.rs
@@ -29,11 +29,14 @@ impl std::error::Error for Error {}
 
 impl std::fmt::Display for Error {
     fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
+        // Allow unreachable_patterns for windows build
+        #[allow(unreachable_patterns)]
         match self {
             #[cfg(target_os = ""macos"")]
             Error::GetFSStatError(err) => write!(f, ""getfsstat failed: {err}""),
             #[cfg(target_os = ""linux"")]
-            Error::IOError(err) => write!(f, ""failed to read /proc/mounts: {err}"")
+            Error::IOError(err) => write!(f, ""failed to read /proc/mounts: {err}""),
+            _ => write!(f, ""Unknown error""),
         }
     }
 }
\ No newline at end of file
diff --git a/src/main.rs b/src/main.rs
index 483e14d..ca28081 100644
--- a/src/main.rs
+++ b/src/main.rs
@@ -62,6 +62,8 @@ mod theme;
 // to `clap` is complete.
 lazy_static! {
     static ref ALL_MOUNTS: HashMap<PathBuf, mounts::MountedFs> = {
+        // Allow unused_mut for windows
+        #[allow(unused_mut)]
         let mut mount_map: HashMap<PathBuf, mounts::MountedFs> = HashMap::new();
 
         #[cfg(any(target_os = ""linux"", target_os = ""macos""))]
",1,"[""81ca000c6a7e7435809081c60be37dda23458ec8""]","[""build""]"
"nginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com> | tests | add gitignore.nix to dep update matrix","diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection

diff --git a/client/src/components/Profile/__test__/EducationCard.test.tsx b/client/src/components/Profile/__test__/EducationCard.test.tsx
index 44b6e00..14539dd 100644
--- a/client/src/components/Profile/__test__/EducationCard.test.tsx
+++ b/client/src/components/Profile/__test__/EducationCard.test.tsx
@@ -53,7 +53,7 @@ describe('EducationCard', () => {
   });
 
   describe('filterPermissions', () => {
-    it('should left only contacts in ""permissionsSettings"" object', () => {
+    it('should left only ""isEducationVisible"" in ""permissionsSettings"" object', () => {
       const permissionsSettings = {
         isProfileVisible: { all: true },
         isAboutVisible: { all: true, mentor: true, student: true },
diff --git a/client/src/components/Profile/__test__/MainCard.test.tsx b/client/src/components/Profile/__test__/MainCard.test.tsx
index 8fb2840..552804b 100644
--- a/client/src/components/Profile/__test__/MainCard.test.tsx
+++ b/client/src/components/Profile/__test__/MainCard.test.tsx
@@ -3,6 +3,8 @@ import { shallow } from 'enzyme';
 import { shallowToJson } from 'enzyme-to-json';
 import MainCard from '../MainCard';
 
+// TODO: Known Issue: https://stackoverflow.com/questions/59942808/how-can-i-use-jest-coverage-in-next-js-styled-jsx
+
 describe('MainCard', () => {
   describe('Should render correctly', () => {
     it('if is editing mode disabled', () => {
@@ -21,49 +23,89 @@ describe('MainCard', () => {
       );
       expect(shallowToJson(output)).toMatchSnapshot();
     });
+    it('if is editing mode enabled', () => {
+      const output = shallow(
+        <MainCard
+          data={{
+            name: 'Petr Pervyi',
+            githubId: 'piter',
+            locationName: 'SPB',
+            locationId: '1',
+          }}
+          isEditingModeEnabled={true}
+          onPermissionsSettingsChange={() => {}}
+          onProfileSettingsChange={() => {}}
+        />,
+      );
+      expect(shallowToJson(output)).toMatchSnapshot();
+    });
   });
 
-  // const wrapper = shallow(
-  //   <MainCard
-  //     data={{
-  //       name: 'Petr Pervyi',
-  //       githubId: 'piter',
-  //       locationName: 'SPB',
-  //       locationId: '1',
-  //     }}
-  //     isEditingModeEnabled={false}
-  //     onPermissionsSettingsChange={() => {}}
-  //     onProfileSettingsChange={() => {}}
-  //   />);
-  // const instance = wrapper.instance();
-  // describe('showVisibilitySettings', () => {
-  //   it('should set ""state.isVisibilitySettingsVisible"" as ""true""', () => {
-  //     expect(instance.state.isVisibilitySettingsVisible).toBe(false);
-  //     instance.showVisibilitySettings();
-  //     expect(instance.state.isVisibilitySettingsVisible).toBe(true);
-  //   });
-  // });
-  // describe('hideVisibilitySettings', () => {
-  //   it('should set ""state.isVisibilitySettingsVisible"" as ""false""', () => {
-  //     instance.state.isVisibilitySettingsVisible = true;
-  //     expect(instance.state.isVisibilitySettingsVisible).toBe(true);
-  //     instance.hideVisibilitySettings();
-  //     expect(instance.state.isVisibilitySettingsVisible).toBe(false);
-  //   });
-  // });
-  // describe('showProfileSettings', () => {
-  //   it('should set ""state.isProfileSettingsVisible"" as ""true""', () => {
-  //     expect(instance.state.isProfileSettingsVisible).toBe(false);
-  //     instance.showProfileSettings();
-  //     expect(instance.state.isProfileSettingsVisible).toBe(true);
-  //   });
-  // });
-  // describe('hideProfileSettings', () => {
-  //   it('should set ""state.isProfileSettingsVisible"" as ""false""', () => {
-  //     instance.state.isProfileSettingsVisible = true;
-  //     expect(instance.state.isProfileSettingsVisible).toBe(true);
-  //     instance.hideProfileSettings();
-  //     expect(instance.state.isProfileSettingsVisible).toBe(false);
-  //   });
-  // });
+  const wrapper = shallow(
+    <MainCard
+      data={{
+        name: 'Petr Pervyi',
+        githubId: 'piter',
+        locationName: 'SPB',
+        locationId: '1',
+      }}
+      isEditingModeEnabled={false}
+      onPermissionsSettingsChange={() => {}}
+      onProfileSettingsChange={() => {}}
+    />);
+  const instance = wrapper.instance();
+  describe('showVisibilitySettings', () => {
+    it('should set ""state.isVisibilitySettingsVisible"" as ""true""', () => {
+      expect(instance.state.isVisibilitySettingsVisible).toBe(false);
+      instance.showVisibilitySettings();
+      expect(instance.state.isVisibilitySettingsVisible).toBe(true);
+    });
+  });
+  describe('hideVisibilitySettings', () => {
+    it('should set ""state.isVisibilitySettingsVisible"" as ""false""', () => {
+      instance.state.isVisibilitySettingsVisible = true;
+      expect(instance.state.isVisibilitySettingsVisible).toBe(true);
+      instance.hideVisibilitySettings();
+      expect(instance.state.isVisibilitySettingsVisible).toBe(false);
+    });
+  });
+  describe('showProfileSettings', () => {
+    it('should set ""state.isProfileSettingsVisible"" as ""true""', () => {
+      expect(instance.state.isProfileSettingsVisible).toBe(false);
+      instance.showProfileSettings();
+      expect(instance.state.isProfileSettingsVisible).toBe(true);
+    });
+  });
+  describe('hideProfileSettings', () => {
+    it('should set ""state.isProfileSettingsVisible"" as ""false""', () => {
+      instance.state.isProfileSettingsVisible = true;
+      expect(instance.state.isProfileSettingsVisible).toBe(true);
+      instance.hideProfileSettings();
+      expect(instance.state.isProfileSettingsVisible).toBe(false);
+    });
+  });
+  describe('filterPermissions', () => {
+    it('should left only ""isProfileVisible"" in ""permissionsSettings"" object', () => {
+      const permissionsSettings = {
+        isProfileVisible: { all: true },
+        isAboutVisible: { all: true, mentor: true, student: true },
+        isEducationVisible: { all: true, mentor: true, student: true },
+        isEnglishVisible: { all: false, student: false },
+        isEmailVisible: { all: true, student: true },
+        isTelegramVisible: { all: false, student: false },
+        isSkypeVisible: { all: true, student: true },
+        isPhoneVisible: { all: false, student: false },
+        isContactsNotesVisible: { all: true, student: true },
+        isLinkedInVisible: { all: false, mentor: false, student: false },
+        isPublicFeedbackVisible: { all: true, mentor: true, student: true },
+        isMentorStatsVisible: { all: true, mentor: true, student: true },
+        isStudentStatsVisible: { all: true, student: true },
+      };
+      const instance = wrapper.instance();
+      const result = instance.filterPermissions(permissionsSettings);
+      expect(result).toEqual({
+        isProfileVisible: { all: true },
+      });
+    });
+  });
 });
diff --git a/client/src/components/Profile/__test__/__snapshots__/MainCard.test.tsx.snap b/client/src/components/Profile/__test__/__snapshots__/MainCard.test.tsx.snap
index 40331eb..fef20dd 100644
--- a/client/src/components/Profile/__test__/__snapshots__/MainCard.test.tsx.snap
+++ b/client/src/components/Profile/__test__/__snapshots__/MainCard.test.tsx.snap
@@ -71,3 +71,158 @@ exports[`MainCard Should render correctly if is editing mode disabled 1`] = `
   </Card>
 </Fragment>
 `;
+
+exports[`MainCard Should render correctly if is editing mode enabled 1`] = `
+<Fragment>
+  <Card
+    actions={
+      Array [
+        <ForwardRef(EditOutlined)
+          onClick={[Function]}
+        />,
+        <ForwardRef(SettingOutlined)
+          onClick={[Function]}
+        />,
+      ]
+    }
+  >
+    <GithubAvatar
+      githubId=""piter""
+      size={96}
+      style={
+        Object {
+          ""display"": ""block"",
+          ""margin"": ""0 auto 10px"",
+        }
+      }
+    />
+    <Title
+      level={1}
+      style={
+        Object {
+          ""fontSize"": 24,
+          ""margin"": 0,
+          ""textAlign"": ""center"",
+        }
+      }
+    >
+      Petr Pervyi
+    </Title>
+    <Paragraph
+      style={
+        Object {
+          ""marginBottom"": 20,
+          ""textAlign"": ""center"",
+        }
+      }
+    >
+      <a
+        href=""https://github.com/piter""
+        style={
+          Object {
+            ""fontSize"": 16,
+            ""marginLeft"": ""-14px"",
+          }
+        }
+        target=""_blank""
+      >
+        <ForwardRef(GithubFilled) />
+         
+        piter
+      </a>
+    </Paragraph>
+    <Paragraph
+      style={
+        Object {
+          ""margin"": 0,
+          ""textAlign"": ""center"",
+        }
+      }
+    >
+      <span
+        style={
+          Object {
+            ""marginLeft"": ""-14px"",
+          }
+        }
+      >
+        <ForwardRef(EnvironmentFilled) />
+         
+        SPB
+      </span>
+    </Paragraph>
+    <PermissionsSettingsDrawer
+      hideSettings={[Function]}
+      isSettingsVisible={false}
+      onPermissionsSettingsChange={[Function]}
+    />
+    <ProfileSettingsDrawer
+      content={
+        <div>
+          <p
+            style={
+              Object {
+                ""fontSize"": 18,
+                ""marginBottom"": 5,
+              }
+            }
+          >
+            <Text
+              strong={true}
+            >
+              Name:
+            </Text>
+          </p>
+          <p
+            style={
+              Object {
+                ""marginBottom"": 20,
+              }
+            }
+          >
+            <Input
+              onChange={[Function]}
+              placeholder=""Firstname Lastname""
+              type=""text""
+              value=""Petr Pervyi""
+            />
+          </p>
+          <p
+            style={
+              Object {
+                ""fontSize"": 18,
+                ""marginBottom"": 5,
+              }
+            }
+          >
+            <Text
+              strong={true}
+            >
+              Location:
+            </Text>
+          </p>
+          <div
+            style={
+              Object {
+                ""marginBottom"": 5,
+              }
+            }
+          >
+            <LocationSelect
+              defaultValue=""1""
+              onChange={[Function]}
+              style={
+                Object {
+                  ""width"": ""100%"",
+                }
+              }
+            />
+          </div>
+        </div>
+      }
+      hideSettings={[Function]}
+      isSettingsVisible={false}
+    />
+  </Card>
+</Fragment>
+`;
diff --git a/client/src/jest.config.js b/client/src/jest.config.js
index df39788..654f9f3 100644
--- a/client/src/jest.config.js
+++ b/client/src/jest.config.js
@@ -7,4 +7,5 @@ module.exports = {
     '^services(.*)$': '<rootDir>/services/$1',
     '^utils(.*)$': '<rootDir>/utils/$1',
   },
+  verbose: true,
 };

diff --git a/.github/workflows/update-deps.yml b/.github/workflows/update-deps.yml
index e0ccd62..1236f58 100644
--- a/.github/workflows/update-deps.yml
+++ b/.github/workflows/update-deps.yml
@@ -13,6 +13,7 @@ jobs:
           - nixpkgs
           - poetry2nix
           - pre-commit-hooks
+          - gitignore.nix
     steps:
       - name: Checkout
         uses: actions/checkout@v2
",3,"[""e12d9e77a6fd531a22325337838a841b1c67f00d"", ""f87659953e9af59bc7cb314a22dd076d988ef607"", ""c444fdb9e85ce44c5c0c99addc777dd7b6085153""]","[""docs"", ""test"", ""cicd""]"
"reset padding first on PadLog

Signed-off-by: Carlos A Becker <caarlos0@users.noreply.github.com>","diff --git a/internal/middleware/logging/logging.go b/internal/middleware/logging/logging.go
index 1a3adc7..92c8eb5 100644
--- a/internal/middleware/logging/logging.go
+++ b/internal/middleware/logging/logging.go
@@ -35,6 +35,7 @@ func Log(title string, next middleware.Action) middleware.Action {
 func PadLog(title string, next middleware.Action) middleware.Action {
 	return func(ctx *context.Context) error {
 		defer log.ResetPadding()
+		log.ResetPadding()
 		log.IncreasePadding()
 		log.Infof(bold.Render(title))
 		log.IncreasePadding()
",1,"[""c5904a9004fca1e438168ca7334a0deefab536ff""]","[""fix""]"
"removing automatic page push on nav | reintroduce timeout for assertion

The timeout had been removed by a previous commit. Without the timeout the test might be flaky.
Also removed obsolete code","diff --git a/ionic/components/nav/test/basic/index.ts b/ionic/components/nav/test/basic/index.ts
index 4b1a8ea..2834f68 100644
--- a/ionic/components/nav/test/basic/index.ts
+++ b/ionic/components/nav/test/basic/index.ts
@@ -63,12 +63,6 @@ class FirstPage {
     }
   }
 
-  onPageDidEnter() {
-    setTimeout(() => {
-      this.nav.push(PrimaryHeaderPage);
-    }, 1000);
-  }
-
   setPages() {
     let items = [
       PrimaryHeaderPage

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
index d0ee4f3..c2ab83c 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
@@ -13,6 +13,7 @@ import static io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent.ACTI
 import static io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent.ELEMENT_ACTIVATING;
 import static java.util.function.Predicate.isEqual;
 import static org.assertj.core.api.Assertions.assertThat;
+import static org.awaitility.Awaitility.await;
 import static org.mockito.ArgumentMatchers.any;
 import static org.mockito.ArgumentMatchers.anyLong;
 import static org.mockito.ArgumentMatchers.eq;
@@ -30,7 +31,6 @@ import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.streamprocessor.StreamProcessor;
 import io.camunda.zeebe.streamprocessor.StreamProcessor.Phase;
 import io.camunda.zeebe.streamprocessor.StreamProcessorMode;
-import org.awaitility.Awaitility;
 import org.junit.Rule;
 import org.junit.Test;
 import org.mockito.InOrder;
@@ -71,7 +71,7 @@ public final class StreamProcessorReplayModeTest {
     // when
     startStreamProcessor(replayUntilEnd);
 
-    Awaitility.await()
+    await()
         .untilAsserted(
             () -> assertThat(getCurrentPhase(replayUntilEnd)).isEqualTo(Phase.PROCESSING));
 
@@ -163,7 +163,7 @@ public final class StreamProcessorReplayModeTest {
         command().processInstance(ACTIVATE_ELEMENT, RECORD),
         event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
 
-    Awaitility.await(""should have replayed first events"")
+    await(""should have replayed first events"")
         .until(replayContinuously::getLastSuccessfulProcessedRecordPosition, (pos) -> pos > 0);
 
     // when
@@ -210,7 +210,7 @@ public final class StreamProcessorReplayModeTest {
         command().processInstance(ACTIVATE_ELEMENT, RECORD),
         event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
 
-    Awaitility.await(""should have replayed first events"")
+    await(""should have replayed first events"")
         .until(replayContinuously::getLastSuccessfulProcessedRecordPosition, (pos) -> pos > 0);
     streamProcessor.pauseProcessing().join();
     replayContinuously.writeBatch(
@@ -244,7 +244,7 @@ public final class StreamProcessorReplayModeTest {
     // then
     verify(eventApplier, TIMEOUT).applyState(anyLong(), eq(ELEMENT_ACTIVATING), any());
 
-    Awaitility.await()
+    await()
         .untilAsserted(
             () -> {
               final var lastProcessedPosition = getLastProcessedPosition(replayContinuously);
@@ -273,8 +273,7 @@ public final class StreamProcessorReplayModeTest {
 
     verify(eventApplier, TIMEOUT).applyState(anyLong(), eq(ELEMENT_ACTIVATING), any());
 
-    Awaitility.await()
-        .until(() -> getLastProcessedPosition(replayContinuously), isEqual(commandPosition));
+    await().until(() -> getLastProcessedPosition(replayContinuously), isEqual(commandPosition));
 
     // then
     assertThat(replayContinuously.getLastSuccessfulProcessedRecordPosition())
@@ -285,7 +284,6 @@ public final class StreamProcessorReplayModeTest {
   @Test
   public void shouldNotSetLastProcessedPositionIfLessThanSnapshotPosition() {
     // given
-    final var commandPositionBeforeSnapshot = 1L;
     final var snapshotPosition = 2L;
 
     startStreamProcessor(replayContinuously);
@@ -298,23 +296,20 @@ public final class StreamProcessorReplayModeTest {
     // when
     startStreamProcessor(replayContinuously);
 
-    Awaitility.await()
+    await()
         .untilAsserted(
             () -> assertThat(getCurrentPhase(replayContinuously)).isEqualTo(Phase.REPLAY));
 
-    final var eventPosition =
-        replayContinuously.writeEvent(
-            ELEMENT_ACTIVATING,
-            RECORD,
-            writer -> writer.sourceRecordPosition(commandPositionBeforeSnapshot));
-
     // then
     final var lastProcessedPositionState = replayContinuously.getLastProcessedPositionState();
 
-    assertThat(lastProcessedPositionState.getLastSuccessfulProcessedRecordPosition())
-        .describedAs(
-            ""Expected that the last processed position is not less than the snapshot position"")
-        .isEqualTo(snapshotPosition);
+    await()
+        .untilAsserted(
+            () ->
+                assertThat(lastProcessedPositionState.getLastSuccessfulProcessedRecordPosition())
+                    .describedAs(
+                        ""Expected that the last processed position is not less than the snapshot position"")
+                    .isEqualTo(snapshotPosition));
   }
 
   private StreamProcessor startStreamProcessor(final StreamProcessorRule streamProcessorRule) {
",2,"[""cd9e6a2ab17c5961b0f977bb8a06f8545da49a97"", ""0d23f1b3ed22e615b9611bb4eae01d2241e64dff""]","[""test"", ""refactor""]"
"add .nullif() example | update build | alerts do not trigger modal lifecycle events

fixes #8616","diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        
+         sex    
+        
+         string 
+        
+         male   
+         female 
+         female 
+         NULL   
+         female 
+        
+        >>> vals.nullif(""male"")
+        
+         NullIf(sex, 'male') 
+        
+         string              
+        
+         NULL                
+         female              
+         female              
+         NULL                
+         female              
+        
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 

diff --git a/bootstrap/scripts/publish-patch.sh b/bootstrap/scripts/publish-patch.sh
index a1b6f12..0d849a5 100755
--- a/bootstrap/scripts/publish-patch.sh
+++ b/bootstrap/scripts/publish-patch.sh
@@ -5,4 +5,4 @@ lerna version patch
 lerna publish from-package -y
 git push
 
-./pack_and_install.sh
\ No newline at end of file
+./bootstrap/scripts/pack_and_install.sh
\ No newline at end of file

diff --git a/src/components/app/app-root.ts b/src/components/app/app-root.ts
index ec7daee..29dc797 100644
--- a/src/components/app/app-root.ts
+++ b/src/components/app/app-root.ts
@@ -15,6 +15,7 @@ export const AppRootToken = new OpaqueToken('USERROOT');
   selector: 'ion-app',
   template:
     '<div #viewport app-viewport></div>' +
+    '<div #modalPortal overlay-portal></div>' +
     '<div #overlayPortal overlay-portal></div>' +
     '<div #loadingPortal class=""loading-portal"" overlay-portal></div>' +
     '<div #toastPortal class=""toast-portal"" overlay-portal></div>' +
@@ -24,6 +25,8 @@ export class IonicApp extends Ion implements OnInit {
 
   @ViewChild('viewport', {read: ViewContainerRef}) _viewport: ViewContainerRef;
 
+  @ViewChild('modalPortal', { read: OverlayPortal }) _modalPortal: OverlayPortal;
+
   @ViewChild('overlayPortal', { read: OverlayPortal }) _overlayPortal: OverlayPortal;
 
   @ViewChild('loadingPortal', { read: OverlayPortal }) _loadingPortal: OverlayPortal;
@@ -96,6 +99,9 @@ export class IonicApp extends Ion implements OnInit {
     if (portal === AppPortal.TOAST) {
       return this._toastPortal;
     }
+    if (portal === AppPortal.MODAL) {
+      return this._modalPortal;
+    }
     return this._overlayPortal;
   }
 
@@ -110,6 +116,7 @@ export class IonicApp extends Ion implements OnInit {
 
 export enum AppPortal {
   DEFAULT,
+  MODAL,
   LOADING,
   TOAST
 };
diff --git a/src/components/modal/modal.ts b/src/components/modal/modal.ts
index bd4d406..c3e7a62 100644
--- a/src/components/modal/modal.ts
+++ b/src/components/modal/modal.ts
@@ -1,6 +1,7 @@
 import { Injectable } from '@angular/core';
 
 import { App } from '../app/app';
+import { AppPortal } from '../app/app-root';
 import { isPresent } from '../../util/util';
 import { ModalCmp } from './modal-component';
 import { ModalOptions } from './modal-options';
@@ -40,7 +41,7 @@ export class Modal extends ViewController {
    * @returns {Promise} Returns a promise which is resolved when the transition has completed.
    */
   present(navOptions: NavOptions = {}) {
-    return this._app.present(this, navOptions);
+    return this._app.present(this, navOptions, AppPortal.MODAL);
   }
 
   /**
",3,"[""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21"", ""3fcfb20b0feb371b357edc42fcb7c87085c9b82a"", ""e2704a4a25b9e348764e1cc922ca7d6a927550eb""]","[""docs"", ""build"", ""fix""]"
update README.md about the NPM package | add canonical `_name` to edge packages,"diff --git a/README.md b/README.md
index 9faf168..bbb5b5c 100644
--- a/README.md
+++ b/README.md
@@ -126,23 +126,24 @@ pacman -S git-cliff
 
 ### From NPM
 
-[git-cliff](https://www.npmjs.com/package/git-cliff) can be installed from NPM:
+
+You can install and run [git-cliff](https://www.npmjs.com/package/git-cliff) with a single command:
 
 ```sh
-yarn add -D git-cliff
+npx git-cliff@latest
 ```
 
-or:
+Also, if you want to add `git-cliff` to your project:
 
 ```sh
+# with yarn
+yarn add -D git-cliff
+
+# with npm
 npm install git-cliff --save-dev
 ```
 
-You can also use `git-cliff` directly with `npx`:
-
-```sh
-npx git-cliff
-```
+Afterwards, you can run `git-cliff` via `npm exec git-cliff` or `npx git-cliff@latest`.
 
 ### From MacPorts
 

diff --git a/scripts/bump-edge.ts b/scripts/bump-edge.ts
index e92e3c9..0b7a11a 100644
--- a/scripts/bump-edge.ts
+++ b/scripts/bump-edge.ts
@@ -53,6 +53,7 @@ async function loadWorkspace (dir: string) {
   }
 
   const rename = (from: string, to: string) => {
+    find(from).data._name = find(from).data.name
     find(from).data.name = to
     for (const pkg of packages) {
       pkg.updateDeps((dep) => {
",2,"[""e0177c25e13812306aab0b0991562d58b6d14767"", ""573f87edf9bdc19c9c4c3a978fad6ed3ce788f5f""]","[""docs"", ""build""]"
remove duplicated code,"diff --git a/packages/core/src/components/action-sheet/action-sheet.tsx b/packages/core/src/components/action-sheet/action-sheet.tsx
index 7166508..dad7daf 100644
--- a/packages/core/src/components/action-sheet/action-sheet.tsx
+++ b/packages/core/src/components/action-sheet/action-sheet.tsx
@@ -1,9 +1,9 @@
 import { Component, CssClassMap, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { Animation, AnimationBuilder, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
 
-import { domControllerAsync, isDef, playAnimationAsync } from '../../utils/helpers';
+import { domControllerAsync } from '../../utils/helpers';
 import { createThemedClasses, getClassMap } from '../../utils/theme';
-import { OverlayInterface, BACKDROP } from '../../utils/overlays';
+import { OverlayInterface, BACKDROP, overlayAnimation } from '../../utils/overlays';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
@@ -23,15 +23,15 @@ import mdLeaveAnimation from './animations/md.leave';
 })
 export class ActionSheet implements OverlayInterface {
 
+  private presented = false;
+
   mode: string;
   color: string;
-
-  private presented = false;
-  private animation: Animation | null = null;
+  animation: Animation;
 
   @Element() private el: HTMLElement;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
   @Prop() overlayId: number;
@@ -178,25 +178,8 @@ export class ActionSheet implements OverlayInterface {
     });
   }
 
-  private playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el).then(animation => {
-      this.animation = animation;
-      // Check if prop animate is false or if the config for animate is defined/false
-      if (!this.willAnimate || (isDef(this.config.get('willAnimate')) && this.config.get('willAnimate') === false)) {
-        // if the duration is 0, it won't actually animate I don't think
-        // TODO - validate this
-        this.animation = animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then((animation) => {
-      animation.destroy();
-      this.animation = null;
-    });
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, undefined);
   }
 
   protected buttonClick(button: ActionSheetButton) {
diff --git a/packages/core/src/components/alert/alert.tsx b/packages/core/src/components/alert/alert.tsx
index 800b77b..bdf4fc5 100644
--- a/packages/core/src/components/alert/alert.tsx
+++ b/packages/core/src/components/alert/alert.tsx
@@ -1,8 +1,8 @@
 import { Component, CssClassMap, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
-import { domControllerAsync, playAnimationAsync, autoFocus } from '../../utils/helpers';
+import { Animation, AnimationBuilder, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { domControllerAsync, autoFocus } from '../../utils/helpers';
 import { createThemedClasses, getClassMap } from '../../utils/theme';
-import { OverlayInterface, BACKDROP } from '../../utils/overlays';
+import { OverlayInterface, BACKDROP, overlayAnimation } from '../../utils/overlays';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
@@ -21,18 +21,19 @@ import mdLeaveAnimation from './animations/md.leave';
   }
 })
 export class Alert implements OverlayInterface {
-  mode: string;
-  color: string;
 
   private presented = false;
-  private animation: Animation | null = null;
   private activeId: string;
   private inputType: string | null = null;
   private hdrId: string;
 
+  animation: Animation;
+  mode: string;
+  color: string;
+
   @Element() private el: HTMLElement;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
   @Prop() overlayId: number;
@@ -264,25 +265,10 @@ export class Alert implements OverlayInterface {
     return values;
   }
 
-  private playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el).then(animation => {
-      this.animation = animation;
-      if (!this.willAnimate) {
-        animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then(animation => {
-      animation.destroy();
-      this.animation = null;
-    });
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, undefined);
   }
 
-
   private renderCheckbox(inputs: AlertInput[]) {
     if (inputs.length === 0) return null;
 
diff --git a/packages/core/src/components/loading/loading.tsx b/packages/core/src/components/loading/loading.tsx
index f45eaf1..cc4f511 100644
--- a/packages/core/src/components/loading/loading.tsx
+++ b/packages/core/src/components/loading/loading.tsx
@@ -1,13 +1,13 @@
 import { Component, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
-import { domControllerAsync, playAnimationAsync } from '../../utils/helpers';
+import { Animation, AnimationBuilder, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { domControllerAsync } from '../../utils/helpers';
 import { createThemedClasses, getClassMap } from '../../utils/theme';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
 import mdEnterAnimation from './animations/md.enter';
 import mdLeaveAnimation from './animations/md.leave';
-import { OverlayInterface, BACKDROP } from '../../utils/overlays';
+import { OverlayInterface, BACKDROP, overlayAnimation } from '../../utils/overlays';
 
 @Component({
   tag: 'ion-loading',
@@ -21,16 +21,17 @@ import { OverlayInterface, BACKDROP } from '../../utils/overlays';
 })
 
 export class Loading implements OverlayInterface {
-  color: string;
-  mode: string;
 
   private presented = false;
-  private animation: Animation;
   private durationTimeout: any;
 
+  animation: Animation;
+  color: string;
+  mode: string;
+
   @Element() private el: HTMLElement;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
   @Prop() overlayId: number;
@@ -199,24 +200,8 @@ export class Loading implements OverlayInterface {
     });
   }
 
-  private playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el).then(animation => {
-      this.animation = animation;
-      if (!this.willAnimate) {
-        // if the duration is 0, it won't actually animate I don't think
-        // TODO - validate this
-        animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then(animation => {
-      animation.destroy();
-      this.animation = null;
-    });
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, undefined);
   }
 
   hostData() {
diff --git a/packages/core/src/components/modal/modal.tsx b/packages/core/src/components/modal/modal.tsx
index af50d63..2b7510c 100644
--- a/packages/core/src/components/modal/modal.tsx
+++ b/packages/core/src/components/modal/modal.tsx
@@ -1,10 +1,10 @@
 import { Component, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, DomController, FrameworkDelegate, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { Animation, AnimationBuilder, Config, DomController, FrameworkDelegate, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
 
 import { DomFrameworkDelegate } from '../../utils/dom-framework-delegate';
-import { domControllerAsync, playAnimationAsync } from '../../utils/helpers';
+import { domControllerAsync } from '../../utils/helpers';
 import { createThemedClasses } from '../../utils/theme';
-import { OverlayInterface, BACKDROP } from '../../utils/overlays';
+import { OverlayInterface, BACKDROP, overlayAnimation } from '../../utils/overlays';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
@@ -25,14 +25,16 @@ import mdLeaveAnimation from './animations/md.leave';
 export class Modal implements OverlayInterface {
 
   private presented = false;
-  private animation: Animation;
   private usersComponentElement: HTMLElement;
 
+  animation: Animation;
+
   @Element() private el: HTMLElement;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
+
   @Prop() overlayId: number;
   @Prop({ mutable: true }) delegate: FrameworkDelegate;
 
@@ -208,22 +210,8 @@ export class Modal implements OverlayInterface {
     });
   }
 
-  private playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el).then(animation => {
-      this.animation = animation;
-      if (!this.willAnimate) {
-        animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then((animation) => {
-      animation.destroy();
-      this.animation = null;
-    });
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, undefined);
   }
 
   @Method()
diff --git a/packages/core/src/components/picker/picker.tsx b/packages/core/src/components/picker/picker.tsx
index 13faa3e..d70381e 100644
--- a/packages/core/src/components/picker/picker.tsx
+++ b/packages/core/src/components/picker/picker.tsx
@@ -1,9 +1,9 @@
 import { Component, CssClassMap, Element, Event, EventEmitter, Listen, Method, Prop, State } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { Animation, AnimationBuilder, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
 
-import { domControllerAsync, playAnimationAsync } from '../../utils/helpers';
+import { domControllerAsync } from '../../utils/helpers';
 import { getClassMap } from '../../utils/theme';
-import { OverlayInterface } from '../../utils/overlays';
+import { OverlayInterface, overlayAnimation } from '../../utils/overlays';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
@@ -21,16 +21,17 @@ import iosLeaveAnimation from './animations/ios.leave';
 export class Picker implements OverlayInterface {
 
   private presented = false;
-  private animation: Animation;
   private durationTimeout: any;
   private mode: string;
 
+  animation: Animation;
+
   @Element() private el: HTMLElement;
 
   @State() private showSpinner: boolean = null;
   @State() private spinner: string;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
   @Prop() overlayId: number;
@@ -231,22 +232,8 @@ export class Picker implements OverlayInterface {
     return this.columns;
   }
 
-  private playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el).then(animation => {
-      this.animation = animation;
-      if (!this.willAnimate) {
-        animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then(animation => {
-      animation.destroy();
-      this.animation = null;
-    })
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, undefined);
   }
 
   private buttonClick(button: PickerButton) {
diff --git a/packages/core/src/components/popover/popover.tsx b/packages/core/src/components/popover/popover.tsx
index 65031ff..6a47bf6 100644
--- a/packages/core/src/components/popover/popover.tsx
+++ b/packages/core/src/components/popover/popover.tsx
@@ -1,10 +1,10 @@
 import { Component, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, DomController, FrameworkDelegate, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { Animation, AnimationBuilder, Config, DomController, FrameworkDelegate, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
 
 import { DomFrameworkDelegate } from '../../utils/dom-framework-delegate';
-import { domControllerAsync, playAnimationAsync } from '../../utils/helpers';
+import { domControllerAsync } from '../../utils/helpers';
 import { createThemedClasses } from '../../utils/theme';
-import { OverlayInterface, BACKDROP } from '../../utils/overlays';
+import { OverlayInterface, BACKDROP, overlayAnimation } from '../../utils/overlays';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
@@ -24,12 +24,13 @@ import mdLeaveAnimation from './animations/md.leave';
 export class Popover implements OverlayInterface {
 
   private presented = false;
-  private animation: Animation;
   private usersComponentElement: HTMLElement;
 
+  animation: Animation;
+
   @Element() private el: HTMLElement;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
   @Prop({ mutable: true }) delegate: FrameworkDelegate;
@@ -224,22 +225,8 @@ export class Popover implements OverlayInterface {
     });
   }
 
-  private playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el, this.ev).then((animation) => {
-      this.animation = animation;
-      if (!this.willAnimate) {
-        animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then(animation => {
-      animation.destroy();
-      this.animation = null;
-    })
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, this.ev);
   }
 
   hostData() {
diff --git a/packages/core/src/components/toast/toast.tsx b/packages/core/src/components/toast/toast.tsx
index 1afa318..372070a 100644
--- a/packages/core/src/components/toast/toast.tsx
+++ b/packages/core/src/components/toast/toast.tsx
@@ -1,9 +1,9 @@
 import { Component, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, CssClassMap, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { Animation, AnimationBuilder, Config, CssClassMap, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
 
-import { domControllerAsync, playAnimationAsync } from '../../utils/helpers';
+import { domControllerAsync } from '../../utils/helpers';
 import { createThemedClasses, getClassMap } from '../../utils/theme';
-import { OverlayInterface } from '../../utils/overlays';
+import { OverlayInterface, overlayAnimation } from '../../utils/overlays';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
@@ -24,14 +24,14 @@ import mdLeaveAnimation from './animations/md.leave';
 export class Toast implements OverlayInterface {
 
   private presented = false;
-  private animation: Animation | null;
 
   @Element() private el: HTMLElement;
 
   mode: string;
   color: string;
+  animation: Animation | null;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
   @Prop() overlayId: number;
@@ -123,6 +123,22 @@ export class Toast implements OverlayInterface {
    */
   @Event() ionToastDidUnload: EventEmitter<ToastEventDetail>;
 
+  componentDidLoad() {
+    this.ionToastDidLoad.emit();
+  }
+
+  componentDidUnload() {
+    this.ionToastDidUnload.emit();
+  }
+
+  @Listen('ionDismiss')
+  protected onDismiss(ev: UIEvent) {
+    ev.stopPropagation();
+    ev.preventDefault();
+
+    this.dismiss();
+  }
+
   /**
    * Present the toast overlay after it has been created.
    */
@@ -169,38 +185,8 @@ export class Toast implements OverlayInterface {
     });
   }
 
-  playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el, this.position).then(animation => {
-      this.animation = animation;
-      if (!this.willAnimate) {
-        animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then((animation) => {
-      animation.destroy();
-      this.animation = null;
-    });
-  }
-
-  componentDidLoad() {
-    this.ionToastDidLoad.emit();
-  }
-
-  componentDidUnload() {
-    this.ionToastDidUnload.emit();
-  }
-
-  @Listen('ionDismiss')
-  protected onDismiss(ev: UIEvent) {
-    ev.stopPropagation();
-    ev.preventDefault();
-
-    this.dismiss();
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, this.position);
   }
 
   private wrapperClass(): CssClassMap {
diff --git a/packages/core/src/utils/overlays.ts b/packages/core/src/utils/overlays.ts
index 8926544..634df43 100644
--- a/packages/core/src/utils/overlays.ts
+++ b/packages/core/src/utils/overlays.ts
@@ -1,3 +1,5 @@
+import { AnimationBuilder, Animation } from "".."";
+import { playAnimationAsync } from ""./helpers"";
 
 let lastId = 1;
 
@@ -56,8 +58,33 @@ export function removeLastOverlay(overlays: OverlayMap) {
   return toRemove ? toRemove.dismiss() : Promise.resolve();
 }
 
+export function overlayAnimation(
+  overlay: OverlayInterface,
+  animationBuilder: AnimationBuilder,
+  animate: boolean,
+  baseEl: HTMLElement,
+  opts: any
+): Promise<void> {
+  if (overlay.animation) {
+    overlay.animation.destroy();
+    overlay.animation = null;
+  }
+  return overlay.animationCtrl.create(animationBuilder, baseEl, opts).then(animation => {
+    overlay.animation = animation;
+    if (!animate) {
+      animation.duration(0);
+    }
+    return playAnimationAsync(animation);
+  }).then((animation) => {
+    animation.destroy();
+    overlay.animation = null;
+  });
+}
+
 export interface OverlayInterface {
   overlayId: number;
+  animation: Animation;
+  animationCtrl: HTMLIonAnimationControllerElement;
 
   present(): Promise<void>;
   dismiss(data?: any, role?: string): Promise<void>;
",1,"[""9e3f295bbfd4098ffda1ae6656699f60b86c1f92""]","[""refactor""]"
"ensure checksum persist flushes to disk | only restart if pages directory itself is changed

resolves #429","diff --git a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
index eed9424..a1ae702 100644
--- a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
+++ b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
@@ -10,6 +10,10 @@ package io.camunda.zeebe.snapshots.impl;
 import static org.assertj.core.api.Assertions.assertThat;
 
 import io.camunda.zeebe.snapshots.ImmutableChecksumsSFV;
+import io.camunda.zeebe.test.util.STracer;
+import io.camunda.zeebe.test.util.STracer.Syscall;
+import io.camunda.zeebe.test.util.asserts.strace.FSyncTraceAssert;
+import io.camunda.zeebe.test.util.asserts.strace.STracerAssert;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
@@ -124,6 +128,28 @@ public class SnapshotChecksumTest {
   }
 
   @Test
+  public void shouldFlushOnPersist() throws Exception {
+    // given
+    final var traceFile = temporaryFolder.newFile().toPath();
+    final var expectedChecksum = SnapshotChecksum.calculate(multipleFileSnapshot);
+    final var checksumPath = multipleFileSnapshot.resolveSibling(""checksum"");
+    final var tracer = STracer.traceFor(Syscall.FSYNC, traceFile);
+
+    // when
+    try (tracer) {
+      SnapshotChecksum.persist(checksumPath, expectedChecksum);
+    }
+
+    // then
+    STracerAssert.assertThat(tracer)
+        .fsyncTraces()
+        .hasSize(1)
+        .first(FSyncTraceAssert.factory())
+        .hasPath(checksumPath)
+        .isSuccessful();
+  }
+
+  @Test
   public void shouldDetectCorruptedSnapshot() throws IOException {
     // given
     final var expectedChecksum = SnapshotChecksum.calculate(corruptedSnapshot);

diff --git a/packages/cli/src/commands/dev.ts b/packages/cli/src/commands/dev.ts
index 35d859e..d6d91ed 100644
--- a/packages/cli/src/commands/dev.ts
+++ b/packages/cli/src/commands/dev.ts
@@ -1,4 +1,4 @@
-import { resolve } from 'upath'
+import { resolve, relative } from 'upath'
 import chokidar from 'chokidar'
 import debounce from 'debounce-promise'
 import type { Nuxt } from '@nuxt/kit'
@@ -27,9 +27,9 @@ export default defineNuxtCommand({
     const { loadNuxt, buildNuxt } = requireModule('@nuxt/kit', rootDir) as typeof import('@nuxt/kit')
 
     let currentNuxt: Nuxt
-    const load = async (isRestart: boolean) => {
+    const load = async (isRestart: boolean, reason?: string) => {
       try {
-        const message = `${isRestart ? 'Restarting' : 'Starting'} nuxt...`
+        const message = `${reason ? reason + '. ' : ''}${isRestart ? 'Restarting' : 'Starting'} nuxt...`
         server.setApp(createLoadingHandler(message))
         if (isRestart) {
           console.log(message)
@@ -59,12 +59,8 @@ export default defineNuxtCommand({
     const dLoad = debounce(load, 250)
     const watcher = chokidar.watch([rootDir], { ignoreInitial: true, depth: 1 })
     watcher.on('all', (_event, file) => {
-      // Ignore any changes to files within the Nuxt build directory
-      if (file.includes(currentNuxt.options.buildDir)) {
-        return
-      }
-      if (file.includes('nuxt.config') || file.includes('modules') || file.includes('pages')) {
-        dLoad(true)
+      if (file.match(/nuxt\.config\.(js|ts|mjs|cjs)$|pages$/)) {
+        dLoad(true, `${relative(rootDir, file)} updated`)
       }
     })
 
",2,"[""b7ce2894fd1794064bd6db4ed730bb6cb7728739"", ""cbce777addb3dd118232a9f28db9d425d4c937b2""]","[""test"", ""fix""]"
"remove git-crypt, switch to sops

Signed-off-by: Andrea Luzzardi <aluzzardi@gmail.com> | use connect instead of begin to avoid nesting transactions","diff --git a/.gitattributes b/.gitattributes
deleted file mode 100644
index 00b39fd..0000000
--- a/.gitattributes
+++ /dev/null
@@ -1,3 +0,0 @@
-*.secret filter=git-crypt diff=git-crypt
-*.key filter=git-crypt diff=git-crypt
-*.secret.* filter=git-crypt diff=git-crypt
diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml
index 8b6209f..47ec885 100644
--- a/.github/workflows/ci.yml
+++ b/.github/workflows/ci.yml
@@ -14,26 +14,31 @@ jobs:
       - name: Check out
         uses: actions/checkout@v2
 
+      - name: Set up Go
+        uses: actions/setup-go@v1
+        with:
+          go-version: 1.16
+
       - name: Install Dependencies
         run: |
-          sudo apt-get update
-          sudo apt-get install -y --no-install-recommends shellcheck git-crypt
-
+          # Cue
           export CUE_VERSION=""$(grep cue ./go.mod | cut -d' ' -f2)""
           export CUE_TARBALL=""cue_${CUE_VERSION}_linux_amd64.tar.gz""
-
           echo ""Installing cue version $CUE_VERSION""
-          curl -sfL https://install.goreleaser.com/github.com/golangci/golangci-lint.sh | sudo sh -s -- -b /usr/local/bin v1.23.8
-
           curl -L https://github.com/cuelang/cue/releases/download/${CUE_VERSION}/${CUE_TARBALL} | sudo tar zxf - -C /usr/local/bin
 
-      - name: Unlock secrets
+          # SOPS
+          sudo curl -L -o /usr/local/bin/sops https://github.com/mozilla/sops/releases/download/v3.6.1/sops-v3.6.1.linux
+          sudo chmod +x /usr/local/bin/sops
+
+          # golangci
+          curl -sfL https://install.goreleaser.com/github.com/golangci/golangci-lint.sh | sudo sh -s -- -b /usr/local/bin v1.23.8
+
+      - name: Import PGP private key
         env:
-          GIT_CRYPT_KEY: ${{ secrets.GIT_CRYPT_KEY }}
+          SOPS_PGP_KEY: ${{ secrets.SOPS_PGP_KEY }}
         run: |
-          echo ""$GIT_CRYPT_KEY"" | base64  -d > /tmp/git-crypt-key
-          git-crypt unlock /tmp/git-crypt-key
-          rm -f /tmp/git-crypt-key
+          echo ""$SOPS_PGP_KEY"" | base64 -d | gpg --import
 
       - name: Login to Docker Hub
         uses: docker/login-action@v1
@@ -41,12 +46,6 @@ jobs:
           username: ${{ secrets.DOCKERHUB_USERNAME }}
           password: ${{ secrets.DOCKERHUB_TOKEN }}
 
-      - name: Set up Go
-        uses: actions/setup-go@v1
-        with:
-          go-version: 1.16
-        id: go
-
       - name: Lint
         run: |
           make lint
diff --git a/tests/test-lib.sh b/tests/test-lib.sh
index 242ee92..4b2858d 100644
--- a/tests/test-lib.sh
+++ b/tests/test-lib.sh
@@ -127,14 +127,18 @@ test::one(){
   return ""$ret""
 }
 
-disable(){
-  logger::warning ""Test \""$2\"" has been disabled.""
-}
+# Similar to test::one, however tests will be skipped if secrets cannot be decrypted
+test::secret(){
+  local inputFile=""$1""
+  shift
 
-secret(){
-  if [ -z ""${DAGGER_SECRETS_LOADED+x}"" ] || [ ""$DAGGER_SECRETS_LOADED"" != ""1"" ]; then
-    logger::warning ""Skip \""$2\"": secrets not available""
+  if sops exec-file ""$inputFile"" echo  > /dev/null 2>&1; then
+    test::one ""$@"" --input-yaml ""$inputFile""
   else
-    ""$@""
+    logger::warning ""Skip \""$1\"": secrets not available""
   fi
 }
+
+disable(){
+  logger::warning ""Test \""$2\"" has been disabled.""
+}
diff --git a/tests/test.secret b/tests/test.secret
deleted file mode 100644
index 17fca19..0000000
Binary files a/tests/test.secret and /dev/null differ
diff --git a/tests/test.sh b/tests/test.sh
index ce5d936..3f54136 100755
--- a/tests/test.sh
+++ b/tests/test.sh
@@ -6,11 +6,6 @@ readonly d=$(cd ""$(dirname ""${BASH_SOURCE[0]:-$PWD}"")"" 2>/dev/null 1>&2 && pwd)
 # shellcheck source=/dev/null
 . ""$d/test-lib.sh""
 
-# shellcheck source=/dev/null
-if grep -q ""DAGGER_SECRETS"" ""$d/test.secret""; then
-    source ""$d/test.secret""
-fi
-
 # Point this to your dagger binary
 readonly DAGGER_BINARY=""${DAGGER_BINARY:-$d/../cmd/dagger/dagger}""
 # The default arguments are a no-op, but having ""anything"" is a little cheat necessary for ""${DAGGER_BINARY_ARGS[@]}"" to not be empty down there

diff --git a/ibis/backends/duckdb/__init__.py b/ibis/backends/duckdb/__init__.py
index 2006f59..bb2028e 100644
--- a/ibis/backends/duckdb/__init__.py
+++ b/ibis/backends/duckdb/__init__.py
@@ -1180,7 +1180,7 @@ WHERE catalog_name = :database""""""
     def _register_udfs(self, expr: ir.Expr) -> None:
         import ibis.expr.operations as ops
 
-        with self.begin() as con:
+        with self.con.connect() as con:
             for udf_node in expr.op().find(ops.ScalarUDF):
                 compile_func = getattr(
                     self, f""_compile_{udf_node.__input_type__.name.lower()}_udf""
",2,"[""87d576e936e234d0429ad753267a2760c5dfd314"", ""6889543bec720e7e7da66535e1012cb66edfe081""]","[""cicd"", ""fix""]"
"Publish crates | metaDiff - include Links column as well

Signed-off-by: Pranav C <pranavxc@gmail.com>","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 7b98b44..f17ad6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -7,6 +7,9 @@
 
 - **(css/parser)** Fix parsing of at rules (#3328) ([506a310](https://github.com/swc-project/swc/commit/506a31078aaebf50129658f096bbd5929995205f))
 
+
+- **(es/compat)** Fix regression of `destructuring` (#3326) ([6d1ad36](https://github.com/swc-project/swc/commit/6d1ad368aca53ee64a63ae565cd015909f2f4458))
+
 ### Performance
 
 
diff --git a/Cargo.lock b/Cargo.lock
index 3c6598b..4baa252 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -2652,7 +2652,7 @@ dependencies = [
 
 [[package]]
 name = ""swc""
-version = ""0.116.15""
+version = ""0.116.16""
 dependencies = [
  ""ahash"",
  ""anyhow"",
@@ -3097,7 +3097,7 @@ dependencies = [
 
 [[package]]
 name = ""swc_ecma_transforms""
-version = ""0.113.3""
+version = ""0.113.4""
 dependencies = [
  ""pretty_assertions 0.7.2"",
  ""sourcemap"",
@@ -3157,7 +3157,7 @@ dependencies = [
 
 [[package]]
 name = ""swc_ecma_transforms_compat""
-version = ""0.68.2""
+version = ""0.68.3""
 dependencies = [
  ""ahash"",
  ""arrayvec 0.7.2"",
@@ -3366,7 +3366,7 @@ dependencies = [
 
 [[package]]
 name = ""swc_ecmascript""
-version = ""0.110.14""
+version = ""0.110.15""
 dependencies = [
  ""swc_ecma_ast"",
  ""swc_ecma_codegen"",
diff --git a/crates/swc/Cargo.toml b/crates/swc/Cargo.toml
index 756cfc8..2f02d22 100644
--- a/crates/swc/Cargo.toml
+++ b/crates/swc/Cargo.toml
@@ -9,7 +9,7 @@ include = [""Cargo.toml"", ""src/**/*.rs""]
 license = ""Apache-2.0""
 name = ""swc""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.116.15""
+version = ""0.116.16""
 
 [lib]
 name = ""swc""
@@ -55,7 +55,7 @@ swc_ecma_loader = {version = ""0.27.0"", path = ""../swc_ecma_loader"", features = [
 swc_ecma_minifier = {version = ""0.70.9"", path = ""../swc_ecma_minifier""}
 swc_ecma_parser = {version = ""0.87.0"", path = ""../swc_ecma_parser""}
 swc_ecma_preset_env = {version = ""0.86.1"", path = ""../swc_ecma_preset_env""}
-swc_ecma_transforms = {version = ""0.113.3"", path = ""../swc_ecma_transforms"", features = [
+swc_ecma_transforms = {version = ""0.113.4"", path = ""../swc_ecma_transforms"", features = [
   ""compat"",
   ""module"",
   ""optimization"",
@@ -64,11 +64,11 @@ swc_ecma_transforms = {version = ""0.113.3"", path = ""../swc_ecma_transforms"", fea
   ""typescript"",
 ]}
 swc_ecma_transforms_base = {version = ""0.57.1"", path = ""../swc_ecma_transforms_base""}
-swc_ecma_transforms_compat = {version = ""0.68.2"", path = ""../swc_ecma_transforms_compat""}
+swc_ecma_transforms_compat = {version = ""0.68.3"", path = ""../swc_ecma_transforms_compat""}
 swc_ecma_transforms_optimization = {version = ""0.83.0"", path = ""../swc_ecma_transforms_optimization""}
 swc_ecma_utils = {version = ""0.64.0"", path = ""../swc_ecma_utils""}
 swc_ecma_visit = {version = ""0.51.1"", path = ""../swc_ecma_visit""}
-swc_ecmascript = {version = ""0.110.14"", path = ""../swc_ecmascript""}
+swc_ecmascript = {version = ""0.110.15"", path = ""../swc_ecmascript""}
 swc_node_comments = {version = ""0.4.0"", path = ""../swc_node_comments""}
 swc_plugin_runner = {version = ""0.30.0"", path = ""../swc_plugin_runner"", optional = true}
 swc_visit = {version = ""0.3.0"", path = ""../swc_visit""}
diff --git a/crates/swc_ecma_transforms/Cargo.toml b/crates/swc_ecma_transforms/Cargo.toml
index 1604f4e..a0aafae 100644
--- a/crates/swc_ecma_transforms/Cargo.toml
+++ b/crates/swc_ecma_transforms/Cargo.toml
@@ -6,7 +6,7 @@ edition = ""2021""
 license = ""Apache-2.0""
 name = ""swc_ecma_transforms""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.113.3""
+version = ""0.113.4""
 
 [package.metadata.docs.rs]
 all-features = true
@@ -28,7 +28,7 @@ swc_common = {version = ""0.17.0"", path = ""../swc_common""}
 swc_ecma_ast = {version = ""0.65.0"", path = ""../swc_ecma_ast""}
 swc_ecma_parser = {version = ""0.87.0"", path = ""../swc_ecma_parser""}
 swc_ecma_transforms_base = {version = ""0.57.1"", path = ""../swc_ecma_transforms_base""}
-swc_ecma_transforms_compat = {version = ""0.68.2"", path = ""../swc_ecma_transforms_compat"", optional = true}
+swc_ecma_transforms_compat = {version = ""0.68.3"", path = ""../swc_ecma_transforms_compat"", optional = true}
 swc_ecma_transforms_module = {version = ""0.74.0"", path = ""../swc_ecma_transforms_module"", optional = true}
 swc_ecma_transforms_optimization = {version = ""0.83.0"", path = ""../swc_ecma_transforms_optimization"", optional = true}
 swc_ecma_transforms_proposal = {version = ""0.74.0"", path = ""../swc_ecma_transforms_proposal"", optional = true}
diff --git a/crates/swc_ecma_transforms_compat/Cargo.toml b/crates/swc_ecma_transforms_compat/Cargo.toml
index 0ea6609..58374e3 100644
--- a/crates/swc_ecma_transforms_compat/Cargo.toml
+++ b/crates/swc_ecma_transforms_compat/Cargo.toml
@@ -6,7 +6,7 @@ edition = ""2021""
 license = ""Apache-2.0""
 name = ""swc_ecma_transforms_compat""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.68.2""
+version = ""0.68.3""
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [features]
diff --git a/crates/swc_ecmascript/Cargo.toml b/crates/swc_ecmascript/Cargo.toml
index 63680a0..775208a 100644
--- a/crates/swc_ecmascript/Cargo.toml
+++ b/crates/swc_ecmascript/Cargo.toml
@@ -6,7 +6,7 @@ edition = ""2021""
 license = ""Apache-2.0""
 name = ""swc_ecmascript""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.110.14""
+version = ""0.110.15""
 
 [package.metadata.docs.rs]
 all-features = true
@@ -39,7 +39,7 @@ swc_ecma_dep_graph = {version = ""0.58.0"", path = ""../swc_ecma_dep_graph"", option
 swc_ecma_minifier = {version = ""0.70.9"", path = ""../swc_ecma_minifier"", optional = true}
 swc_ecma_parser = {version = ""0.87.0"", path = ""../swc_ecma_parser"", optional = true, default-features = false}
 swc_ecma_preset_env = {version = ""0.86.1"", path = ""../swc_ecma_preset_env"", optional = true}
-swc_ecma_transforms = {version = ""0.113.3"", path = ""../swc_ecma_transforms"", optional = true}
+swc_ecma_transforms = {version = ""0.113.4"", path = ""../swc_ecma_transforms"", optional = true}
 swc_ecma_utils = {version = ""0.64.0"", path = ""../swc_ecma_utils"", optional = true}
 swc_ecma_visit = {version = ""0.51.1"", path = ""../swc_ecma_visit"", optional = true}
 

diff --git a/packages/nocodb/src/services/meta-diffs.service.ts b/packages/nocodb/src/services/meta-diffs.service.ts
index e676ce5..13999f3 100644
--- a/packages/nocodb/src/services/meta-diffs.service.ts
+++ b/packages/nocodb/src/services/meta-diffs.service.ts
@@ -1,5 +1,11 @@
 import { Injectable } from '@nestjs/common';
-import { isVirtualCol, ModelTypes, RelationTypes, UITypes } from 'nocodb-sdk';
+import {
+  isLinksOrLTAR,
+  isVirtualCol,
+  ModelTypes,
+  RelationTypes,
+  UITypes,
+} from 'nocodb-sdk';
 import { T } from 'nc-help';
 import { pluralize, singularize } from 'inflection';
 import { Base, Column, Model, Project } from '../models';
@@ -10,7 +16,7 @@ import { getUniqueColumnAliasName } from '../helpers/getUniqueName';
 import mapDefaultDisplayValue from '../helpers/mapDefaultDisplayValue';
 import NcConnectionMgrv2 from '../utils/common/NcConnectionMgrv2';
 import NcHelp from '../utils/NcHelp';
-import type { LinkToAnotherRecordColumn } from '../models';
+import type { LinksColumn, LinkToAnotherRecordColumn } from '../models';
 
 // todo:move enum and types
 export enum MetaDiffType {
@@ -223,12 +229,13 @@ export class MetaDiffsService {
         if (
           [
             UITypes.LinkToAnotherRecord,
+            UITypes.Links,
             UITypes.Rollup,
             UITypes.Lookup,
             UITypes.Formula,
           ].includes(column.uidt)
         ) {
-          if (column.uidt === UITypes.LinkToAnotherRecord) {
+          if (isLinksOrLTAR(column.uidt)) {
             virtualRelationColumns.push(column);
           }
 
@@ -508,6 +515,7 @@ export class MetaDiffsService {
             UITypes.Rollup,
             UITypes.Lookup,
             UITypes.Formula,
+            UITypes.Links,
           ].includes(column.uidt)
         ) {
           continue;
@@ -947,7 +955,7 @@ export class MetaDiffsService {
                     childModel.columns,
                     pluralize(childModel.title || childModel.table_name),
                   );
-                  await Column.insert<LinkToAnotherRecordColumn>({
+                  await Column.insert<LinksColumn>({
                     uidt: UITypes.Links,
                     title,
                     fk_model_id: parentModel.id,
@@ -984,7 +992,7 @@ export class MetaDiffsService {
     const colChildOpt =
       await belongsToCol.getColOptions<LinkToAnotherRecordColumn>();
     for (const col of await model.getColumns()) {
-      if (col.uidt === UITypes.LinkToAnotherRecord) {
+      if (isLinksOrLTAR(col.uidt)) {
         const colOpt = await col.getColOptions<LinkToAnotherRecordColumn>();
         if (
           colOpt &&
@@ -1043,7 +1051,7 @@ export class MetaDiffsService {
         );
 
         if (!isRelationAvailInA) {
-          await Column.insert<LinkToAnotherRecordColumn>({
+          await Column.insert<LinksColumn>({
             title: getUniqueColumnAliasName(
               modelA.columns,
               pluralize(modelB.title),
@@ -1067,7 +1075,7 @@ export class MetaDiffsService {
           });
         }
         if (!isRelationAvailInB) {
-          await Column.insert<LinkToAnotherRecordColumn>({
+          await Column.insert<LinksColumn>({
             title: getUniqueColumnAliasName(
               modelB.columns,
               pluralize(modelA.title),
@@ -1099,7 +1107,7 @@ export class MetaDiffsService {
           const model = await colOpt.getRelatedTable();
 
           for (const col of await model.getColumns()) {
-            if (col.uidt !== UITypes.LinkToAnotherRecord) continue;
+            if (!isLinksOrLTAR(col.uidt)) continue;
 
             const colOpt1 =
               await col.getColOptions<LinkToAnotherRecordColumn>();
",2,"[""af53b9487f74ff28438928903fb1f2db93fe4fa8"", ""30ed3b4ed089cb69e6b6b51aaccc15db66d1ee49""]","[""build"", ""fix""]"
"bump version

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com> | repository creation","diff --git a/scripts/helmcharts/init.sh b/scripts/helmcharts/init.sh
index 5a2b4b0..69a6944 100644
--- a/scripts/helmcharts/init.sh
+++ b/scripts/helmcharts/init.sh
@@ -26,7 +26,7 @@ usr=$(whoami)
 
 # Installing k3s
 function install_k8s() {
-    curl -sL https://get.k3s.io | sudo K3S_KUBECONFIG_MODE=""644"" INSTALL_K3S_VERSION='v1.22.8+k3s1' INSTALL_K3S_EXEC=""--no-deploy=traefik"" sh -
+    curl -sL https://get.k3s.io | sudo K3S_KUBECONFIG_MODE=""644"" INSTALL_K3S_VERSION='v1.25.6+k3s1' INSTALL_K3S_EXEC=""--disable=traefik"" sh -
     [[ -d ~/.kube ]] || mkdir ~/.kube
     sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config
     sudo chmod 0644 ~/.kube/config

diff --git a/server/src/services/repository.service.ts b/server/src/services/repository.service.ts
index 3869c98..d675b30 100644
--- a/server/src/services/repository.service.ts
+++ b/server/src/services/repository.service.ts
@@ -19,6 +19,8 @@ export class RepositoryService {
       return;
     }
 
+    await this.createTeam(this.github, this.getTeamName(course), course.id);
+
     const studentRepo = getCustomRepository(StudentRepository);
     const students = await studentRepo.findActiveByCourseId(this.courseId);
 
@@ -31,8 +33,8 @@ export class RepositoryService {
         if (mentorGithubId) {
           await this.inviteMentor(mentorGithubId, course);
         }
-        await this.addTeamToRepository(this.github, course, student.githubId);
       }
+      await this.addTeamToRepository(this.github, course, student.githubId);
       if (record?.repository) {
         result.push({ repository: record.repository });
       }
",2,"[""9a25fe59dfb63d32505afcea3a164ff0b8ea4c71"", ""87d5d4e55ab7149b593d29410f1fe426ba2447d4""]","[""build"", ""fix""]"
use a closure | rebuild when environment variables change (#11471),"diff --git a/ibis/expr/analysis.py b/ibis/expr/analysis.py
index bb17a7a..975c658 100644
--- a/ibis/expr/analysis.py
+++ b/ibis/expr/analysis.py
@@ -39,7 +39,9 @@ def sub_for(expr, substitutions):
         An Ibis expression
     """"""
 
-    def fn(node, mapping={k.op(): v for k, v in substitutions}):
+    mapping = {k.op(): v for k, v in substitutions}
+
+    def fn(node):
         try:
             return mapping[node]
         except KeyError:

diff --git a/cli/build.rs b/cli/build.rs
index 548fbb5..d7bed21 100644
--- a/cli/build.rs
+++ b/cli/build.rs
@@ -269,8 +269,17 @@ fn main() {
   // To debug snapshot issues uncomment:
   // op_fetch_asset::trace_serializer();
 
-  println!(""cargo:rustc-env=TS_VERSION={}"", ts_version());
+  if let Ok(c) = env::var(""DENO_CANARY"") {
+    println!(""cargo:rustc-env=DENO_CANARY={}"", c);
+  }
+  println!(""cargo:rerun-if-env-changed=DENO_CANARY"");
+
   println!(""cargo:rustc-env=GIT_COMMIT_HASH={}"", git_commit_hash());
+  println!(""cargo:rerun-if-env-changed=GIT_COMMIT_HASH"");
+
+  println!(""cargo:rustc-env=TS_VERSION={}"", ts_version());
+  println!(""cargo:rerun-if-env-changed=TS_VERSION"");
+
   println!(
     ""cargo:rustc-env=DENO_CONSOLE_LIB_PATH={}"",
     deno_console::get_declaration().display()
@@ -322,9 +331,6 @@ fn main() {
 
   println!(""cargo:rustc-env=TARGET={}"", env::var(""TARGET"").unwrap());
   println!(""cargo:rustc-env=PROFILE={}"", env::var(""PROFILE"").unwrap());
-  if let Ok(c) = env::var(""DENO_CANARY"") {
-    println!(""cargo:rustc-env=DENO_CANARY={}"", c);
-  }
 
   let c = PathBuf::from(env::var_os(""CARGO_MANIFEST_DIR"").unwrap());
   let o = PathBuf::from(env::var_os(""OUT_DIR"").unwrap());
",2,"[""ad52e1d67fd77f0b6a73fbf989b33f9abf395ecc"", ""63546c15bfb1284ac6d956eee274e6d7cf263a8f""]","[""refactor"", ""build""]"
abort parallel stages if one failed,"diff --git a/Jenkinsfile b/Jenkinsfile
index 168f446..a4da961 100644
--- a/Jenkinsfile
+++ b/Jenkinsfile
@@ -28,6 +28,7 @@ pipeline {
         }
 
         stage('Verify') {
+            failFast true
             parallel {
                 stage('Tests') {
                     steps {
",1,"[""28e623b294816c4e070971782a75c8697a11966f""]","[""cicd""]"
do not use scripts and binaries from the libcc repo,"diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |
",1,"[""45837af24a33308a70a3454f0f650f9fe728e272""]","[""cicd""]"
"updated riot to v6, fixed build | autostart feature fixed","diff --git a/components/riot/package.json b/components/riot/package.json
index c41743a..eb69756 100644
--- a/components/riot/package.json
+++ b/components/riot/package.json
@@ -61,7 +61,7 @@
   },
   ""devDependencies"": {
     ""@babel/preset-typescript"": ""^7.14.5"",
-    ""@riotjs/cli"": ""^6.0.4"",
+    ""@riotjs/cli"": ""^6.0.5"",
     ""@riotjs/compiler"": ""^6.0.0"",
     ""chai"": ""^4.3.4"",
     ""esm"": ""^3.2.25"",

diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();
",2,"[""5d256f937f93e5a5ed003df86d38c44834095a11"", ""bed78248c941d57ad4cc20a455147e186e97c7a1""]","[""build"", ""fix""]"
skip ruff format in pre-commit ci runner | add getter for protocol id,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 6193d96..4ba39d6 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -9,6 +9,7 @@ ci:
     - nixpkgs-fmt
     - prettier
     - ruff
+    - ruff-format
     - shellcheck
     - shfmt
     - statix

diff --git a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
index ad0015f..68624d8 100644
--- a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
+++ b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
@@ -50,4 +50,9 @@ public class TransportHeaderDescriptor
         return this;
     }
 
+    public int protocolId()
+    {
+        return buffer.getShort(PROTOCOL_ID_OFFSET);
+    }
+
 }
",2,"[""9117fdedb9b5ce0345c31b3e1fa22ae8554944d4"", ""dc5238b2bda98a7c4f2fe9584fc3b0191a408109""]","[""cicd"", ""feat""]"
run nix macos jobs on macos-13 to try and avoid SIP,"diff --git a/.github/actionlint.yaml b/.github/actionlint.yaml
new file mode 100644
index 0000000..5be7d17
--- /dev/null
+++ b/.github/actionlint.yaml
@@ -0,0 +1,7 @@
+self-hosted-runner:
+  # Labels of self-hosted runner in array of strings.
+  labels: [macos-13]
+# Configuration variables in array of strings defined in your repository or
+# organization. `null` means disabling configuration variables check.
+# Empty array means no configuration variable is allowed.
+config-variables: null
diff --git a/.github/workflows/nix.yml b/.github/workflows/nix.yml
index e37346c..dce77e1 100644
--- a/.github/workflows/nix.yml
+++ b/.github/workflows/nix.yml
@@ -37,7 +37,7 @@ jobs:
           - ""3.10""
           - ""3.11""
         include:
-          - os: macos-latest
+          - os: macos-13
             python-version: ""3.10""
     steps:
       - name: checkout
diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 005a850..8db22e2 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -3,7 +3,7 @@ ci:
   autofix_prs: false
   autoupdate_commit_msg: ""chore(deps): pre-commit.ci autoupdate""
   skip:
-    - actionlint
+    - actionlint-system
     - deadnix
     - just
     - nixpkgs-fmt
@@ -17,9 +17,9 @@ default_stages:
   - commit
 repos:
   - repo: https://github.com/rhysd/actionlint
-    rev: v1.6.24
+    rev: v1.6.25
     hooks:
-      - id: actionlint
+      - id: actionlint-system
   - repo: https://github.com/psf/black
     rev: 23.3.0
     hooks:
@@ -30,7 +30,7 @@ repos:
       - id: nbstripout
         exclude: .+/rendered/.+
   - repo: https://github.com/codespell-project/codespell
-    rev: v2.2.4
+    rev: v2.2.5
     hooks:
       - id: codespell
         additional_dependencies:
",1,"[""54cb6d4643b4a072ff997592a7fa14a69a6c068d""]","[""cicd""]"
"use an action for issue assignment | permission check | enable user to re-order attachment in modal view

re #383

Signed-off-by: Pranav C <pranavxc@gmail.com>","diff --git a/.github/workflows/assign.yml b/.github/workflows/assign.yml
index 29d92a8..758874e 100644
--- a/.github/workflows/assign.yml
+++ b/.github/workflows/assign.yml
@@ -8,8 +8,6 @@ jobs:
     runs-on: ubuntu-latest
     if: ${{ github.event.comment.body == '/take' }}
     steps:
-      - uses: actions/checkout@v2
-      - name: Assign issue ${{ github.event.issue.number }} to ${{ github.event.comment.user.login }}
-        run: gh issue edit ${{ github.event.issue.number }} --add-assignee ""${{ github.event.comment.user.login }}""
-        env:
-          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+      - uses: pozil/auto-assign-issue@v1.1.0
+        with:
+          assignees: ${{ github.event.comment.user.login }}

diff --git a/server/src/routes/course/index.ts b/server/src/routes/course/index.ts
index 557f5fb..bc0e490 100644
--- a/server/src/routes/course/index.ts
+++ b/server/src/routes/course/index.ts
@@ -209,7 +209,7 @@ function addStudentApi(router: Router, logger: ILogger) {
   router.post('/student/:githubId/status', ...mentorValidators, updateStudentStatus(logger));
   router.post('/student/:githubId/status-self', courseGuard, selfUpdateStudentStatus(logger));
   router.get('/student/:githubId/score', courseGuard, getScoreByStudent(logger));
-  router.post('/student/:githubId/certificate', courseManagerGuard, ...validators, postStudentCertificate(logger));
+  router.post('/student/:githubId/certificate', courseManagerGuard, validateGithubId, postStudentCertificate(logger));
 
   router.get('/students', courseSupervisorGuard, getStudents(logger));
   router.get('/students/csv', courseSupervisorGuard, getStudentsCsv(logger));

diff --git a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
index 7e9d06c..cbc5775 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
@@ -18,13 +18,16 @@
     </div>
 
     <div class=""d-flex align-center img-container"">
-      <div v-for=""(item,i) in localState"" :key=""i"" class=""thumbnail align-center justify-center d-flex"">
+      <div
+        v-for=""(item,i) in localState""
+        :key=""item.url""
+        class=""thumbnail align-center justify-center d-flex""
+      >
         <v-tooltip bottom>
           <template #activator=""{on}"">
             <!--            <img alt=""#"" v-if=""isImage(item.title)"" :src=""item.url"" v-on=""on"" @click=""selectImage(item.url,i)"">-->
             <v-img
               v-if=""isImage(item.title)""
-              :key=""item.url""
               lazy-src=""https://via.placeholder.com/60.png?text=Loading...""
               alt=""#""
               max-height=""33px""
@@ -89,7 +92,11 @@
 
           <div class=""d-flex flex-wrap h-100"">
             <v-container fluid style=""max-height:calc(90vh - 80px);overflow-y: auto"">
-              <v-row>
+              <draggable
+                v-model=""localState""
+                class=""row""
+                @update=""onOrderUpdate""
+              >
                 <v-col v-for=""(item,i) in localState"" :key=""i"" cols=""4"">
                   <v-card
                     class=""modal-thumbnail-card align-center justify-center d-flex""
@@ -125,7 +132,7 @@
                     {{ item.title }}
                   </p>
                 </v-col>
-              </v-row>
+              </draggable>
             </v-container>
           </div>
         </v-card-text>
@@ -216,9 +223,12 @@
 
 <script>
 import FileSaver from 'file-saver'
+import draggable from 'vuedraggable'
 import { isImage } from '@/components/project/spreadsheet/helpers/imageExt'
+
 export default {
   name: 'EditableAttachmentCell',
+  components: { draggable },
   props: ['dbAlias', 'value', 'active', 'isLocked', 'meta', 'column'],
   data: () => ({
     carousel: null,
@@ -301,6 +311,10 @@ export default {
       this.$emit('input', JSON.stringify(this.localState))
       this.$emit('update')
     },
+    onOrderUpdate() {
+      this.$emit('input', JSON.stringify(this.localState))
+      this.$emit('update')
+    },
     removeItem(i) {
       this.localState.splice(i, 1)
       this.$emit('input', JSON.stringify(this.localState))
@@ -394,18 +408,19 @@ export default {
   top: 5px;
   right: 5px
 }
-.modal-thumbnail-card{
+
+.modal-thumbnail-card {
 
   .download-icon {
     position: absolute;
     bottom: 5px;
     right: 5px;
-    opacity:0;
-    transition:.4s opacity;
+    opacity: 0;
+    transition: .4s opacity;
   }
 
-  &:hover .download-icon{
-    opacity:1
+  &:hover .download-icon {
+    opacity: 1
   }
 }
 
",3,"[""fb3a231b29bc8bff9270b99dd4aff9dad599f21f"", ""33c25b2f59c931a7f4af994365522221a7821dca"", ""fd8e563cc19ca4684885d4692acee6bebcca4ada""]","[""cicd"", ""fix"", ""feat""]"
add important to override paragraphs in items | fixed tick interval,"diff --git a/packages/core/src/components/text/text.ios.scss b/packages/core/src/components/text/text.ios.scss
index a3c58e2..2a020ab 100644
--- a/packages/core/src/components/text/text.ios.scss
+++ b/packages/core/src/components/text/text.ios.scss
@@ -9,8 +9,9 @@
 @each $color-name, $color-base, $color-contrast in get-colors($colors-ios) {
 
   .text-ios-#{$color-name},
-  .text-ios-#{$color-name} a {
-    color: $color-base;
+  .text-ios-#{$color-name} a,
+  .text-ios-#{$color-name} p {
+    color: $color-base !important
   }
 
 }
diff --git a/packages/core/src/components/text/text.md.scss b/packages/core/src/components/text/text.md.scss
index b397acb..050af1a 100644
--- a/packages/core/src/components/text/text.md.scss
+++ b/packages/core/src/components/text/text.md.scss
@@ -9,8 +9,9 @@
 @each $color-name, $color-base, $color-contrast in get-colors($colors-md) {
 
   .text-md-#{$color-name},
-  .text-md-#{$color-name} a {
-    color: $color-base;
+  .text-md-#{$color-name} a,
+  .text-md-#{$color-name} p {
+    color: $color-base !important;
   }
 
 }

diff --git a/backend/services/integrations/main.go b/backend/services/integrations/main.go
index 4a5e764..35c3ff2 100644
--- a/backend/services/integrations/main.go
+++ b/backend/services/integrations/main.go
@@ -54,7 +54,7 @@ func main() {
 	sigchan := make(chan os.Signal, 1)
 	signal.Notify(sigchan, syscall.SIGINT, syscall.SIGTERM)
 
-	tick := time.Tick(intervals.INTEGRATIONS_REQUEST_INTERVAL)
+	tick := time.Tick(intervals.INTEGRATIONS_REQUEST_INTERVAL * time.Millisecond)
 
 	log.Printf(""Integration service started\n"")
 	manager.RequestAll()
@@ -66,7 +66,7 @@ func main() {
 			pg.Close()
 			os.Exit(0)
 		case <-tick:
-			// log.Printf(""Requesting all...\n"")
+			log.Printf(""Requesting all...\n"")
 			manager.RequestAll()
 		case event := <-manager.Events:
 			// log.Printf(""New integration event: %v\n"", *event.RawErrorEvent)
",2,"[""7ab363f7ba2807b3eb9895e47f4fcd058f43ae5e"", ""7dc3b70fe40fc7de255a28bb3098bcb8c0d35365""]","[""test"", ""fix""]"
"use new, public `quay.io/influxdb/iox` image | updated riot to v6, fixed build | create mock img server","diff --git a/.circleci/config.yml b/.circleci/config.yml
index 3ae6728..a5f2d2f 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -12,7 +12,7 @@
 # The CI for every PR and merge to main runs tests, fmt, lints and compiles debug binaries
 #
 # On main if all these checks pass it will then additionally compile in ""release"" mode and
-# publish a docker image to quay.io/influxdb/fusion:$COMMIT_SHA
+# publish a docker image to quay.io/influxdb/iox:$COMMIT_SHA
 #
 # Manual CI Image:
 #
@@ -317,11 +317,11 @@ jobs:
   #
   # Uses the latest ci_image (influxdb/rust below) to build a release binary and
   # copies it to a minimal container image based upon `rust:slim-buster`. This
-  # minimal image is then pushed to `quay.io/influxdb/fusion:${BRANCH}` with '/'
+  # minimal image is then pushed to `quay.io/influxdb/iox:${BRANCH}` with '/'
   # repaced by '.' - as an example:
   #
   #   git branch: dom/my-awesome-feature/perf
-  #   container: quay.io/influxdb/fusion:dom.my-awesome-feature.perf
+  #   container: quay.io/influxdb/iox:dom.my-awesome-feature.perf
   #
   # Subsequent CI runs will overwrite the tag if you push more changes, so watch
   # out for parallel CI runs!
@@ -365,7 +365,7 @@ jobs:
           sudo apt-get update
           sudo apt-get install -y docker.io
       - run: |
-          echo ""$QUAY_PASS"" | docker login quay.io --username $QUAY_USER --password-stdin
+          echo ""$QUAY_INFLUXDB_IOX_PASS"" | docker login quay.io --username $QUAY_INFLUXDB_IOX_USER --password-stdin
       - run:
           # Docker has functionality to support per-Dockerfile .dockerignore
           # This was added in https://github.com/moby/buildkit/pull/901
@@ -379,8 +379,8 @@ jobs:
           echo sha256sum after build is
           sha256sum target/release/influxdb_iox
           COMMIT_SHA=$(git rev-parse --short HEAD)
-          docker build -t quay.io/influxdb/fusion:$COMMIT_SHA -f docker/Dockerfile.iox .
-          docker push quay.io/influxdb/fusion:$COMMIT_SHA
+          docker build -t quay.io/influxdb/iox:$COMMIT_SHA -f docker/Dockerfile.iox .
+          docker push quay.io/influxdb/iox:$COMMIT_SHA
           echo ""export COMMIT_SHA=${COMMIT_SHA}"" >> $BASH_ENV
       - run:
           name: Deploy tags

diff --git a/components/riot/package.json b/components/riot/package.json
index c41743a..eb69756 100644
--- a/components/riot/package.json
+++ b/components/riot/package.json
@@ -61,7 +61,7 @@
   },
   ""devDependencies"": {
     ""@babel/preset-typescript"": ""^7.14.5"",
-    ""@riotjs/cli"": ""^6.0.4"",
+    ""@riotjs/cli"": ""^6.0.5"",
     ""@riotjs/compiler"": ""^6.0.0"",
     ""chai"": ""^4.3.4"",
     ""esm"": ""^3.2.25"",

diff --git a/scripts/gulp/tasks/test.ts b/scripts/gulp/tasks/test.ts
index 8014b12..d10c1aa 100644
--- a/scripts/gulp/tasks/test.ts
+++ b/scripts/gulp/tasks/test.ts
@@ -26,12 +26,18 @@ task('test.imageserver', () => {
   function handleRequest(req, res) {
     const urlParse = url.parse(req.url, true);
 
+    res.setHeader('Access-Control-Allow-Origin', '*');
+    res.setHeader('Access-Control-Allow-Methods', 'GET');
+    res.setHeader('Connection', 'keep-alive');
+    res.setHeader('Age', '0');
+    res.setHeader('cache-control', 'no-store');
+
     if (urlParse.pathname === '/reset') {
       console.log('Image Server Reset');
       console.log('---------------------------');
       requestedUrls.length = 0;
       start = Date.now();
-      res.setHeader('Access-Control-Allow-Origin', '*');
+      res.setHeader('Content-Type', 'text/plain');
       res.end('reset');
       return;
     }
@@ -48,9 +54,8 @@ task('test.imageserver', () => {
 
     setTimeout(() => {
       res.setHeader('Content-Type', 'image/svg+xml');
-      res.setHeader('Access-Control-Allow-Origin', '*');
       res.end(`<svg xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink""
-                   style=""background-color: ${color}; width: ${width}px; height: ${height}px;"">
+                   viewBox=""0 0 ${width} ${height}"" style=""background-color: ${color};"">
                  <text x=""5"" y=""22"" style=""font-family: Courier; font-size: 24px"">${id}</text>
                </svg>`);
     }, delay);
",3,"[""f751bb5426b87f82096d620f1cd6203badf45d58"", ""5d256f937f93e5a5ed003df86d38c44834095a11"", ""32b76173a259ea1993298289b436cf10c1e800bf""]","[""cicd"", ""build"", ""test""]"
"add user role enum

Signed-off-by: Braks <78412429+bcakmakoglu@users.noreply.github.com> | use `regexp_instr != 0` instead of `REGEXP` keyword | test AsyncAggregatingSubscriber","diff --git a/packages/nc-gui-v2/lib/enums.ts b/packages/nc-gui-v2/lib/enums.ts
index e87b69a..c6751a3 100644
--- a/packages/nc-gui-v2/lib/enums.ts
+++ b/packages/nc-gui-v2/lib/enums.ts
@@ -1,3 +1,9 @@
+export enum Role {
+  Super = 'super',
+  Admin = 'admin',
+  User = 'user',
+}
+
 export enum Language {
   de = 'Deutsch',
   en = 'English',
diff --git a/packages/nc-gui-v2/lib/types.ts b/packages/nc-gui-v2/lib/types.ts
index bf152c4..dd8a1ce 100644
--- a/packages/nc-gui-v2/lib/types.ts
+++ b/packages/nc-gui-v2/lib/types.ts
@@ -1,11 +1,12 @@
 import type { ComputedRef, ToRefs } from 'vue'
+import type { Role } from '~/lib/enums'
 
 export interface User {
   id: string
   email: string
   firstname: string | null
   lastname: string | null
-  roles: string[]
+  roles: (Role | string)[]
 }
 
 export interface State {

diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(

diff --git a/backup-stores/s3/pom.xml b/backup-stores/s3/pom.xml
index 282a4dc..1db7a33 100644
--- a/backup-stores/s3/pom.xml
+++ b/backup-stores/s3/pom.xml
@@ -149,6 +149,12 @@
       <artifactId>aws-java-sdk-core</artifactId>
       <scope>test</scope>
     </dependency>
+
+    <dependency>
+      <groupId>org.mockito</groupId>
+      <artifactId>mockito-core</artifactId>
+      <scope>test</scope>
+    </dependency>
   </dependencies>
 
   <build>
diff --git a/backup-stores/s3/src/test/java/io/camunda/zeebe/backup/s3/util/AsyncAggregatingSubscriberTest.java b/backup-stores/s3/src/test/java/io/camunda/zeebe/backup/s3/util/AsyncAggregatingSubscriberTest.java
new file mode 100644
index 0000000..b83ec84
--- /dev/null
+++ b/backup-stores/s3/src/test/java/io/camunda/zeebe/backup/s3/util/AsyncAggregatingSubscriberTest.java
@@ -0,0 +1,97 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.backup.s3.util;
+
+import static org.assertj.core.api.Assertions.assertThat;
+import static org.mockito.Mockito.mock;
+
+import java.time.Duration;
+import java.util.Collection;
+import java.util.concurrent.CompletableFuture;
+import java.util.concurrent.ExecutionException;
+import org.junit.jupiter.api.Test;
+import org.reactivestreams.Subscription;
+import org.testcontainers.shaded.org.awaitility.Awaitility;
+
+final class AsyncAggregatingSubscriberTest {
+
+  @Test
+  void shouldCompleteOnlyAfterAllFuturesComplete() {
+    // given
+    final var aggregator = new AsyncAggregatingSubscriber<Integer>(16);
+    final var completed = CompletableFuture.completedFuture(1);
+    final var delayed = new CompletableFuture<Integer>();
+
+    aggregator.onSubscribe(mock(Subscription.class));
+    final CompletableFuture<Collection<Integer>> result = aggregator.result();
+
+    // when
+    aggregator.onNext(completed);
+    aggregator.onNext(delayed);
+    aggregator.onComplete();
+
+    // then
+    assertThat(result).isNotDone();
+
+    delayed.complete(2);
+    Awaitility.await().until(result::isDone);
+    assertThat(result.join()).containsExactlyInAnyOrder(1, 2);
+  }
+
+  @Test
+  void shouldFailIfOneFutureFails() {
+    // given
+    final var aggregator = new AsyncAggregatingSubscriber<Integer>(16);
+    final var completed = CompletableFuture.completedFuture(1);
+    final var failed = new CompletableFuture<Integer>();
+
+    aggregator.onSubscribe(mock(Subscription.class));
+    final CompletableFuture<Collection<Integer>> result = aggregator.result();
+
+    // when
+    aggregator.onNext(completed);
+    aggregator.onNext(failed);
+    aggregator.onComplete();
+
+    // then
+    failed.completeExceptionally(new RuntimeException(""Failed""));
+
+    Awaitility.await()
+        .untilAsserted(
+            () ->
+                assertThat(result)
+                    .failsWithin(Duration.ofMillis(100))
+                    .withThrowableOfType(ExecutionException.class)
+                    .withMessageContaining(""Failed""));
+  }
+
+  @Test
+  void shouldFailsIfSubscriptionFails() {
+    // given
+    final var aggregator = new AsyncAggregatingSubscriber<Integer>(16);
+    final var completed = CompletableFuture.completedFuture(1);
+    final var failed = new CompletableFuture<Integer>();
+
+    aggregator.onSubscribe(mock(Subscription.class));
+    final CompletableFuture<Collection<Integer>> result = aggregator.result();
+
+    // when
+    aggregator.onNext(completed);
+    aggregator.onNext(failed);
+    aggregator.onError(new RuntimeException(""Failed""));
+
+    // then
+    Awaitility.await()
+        .untilAsserted(
+            () ->
+                assertThat(result)
+                    .failsWithin(Duration.ofMillis(100))
+                    .withThrowableOfType(ExecutionException.class)
+                    .withMessageContaining(""Failed""));
+  }
+}
",3,"[""176a959eb80d17f9abc5c6b5354e6097be95b42d"", ""06e2be4e2019b6fa714e1fcb34485860ef1ede79"", ""266706b864ff773dc67e04fa9df2fbf02d0c8b54""]","[""feat"", ""fix"", ""test""]"
"fix monorepo.dir prop

Signed-off-by: Carlos Alexandro Becker <caarlos0@gmail.com>","diff --git a/www/docs/customization/monorepo.md b/www/docs/customization/monorepo.md
index 6d0e857..e45490f 100644
--- a/www/docs/customization/monorepo.md
+++ b/www/docs/customization/monorepo.md
@@ -18,7 +18,7 @@ project_name: subproj1
 
 monorepo:
   tag_prefix: subproject1/
-  folder: subproj1
+  dir: subproj1
 ```
 
 Then, you can release with (from the project's root directory):
@@ -30,11 +30,11 @@ goreleaser release --rm-dist -f ./subproj1/.goreleaser.yml
 Then, the following is different from a ""regular"" run:
 
 - GoReleaser will then look if current commit has a tag prefixed with `subproject1`, and also the previous tag with the same prefix;
-- Changelog will include only commits that contain changes to files within the `subproj1` folder;
+- Changelog will include only commits that contain changes to files within the `subproj1` directory;
 - Release name gets prefixed with `{{ .ProjectName }} ` if empty;
-- All build's `dir` setting get set to `monorepo.folder` if empty;
+- All build's `dir` setting get set to `monorepo.dir` if empty;
   - if yours is not, you might want to change that manually;
-- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.folder`;
+- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.dir`;
 - On templates, `{{.PrefixedTag}}` will be `monorepo.prefix/tag` (aka the actual tag name), and `{{.Tag}}` has the prefix stripped;
 
 The rest of the release process should work as usual.
",1,"[""9ed3c0c4a72af977fc9150512fb6538f20a94b22""]","[""docs""]"
"terminated tasks linger for a bit

Signed-off-by: Eliza Weisman <eliza@buoyant.io> | run nix macos jobs on macos-13 to try and avoid SIP | add `to_sql`

Co-authored-by: Gil Forsyth <gforsyth@users.noreply.github.com>","diff --git a/console/src/main.rs b/console/src/main.rs
index ebfa315..5328d96 100644
--- a/console/src/main.rs
+++ b/console/src/main.rs
@@ -69,6 +69,7 @@ async fn main() -> Result<(), Box<dyn std::error::Error>> {
                 .wrap(Wrap { trim: true });
             f.render_widget(header, chunks[0]);
             tasks.render(f, chunks[1]);
+            tasks.retain_active();
         })?;
     }
 
diff --git a/console/src/tasks.rs b/console/src/tasks.rs
index 7be39a4..eb41495 100644
--- a/console/src/tasks.rs
+++ b/console/src/tasks.rs
@@ -19,6 +19,7 @@ struct Task {
     fields: String,
     kind: &'static str,
     stats: Stats,
+    completed_for: usize,
 }
 
 #[derive(Default, Debug)]
@@ -28,10 +29,15 @@ struct Stats {
     idle: Duration,
     total: Duration,
 }
+
 impl State {
+    // How many updates to retain completed tasks for
+    const RETAIN_COMPLETED_FOR: usize = 6;
+
     pub(crate) fn len(&self) -> usize {
         self.tasks.len()
     }
+
     pub(crate) fn update(&mut self, update: proto::tasks::TaskUpdate) {
         let new_tasks = update.new_tasks.into_iter().filter_map(|task| {
             if task.id.is_none() {
@@ -48,6 +54,7 @@ impl State {
                 fields: task.string_fields,
                 kind,
                 stats: Default::default(),
+                completed_for: 0,
             };
             Some((id, task))
         });
@@ -60,7 +67,10 @@ impl State {
         }
 
         for proto::SpanId { id } in update.completed {
-            if self.tasks.remove(&id).is_none() {
+            if let Some(task) = self.tasks.get_mut(&id) {
+                task.kind = ""!"";
+                task.completed_for = 1;
+            } else {
                 tracing::warn!(?id, ""tried to complete a task that didn't exist"");
             }
         }
@@ -79,7 +89,7 @@ impl State {
         const DUR_PRECISION: usize = 4;
         const POLLS_LEN: usize = 5;
         let rows = self.tasks.values().map(|task| {
-            let row = Row::new(vec![
+            let mut row = Row::new(vec![
                 Cell::from(task.id_hex.as_str()),
                 // TODO(eliza): is there a way to write a `fmt::Debug` impl
                 // directly to tui without doing an allocation?
@@ -105,6 +115,9 @@ impl State {
                 Cell::from(format!(""{:>width$}"", task.stats.polls, width = POLLS_LEN)),
                 Cell::from(task.fields.as_str()),
             ]);
+            if task.completed_for > 0 {
+                row = row.style(Style::default().add_modifier(style::Modifier::DIM));
+            }
             row
         });
         let t = Table::new(rows)
@@ -126,6 +139,16 @@ impl State {
 
         frame.render_widget(t, area)
     }
+
+    pub(crate) fn retain_active(&mut self) {
+        self.tasks.retain(|_, task| {
+            if task.completed_for == 0 {
+                return true;
+            }
+            task.completed_for += 1;
+            task.completed_for <= Self::RETAIN_COMPLETED_FOR
+        })
+    }
 }
 
 impl From<proto::tasks::Stats> for Stats {

diff --git a/.github/actionlint.yaml b/.github/actionlint.yaml
new file mode 100644
index 0000000..5be7d17
--- /dev/null
+++ b/.github/actionlint.yaml
@@ -0,0 +1,7 @@
+self-hosted-runner:
+  # Labels of self-hosted runner in array of strings.
+  labels: [macos-13]
+# Configuration variables in array of strings defined in your repository or
+# organization. `null` means disabling configuration variables check.
+# Empty array means no configuration variable is allowed.
+config-variables: null
diff --git a/.github/workflows/nix.yml b/.github/workflows/nix.yml
index e37346c..dce77e1 100644
--- a/.github/workflows/nix.yml
+++ b/.github/workflows/nix.yml
@@ -37,7 +37,7 @@ jobs:
           - ""3.10""
           - ""3.11""
         include:
-          - os: macos-latest
+          - os: macos-13
             python-version: ""3.10""
     steps:
       - name: checkout
diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 005a850..8db22e2 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -3,7 +3,7 @@ ci:
   autofix_prs: false
   autoupdate_commit_msg: ""chore(deps): pre-commit.ci autoupdate""
   skip:
-    - actionlint
+    - actionlint-system
     - deadnix
     - just
     - nixpkgs-fmt
@@ -17,9 +17,9 @@ default_stages:
   - commit
 repos:
   - repo: https://github.com/rhysd/actionlint
-    rev: v1.6.24
+    rev: v1.6.25
     hooks:
-      - id: actionlint
+      - id: actionlint-system
   - repo: https://github.com/psf/black
     rev: 23.3.0
     hooks:
@@ -30,7 +30,7 @@ repos:
       - id: nbstripout
         exclude: .+/rendered/.+
   - repo: https://github.com/codespell-project/codespell
-    rev: v2.2.4
+    rev: v2.2.5
     hooks:
       - id: codespell
         additional_dependencies:

diff --git a/docs/api/expressions/top_level.md b/docs/api/expressions/top_level.md
index efaffbd..34b529e 100644
--- a/docs/api/expressions/top_level.md
+++ b/docs/api/expressions/top_level.md
@@ -28,7 +28,7 @@ These methods and objects are available directly in the `ibis` module.
 ::: ibis.or_
 ::: ibis.param
 ::: ibis.show_sql
-::: ibis.sql
+::: ibis.to_sql
 ::: ibis.random
 ::: ibis.range_window
 ::: ibis.row_number
",3,"[""1bcf88670b50155b50071e707f98f30cea0b7a24"", ""54cb6d4643b4a072ff997592a7fa14a69a6c068d"", ""e2821a56c7d867b8b591f1777019843a2ffca797""]","[""feat"", ""cicd"", ""docs""]"
rename ELECTRON_CACHE env variable to electron_config_cache (#21313),"diff --git a/docs/tutorial/installation.md b/docs/tutorial/installation.md
index d4af120..1a09eea 100644
--- a/docs/tutorial/installation.md
+++ b/docs/tutorial/installation.md
@@ -82,7 +82,7 @@ with the network at all.
 On environments that have been using older versions of Electron, you might find the
 cache also in `~/.electron`.
 
-You can also override the local cache location by providing a `ELECTRON_CACHE`
+You can also override the local cache location by providing a `electron_config_cache`
 environment variable.
 
 The cache contains the version's official zip file as well as a checksum, stored as
",1,"[""f2f52c23b513dd857350f3c163f676d37189d0d3""]","[""docs""]"
"trigger build every hour for develop

To better track stability of the develop branch the build should be
triggered on commit and every hour. Other branches should not be
effected.

- add cron trigger to develop branch
- extract variables to identify stable and develop branch","diff --git a/Jenkinsfile b/Jenkinsfile
index 2c58f61..9daa38f 100644
--- a/Jenkinsfile
+++ b/Jenkinsfile
@@ -4,9 +4,17 @@
 
 def buildName = ""${env.JOB_BASE_NAME.replaceAll(""%2F"", ""-"").replaceAll(""\\."", ""-"").take(20)}-${env.BUILD_ID}""
 
+def masterBranchName = 'master'
+def isMasterBranch = env.BRANCH_NAME == masterBranchName
+def developBranchName = 'develop'
+def isDevelopBranch = env.BRANCH_NAME == developBranchName
+
 //for develop branch keep builds for 7 days to be able to analyse build errors, for all other branches, keep the last 10 builds
-def daysToKeep = (env.BRANCH_NAME=='develop') ? '7' : '-1'
-def numToKeep = (env.BRANCH_NAME=='develop') ? '-1' : '10'
+def daysToKeep = isDevelopBranch ? '7' : '-1'
+def numToKeep = isDevelopBranch ? '-1' : '10'
+
+//the develop branch should be run hourly to detect flaky tests and instability, other branches only on commit
+def cronTrigger = isDevelopBranch ? '@hourly' : ''
 
 pipeline {
     agent {
@@ -23,6 +31,10 @@ pipeline {
       SONARCLOUD_TOKEN = credentials('zeebe-sonarcloud-token')
     }
 
+    triggers {
+      cron(cronTrigger)
+    }
+
     options {
         buildDiscarder(logRotator(daysToKeepStr: daysToKeep, numToKeepStr: numToKeep))
         timestamps()
@@ -201,7 +213,7 @@ pipeline {
         }
 
         stage('Upload') {
-            when { branch 'develop' }
+            when { allOf { branch developBranchName ; not {  triggeredBy 'TimerTrigger' } } }
             steps {
                 retry(3) {
                     container('maven') {
@@ -214,9 +226,11 @@ pipeline {
         }
 
         stage('Post') {
+            when { not { triggeredBy 'TimerTrigger' } }
+
             parallel {
                 stage('Docker') {
-                    when { branch 'develop' }
+                    when { branch developBranchName }
 
                     environment {
                         VERSION = readMavenPom(file: 'parent/pom.xml').getVersion()
@@ -227,20 +241,20 @@ pipeline {
                             build job: 'zeebe-docker', parameters: [
                                 string(name: 'BRANCH', value: env.BRANCH_NAME),
                                 string(name: 'VERSION', value: env.VERSION),
-                                booleanParam(name: 'IS_LATEST', value: env.BRANCH_NAME == 'master'),
-                                booleanParam(name: 'PUSH', value: env.BRANCH_NAME == 'develop')
+                                booleanParam(name: 'IS_LATEST', value: isMasterBranch),
+                                booleanParam(name: 'PUSH', value: isDevelopBranch)
                             ]
                         }
                     }
                 }
 
                 stage('Docs') {
-                    when { anyOf { branch 'master'; branch 'develop' } }
+                    when { anyOf { branch masterBranchName; branch developBranchName } }
                     steps {
                         retry(3) {
                             build job: 'zeebe-docs', parameters: [
                                 string(name: 'BRANCH', value: env.BRANCH_NAME),
-                                booleanParam(name: 'LIVE', value: env.BRANCH_NAME == 'master')
+                                booleanParam(name: 'LIVE', value: isMasterBranch)
                             ]
                         }
                     }
",1,"[""3bc1541d6c95ef8cb5ce5da741733f09c98e4b29""]","[""cicd""]"
add canonical `_name` to edge packages,"diff --git a/scripts/bump-edge.ts b/scripts/bump-edge.ts
index e92e3c9..0b7a11a 100644
--- a/scripts/bump-edge.ts
+++ b/scripts/bump-edge.ts
@@ -53,6 +53,7 @@ async function loadWorkspace (dir: string) {
   }
 
   const rename = (from: string, to: string) => {
+    find(from).data._name = find(from).data.name
     find(from).data.name = to
     for (const pkg of packages) {
       pkg.updateDeps((dep) => {
",1,"[""573f87edf9bdc19c9c4c3a978fad6ed3ce788f5f""]","[""build""]"
"metaDiff - include Links column as well

Signed-off-by: Pranav C <pranavxc@gmail.com> | use new freespace config for disk space recory test","diff --git a/packages/nocodb/src/services/meta-diffs.service.ts b/packages/nocodb/src/services/meta-diffs.service.ts
index e676ce5..13999f3 100644
--- a/packages/nocodb/src/services/meta-diffs.service.ts
+++ b/packages/nocodb/src/services/meta-diffs.service.ts
@@ -1,5 +1,11 @@
 import { Injectable } from '@nestjs/common';
-import { isVirtualCol, ModelTypes, RelationTypes, UITypes } from 'nocodb-sdk';
+import {
+  isLinksOrLTAR,
+  isVirtualCol,
+  ModelTypes,
+  RelationTypes,
+  UITypes,
+} from 'nocodb-sdk';
 import { T } from 'nc-help';
 import { pluralize, singularize } from 'inflection';
 import { Base, Column, Model, Project } from '../models';
@@ -10,7 +16,7 @@ import { getUniqueColumnAliasName } from '../helpers/getUniqueName';
 import mapDefaultDisplayValue from '../helpers/mapDefaultDisplayValue';
 import NcConnectionMgrv2 from '../utils/common/NcConnectionMgrv2';
 import NcHelp from '../utils/NcHelp';
-import type { LinkToAnotherRecordColumn } from '../models';
+import type { LinksColumn, LinkToAnotherRecordColumn } from '../models';
 
 // todo:move enum and types
 export enum MetaDiffType {
@@ -223,12 +229,13 @@ export class MetaDiffsService {
         if (
           [
             UITypes.LinkToAnotherRecord,
+            UITypes.Links,
             UITypes.Rollup,
             UITypes.Lookup,
             UITypes.Formula,
           ].includes(column.uidt)
         ) {
-          if (column.uidt === UITypes.LinkToAnotherRecord) {
+          if (isLinksOrLTAR(column.uidt)) {
             virtualRelationColumns.push(column);
           }
 
@@ -508,6 +515,7 @@ export class MetaDiffsService {
             UITypes.Rollup,
             UITypes.Lookup,
             UITypes.Formula,
+            UITypes.Links,
           ].includes(column.uidt)
         ) {
           continue;
@@ -947,7 +955,7 @@ export class MetaDiffsService {
                     childModel.columns,
                     pluralize(childModel.title || childModel.table_name),
                   );
-                  await Column.insert<LinkToAnotherRecordColumn>({
+                  await Column.insert<LinksColumn>({
                     uidt: UITypes.Links,
                     title,
                     fk_model_id: parentModel.id,
@@ -984,7 +992,7 @@ export class MetaDiffsService {
     const colChildOpt =
       await belongsToCol.getColOptions<LinkToAnotherRecordColumn>();
     for (const col of await model.getColumns()) {
-      if (col.uidt === UITypes.LinkToAnotherRecord) {
+      if (isLinksOrLTAR(col.uidt)) {
         const colOpt = await col.getColOptions<LinkToAnotherRecordColumn>();
         if (
           colOpt &&
@@ -1043,7 +1051,7 @@ export class MetaDiffsService {
         );
 
         if (!isRelationAvailInA) {
-          await Column.insert<LinkToAnotherRecordColumn>({
+          await Column.insert<LinksColumn>({
             title: getUniqueColumnAliasName(
               modelA.columns,
               pluralize(modelB.title),
@@ -1067,7 +1075,7 @@ export class MetaDiffsService {
           });
         }
         if (!isRelationAvailInB) {
-          await Column.insert<LinkToAnotherRecordColumn>({
+          await Column.insert<LinksColumn>({
             title: getUniqueColumnAliasName(
               modelB.columns,
               pluralize(modelA.title),
@@ -1099,7 +1107,7 @@ export class MetaDiffsService {
           const model = await colOpt.getRelatedTable();
 
           for (const col of await model.getColumns()) {
-            if (col.uidt !== UITypes.LinkToAnotherRecord) continue;
+            if (!isLinksOrLTAR(col.uidt)) continue;
 
             const colOpt1 =
               await col.getColOptions<LinkToAnotherRecordColumn>();

diff --git a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/health/DiskSpaceRecoveryIT.java b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/health/DiskSpaceRecoveryIT.java
index 0854323..bfc7b7e 100644
--- a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/health/DiskSpaceRecoveryIT.java
+++ b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/health/DiskSpaceRecoveryIT.java
@@ -47,7 +47,8 @@ final class DiskSpaceRecoveryIT {
           .withZeebeData(volume)
           .withEnv(""ZEEBE_BROKER_DATA_LOGSEGMENTSIZE"", ""1MB"")
           .withEnv(""ZEEBE_BROKER_NETWORK_MAXMESSAGESIZE"", ""1MB"")
-          .withEnv(""ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK"", ""0.5"");
+          .withEnv(""ZEEBE_BROKER_DATA_DISK_FREESPACE_PROCESSING"", ""10MB"")
+          .withEnv(""ZEEBE_BROKER_DATA_DISK_FREESPACE_REPLICATION"", ""1MB"");
 
   private ZeebeClient client;
 
@@ -127,7 +128,9 @@ final class DiskSpaceRecoveryIT {
         ContainerEngine.builder()
             .withDebugReceiverPort(SocketUtil.getNextAddress().getPort())
             .withContainer(
-                container.withEnv(""ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK"", ""0.0001""))
+                container
+                    .withEnv(""ZEEBE_BROKER_DATA_DISK_FREESPACE_PROCESSING"", ""16MB"")
+                    .withEnv(""ZEEBE_BROKER_DATA_DISK_FREESPACE_REPLICATION"", ""10MB""))
             .build();
 
     @BeforeEach
",2,"[""30ed3b4ed089cb69e6b6b51aaccc15db66d1ee49"", ""672cd2b9775fb6dac2d522cb3f4469db47c0556b""]","[""fix"", ""test""]"
setup jest and add m.ts tests | use connect instead of begin to avoid nesting transactions,"diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });

diff --git a/ibis/backends/duckdb/__init__.py b/ibis/backends/duckdb/__init__.py
index 2006f59..bb2028e 100644
--- a/ibis/backends/duckdb/__init__.py
+++ b/ibis/backends/duckdb/__init__.py
@@ -1180,7 +1180,7 @@ WHERE catalog_name = :database""""""
     def _register_udfs(self, expr: ir.Expr) -> None:
         import ibis.expr.operations as ops
 
-        with self.begin() as con:
+        with self.con.connect() as con:
             for udf_node in expr.op().find(ops.ScalarUDF):
                 compile_func = getattr(
                     self, f""_compile_{udf_node.__input_type__.name.lower()}_udf""
",2,"[""229b53a632ea97d47c4be11f096bdd828fb415d8"", ""6889543bec720e7e7da66535e1012cb66edfe081""]","[""test"", ""fix""]"
"spring version, core version","diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   jmeter xstream bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 
",1,"[""c55591ba157298a9c5816693c102a89dfd058830""]","[""build""]"
"autostart feature fixed | update sandbox-option.md (#18275)

Co-Authored-By: Mark Lee <malept@users.noreply.github.com> | fix unstable MessageCorrelationTest","diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();

diff --git a/docs/api/sandbox-option.md b/docs/api/sandbox-option.md
index 7d24bee..e293d34 100644
--- a/docs/api/sandbox-option.md
+++ b/docs/api/sandbox-option.md
@@ -113,8 +113,8 @@ window.open = customWindowOpen
 Important things to notice in the preload script:
 
 - Even though the sandboxed renderer doesn't have Node.js running, it still has
-  access to a limited node-like environment: `Buffer`, `process`, `setImmediate`
-  and `require` are available.
+  access to a limited node-like environment: `Buffer`, `process`, `setImmediate`,
+  `clearImmediate` and `require` are available.
 - The preload script can indirectly access all APIs from the main process through the
   `remote` and `ipcRenderer` modules.
 - The preload script must be contained in a single script, but it is possible to have
@@ -162,16 +162,17 @@ feature. We are still not aware of the security implications of exposing some
 Electron renderer APIs to the preload script, but here are some things to
 consider before rendering untrusted content:
 
-- A preload script can accidentally leak privileged APIs to untrusted code.
+- A preload script can accidentally leak privileged APIs to untrusted code,
+  unless [`contextIsolation`](../tutorial/security.md#3-enable-context-isolation-for-remote-content)
+  is also enabled.
 - Some bug in V8 engine may allow malicious code to access the renderer preload
   APIs, effectively granting full access to the system through the `remote`
-  module.
+  module. Therefore, it is highly recommended to
+  [disable the `remote` module](../tutorial/security.md#15-disable-the-remote-module).
+  If disabling is not feasible, you should selectively
+  [filter the `remote` module](../tutorial/security.md#16-filter-the-remote-module).
 
 Since rendering untrusted content in Electron is still uncharted territory,
 the APIs exposed to the sandbox preload script should be considered more
 unstable than the rest of Electron APIs, and may have breaking changes to fix
 security issues.
-
-One planned enhancement that should greatly increase security is to block IPC
-messages from sandboxed renderers by default, allowing the main process to
-explicitly define a set of messages the renderer is allowed to send.

diff --git a/broker-core/src/test/java/io/zeebe/broker/workflow/MessageCorrelationTest.java b/broker-core/src/test/java/io/zeebe/broker/workflow/MessageCorrelationTest.java
index 0f5fed9..796393c 100644
--- a/broker-core/src/test/java/io/zeebe/broker/workflow/MessageCorrelationTest.java
+++ b/broker-core/src/test/java/io/zeebe/broker/workflow/MessageCorrelationTest.java
@@ -27,7 +27,6 @@ import static io.zeebe.test.util.MsgPackUtil.asMsgPack;
 import static org.assertj.core.api.Assertions.assertThat;
 import static org.assertj.core.api.Assertions.entry;
 
-import io.zeebe.UnstableTest;
 import io.zeebe.broker.test.EmbeddedBrokerRule;
 import io.zeebe.model.bpmn.Bpmn;
 import io.zeebe.model.bpmn.BpmnModelInstance;
@@ -50,7 +49,6 @@ import org.agrona.DirectBuffer;
 import org.junit.Before;
 import org.junit.Rule;
 import org.junit.Test;
-import org.junit.experimental.categories.Category;
 import org.junit.rules.RuleChain;
 import org.junit.runner.RunWith;
 import org.junit.runners.Parameterized;
@@ -165,7 +163,7 @@ public class MessageCorrelationTest {
             ""receive-message"", WorkflowInstanceIntent.ELEMENT_ACTIVATED);
 
     final SubscribedRecord messageSubscription =
-        findMessageSubscription(testClient, MessageSubscriptionIntent.OPENED);
+        findMessageSubscription(MessageSubscriptionIntent.OPENED);
     assertThat(messageSubscription.valueType()).isEqualTo(ValueType.MESSAGE_SUBSCRIPTION);
     assertThat(messageSubscription.recordType()).isEqualTo(RecordType.EVENT);
     assertThat(messageSubscription.value())
@@ -244,7 +242,7 @@ public class MessageCorrelationTest {
     final long workflowInstanceKey =
         testClient.createWorkflowInstance(""wf"", asMsgPack(""orderId"", ""order-123""));
 
-    testClient.receiveFirstWorkflowInstanceEvent(WorkflowInstanceIntent.ELEMENT_ACTIVATED);
+    findMessageSubscription(MessageSubscriptionIntent.OPENED);
 
     // when
     testClient.publishMessage(""order canceled"", ""order-123"", asMsgPack(""foo"", ""bar""));
@@ -308,13 +306,12 @@ public class MessageCorrelationTest {
   }
 
   @Test
-  @Category(UnstableTest.class) // => https://github.com/zeebe-io/zeebe/issues/1234
   public void shouldCorrelateMessageWithZeroTTL() throws Exception {
     // given
     final long workflowInstanceKey =
         testClient.createWorkflowInstance(""wf"", asMsgPack(""orderId"", ""order-123""));
 
-    testClient.receiveElementInState(""receive-message"", WorkflowInstanceIntent.ELEMENT_ACTIVATED);
+    findMessageSubscription(MessageSubscriptionIntent.OPENED);
 
     // when
     testClient.publishMessage(""order canceled"", ""order-123"", asMsgPack(""foo"", ""bar""), 0);
@@ -499,10 +496,9 @@ public class MessageCorrelationTest {
         .containsEntry(""activityInstanceKey"", catchEventEntered.key());
   }
 
-  private SubscribedRecord findMessageSubscription(
-      final TestPartitionClient client, final MessageSubscriptionIntent intent)
+  private SubscribedRecord findMessageSubscription(final MessageSubscriptionIntent intent)
       throws AssertionError {
-    return client
+    return testClient
         .receiveEvents()
         .filter(intent(intent))
         .findFirst()
",3,"[""bed78248c941d57ad4cc20a455147e186e97c7a1"", ""dbb8617214aaa8b56b827deef1265d9ee38765bd"", ""98bed2a8137930149559bc1cae9bd34a1a75e556""]","[""fix"", ""docs"", ""test""]"
init environ cache,"diff --git a/src/environment.go b/src/environment.go
index ae5e26a..0c961c5 100644
--- a/src/environment.go
+++ b/src/environment.go
@@ -229,6 +229,7 @@ func (env *environment) environ() map[string]string {
 	if env.environCache != nil {
 		return env.environCache
 	}
+	env.environCache = make(map[string]string)
 	const separator = ""=""
 	values := os.Environ()
 	for value := range values {
",1,"[""dc50bd35462a49058c91a939fc8830ae7a9eb692""]","[""fix""]"
"support document.html | small error msg improvement

refs #1005 | add more tests for Utils.lookupPathFromDecorator","diff --git a/packages/nuxt3/src/builder/builder.ts b/packages/nuxt3/src/builder/builder.ts
index a24bd88..ecc22ef 100644
--- a/packages/nuxt3/src/builder/builder.ts
+++ b/packages/nuxt3/src/builder/builder.ts
@@ -3,6 +3,7 @@ import fsExtra from 'fs-extra'
 import { debounce } from 'lodash'
 import { BundleBuilder } from 'src/webpack'
 import { Nuxt } from '../core'
+import { DeterminedGlobals, determineGlobals } from '../utils'
 import {
   templateData,
   compileTemplates,
@@ -15,12 +16,14 @@ import Ignore from './ignore'
 
 export class Builder {
   nuxt: Nuxt
+  globals: DeterminedGlobals
   ignore: Ignore
-  app: NuxtApp
   templates: NuxtTemplate[]
+  app: NuxtApp
 
   constructor (nuxt) {
     this.nuxt = nuxt
+    this.globals = determineGlobals(nuxt.options.globalName, nuxt.options.globals)
     this.ignore = new Ignore({
       rootDir: nuxt.options.srcDir,
       ignoreArray: nuxt.options.ignore.concat(
@@ -32,6 +35,10 @@ export class Builder {
   build () {
     return build(this)
   }
+
+  close () {
+    // TODO: close watchers
+  }
 }
 
 // Extends VueRouter
diff --git a/packages/nuxt3/src/builder/template.ts b/packages/nuxt3/src/builder/template.ts
index 63a9115..fe09f16 100644
--- a/packages/nuxt3/src/builder/template.ts
+++ b/packages/nuxt3/src/builder/template.ts
@@ -11,6 +11,7 @@ export interface NuxtTemplate {
 
 export function templateData (builder) {
   return {
+    globals: builder.globals,
     app: builder.app
   }
 }
diff --git a/packages/nuxt3/src/builder/watch.ts b/packages/nuxt3/src/builder/watch.ts
index b4d1415..d148fec 100644
--- a/packages/nuxt3/src/builder/watch.ts
+++ b/packages/nuxt3/src/builder/watch.ts
@@ -38,7 +38,8 @@ export function createWatcher (
   return {
     watchAll,
     watch,
-    debug
+    debug,
+    close: () => watcher.close()
   }
 }
 
diff --git a/packages/nuxt3/src/config/options.ts b/packages/nuxt3/src/config/options.ts
index 5aac8ac..6e7f93c 100644
--- a/packages/nuxt3/src/config/options.ts
+++ b/packages/nuxt3/src/config/options.ts
@@ -12,7 +12,7 @@ import { DefaultConfiguration, defaultNuxtConfigFile, getDefaultNuxtConfig } fro
 import { deleteProp, mergeConfigs, setProp, overrideProp, Optional } from './transformers'
 
 interface InputConfiguration {
-  appTemplatePath?: string
+  documentPath?: string
   layoutTransition?: string | DefaultConfiguration['layoutTransition']
   loading?: true | false | DefaultConfiguration['loading']
   manifest?: {
@@ -197,13 +197,16 @@ function normalizeConfig (_options: CliConfiguration) {
     .concat(options.extensions))
 
   // If app.html is defined, set the template path to the user template
-  if (options.appTemplatePath === undefined) {
-    options.appTemplatePath = path.resolve(options.buildDir, 'views/app.template.html')
-    if (fs.existsSync(path.join(options.srcDir, 'app.html'))) {
-      options.appTemplatePath = path.join(options.srcDir, 'app.html')
+  if (options.documentPath === undefined) {
+    options.documentPath = path.resolve(options.buildDir, 'views/document.template.html')
+    const userDocumentPath = path.join(options.srcDir, 'document.html')
+    if (fs.existsSync(userDocumentPath)) {
+      options.documentPath = userDocumentPath
+    } else {
+      options.watch.push(userDocumentPath)
     }
   } else {
-    options.appTemplatePath = path.resolve(options.srcDir, options.appTemplatePath)
+    options.documentPath = path.resolve(options.srcDir, options.documentPath)
   }
 
   overrideProp(options.build, 'publicPath', options.build.publicPath.replace(/([^/])$/, '$1/'))
diff --git a/packages/nuxt3/src/vue-renderer/renderers/ssr.ts b/packages/nuxt3/src/vue-renderer/renderers/ssr.ts
index 3e3ce2d..482bd6b 100644
--- a/packages/nuxt3/src/vue-renderer/renderers/ssr.ts
+++ b/packages/nuxt3/src/vue-renderer/renderers/ssr.ts
@@ -96,6 +96,9 @@ export default class SSRRenderer extends BaseRenderer {
     // Call Vue renderer renderToString
     let APP = await this.vueRenderer.renderToString(renderContext)
 
+    // Wrap with Nuxt id
+    APP = `<div id=""${this.serverContext.globals.id}"">${APP}</div>`
+
     // Call render:done in app
     await renderContext.nuxt.hooks.callHook('vue-renderer:done')
 
diff --git a/packages/nuxt3/src/webpack/configs/client.ts b/packages/nuxt3/src/webpack/configs/client.ts
index a257948..4fb35e0 100644
--- a/packages/nuxt3/src/webpack/configs/client.ts
+++ b/packages/nuxt3/src/webpack/configs/client.ts
@@ -94,7 +94,7 @@ function clientHTML (ctx: WebpackConfigContext) {
     config.plugins.push(
       new HTMLPlugin({
         filename: '../server/index.ssr.html',
-        template: options.appTemplatePath,
+        template: options.documentPath,
         minify: options.build.html.minify as any,
         inject: false // Resources will be injected using bundleRenderer
       })
@@ -104,7 +104,7 @@ function clientHTML (ctx: WebpackConfigContext) {
   config.plugins.push(
     new HTMLPlugin({
       filename: '../server/index.spa.html',
-      template: options.appTemplatePath,
+      template: options.documentPath,
       minify: options.build.html.minify as any,
       inject: true
     })

diff --git a/internal/pipe/git/errors.go b/internal/pipe/git/errors.go
index a8c15d5..13dfb56 100644
--- a/internal/pipe/git/errors.go
+++ b/internal/pipe/git/errors.go
@@ -11,7 +11,7 @@ type ErrDirty struct {
 }
 
 func (e ErrDirty) Error() string {
-	return fmt.Sprintf(""git is currently in a dirty state:\n%v"", e.status)
+	return fmt.Sprintf(""git is currently in a dirty state, please check in your pipeline what can be changing the following files:\n%v"", e.status)
 }
 
 // ErrWrongRef happens when the HEAD reference is different from the tag being built

diff --git a/lib/utils/Utils.ts b/lib/utils/Utils.ts
index 6de6e05..b03b3e9 100644
--- a/lib/utils/Utils.ts
+++ b/lib/utils/Utils.ts
@@ -338,15 +338,8 @@ export class Utils {
       line++;
     }
 
-    if (stack[line].match(/\(.+\)/i)) {
-      meta.path = Utils.normalizePath(
-        stack[line].match(/\((.*):\d+:\d+\)/)![1],
-      );
-    } else {
-      meta.path = Utils.normalizePath(
-        stack[line].match(/at\s*(.*):\d+:\d+$/)![1],
-      );
-    }
+    const re = stack[line].match(/\(.+\)/i) ? /\((.*):\d+:\d+\)/ : /at\s*(.*):\d+:\d+$/;
+    meta.path = Utils.normalizePath(stack[line].match(re)![1]);
 
     return meta.path;
   }
diff --git a/tests/Utils.test.ts b/tests/Utils.test.ts
index c3e9aa1..4d2a209 100644
--- a/tests/Utils.test.ts
+++ b/tests/Utils.test.ts
@@ -256,7 +256,7 @@ describe('Utils', () => {
       '    at Object.__decorate (/usr/local/var/www/my-project/node_modules/tslib/tslib.js:92:96)',
       '    at Object.<anonymous> (/usr/local/var/www/my-project/dist/entities/Customer.js:20:9)',
       '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
-      '    at Object.Module._extensions..js (internal/modules/cjs/loader.js:787:10)',
+      '    at Object.Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
       '    at Module.load (internal/modules/cjs/loader.js:643:32)',
       '    at Function.Module._load (internal/modules/cjs/loader.js:556:12)',
     ];
@@ -272,10 +272,25 @@ describe('Utils', () => {
       '    at Object.<anonymous> (/usr/local/var/www/my-project/src/entities/Customer.ts:9:3)',
       '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
       '    at Module.m._compile (/usr/local/var/www/my-project/node_modules/ts-node/src/index.ts:473:23)',
-      '    at Module._extensions..js (internal/modules/cjs/loader.js:787:10)',
+      '    at Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
       '    at Object.require.extensions.<computed> [as .ts] (/usr/local/var/www/my-project/node_modules/ts-node/src/index.ts:476:12)',
     ];
     expect(Utils.lookupPathFromDecorator({} as any, stack2)).toBe('/usr/local/var/www/my-project/src/entities/Customer.ts');
+
+    // no parens
+    const stack3 = [
+      '    at Function.lookupPathFromDecorator (/usr/local/var/www/my-project/node_modules/mikro-orm/dist/utils/Utils.js:170:23)',
+      '    at /usr/local/var/www/my-project/node_modules/mikro-orm/dist/decorators/PrimaryKey.js:12:23',
+      '    at DecorateProperty (/usr/local/var/www/my-project/node_modules/reflect-metadata/Reflect.js:553:33)',
+      '    at Object.decorate (/usr/local/var/www/my-project/node_modules/reflect-metadata/Reflect.js:123:24)',
+      '    at Object.__decorate (/usr/local/var/www/my-project/node_modules/tslib/tslib.js:92:96)',
+      '    at /usr/local/var/www/my-project/dist/entities/Customer.js:20:9',
+      '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
+      '    at Object.Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
+      '    at Module.load (internal/modules/cjs/loader.js:643:32)',
+      '    at Function.Module._load (internal/modules/cjs/loader.js:556:12)',
+    ];
+    expect(Utils.lookupPathFromDecorator({} as any, stack3)).toBe('/usr/local/var/www/my-project/dist/entities/Customer.js');
   });
 
   test('lookup path from decorator on windows', () => {
@@ -287,7 +302,7 @@ describe('Utils', () => {
       '    at Object.<anonymous> (C:\\www\\my-project\\src\\entities\\Customer.ts:7:5)',
       '    at Module._compile (internal/modules/cjs/loader.js:936:30)',
       '    at Module.m._compile (C:\\www\\my-project\\node_modules\\ts-node\\src\\index.ts:493:23)',
-      '    at Module._extensions..js (internal/modules/cjs/loader.js:947:10)',
+      '    at Module._extensions.js (internal/modules/cjs/loader.js:947:10)',
       '    at Object.require.extensions.<computed> [as .ts] (C:\\www\\my-project\\node_modules\\ts-node\\src\\index.ts:496:12)',
       '    at Module.load (internal/modules/cjs/loader.js:790:32)',
       '    at Function.Module._load (internal/modules/cjs/loader.js:703:12)',
",3,"[""09476134eeeb12c025618919ab9a795a680a9b30"", ""a62314d9bb632be6af026686615d14b912250512"", ""c5e86dbc00a13a355bffadeb2db197e2fea5640f""]","[""feat"", ""refactor"", ""test""]"
"apply permissions to profile request | fix monorepo.dir prop

Signed-off-by: Carlos Alexandro Becker <caarlos0@gmail.com> | fixed start types for size and opacity","diff --git a/client/src/components/Profile/AboutCard.tsx b/client/src/components/Profile/AboutCard.tsx
index 3bd6e9a..e07ddb6 100644
--- a/client/src/components/Profile/AboutCard.tsx
+++ b/client/src/components/Profile/AboutCard.tsx
@@ -11,6 +11,7 @@ import { InfoCircleOutlined } from '@ant-design/icons';
 
 type Props = {
   data: GeneralInfo;
+  isEditingModeEnabled: boolean;
 };
 
 class AboutCard extends React.Component<Props> {
diff --git a/client/src/components/Profile/ContactsCard.tsx b/client/src/components/Profile/ContactsCard.tsx
index 6fe80a3..3a35c9f 100644
--- a/client/src/components/Profile/ContactsCard.tsx
+++ b/client/src/components/Profile/ContactsCard.tsx
@@ -12,8 +12,11 @@ import { ContactsOutlined } from '@ant-design/icons';
 
 type Props = {
   data: Contacts;
+  isEditingModeEnabled: boolean;
 };
 
+type Contact = { name: string, value?: string };
+
 class ContactsCard extends React.Component<Props> {
   render() {
     const { email, telegram, phone, skype, notes } = this.props.data;
@@ -32,7 +35,7 @@ class ContactsCard extends React.Component<Props> {
     }, {
       name: 'Notes',
       value: notes,
-    }].filter(({ value }: { name: string, value: string | null }) => value);
+    }].filter(({ value }: Contact) => value);
 
     return (
       <CommonCard
@@ -42,7 +45,7 @@ class ContactsCard extends React.Component<Props> {
           <List
             itemLayout=""horizontal""
             dataSource={contacts}
-            renderItem={({ name, value }: { name: string, value: string }) => (
+            renderItem={({ name, value }: Contact) => (
               <List.Item>
                 <Text strong>{name}:</Text> {value}
               </List.Item>
diff --git a/client/src/components/Profile/EducationCard.tsx b/client/src/components/Profile/EducationCard.tsx
index 4279c9f..b409c29 100644
--- a/client/src/components/Profile/EducationCard.tsx
+++ b/client/src/components/Profile/EducationCard.tsx
@@ -12,6 +12,7 @@ import { ReadOutlined } from '@ant-design/icons';
 
 type Props = {
   data: GeneralInfo;
+  isEditingModeEnabled: boolean;
 };
 
 class EducationCard extends React.Component<Props> {
diff --git a/client/src/components/Profile/EnglishCard.tsx b/client/src/components/Profile/EnglishCard.tsx
index d8f8ab4..2d5efa0 100644
--- a/client/src/components/Profile/EnglishCard.tsx
+++ b/client/src/components/Profile/EnglishCard.tsx
@@ -11,6 +11,7 @@ import { TagOutlined } from '@ant-design/icons';
 
 type Props = {
   data: GeneralInfo;
+  isEditingModeEnabled: boolean;
 };
 
 class EnglishCard extends React.Component<Props> {
diff --git a/client/src/components/Profile/MainCard.tsx b/client/src/components/Profile/MainCard.tsx
index cbfb71b..c0d49cc 100644
--- a/client/src/components/Profile/MainCard.tsx
+++ b/client/src/components/Profile/MainCard.tsx
@@ -4,6 +4,8 @@ import { GithubAvatar } from 'components';
 import {
   Card,
   Typography,
+  Drawer,
+  Checkbox,
 } from 'antd';
 
 const { Title, Paragraph } = Typography;
@@ -11,30 +13,70 @@ const { Title, Paragraph } = Typography;
 import {
   GithubFilled,
   EnvironmentFilled,
+  EditOutlined,
+  SettingOutlined,
 } from '@ant-design/icons';
 
 type Props = {
   data: GeneralInfo;
+  isEditingModeEnabled: boolean;
 };
 
-class MainCard extends React.Component<Props> {
+type State = {
+  isSettingsVisible: boolean;
+}
+
+class MainCard extends React.Component<Props, State> {
+  state = {
+    isSettingsVisible: false,
+  }
+
+  private showSettings = () => {
+    this.setState({ isSettingsVisible: true });
+  }
+
+  private hideSettings = () => {
+    this.setState({ isSettingsVisible: false });
+  }
+
   render() {
     const { githubId, name, locationName } = this.props.data;
+    const { isSettingsVisible } = this.state;
+
     return (
-      <Card>
-        <GithubAvatar size={96} githubId={githubId} style={{ margin: '0 auto 10px', display: 'block' }} />
-        <Title level={1} style={{ fontSize: 24, textAlign: 'center', margin: 0 }}>{name}</Title>
-        <Paragraph style={{ textAlign: 'center', marginBottom: 20 }}>
-          <a target=""_blank"" href={`https://github.com/${githubId}`} style={{ marginLeft: '-14px', fontSize: 16 }}>
-            <GithubFilled /> {githubId}
-          </a>
-        </Paragraph>
-        <Paragraph style={{ textAlign: 'center', margin: 0 }}>
-          <span style={{ marginLeft: '-14px' }}>
-            <EnvironmentFilled /> {locationName}
-          </span>
-        </Paragraph>
-      </Card>
+      <>
+
+        <Card
+          actions={[
+            <EditOutlined key=""main-card-actions-edit""/>,
+            <SettingOutlined key=""main-card-actions-settings"" onClick={this.showSettings} />,
+          ]}
+        >
+          <GithubAvatar size={96} githubId={githubId} style={{ margin: '0 auto 10px', display: 'block' }} />
+          <Title level={1} style={{ fontSize: 24, textAlign: 'center', margin: 0 }}>{name}</Title>
+          <Paragraph style={{ textAlign: 'center', marginBottom: 20 }}>
+            <a target=""_blank"" href={`https://github.com/${githubId}`} style={{ marginLeft: '-14px', fontSize: 16 }}>
+              <GithubFilled /> {githubId}
+            </a>
+          </Paragraph>
+          <Paragraph style={{ textAlign: 'center', margin: 0 }}>
+            <span style={{ marginLeft: '-14px' }}>
+              <EnvironmentFilled /> {locationName}
+            </span>
+          </Paragraph>
+          <Drawer
+            title=""Who can see my profile?""
+            placement=""top""
+            closable={true}
+            onClose={this.hideSettings}
+            visible={isSettingsVisible}
+            getContainer={false}
+            style={{ position: 'absolute', display: isSettingsVisible ? 'block' : 'none' }}
+          >
+            <Checkbox>Nobody</Checkbox>
+          </Drawer>
+        </Card>
+      </>
     );
   }
 }
diff --git a/client/src/components/Profile/MentorStatsCard.tsx b/client/src/components/Profile/MentorStatsCard.tsx
index ca54480..1ec3b9c 100644
--- a/client/src/components/Profile/MentorStatsCard.tsx
+++ b/client/src/components/Profile/MentorStatsCard.tsx
@@ -18,6 +18,7 @@ import {
 
 type Props = {
   data: MentorStats[];
+  isEditingModeEnabled: boolean;
 };
 
 type State = {
@@ -80,7 +81,7 @@ class MentorStatsCard extends React.Component<Props, State> {
                         <Text strong>{courseName}{locationName && ` / ${locationName}`}</Text>
                       </p>
                       {
-                        idx === 0 && (
+                        students ? idx === 0 && (
                           <List
                             itemLayout=""horizontal""
                             dataSource={students}
@@ -116,12 +117,14 @@ class MentorStatsCard extends React.Component<Props, State> {
                               </List.Item>
                             )}
                           />
-                        )
+                        ) : <p>Doesn't have students at this course yet</p>
                       }
                     </div>
-                    <Button type=""dashed"" onClick={this.showMentorStatsModal.bind(null, idx)}>
-                      <FullscreenOutlined/>
-                    </Button>
+                    {
+                      students && <Button type=""dashed"" onClick={this.showMentorStatsModal.bind(null, idx)}>
+                        <FullscreenOutlined/>
+                      </Button>
+                    }
                   </List.Item>
                 )}
               />
diff --git a/client/src/components/Profile/MentorStatsModal.tsx b/client/src/components/Profile/MentorStatsModal.tsx
index 47b5f2a..0e94cc1 100644
--- a/client/src/components/Profile/MentorStatsModal.tsx
+++ b/client/src/components/Profile/MentorStatsModal.tsx
@@ -38,7 +38,7 @@ class MentorStatsModal extends React.Component<Props> {
       >
         <Row gutter={[16, 16]}>
         {
-          students.map(({ name, githubId, isExpelled, totalScore }) => {
+          students?.map(({ name, githubId, isExpelled, totalScore }) => {
             const profile = `/profile?githubId=${githubId}`;
             const guithubLink = `https://github.com/${githubId}`;
             const privateRepoLink = `https://github.com/rolling-scopes-school/${githubId}-${courseYearPostfix}`;
diff --git a/client/src/components/Profile/PublicFeedbackCard.tsx b/client/src/components/Profile/PublicFeedbackCard.tsx
index 2f8a999..6ce1862 100644
--- a/client/src/components/Profile/PublicFeedbackCard.tsx
+++ b/client/src/components/Profile/PublicFeedbackCard.tsx
@@ -22,6 +22,7 @@ import {
 
 type Props = {
   data: PublicFeedback[];
+  isEditingModeEnabled: boolean;
 };
 
 interface State {
diff --git a/client/src/components/Profile/StudentStatsCard.tsx b/client/src/components/Profile/StudentStatsCard.tsx
index c811640..b472e49 100644
--- a/client/src/components/Profile/StudentStatsCard.tsx
+++ b/client/src/components/Profile/StudentStatsCard.tsx
@@ -18,6 +18,7 @@ import {
 
 type Props = {
   data: StudentStats[];
+  isEditingModeEnabled: boolean;
 };
 
 type State = {
diff --git a/client/src/pages/profile/index.tsx b/client/src/pages/profile/index.tsx
index 68b2a70..b6ffb1a 100644
--- a/client/src/pages/profile/index.tsx
+++ b/client/src/pages/profile/index.tsx
@@ -1,6 +1,7 @@
 import * as React from 'react';
 import {
   Result,
+  Button,
 } from 'antd';
 import css from 'styled-jsx/css';
 import Masonry from 'react-masonry-css';
@@ -23,18 +24,25 @@ import CoreJsIviewsCard from 'components/Profile/CoreJsIviewsCard';
 import { CoreJsInterviewData } from 'components/Profile/CoreJsIviewsCard';
 import PreScreeningIviewCard from 'components/Profile/PreScreeningIviewCard';
 
+import {
+  EditOutlined,
+  EyeOutlined,
+} from '@ant-design/icons';
+
 type Props = {
   router: NextRouter;
   session: Session;
 };
 
 type State = {
+  isEditingModeEnabled: boolean;
   profile: ProfileInfo | null;
   isLoading: boolean;
 };
 
 class ProfilePage extends React.Component<Props, State> {
   state: State = {
+    isEditingModeEnabled: false,
     isLoading: true,
     profile: null,
   };
@@ -79,6 +87,12 @@ class ProfilePage extends React.Component<Props, State> {
     }
   };
 
+  private toggleEditViewProfileButton = () => {
+    const { isEditingModeEnabled } = this.state;
+
+    this.setState({ isEditingModeEnabled: !isEditingModeEnabled });
+  }
+
   async componentDidMount() {
     await this.fetchData();
   }
@@ -90,21 +104,29 @@ class ProfilePage extends React.Component<Props, State> {
   }
 
   render() {
-    const { profile } = this.state;
+    const { profile, isEditingModeEnabled } = this.state;
 
     const cards = [
-      profile?.generalInfo && <MainCard data={profile.generalInfo}/>,
-      profile?.generalInfo?.aboutMyself && <AboutCard data={profile.generalInfo}/>,
-      profile?.generalInfo?.englishLevel && <EnglishCard data={profile.generalInfo}/>,
-      profile?.generalInfo?.educationHistory.length && <EducationCard data={profile.generalInfo}/>,
-      profile?.contacts && <ContactsCard data={profile.contacts}/>,
-      profile?.publicFeedback.length && <PublicFeedbackCard data={profile.publicFeedback}/>,
-      profile?.studentStats.length && <StudentStatsCard data={profile.studentStats}/>,
-      profile?.mentorStats.length && <MentorStatsCard data={profile.mentorStats}/>,
-      profile?.studentStats.length &&
-        this.hadStudentCoreJSInterview(profile.studentStats) &&
+      profile?.generalInfo &&
+        <MainCard data={profile.generalInfo} isEditingModeEnabled={isEditingModeEnabled}/>,
+      profile?.generalInfo?.aboutMyself &&
+        <AboutCard data={profile.generalInfo} isEditingModeEnabled={isEditingModeEnabled}/>,
+      profile?.generalInfo?.englishLevel &&
+        <EnglishCard data={profile.generalInfo} isEditingModeEnabled={isEditingModeEnabled}/>,
+      profile?.generalInfo?.educationHistory?.length &&
+        <EducationCard data={profile.generalInfo} isEditingModeEnabled={isEditingModeEnabled}/>,
+      profile?.contacts &&
+        <ContactsCard data={profile.contacts} isEditingModeEnabled={isEditingModeEnabled}/>,
+      profile?.publicFeedback?.length &&
+        <PublicFeedbackCard data={profile.publicFeedback} isEditingModeEnabled={isEditingModeEnabled}/>,
+      profile?.studentStats?.length &&
+        <StudentStatsCard data={profile.studentStats} isEditingModeEnabled={isEditingModeEnabled}/>,
+      profile?.mentorStats?.length &&
+        <MentorStatsCard data={profile.mentorStats} isEditingModeEnabled={isEditingModeEnabled}/>,
+      profile?.studentStats?.length && this.hadStudentCoreJSInterview(profile.studentStats) &&
         <CoreJsIviewsCard data={this.getStudentCoreJSInterviews(profile.studentStats)}/>,
-      profile?.stageInterviewFeedback.length && <PreScreeningIviewCard data={profile.stageInterviewFeedback}/>,
+      profile?.stageInterviewFeedback.length &&
+        <PreScreeningIviewCard data={profile.stageInterviewFeedback}/>,
     ].filter(Boolean) as JSX.Element[];
 
     return (
@@ -114,6 +136,17 @@ class ProfilePage extends React.Component<Props, State> {
           {
             this.state.profile
               ? <div style={{ padding: 10 }}>
+                  <Button
+                    type=""ghost""
+                    style={{ position: 'fixed', width: 80, right: 10, zIndex: 1 }}
+                    onClick={this.toggleEditViewProfileButton}
+                  >
+                  {
+                    isEditingModeEnabled ?
+                      <span><EditOutlined/> Edit</span> :
+                      <span><EyeOutlined /> View</span>
+                  }
+                  </Button>
                   <Masonry
                     breakpointCols={{
                       default: 4,
diff --git a/common/models/profile.ts b/common/models/profile.ts
index 6a06fd1..ce7abc2 100644
--- a/common/models/profile.ts
+++ b/common/models/profile.ts
@@ -3,26 +3,25 @@ import { EnglishLevel } from './';
 export interface GeneralInfo {
   name: string;
   githubId: string;
-  aboutMyself: string;
+  aboutMyself?: string;
   locationName: string;
-  educationHistory: any;
-  employmentHistory: any;
-  englishLevel: EnglishLevel;
+  educationHistory?: any;
+  englishLevel?: EnglishLevel;
 }
 
 export interface Contacts {
-  phone: string;
-  email: string;
-  skype: string;
-  telegram: string;
-  notes: string;
+  phone?: string;
+  email?: string;
+  skype?: string;
+  telegram?: string;
+  notes?: string;
 }
 
 export interface MentorStats {
   courseName: string;
   locationName: string;
   courseFullName: string;
-  students: {
+  students?: {
     githubId: string;
     name: string;
     isExpelled: boolean;
@@ -102,14 +101,14 @@ export interface StageInterviewDetailedFeedback {
 
 export interface UserInfo {
   generalInfo: GeneralInfo;
-  contacts: Contacts;
+  contacts?: Contacts;
 };
 
 export interface ProfileInfo {
   generalInfo?: GeneralInfo;
   contacts?: Contacts;
-  mentorStats: MentorStats[];
-  studentStats: StudentStats[];
-  publicFeedback: PublicFeedback[];
+  mentorStats?: MentorStats[];
+  studentStats?: StudentStats[];
+  publicFeedback?: PublicFeedback[];
   stageInterviewFeedback: StageInterviewDetailedFeedback[];
 };
diff --git a/server/package.json b/server/package.json
index 1bd6de1..bf2d5f0 100755
--- a/server/package.json
+++ b/server/package.json
@@ -4,7 +4,7 @@
   ""private"": true,
   ""scripts"": {
     ""build"": ""tsc"",
-    ""start"": ""nodemon  --inspect --watch 'src/**/*' -e ts --exec node  -r ts-node/register -r dotenv/config ./index.ts | pino-pretty -i time,hostname,pid,host,method,remoteAddress"",
+    ""start"": ""nodemon  --inspect --watch \""src/**/*\"" -e ts --exec node  -r ts-node/register -r dotenv/config ./index.ts | pino-pretty -i time,hostname,pid,host,method,remoteAddress"",
     ""lint"": ""tslint -c tslint.json -p tsconfig.json"",
     ""swagger"": ""swagger-jsdoc -d swaggerDef.js -o ./public/swagger.yml ./src/routes/**/*.ts ./src/routes/**.ts""
   },
diff --git a/server/src/models/profilePermissions.ts b/server/src/models/profilePermissions.ts
index 1b2a79a..fd06900 100644
--- a/server/src/models/profilePermissions.ts
+++ b/server/src/models/profilePermissions.ts
@@ -1,20 +1,20 @@
 import { Entity, Column, CreateDateColumn, UpdateDateColumn, PrimaryGeneratedColumn, OneToOne } from 'typeorm';
 import { User } from './user';
 
-interface PublicVisibilitySettings {
+export interface PublicVisibilitySettings {
   all: boolean;
 }
 
-interface VisibilitySettings extends PublicVisibilitySettings {
+export interface VisibilitySettings extends PublicVisibilitySettings {
   mentor: boolean;
   student: boolean;
 }
 
-const defaultPublicVisibilitySettings = {
+export const defaultPublicVisibilitySettings = {
   all: false,
 };
 
-const defaultVisibilitySettings = {
+export const defaultVisibilitySettings = {
   mentor: false,
   student: false,
   all: false,
diff --git a/server/src/routes/profile/info.ts b/server/src/routes/profile/info.ts
index f5d249d..22a8132 100644
--- a/server/src/routes/profile/info.ts
+++ b/server/src/routes/profile/info.ts
@@ -1,4 +1,4 @@
-import { NOT_FOUND, OK } from 'http-status-codes';
+import { NOT_FOUND, OK, FORBIDDEN } from 'http-status-codes';
 import Router from 'koa-router';
 import { ILogger } from '../../logger';
 import { setResponse } from '../utils';
@@ -9,7 +9,7 @@ import { getPublicFeedback } from './public-feedback';
 import { getStageInterviewFeedback } from './stage-interview-feedback';
 import { getStudentStats } from './student-stats';
 import { getUserInfo } from './user-info';
-import { getPermissions } from './permissions';
+import { getPermissions, getOwnerPermissions } from './permissions';
 
 /*
   WHO CAN SEE
@@ -60,13 +60,9 @@ import { getPermissions } from './permissions';
 */
 
 export const getProfileInfo = (_: ILogger) => async (ctx: Router.RouterContext) => {
-  const {
-    // id: userId,
-    githubId: userGithubId,
-  } = ctx.state!.user as IUserSession;
+  const { githubId: userGithubId } = ctx.state!.user as IUserSession;
   // const { isAdmin, roles } = ctx.state!.user as IUserSession;
-  const { githubId } = ctx.query as { githubId: string | undefined };
-
+  const { githubId = userGithubId } = ctx.query as { githubId: string | undefined };
   // console.log('GITHUB =>', githubId);
   // console.log('ADMIN =>', isAdmin);
   // console.log('ROLES =>', roles);
@@ -75,16 +71,28 @@ export const getProfileInfo = (_: ILogger) => async (ctx: Router.RouterContext) 
     return setResponse(ctx, NOT_FOUND);
   }
 
+  const isProfileOwner = githubId === userGithubId;
+  console.log('isProfileOwner', isProfileOwner);
   // await getRepository(ProfilePermissions).save({ userId });
 
-  const permissions = await getPermissions(userGithubId, githubId);
+  const permissions = await getPermissions(userGithubId, githubId, { isProfileOwner });
 
-  console.log(JSON.stringify(permissions, null, 2));
+  const { isProfileVisible, isPublicFeedbackVisible, isMentorStatsVisible, isStudentStatsVisible } = permissions;
+
+  if (!isProfileVisible && !isProfileOwner) {
+    return setResponse(ctx, FORBIDDEN);
+  }
+
+  if (isProfileOwner) {
+    const ownerPermissions = await getOwnerPermissions(userGithubId);
+
+    console.log('OWN =>', ownerPermissions);
+  }
 
   const { generalInfo, contacts } = await getUserInfo(githubId, permissions);
-  const publicFeedback = await getPublicFeedback(githubId);
-  const mentorStats = await getMentorStats(githubId);
-  const studentStats = await getStudentStats(githubId);
+  const publicFeedback = isPublicFeedbackVisible ? await getPublicFeedback(githubId) : undefined;
+  const mentorStats = isMentorStatsVisible ? await getMentorStats(githubId) : undefined;
+  const studentStats = isStudentStatsVisible ? await getStudentStats(githubId) : undefined;
   const stageInterviewFeedback = await getStageInterviewFeedback(githubId);
 
   const profileInfo: ProfileInfo = {
@@ -96,7 +104,8 @@ export const getProfileInfo = (_: ILogger) => async (ctx: Router.RouterContext) 
     studentStats,
   };
 
-  // console.log(JSON.stringify(profileInfo, null, 2));
+  console.log(JSON.stringify(permissions, null, 2));
+  console.log(JSON.stringify(profileInfo, null, 2));
 
   setResponse(ctx, OK, profileInfo);
 };
diff --git a/server/src/routes/profile/mentor-stats.ts b/server/src/routes/profile/mentor-stats.ts
index 843a2f7..72e6b30 100644
--- a/server/src/routes/profile/mentor-stats.ts
+++ b/server/src/routes/profile/mentor-stats.ts
@@ -36,11 +36,11 @@ export const getMentorStats = async (githubId: string): Promise<MentorStats[]> =
     studentIsExpelledStatuses,
     studentTotalScores,
   }: any) => {
-    const students = studentGithubIds.map((githubId: string, idx: number) => ({
+    const students = studentGithubIds[0] ? studentGithubIds.map((githubId: string, idx: number) => ({
       githubId,
       name: getFullName(studentFirstNames[idx], studentLastNames[idx], githubId),
       isExpelled: studentIsExpelledStatuses[idx],
       totalScore: studentTotalScores[idx],
-    }));
+    })) : undefined;
     return { courseName, locationName, courseFullName, students };
   });
diff --git a/server/src/routes/profile/permissions.ts b/server/src/routes/profile/permissions.ts
index 61924a8..b40121c 100644
--- a/server/src/routes/profile/permissions.ts
+++ b/server/src/routes/profile/permissions.ts
@@ -1,3 +1,4 @@
+import { get, mapValues } from 'lodash';
 import { getRepository } from 'typeorm';
 import {
   User,
@@ -8,6 +9,12 @@ import {
   TaskInterviewResult,
   StageInterview,
 } from '../../models';
+import {
+  PublicVisibilitySettings,
+  VisibilitySettings,
+  defaultPublicVisibilitySettings,
+  defaultVisibilitySettings,
+} from '../../models/profilePermissions';
 
 interface Relations {
   student: string;
@@ -19,7 +26,43 @@ interface Relations {
 
 type RelationRole = 'student' | 'mentor' | 'all';
 
-const getAllProfilePermissions = async (githubId: string): Promise<any> => (
+interface SuperAccessRights {
+  isProfileOwner: boolean;
+}
+
+interface ConfigurableProfilePermissions {
+  isProfileVisible: PublicVisibilitySettings;
+  isAboutVisible: VisibilitySettings;
+  isEducationVisible: VisibilitySettings;
+  isEnglishVisible: VisibilitySettings;
+  isEmailVisible: VisibilitySettings;
+  isTelegramVisible: VisibilitySettings;
+  isSkypeVisible: VisibilitySettings;
+  isPhoneVisible: VisibilitySettings;
+  isContactsNotesVisible: VisibilitySettings;
+  isLinkedInVisible: VisibilitySettings;
+  isPublicFeedbackVisible: VisibilitySettings;
+  isMentorStatsVisible: VisibilitySettings;
+  isStudentStatsVisible: VisibilitySettings;
+}
+
+export interface Permissions {
+  isProfileVisible: boolean;
+  isAboutVisible: boolean;
+  isEducationVisible: boolean;
+  isEnglishVisible: boolean;
+  isEmailVisible: boolean;
+  isTelegramVisible: boolean;
+  isSkypeVisible: boolean;
+  isPhoneVisible: boolean;
+  isContactsNotesVisible: boolean;
+  isLinkedInVisible: boolean;
+  isPublicFeedbackVisible: boolean;
+  isMentorStatsVisible: boolean;
+  isStudentStatsVisible: boolean;
+}
+
+const getConfigurableProfilePermissions = async (githubId: string): Promise<ConfigurableProfilePermissions> => (
   (await getRepository(ProfilePermissions)
     .createQueryBuilder('pp')
     .select('""pp"".""isProfileVisible"" AS ""isProfileVisible""')
@@ -85,16 +128,67 @@ const getRelationRole = async (userGithubId: string, requestedGithubId: string):
   return 'all';
 };
 
-const matchPermissions = (permissions: any, role: RelationRole) => {
-  const obj: any = {};
-  Object.keys(permissions).forEach((key) => {
-    obj[key] = permissions[key].all || permissions[key][role];
-  });
-  return obj;
+const matchPermissions = (
+  permissions: ConfigurableProfilePermissions,
+  role: RelationRole,
+  { isProfileOwner }: SuperAccessRights,
+): Permissions => {
+  const p: Permissions = {
+    isProfileVisible: false,
+    isAboutVisible: false,
+    isEducationVisible: false,
+    isEnglishVisible: false,
+    isEmailVisible: false,
+    isTelegramVisible: false,
+    isSkypeVisible: false,
+    isPhoneVisible: false,
+    isContactsNotesVisible: false,
+    isLinkedInVisible: false,
+    isPublicFeedbackVisible: false,
+    isMentorStatsVisible: false,
+    isStudentStatsVisible: false,
+  };
+
+  // (Object.keys(p) as (keyof Permissions)[]).forEach((key) => {
+  //   p[key] = isProfileOwner || permissions[key].all || permissions[key][role];
+  // });
+
+  // return p;
+
+  return mapValues(p, (_, key) => isProfileOwner ||
+    get(permissions, `${key}.all`) ||
+    get(permissions, `${key}.${role}`) ||
+    false,
+  );
 };
 
-export const getPermissions = async (userGithubId: string, requestedGithubId: string) => {
-  const permissions = await getAllProfilePermissions(requestedGithubId);
+export const getPermissions = async (
+  userGithubId: string,
+  requestedGithubId: string,
+  superAccessRights: SuperAccessRights,
+) => {
+  const permissions = await getConfigurableProfilePermissions(requestedGithubId);
   const role = await getRelationRole(userGithubId, requestedGithubId);
-  return matchPermissions(permissions, role);
+  return matchPermissions(permissions, role, superAccessRights);
+};
+
+export const getOwnerPermissions = async (githubId: string) => {
+  const permissions = await getConfigurableProfilePermissions(githubId);
+  const p: ConfigurableProfilePermissions = {
+    isProfileVisible: defaultPublicVisibilitySettings,
+    isAboutVisible: defaultVisibilitySettings,
+    isEducationVisible: defaultVisibilitySettings,
+    isEnglishVisible: defaultVisibilitySettings,
+    isEmailVisible: defaultVisibilitySettings,
+    isTelegramVisible: defaultVisibilitySettings,
+    isSkypeVisible: defaultVisibilitySettings,
+    isPhoneVisible: defaultVisibilitySettings,
+    isContactsNotesVisible: defaultVisibilitySettings,
+    isLinkedInVisible: defaultVisibilitySettings,
+    isPublicFeedbackVisible: defaultVisibilitySettings,
+    isMentorStatsVisible: defaultVisibilitySettings,
+    isStudentStatsVisible: defaultVisibilitySettings,
+  };
+
+  return mapValues(p, (value, key) => get(permissions, key, value));
 };
diff --git a/server/src/routes/profile/user-info.ts b/server/src/routes/profile/user-info.ts
index 5b871e0..1998ed0 100644
--- a/server/src/routes/profile/user-info.ts
+++ b/server/src/routes/profile/user-info.ts
@@ -2,23 +2,53 @@ import { getRepository } from 'typeorm';
 import { UserInfo } from '../../../../common/models/profile';
 import { getFullName } from '../../lib/utils';
 import { User } from '../../models';
+import { Permissions } from './permissions';
 
-export const getUserInfo = async (githubId: string, permissions: any): Promise<UserInfo> => {
-  const { isAboutVisible } = permissions;
+export const getUserInfo = async (githubId: string, permissions: Permissions): Promise<UserInfo> => {
+  const {
+    isAboutVisible,
+    isEducationVisible,
+    isEnglishVisible,
+    isPhoneVisible,
+    isEmailVisible,
+    isTelegramVisible,
+    isSkypeVisible,
+    isContactsNotesVisible,
+  } = permissions;
 
   const query = await getRepository(User)
     .createQueryBuilder('user')
     .select('""user"".""firstName"" AS ""firstName"", ""user"".""lastName"" AS ""lastName""')
     .addSelect('""user"".""githubId"" AS ""githubId""')
-    .addSelect('""user"".""locationName"" AS ""locationName""')
-    .addSelect('""user"".""educationHistory"" AS ""educationHistory""')
-    .addSelect('""user"".""employmentHistory"" AS ""employmentHistory""')
-    .addSelect('""user"".""englishLevel"" AS ""englishLevel""')
-    .addSelect('""user"".""contactsPhone"" AS ""contactsPhone""')
-    .addSelect('""user"".""contactsEmail"" AS ""contactsEmail""')
-    .addSelect('""user"".""contactsTelegram"" AS ""contactsTelegram""')
-    .addSelect('""user"".""contactsSkype"" AS ""contactsSkype""')
-    .addSelect('""user"".""contactsNotes"" AS ""contactsNotes""');
+    .addSelect('""user"".""locationName"" AS ""locationName""');
+
+  if (isEducationVisible) {
+    query.addSelect('""user"".""educationHistory"" AS ""educationHistory""');
+  }
+
+  if (isEnglishVisible) {
+    query.addSelect('""user"".""englishLevel"" AS ""englishLevel""');
+  }
+
+  if (isPhoneVisible) {
+    query.addSelect('""user"".""contactsPhone"" AS ""contactsPhone""');
+  }
+
+  if (isEmailVisible) {
+    query.addSelect('""user"".""contactsEmail"" AS ""contactsEmail""');
+  }
+
+  if (isTelegramVisible) {
+    query.addSelect('""user"".""contactsTelegram"" AS ""contactsTelegram""');
+  }
+
+  if (isSkypeVisible) {
+    query.addSelect('""user"".""contactsSkype"" AS ""contactsSkype""');
+  }
+
+  if (isContactsNotesVisible) {
+    query.addSelect('""user"".""contactsNotes"" AS ""contactsNotes""');
+  }
 
   if (isAboutVisible) {
     query.addSelect('""user"".""aboutMyself"" AS ""aboutMyself""');
@@ -33,7 +63,6 @@ export const getUserInfo = async (githubId: string, permissions: any): Promise<U
     lastName,
     locationName,
     educationHistory,
-    employmentHistory,
     englishLevel,
     contactsPhone,
     contactsEmail,
@@ -49,16 +78,15 @@ export const getUserInfo = async (githubId: string, permissions: any): Promise<U
       aboutMyself,
       locationName,
       educationHistory,
-      employmentHistory,
       englishLevel,
       name: getFullName(firstName, lastName, githubId),
     },
-    contacts: {
+    contacts: contactsPhone || contactsEmail || contactsSkype || contactsTelegram || contactsNotes ? {
       phone: contactsPhone,
       email: contactsEmail,
       skype: contactsSkype,
       telegram: contactsTelegram,
       notes: contactsNotes,
-    },
+    } : undefined,
   };
 };

diff --git a/www/docs/customization/monorepo.md b/www/docs/customization/monorepo.md
index 6d0e857..e45490f 100644
--- a/www/docs/customization/monorepo.md
+++ b/www/docs/customization/monorepo.md
@@ -18,7 +18,7 @@ project_name: subproj1
 
 monorepo:
   tag_prefix: subproject1/
-  folder: subproj1
+  dir: subproj1
 ```
 
 Then, you can release with (from the project's root directory):
@@ -30,11 +30,11 @@ goreleaser release --rm-dist -f ./subproj1/.goreleaser.yml
 Then, the following is different from a ""regular"" run:
 
 - GoReleaser will then look if current commit has a tag prefixed with `subproject1`, and also the previous tag with the same prefix;
-- Changelog will include only commits that contain changes to files within the `subproj1` folder;
+- Changelog will include only commits that contain changes to files within the `subproj1` directory;
 - Release name gets prefixed with `{{ .ProjectName }} ` if empty;
-- All build's `dir` setting get set to `monorepo.folder` if empty;
+- All build's `dir` setting get set to `monorepo.dir` if empty;
   - if yours is not, you might want to change that manually;
-- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.folder`;
+- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.dir`;
 - On templates, `{{.PrefixedTag}}` will be `monorepo.prefix/tag` (aka the actual tag name), and `{{.Tag}}` has the prefix stripped;
 
 The rest of the release process should work as usual.

diff --git a/core/main/src/Core/Particle.ts b/core/main/src/Core/Particle.ts
index 1aa6fba..6ea6ffc 100644
--- a/core/main/src/Core/Particle.ts
+++ b/core/main/src/Core/Particle.ts
@@ -271,7 +271,7 @@ export class Particle implements IParticle {
             }
         }
 
-        const sizeAnimation = this.options.size.animation;
+        const sizeAnimation = sizeOptions.animation;
 
         if (sizeAnimation.enable) {
             this.size.status = AnimationStatus.increasing;
@@ -279,7 +279,8 @@ export class Particle implements IParticle {
             if (!randomSize) {
                 switch (sizeAnimation.startValue) {
                     case StartValueType.min:
-                        this.size.value = sizeAnimation.minimumValue * pxRatio;
+                        this.size.value = NumberUtils.getRangeMin(sizeOptions.value) * pxRatio;
+                        this.size.status = AnimationStatus.increasing;
 
                         break;
 
@@ -287,11 +288,14 @@ export class Particle implements IParticle {
                         this.size.value = NumberUtils.randomInRange(
                             NumberUtils.setRangeValue(sizeAnimation.minimumValue * pxRatio, this.size.value)
                         );
+                        this.size.status =
+                            Math.random() >= 0.5 ? AnimationStatus.increasing : AnimationStatus.decreasing;
 
                         break;
 
                     case StartValueType.max:
                     default:
+                        this.size.value = NumberUtils.getRangeMax(sizeOptions.value) * pxRatio;
                         this.size.status = AnimationStatus.decreasing;
 
                         break;
@@ -393,7 +397,8 @@ export class Particle implements IParticle {
             if (!randomOpacity) {
                 switch (opacityAnimation.startValue) {
                     case StartValueType.min:
-                        this.opacity.value = opacityAnimation.minimumValue;
+                        this.opacity.value = NumberUtils.getRangeMin(this.opacity.value);
+                        this.opacity.status = AnimationStatus.increasing;
 
                         break;
 
@@ -401,11 +406,14 @@ export class Particle implements IParticle {
                         this.opacity.value = NumberUtils.randomInRange(
                             NumberUtils.setRangeValue(opacityAnimation.minimumValue, this.opacity.value)
                         );
+                        this.opacity.status =
+                            Math.random() >= 0.5 ? AnimationStatus.increasing : AnimationStatus.decreasing;
 
                         break;
 
                     case StartValueType.max:
                     default:
+                        this.opacity.value = NumberUtils.getRangeMax(this.opacity.value);
                         this.opacity.status = AnimationStatus.decreasing;
 
                         break;
diff --git a/presets/confetti/src/options.ts b/presets/confetti/src/options.ts
index 7fc6225..a713425 100644
--- a/presets/confetti/src/options.ts
+++ b/presets/confetti/src/options.ts
@@ -28,7 +28,7 @@ export const loadOptions = (confettiOptions: RecursivePartial<IConfettiOptions>)
                 animation: {
                     enable: true,
                     minimumValue: 0,
-                    speed: 2,
+                    speed: 0.5,
                     startValue: ""max"",
                     destroy: ""min"",
                 },
",3,"[""1f15f71e415ba49b21684c7a3a51c8e3faaa7cf3"", ""9ed3c0c4a72af977fc9150512fb6538f20a94b22"", ""06960183db42cba1b1f1a8077660ba8c801c9e18""]","[""feat"", ""docs"", ""fix""]"
remove unused,"diff --git a/src/content/redux/modules/dictionaries.ts b/src/content/redux/modules/dictionaries.ts
index 88f7215..570d397 100644
--- a/src/content/redux/modules/dictionaries.ts
+++ b/src/content/redux/modules/dictionaries.ts
@@ -3,7 +3,6 @@ import { DictID, appConfigFactory, AppConfig } from '@/app-config'
 import isEqual from 'lodash/isEqual'
 import { saveWord } from '@/_helpers/record-manager'
 import { getDefaultSelectionInfo, SelectionInfo, isSameSelection } from '@/_helpers/selection'
-import { createActiveConfigStream } from '@/_helpers/config-manager'
 import { isContainChinese, isContainEnglish, testerPunct, isContainMinor, testerChinese, testJapanese, testKorean } from '@/_helpers/lang-check'
 import { MsgType, MsgFetchDictResult } from '@/typings/message'
 import { StoreState, DispatcherThunk, Dispatcher } from './index'
diff --git a/src/content/redux/modules/widget.ts b/src/content/redux/modules/widget.ts
index 53ad550..68e0a3d 100644
--- a/src/content/redux/modules/widget.ts
+++ b/src/content/redux/modules/widget.ts
@@ -1,9 +1,9 @@
 import * as recordManager from '@/_helpers/record-manager'
 import { StoreState, DispatcherThunk, Dispatcher } from './index'
-import appConfigFactory, { TCDirection, AppConfig, DictID } from '@/app-config'
+import appConfigFactory, { TCDirection, DictID } from '@/app-config'
 import { message, storage } from '@/_helpers/browser-api'
-import { createActiveConfigStream, createConfigIDListStream } from '@/_helpers/config-manager'
-import { MsgSelection, MsgType, MsgTempDisabledState, MsgEditWord, MsgOpenUrl, MsgFetchDictResult } from '@/typings/message'
+import { createConfigIDListStream } from '@/_helpers/config-manager'
+import { MsgType, MsgTempDisabledState, MsgEditWord, MsgOpenUrl, MsgFetchDictResult } from '@/typings/message'
 import { searchText, restoreDicts } from '@/content/redux/modules/dictionaries'
 import { SelectionInfo, getDefaultSelectionInfo } from '@/_helpers/selection'
 import { Mutable } from '@/typings/helpers'
",1,"[""a50b51999015e210918d9c8e95fd4cac347353be""]","[""refactor""]"
"convert to record | only run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com> | stop playing audio on panel close

Closes #824","diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
index cc998c6..65c8550 100755
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
@@ -167,13 +167,8 @@ public final class ExporterDirectorDistributionTest {
    * <p>This makes sure that even if we miss one export position event, we distribute the event
    * later again, which makes tests less flaky.
    */
-  private static final class ClockShifter implements ConditionEvaluationListener<Void> {
-
-    private final ControlledActorClock clock;
-
-    public ClockShifter(final ControlledActorClock clock) {
-      this.clock = clock;
-    }
+  private record ClockShifter(ControlledActorClock clock)
+      implements ConditionEvaluationListener<Void> {
 
     @Override
     public void conditionEvaluated(final EvaluatedCondition<Void> condition) {

diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest

diff --git a/src/background/audio-manager.ts b/src/background/audio-manager.ts
index 84032f1..9e116fc 100644
--- a/src/background/audio-manager.ts
+++ b/src/background/audio-manager.ts
@@ -1,4 +1,4 @@
-import { timeout } from '@/_helpers/promise-more'
+import { timer } from '@/_helpers/promise-more'
 
 /**
  * To make sure only one audio plays at a time
@@ -16,6 +16,8 @@ export class AudioManager {
 
   private audio?: HTMLAudioElement
 
+  currentSrc?: string
+
   reset() {
     if (this.audio) {
       this.audio.pause()
@@ -23,28 +25,33 @@ export class AudioManager {
       this.audio.src = ''
       this.audio.onended = null
     }
+    this.currentSrc = ''
   }
 
   load(src: string): HTMLAudioElement {
     this.reset()
+    this.currentSrc = src
     return (this.audio = new Audio(src))
   }
 
   async play(src?: string): Promise<void> {
-    if (!src) {
+    if (!src || src === this.currentSrc) {
       this.reset()
       return
     }
 
     const audio = this.load(src)
 
-    const onEnd = new Promise(resolve => {
-      audio.onended = resolve
-    })
+    const onEnd = Promise.race([
+      new Promise(resolve => {
+        audio.onended = resolve
+      }),
+      timer(20000)
+    ])
+
+    await audio.play()
+    await onEnd
 
-    await audio
-      .play()
-      .then(() => timeout(onEnd, 4000))
-      .catch(() => {})
+    this.currentSrc = ''
   }
 }
diff --git a/src/background/server.ts b/src/background/server.ts
index 65f6f6c..4c70196 100644
--- a/src/background/server.ts
+++ b/src/background/server.ts
@@ -64,6 +64,9 @@ export class BackgroundServer {
           return openURL(msg.payload.url, msg.payload.self)
         case 'PLAY_AUDIO':
           return AudioManager.getInstance().play(msg.payload)
+        case 'STOP_AUDIO':
+          AudioManager.getInstance().reset()
+          return
         case 'FETCH_DICT_RESULT':
           return this.fetchDictResult(msg.payload)
         case 'DICT_ENGINE_METHOD':
@@ -79,6 +82,7 @@ export class BackgroundServer {
         case 'OPEN_QS_PANEL':
           return this.openQSPanel()
         case 'CLOSE_QS_PANEL':
+          AudioManager.getInstance().reset()
           return this.qsPanelManager.destroy()
         case 'QS_SWITCH_SIDEBAR':
           return this.qsPanelManager.toggleSidebar(msg.payload)
@@ -105,6 +109,16 @@ export class BackgroundServer {
           return this.youdaoTranslateAjax(msg.payload)
       }
     })
+
+    browser.runtime.onConnect.addListener(port => {
+      if (port.name === 'popup') {
+        // This is a workaround for browser action page
+        // which does not fire beforeunload event
+        port.onDisconnect.addListener(() => {
+          AudioManager.getInstance().reset()
+        })
+      }
+    })
   }
 
   async openQSPanel(): Promise<void> {
diff --git a/src/content/redux/epics/index.ts b/src/content/redux/epics/index.ts
index b941c07..587b54d 100644
--- a/src/content/redux/epics/index.ts
+++ b/src/content/redux/epics/index.ts
@@ -1,6 +1,6 @@
 import { combineEpics } from 'redux-observable'
 import { from, of, EMPTY } from 'rxjs'
-import { map, mapTo, mergeMap, filter } from 'rxjs/operators'
+import { map, mapTo, mergeMap, filter, pairwise } from 'rxjs/operators'
 
 import { isPopupPage, isStandalonePage } from '@/_helpers/saladict'
 import { saveWord } from '@/_helpers/record-manager'
@@ -11,6 +11,7 @@ import { ofType } from './utils'
 import searchStartEpic from './searchStart.epic'
 import newSelectionEpic from './newSelection.epic'
 import { translateCtxs, genCtxText } from '@/_helpers/translateCtx'
+import { message } from '@/_helpers/browser-api'
 
 export const epics = combineEpics<StoreAction, StoreAction, StoreState>(
   /** Start searching text. This will also send to Redux. */
@@ -28,6 +29,17 @@ export const epics = combineEpics<StoreAction, StoreAction, StoreState>(
       )
     ),
   (action$, state$) =>
+    state$.pipe(
+      map(state => state.isShowDictPanel),
+      pairwise(),
+      mergeMap(([oldShow, newShow]) => {
+        if (oldShow && !newShow) {
+          message.send({ type: 'STOP_AUDIO' })
+        }
+        return EMPTY
+      })
+    ),
+  (action$, state$) =>
     action$.pipe(
       ofType('ADD_TO_NOTEBOOK'),
       mergeMap(() => {
diff --git a/src/popup/index.tsx b/src/popup/index.tsx
index cbca1c0..a406bfd 100644
--- a/src/popup/index.tsx
+++ b/src/popup/index.tsx
@@ -21,6 +21,10 @@ import Popup from './Popup'
 import Notebook from './Notebook'
 import './_style.scss'
 
+// This is a workaround for browser action page
+// which does not fire beforeunload event
+browser.runtime.connect({ name: 'popup' } as any) // wrong typing
+
 const Title: FC = () => {
   const { t } = useTranslate('popup')
   return (
diff --git a/src/typings/message.ts b/src/typings/message.ts
index bdd6fad..63238cb 100644
--- a/src/typings/message.ts
+++ b/src/typings/message.ts
@@ -146,6 +146,8 @@ export type MessageConfig = MessageConfigType<{
     payload: string
   }
 
+  STOP_AUDIO: {}
+
   LAST_PLAY_AUDIO: {
     response?: null | { src: string; timestamp: number }
   }
",3,"[""3346331a963766c8193170fb130adad2e658ada2"", ""dbb537a26e388a8d7d17faf131abc30c2f7a84e6"", ""97cabf49e7aca7754edde247003fbcb4ea42dd59""]","[""refactor"", ""cicd"", ""fix""]"
add jackson dependencies for zb-bpmn-model,"diff --git a/parent/pom.xml b/parent/pom.xml
index d475131..6290e66 100644
--- a/parent/pom.xml
+++ b/parent/pom.xml
@@ -35,6 +35,7 @@
     <version.mockito>1.8.5</version.mockito>
     <version.assertj>3.8.0</version.assertj>
     <version.msgpack>0.8.13</version.msgpack>
+    <version.jackson>2.9.0</version.jackson>
     <version.jmh>1.11.2</version.jmh>
     <version.sbe>1.5.6</version.sbe>
     <version.slf4j>1.7.23</version.slf4j>
@@ -64,6 +65,18 @@
       </dependency>
 
       <dependency>
+        <groupId>com.fasterxml.jackson.core</groupId>
+        <artifactId>jackson-databind</artifactId>
+        <version>${version.jackson}</version>
+      </dependency>
+
+      <dependency>
+        <groupId>com.fasterxml.jackson.dataformat</groupId>
+        <artifactId>jackson-dataformat-yaml</artifactId>
+        <version>${version.jackson}</version>
+      </dependency>
+
+      <dependency>
         <groupId>org.msgpack</groupId>
         <artifactId>msgpack-core</artifactId>
         <version>${version.msgpack}</version>
",1,"[""fab09655d5cc30727289cc3f26e5396fce235cd3""]","[""build""]"
"update Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909 | init environ cache | Port shard precreation service from InfluxDB 1.x

Provides new configuration parameters:

```
--storage-shard-precreator-advance-period
--storage-shard-precreator-check-interval
```

Closes #19520","diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })

diff --git a/src/environment.go b/src/environment.go
index ae5e26a..0c961c5 100644
--- a/src/environment.go
+++ b/src/environment.go
@@ -229,6 +229,7 @@ func (env *environment) environ() map[string]string {
 	if env.environCache != nil {
 		return env.environCache
 	}
+	env.environCache = make(map[string]string)
 	const separator = ""=""
 	values := os.Environ()
 	for value := range values {

diff --git a/cmd/influxd/launcher/launcher.go b/cmd/influxd/launcher/launcher.go
index e3548ef..5559e94 100644
--- a/cmd/influxd/launcher/launcher.go
+++ b/cmd/influxd/launcher/launcher.go
@@ -440,6 +440,16 @@ func launcherOpts(l *Launcher) []cli.Opt {
 			Flag:  ""storage-retention-check-interval"",
 			Desc:  ""The interval of time when retention policy enforcement checks run."",
 		},
+		{
+			DestP: &l.StorageConfig.PrecreatorConfig.CheckInterval,
+			Flag:  ""storage-shard-precreator-check-interval"",
+			Desc:  ""The interval of time when the check to pre-create new shards runs."",
+		},
+		{
+			DestP: &l.StorageConfig.PrecreatorConfig.AdvancePeriod,
+			Flag:  ""storage-shard-precreator-advance-period"",
+			Desc:  ""The default period ahead of the endtime of a shard group that its successor group is created."",
+		},
 
 		// InfluxQL Coordinator Config
 		{
diff --git a/storage/config.go b/storage/config.go
index ef953a2..d8e24db 100644
--- a/storage/config.go
+++ b/storage/config.go
@@ -2,6 +2,7 @@ package storage
 
 import (
 	""github.com/influxdata/influxdb/v2/tsdb""
+	""github.com/influxdata/influxdb/v2/v1/services/precreator""
 	""github.com/influxdata/influxdb/v2/v1/services/retention""
 )
 
@@ -10,6 +11,7 @@ type Config struct {
 	Data tsdb.Config
 
 	RetentionService retention.Config
+	PrecreatorConfig precreator.Config
 }
 
 // NewConfig initialises a new config for an Engine.
@@ -17,5 +19,6 @@ func NewConfig() Config {
 	return Config{
 		Data:             tsdb.NewConfig(),
 		RetentionService: retention.NewConfig(),
+		PrecreatorConfig: precreator.NewConfig(),
 	}
 }
diff --git a/storage/engine.go b/storage/engine.go
index 8518f48..ae37fdd 100644
--- a/storage/engine.go
+++ b/storage/engine.go
@@ -19,6 +19,7 @@ import (
 	_ ""github.com/influxdata/influxdb/v2/tsdb/index/tsi1""
 	""github.com/influxdata/influxdb/v2/v1/coordinator""
 	""github.com/influxdata/influxdb/v2/v1/services/meta""
+	""github.com/influxdata/influxdb/v2/v1/services/precreator""
 	""github.com/influxdata/influxdb/v2/v1/services/retention""
 	""github.com/influxdata/influxql""
 	""github.com/pkg/errors""
@@ -42,7 +43,8 @@ type Engine struct {
 		WritePoints(database, retentionPolicy string, consistencyLevel models.ConsistencyLevel, user meta.User, points []models.Point) error
 	}
 
-	retentionService *retention.Service
+	retentionService  *retention.Service
+	precreatorService *precreator.Service
 
 	defaultMetricLabels prometheus.Labels
 
@@ -66,6 +68,7 @@ type MetaClient interface {
 	Database(name string) (di *meta.DatabaseInfo)
 	Databases() []meta.DatabaseInfo
 	DeleteShardGroup(database, policy string, id uint64) error
+	PrecreateShardGroups(now, cutoff time.Time) error
 	PruneShardGroups() error
 	RetentionPolicy(database, policy string) (*meta.RetentionPolicyInfo, error)
 	ShardGroupsByTimeRange(database, policy string, min, max time.Time) (a []meta.ShardGroupInfo, err error)
@@ -115,6 +118,9 @@ func NewEngine(path string, c Config, options ...Option) *Engine {
 	e.retentionService.TSDBStore = e.tsdbStore
 	e.retentionService.MetaClient = e.metaClient
 
+	e.precreatorService = precreator.NewService(c.PrecreatorConfig)
+	e.precreatorService.MetaClient = e.metaClient
+
 	return e
 }
 
@@ -132,6 +138,10 @@ func (e *Engine) WithLogger(log *zap.Logger) {
 	if e.retentionService != nil {
 		e.retentionService.WithLogger(log)
 	}
+
+	if e.precreatorService != nil {
+		e.precreatorService.WithLogger(log)
+	}
 }
 
 // PrometheusCollectors returns all the prometheus collectors associated with
@@ -161,6 +171,10 @@ func (e *Engine) Open(ctx context.Context) (err error) {
 		return err
 	}
 
+	if err := e.precreatorService.Open(ctx); err != nil {
+		return err
+	}
+
 	e.closing = make(chan struct{})
 
 	return nil
@@ -194,6 +208,10 @@ func (e *Engine) Close() error {
 
 	var retErr *multierror.Error
 
+	if err := e.precreatorService.Close(); err != nil {
+		retErr = multierror.Append(retErr, fmt.Errorf(""error closing shard precreator service: %w"", err))
+	}
+
 	if err := e.retentionService.Close(); err != nil {
 		retErr = multierror.Append(retErr, fmt.Errorf(""error closing retention service: %w"", err))
 	}
diff --git a/v1/services/precreator/README.md b/v1/services/precreator/README.md
new file mode 100644
index 0000000..8830b73
--- /dev/null
+++ b/v1/services/precreator/README.md
@@ -0,0 +1,13 @@
+Shard Precreation
+============
+
+During normal operation when InfluxDB receives time-series data, it writes the data to files known as _shards_. Each shard only contains data for a specific range of time. Therefore, before data can be accepted by the system, the shards must exist and InfluxDB always checks that the required shards exist for every incoming data point. If the required shards do not exist, InfluxDB will create those shards. Because this requires a cluster to reach consensus, the process is not instantaneous and can temporarily impact write-throughput.
+
+Since almost all time-series data is written sequentially in time, the system has an excellent idea of the timestamps of future data. Shard precreation takes advantage of this fact by creating required shards ahead of time, thereby ensuring the required shards exist by the time new time-series data actually arrives. Write-throughput is therefore not affected when data is first received for a range of time that would normally trigger shard creation.
+
+Note that the shard-existence check must remain in place in the code, even with shard precreation. This is because while most data is written sequentially in time, this is not always the case. Data may be written with timestamps in the past, or farther in the future than shard precreation handles.
+
+## Configuration
+Shard precreation can be disabled if necessary, though this is not recommended. If it is disabled, then shards will be only be created when explicitly needed.
+
+The interval between runs of the shard precreation service, as well as the time-in-advance the shards are created, are also configurable. The defaults should work for most deployments.
diff --git a/v1/services/precreator/config.go b/v1/services/precreator/config.go
new file mode 100644
index 0000000..5e994e6
--- /dev/null
+++ b/v1/services/precreator/config.go
@@ -0,0 +1,65 @@
+package precreator
+
+import (
+	""errors""
+	""time""
+
+	""github.com/influxdata/influxdb/v2/toml""
+	""github.com/influxdata/influxdb/v2/v1/monitor/diagnostics""
+)
+
+const (
+	// DefaultCheckInterval is the shard precreation check time if none is specified.
+	DefaultCheckInterval = 10 * time.Minute
+
+	// DefaultAdvancePeriod is the default period ahead of the endtime of a shard group
+	// that its successor group is created.
+	DefaultAdvancePeriod = 30 * time.Minute
+)
+
+// Config represents the configuration for shard precreation.
+type Config struct {
+	Enabled       bool          `toml:""enabled""`
+	CheckInterval toml.Duration `toml:""check-interval""`
+	AdvancePeriod toml.Duration `toml:""advance-period""`
+}
+
+// NewConfig returns a new Config with defaults.
+func NewConfig() Config {
+	return Config{
+		Enabled:       true,
+		CheckInterval: toml.Duration(DefaultCheckInterval),
+		AdvancePeriod: toml.Duration(DefaultAdvancePeriod),
+	}
+}
+
+// Validate returns an error if the Config is invalid.
+func (c Config) Validate() error {
+	if !c.Enabled {
+		return nil
+	}
+
+	if c.CheckInterval <= 0 {
+		return errors.New(""check-interval must be positive"")
+	}
+	if c.AdvancePeriod <= 0 {
+		return errors.New(""advance-period must be positive"")
+	}
+
+	return nil
+}
+
+// Diagnostics returns a diagnostics representation of a subset of the Config.
+func (c Config) Diagnostics() (*diagnostics.Diagnostics, error) {
+	if !c.Enabled {
+		return diagnostics.RowFromMap(map[string]interface{}{
+			""enabled"": false,
+		}), nil
+	}
+
+	return diagnostics.RowFromMap(map[string]interface{}{
+		""enabled"":        true,
+		""check-interval"": c.CheckInterval,
+		""advance-period"": c.AdvancePeriod,
+	}), nil
+}
diff --git a/v1/services/precreator/config_test.go b/v1/services/precreator/config_test.go
new file mode 100644
index 0000000..2686001
--- /dev/null
+++ b/v1/services/precreator/config_test.go
@@ -0,0 +1,67 @@
+package precreator_test
+
+import (
+	""testing""
+	""time""
+
+	""github.com/BurntSushi/toml""
+	""github.com/influxdata/influxdb/v2/v1/services/precreator""
+)
+
+func TestConfig_Parse(t *testing.T) {
+	// Parse configuration.
+	var c precreator.Config
+	if _, err := toml.Decode(`
+enabled = true
+check-interval = ""2m""
+advance-period = ""10m""
+`, &c); err != nil {
+
+		t.Fatal(err)
+	}
+
+	// Validate configuration.
+	if !c.Enabled {
+		t.Fatalf(""unexpected enabled state: %v"", c.Enabled)
+	} else if time.Duration(c.CheckInterval) != 2*time.Minute {
+		t.Fatalf(""unexpected check interval: %s"", c.CheckInterval)
+	} else if time.Duration(c.AdvancePeriod) != 10*time.Minute {
+		t.Fatalf(""unexpected advance period: %s"", c.AdvancePeriod)
+	}
+}
+
+func TestConfig_Validate(t *testing.T) {
+	c := precreator.NewConfig()
+	if err := c.Validate(); err != nil {
+		t.Fatalf(""unexpected validation fail from NewConfig: %s"", err)
+	}
+
+	c = precreator.NewConfig()
+	c.CheckInterval = 0
+	if err := c.Validate(); err == nil {
+		t.Fatal(""expected error for check-interval = 0, got nil"")
+	}
+
+	c = precreator.NewConfig()
+	c.CheckInterval *= -1
+	if err := c.Validate(); err == nil {
+		t.Fatal(""expected error for negative check-interval, got nil"")
+	}
+
+	c = precreator.NewConfig()
+	c.AdvancePeriod = 0
+	if err := c.Validate(); err == nil {
+		t.Fatal(""expected error for advance-period = 0, got nil"")
+	}
+
+	c = precreator.NewConfig()
+	c.AdvancePeriod *= -1
+	if err := c.Validate(); err == nil {
+		t.Fatal(""expected error for negative advance-period, got nil"")
+	}
+
+	c.Enabled = false
+	if err := c.Validate(); err != nil {
+		t.Fatalf(""unexpected validation fail from disabled config: %s"", err)
+	}
+}
diff --git a/v1/services/precreator/service.go b/v1/services/precreator/service.go
new file mode 100644
index 0000000..28e8f16
--- /dev/null
+++ b/v1/services/precreator/service.go
@@ -0,0 +1,93 @@
+// Package precreator provides the shard precreation service.
+package precreator // import ""github.com/influxdata/influxdb/v2/v1/services/precreator""
+
+import (
+	""context""
+	""sync""
+	""time""
+
+	""github.com/influxdata/influxdb/v2/logger""
+	""go.uber.org/zap""
+)
+
+// Service manages the shard precreation service.
+type Service struct {
+	checkInterval time.Duration
+	advancePeriod time.Duration
+
+	Logger *zap.Logger
+
+	cancel context.CancelFunc
+	wg     sync.WaitGroup
+
+	MetaClient interface {
+		PrecreateShardGroups(now, cutoff time.Time) error
+	}
+}
+
+// NewService returns an instance of the precreation service.
+func NewService(c Config) *Service {
+	return &Service{
+		checkInterval: time.Duration(c.CheckInterval),
+		advancePeriod: time.Duration(c.AdvancePeriod),
+		Logger:        zap.NewNop(),
+	}
+}
+
+// WithLogger sets the logger for the service.
+func (s *Service) WithLogger(log *zap.Logger) {
+	s.Logger = log.With(zap.String(""service"", ""shard-precreation""))
+}
+
+// Open starts the precreation service.
+func (s *Service) Open(ctx context.Context) error {
+	if s.cancel != nil {
+		return nil
+	}
+
+	s.Logger.Info(""Starting precreation service"",
+		logger.DurationLiteral(""check_interval"", s.checkInterval),
+		logger.DurationLiteral(""advance_period"", s.advancePeriod))
+
+	ctx, s.cancel = context.WithCancel(ctx)
+
+	s.wg.Add(1)
+	go s.runPrecreation(ctx)
+	return nil
+}
+
+// Close stops the precreation service.
+func (s *Service) Close() error {
+	if s.cancel == nil {
+		return nil
+	}
+
+	s.cancel()
+	s.wg.Wait()
+	s.cancel = nil
+
+	return nil
+}
+
+// runPrecreation continually checks if resources need precreation.
+func (s *Service) runPrecreation(ctx context.Context) {
+	defer s.wg.Done()
+
+	for {
+		select {
+		case <-time.After(s.checkInterval):
+			if err := s.precreate(time.Now().UTC()); err != nil {
+				s.Logger.Info(""Failed to precreate shards"", zap.Error(err))
+			}
+		case <-ctx.Done():
+			s.Logger.Info(""Terminating precreation service"")
+			return
+		}
+	}
+}
+
+// precreate performs actual resource precreation.
+func (s *Service) precreate(now time.Time) error {
+	cutoff := now.Add(s.advancePeriod).UTC()
+	return s.MetaClient.PrecreateShardGroups(now, cutoff)
+}
diff --git a/v1/services/precreator/service_test.go b/v1/services/precreator/service_test.go
new file mode 100644
index 0000000..20289b7
--- /dev/null
+++ b/v1/services/precreator/service_test.go
@@ -0,0 +1,56 @@
+package precreator_test
+
+import (
+	""context""
+	""os""
+	""testing""
+	""time""
+
+	""github.com/influxdata/influxdb/v2/logger""
+	""github.com/influxdata/influxdb/v2/toml""
+	""github.com/influxdata/influxdb/v2/v1/internal""
+	""github.com/influxdata/influxdb/v2/v1/services/precreator""
+)
+
+func TestShardPrecreation(t *testing.T) {
+	done := make(chan struct{})
+	precreate := false
+
+	var mc internal.MetaClientMock
+	mc.PrecreateShardGroupsFn = func(now, cutoff time.Time) error {
+		if !precreate {
+			close(done)
+			precreate = true
+		}
+		return nil
+	}
+
+	s := NewTestService()
+	s.MetaClient = &mc
+
+	if err := s.Open(context.Background()); err != nil {
+		t.Fatalf(""unexpected open error: %s"", err)
+	}
+	defer s.Close() // double close should not cause a panic
+
+	timer := time.NewTimer(100 * time.Millisecond)
+	select {
+	case <-done:
+		timer.Stop()
+	case <-timer.C:
+		t.Errorf(""timeout exceeded while waiting for precreate"")
+	}
+
+	if err := s.Close(); err != nil {
+		t.Fatalf(""unexpected close error: %s"", err)
+	}
+}
+
+func NewTestService() *precreator.Service {
+	config := precreator.NewConfig()
+	config.CheckInterval = toml.Duration(10 * time.Millisecond)
+
+	s := precreator.NewService(config)
+	s.WithLogger(logger.New(os.Stderr))
+	return s
+}
",3,"[""c2ee5cd5e709afd15c5565ee009a0d204403a119"", ""dc50bd35462a49058c91a939fc8830ae7a9eb692"", ""6f0cf049caa1a7982669ee685e86621452686551""]","[""docs"", ""fix"", ""feat""]"
"licensing | Adjust test scenario

With the new version of the FEEL engine, a non-existing variable results in `null`. Previously, the evaluation failed
with an error.

To keep the semantics of the test cases, create the incident by failing the job. | do not query all networks","diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
index c0a3472..6a9389b 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
@@ -759,7 +759,7 @@ public final class ProcessExecutionCleanStateTest {
         .withXmlResource(
             Bpmn.createExecutableProcess(PROCESS_ID)
                 .startEvent()
-                .serviceTask(""task"", t -> t.zeebeJobType(""test"").zeebeOutputExpression(""x"", ""y""))
+                .serviceTask(""task"", t -> t.zeebeJobType(""test""))
                 .endEvent()
                 .done())
         .deploy();
@@ -768,7 +768,7 @@ public final class ProcessExecutionCleanStateTest {
     final var processInstanceKey =
         engineRule.processInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    engineRule.job().ofInstance(processInstanceKey).withType(""test"").complete();
+    engineRule.job().ofInstance(processInstanceKey).withType(""test"").withRetries(0).fail();
 
     RecordingExporter.incidentRecords(IncidentIntent.CREATED)
         .withProcessInstanceKey(processInstanceKey)

diff --git a/src/environment/windows_win32.go b/src/environment/windows_win32.go
index be0c7b5..b90e0ff 100644
--- a/src/environment/windows_win32.go
+++ b/src/environment/windows_win32.go
@@ -203,7 +203,6 @@ func (env *ShellEnvironment) getConnections() []*Connection {
 	var pIFTable2 *MIN_IF_TABLE2
 	_, _, _ = hGetIfTable2.Call(uintptr(unsafe.Pointer(&pIFTable2)))
 
-	SSIDs, _ := env.getAllWifiSSID()
 	networks := make([]*Connection, 0)
 
 	for i := 0; i < int(pIFTable2.NumEntries); i++ {
@@ -220,11 +219,13 @@ func (env *ShellEnvironment) getConnections() []*Connection {
 		}
 
 		var connectionType ConnectionType
+		var ssid string
 		switch networkInterface.Type {
 		case 6:
 			connectionType = ETHERNET
 		case 71:
 			connectionType = WIFI
+			ssid = env.getWiFiSSID(networkInterface.InterfaceGUID)
 		case 237, 234, 244:
 			connectionType = CELLULAR
 		}
@@ -243,10 +244,7 @@ func (env *ShellEnvironment) getConnections() []*Connection {
 			Name:         description, // we want a relatable name, alias isn't that
 			TransmitRate: networkInterface.TransmitLinkSpeed,
 			ReceiveRate:  networkInterface.ReceiveLinkSpeed,
-		}
-
-		if SSID, OK := SSIDs[network.Name]; OK {
-			network.SSID = SSID
+			SSID:         ssid,
 		}
 
 		networks = append(networks, network)
@@ -322,13 +320,21 @@ type MIB_IF_ROW2 struct { //nolint: revive
 	OutQLen            uint64
 }
 
-func (env *ShellEnvironment) getAllWifiSSID() (map[string]string, error) {
+var (
+	wlanapi             = syscall.NewLazyDLL(""wlanapi.dll"")
+	hWlanOpenHandle     = wlanapi.NewProc(""WlanOpenHandle"")
+	hWlanCloseHandle    = wlanapi.NewProc(""WlanCloseHandle"")
+	hWlanQueryInterface = wlanapi.NewProc(""WlanQueryInterface"")
+)
+
+func (env *ShellEnvironment) getWiFiSSID(guid windows.GUID) string {
+	// Query wifi connection state
 	var pdwNegotiatedVersion uint32
 	var phClientHandle uint32
 	e, _, err := hWlanOpenHandle.Call(uintptr(uint32(2)), uintptr(unsafe.Pointer(nil)), uintptr(unsafe.Pointer(&pdwNegotiatedVersion)), uintptr(unsafe.Pointer(&phClientHandle)))
 	if e != 0 {
 		env.Log(Error, ""getAllWifiSSID"", err.Error())
-		return nil, err
+		return """"
 	}
 
 	// defer closing handle
@@ -336,42 +342,11 @@ func (env *ShellEnvironment) getAllWifiSSID() (map[string]string, error) {
 		_, _, _ = hWlanCloseHandle.Call(uintptr(phClientHandle), uintptr(unsafe.Pointer(nil)))
 	}()
 
-	ssid := make(map[string]string)
-	// list interfaces
-	var interfaceList *WLAN_INTERFACE_INFO_LIST
-	e, _, err = hWlanEnumInterfaces.Call(uintptr(phClientHandle), uintptr(unsafe.Pointer(nil)), uintptr(unsafe.Pointer(&interfaceList)))
-	if e != 0 {
-		env.Log(Error, ""getAllWifiSSID"", err.Error())
-		return nil, err
-	}
-
-	// use first interface that is connected
-	numberOfInterfaces := int(interfaceList.dwNumberOfItems)
-	infoSize := unsafe.Sizeof(interfaceList.InterfaceInfo[0])
-	for i := 0; i < numberOfInterfaces; i++ {
-		network := (*WLAN_INTERFACE_INFO)(unsafe.Pointer(uintptr(unsafe.Pointer(&interfaceList.InterfaceInfo[0])) + uintptr(i)*infoSize))
-		if network.isState == 1 {
-			wifiInterface := strings.TrimRight(string(utf16.Decode(network.strInterfaceDescription[:])), ""\x00"")
-			ssid[wifiInterface] = env.getWiFiSSID(network, phClientHandle)
-		}
-	}
-	return ssid, nil
-}
-
-var (
-	wlanapi             = syscall.NewLazyDLL(""wlanapi.dll"")
-	hWlanOpenHandle     = wlanapi.NewProc(""WlanOpenHandle"")
-	hWlanCloseHandle    = wlanapi.NewProc(""WlanCloseHandle"")
-	hWlanEnumInterfaces = wlanapi.NewProc(""WlanEnumInterfaces"")
-	hWlanQueryInterface = wlanapi.NewProc(""WlanQueryInterface"")
-)
-
-func (env *ShellEnvironment) getWiFiSSID(network *WLAN_INTERFACE_INFO, clientHandle uint32) string {
-	// Query wifi connection state
 	var dataSize uint16
 	var wlanAttr *WLAN_CONNECTION_ATTRIBUTES
-	e, _, _ := hWlanQueryInterface.Call(uintptr(clientHandle),
-		uintptr(unsafe.Pointer(&network.InterfaceGuid)),
+
+	e, _, _ = hWlanQueryInterface.Call(uintptr(phClientHandle),
+		uintptr(unsafe.Pointer(&guid)),
 		uintptr(7), // wlan_intf_opcode_current_connection
 		uintptr(unsafe.Pointer(nil)),
 		uintptr(unsafe.Pointer(&dataSize)),
@@ -389,18 +364,6 @@ func (env *ShellEnvironment) getWiFiSSID(network *WLAN_INTERFACE_INFO, clientHan
 	return string(ssid.ucSSID[0:ssid.uSSIDLength])
 }
 
-type WLAN_INTERFACE_INFO_LIST struct { //nolint: revive
-	dwNumberOfItems uint32
-	dwIndex         uint32 //nolint: unused
-	InterfaceInfo   [256]WLAN_INTERFACE_INFO
-}
-
-type WLAN_INTERFACE_INFO struct { //nolint: revive
-	InterfaceGuid           syscall.GUID //nolint: revive
-	strInterfaceDescription [256]uint16
-	isState                 uint32
-}
-
 type WLAN_CONNECTION_ATTRIBUTES struct { //nolint: revive
 	isState                   uint32      //nolint: unused
 	wlanConnectionMode        uint32      //nolint: unused
",3,"[""a52a585d74894b3b4eeb8c784fa089ff95cddad0"", ""f411e58cd510f8a2b980b2f1932003a0c0e9f8f3"", ""8a9a022baa15befc325f87892c6bdae25b35bc33""]","[""docs"", ""test"", ""refactor""]"
"rename ELECTRON_CACHE env variable to electron_config_cache (#21313) | apply element migrated events

This is a very straightforward event applier. All it needs to do is
update the persisted data for the element instance using the data in the
event. | release for ppc64

closes #3703

Signed-off-by: Carlos A Becker <caarlos0@users.noreply.github.com>","diff --git a/docs/tutorial/installation.md b/docs/tutorial/installation.md
index d4af120..1a09eea 100644
--- a/docs/tutorial/installation.md
+++ b/docs/tutorial/installation.md
@@ -82,7 +82,7 @@ with the network at all.
 On environments that have been using older versions of Electron, you might find the
 cache also in `~/.electron`.
 
-You can also override the local cache location by providing a `ELECTRON_CACHE`
+You can also override the local cache location by providing a `electron_config_cache`
 environment variable.
 
 The cache contains the version's official zip file as well as a checksum, stored as

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/EventAppliers.java b/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/EventAppliers.java
index da05e13..9231df3 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/EventAppliers.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/EventAppliers.java
@@ -154,6 +154,9 @@ public final class EventAppliers implements EventApplier {
     register(
         ProcessInstanceIntent.SEQUENCE_FLOW_TAKEN,
         new ProcessInstanceSequenceFlowTakenApplier(elementInstanceState, processState));
+    register(
+        ProcessInstanceIntent.ELEMENT_MIGRATED,
+        new ProcessInstanceElementMigratedApplier(elementInstanceState));
   }
 
   private void registerProcessInstanceCreationAppliers(final MutableProcessingState state) {
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/ProcessInstanceElementMigratedApplier.java b/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/ProcessInstanceElementMigratedApplier.java
index e5a0f3a..d38358f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/ProcessInstanceElementMigratedApplier.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/ProcessInstanceElementMigratedApplier.java
@@ -24,5 +24,16 @@ final class ProcessInstanceElementMigratedApplier
   }
 
   @Override
-  public void applyState(final long elementInstanceKey, final ProcessInstanceRecord value) {}
+  public void applyState(final long elementInstanceKey, final ProcessInstanceRecord value) {
+    elementInstanceState.updateInstance(
+        elementInstanceKey,
+        elementInstance ->
+            elementInstance
+                .getValue()
+                .setProcessDefinitionKey(value.getProcessDefinitionKey())
+                .setBpmnProcessId(value.getBpmnProcessId())
+                .setVersion(value.getVersion())
+                .setElementId(value.getElementId())
+                .setFlowScopeKey(value.getFlowScopeKey()));
+  }
 }

diff --git a/.goreleaser.yaml b/.goreleaser.yaml
index 46901cb..7d4d355 100644
--- a/.goreleaser.yaml
+++ b/.goreleaser.yaml
@@ -25,6 +25,7 @@ builds:
     - amd64
     - arm
     - arm64
+    - ppc64
   goarm:
     - ""7""
   mod_timestamp: '{{ .CommitTimestamp }}'
",3,"[""f2f52c23b513dd857350f3c163f676d37189d0d3"", ""39d5d1cfe8d2210305df2c8fab4a4ae430732cf7"", ""e27e3a6478d59eb0f93af0a51a9c474bad6f8350""]","[""docs"", ""feat"", ""build""]"
add more tests for Utils.lookupPathFromDecorator,"diff --git a/lib/utils/Utils.ts b/lib/utils/Utils.ts
index 6de6e05..b03b3e9 100644
--- a/lib/utils/Utils.ts
+++ b/lib/utils/Utils.ts
@@ -338,15 +338,8 @@ export class Utils {
       line++;
     }
 
-    if (stack[line].match(/\(.+\)/i)) {
-      meta.path = Utils.normalizePath(
-        stack[line].match(/\((.*):\d+:\d+\)/)![1],
-      );
-    } else {
-      meta.path = Utils.normalizePath(
-        stack[line].match(/at\s*(.*):\d+:\d+$/)![1],
-      );
-    }
+    const re = stack[line].match(/\(.+\)/i) ? /\((.*):\d+:\d+\)/ : /at\s*(.*):\d+:\d+$/;
+    meta.path = Utils.normalizePath(stack[line].match(re)![1]);
 
     return meta.path;
   }
diff --git a/tests/Utils.test.ts b/tests/Utils.test.ts
index c3e9aa1..4d2a209 100644
--- a/tests/Utils.test.ts
+++ b/tests/Utils.test.ts
@@ -256,7 +256,7 @@ describe('Utils', () => {
       '    at Object.__decorate (/usr/local/var/www/my-project/node_modules/tslib/tslib.js:92:96)',
       '    at Object.<anonymous> (/usr/local/var/www/my-project/dist/entities/Customer.js:20:9)',
       '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
-      '    at Object.Module._extensions..js (internal/modules/cjs/loader.js:787:10)',
+      '    at Object.Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
       '    at Module.load (internal/modules/cjs/loader.js:643:32)',
       '    at Function.Module._load (internal/modules/cjs/loader.js:556:12)',
     ];
@@ -272,10 +272,25 @@ describe('Utils', () => {
       '    at Object.<anonymous> (/usr/local/var/www/my-project/src/entities/Customer.ts:9:3)',
       '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
       '    at Module.m._compile (/usr/local/var/www/my-project/node_modules/ts-node/src/index.ts:473:23)',
-      '    at Module._extensions..js (internal/modules/cjs/loader.js:787:10)',
+      '    at Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
       '    at Object.require.extensions.<computed> [as .ts] (/usr/local/var/www/my-project/node_modules/ts-node/src/index.ts:476:12)',
     ];
     expect(Utils.lookupPathFromDecorator({} as any, stack2)).toBe('/usr/local/var/www/my-project/src/entities/Customer.ts');
+
+    // no parens
+    const stack3 = [
+      '    at Function.lookupPathFromDecorator (/usr/local/var/www/my-project/node_modules/mikro-orm/dist/utils/Utils.js:170:23)',
+      '    at /usr/local/var/www/my-project/node_modules/mikro-orm/dist/decorators/PrimaryKey.js:12:23',
+      '    at DecorateProperty (/usr/local/var/www/my-project/node_modules/reflect-metadata/Reflect.js:553:33)',
+      '    at Object.decorate (/usr/local/var/www/my-project/node_modules/reflect-metadata/Reflect.js:123:24)',
+      '    at Object.__decorate (/usr/local/var/www/my-project/node_modules/tslib/tslib.js:92:96)',
+      '    at /usr/local/var/www/my-project/dist/entities/Customer.js:20:9',
+      '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
+      '    at Object.Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
+      '    at Module.load (internal/modules/cjs/loader.js:643:32)',
+      '    at Function.Module._load (internal/modules/cjs/loader.js:556:12)',
+    ];
+    expect(Utils.lookupPathFromDecorator({} as any, stack3)).toBe('/usr/local/var/www/my-project/dist/entities/Customer.js');
   });
 
   test('lookup path from decorator on windows', () => {
@@ -287,7 +302,7 @@ describe('Utils', () => {
       '    at Object.<anonymous> (C:\\www\\my-project\\src\\entities\\Customer.ts:7:5)',
       '    at Module._compile (internal/modules/cjs/loader.js:936:30)',
       '    at Module.m._compile (C:\\www\\my-project\\node_modules\\ts-node\\src\\index.ts:493:23)',
-      '    at Module._extensions..js (internal/modules/cjs/loader.js:947:10)',
+      '    at Module._extensions.js (internal/modules/cjs/loader.js:947:10)',
       '    at Object.require.extensions.<computed> [as .ts] (C:\\www\\my-project\\node_modules\\ts-node\\src\\index.ts:496:12)',
       '    at Module.load (internal/modules/cjs/loader.js:790:32)',
       '    at Function.Module._load (internal/modules/cjs/loader.js:703:12)',
",1,"[""c5e86dbc00a13a355bffadeb2db197e2fea5640f""]","[""test""]"
"add clean up test

Add another clean up test, which verifies that the state is cleaned up
after the timer (non-recurring) is triggered. | update flushed index before truncating | remove git-crypt, switch to sops

Signed-off-by: Andrea Luzzardi <aluzzardi@gmail.com>","diff --git a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
index d36b4c9..ca5047f 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
@@ -630,6 +630,40 @@ public final class ProcessExecutionCleanStateTest {
   }
 
   @Test
+  public void testProcessWithTriggerTimerStartEvent() {
+    // given
+    final var deployment =
+        engineRule
+            .deployment()
+            .withXmlResource(
+                Bpmn.createExecutableProcess(PROCESS_ID)
+                    .startEvent()
+                    .timerWithDate(""=now() + duration(\""PT15S\"")"")
+                    .endEvent()
+                    .done())
+            .deploy();
+
+    final var processDefinitionKey =
+        deployment.getValue().getProcessesMetadata().get(0).getProcessDefinitionKey();
+
+    // when
+    engineRule.awaitProcessingOf(
+        RecordingExporter.timerRecords(TimerIntent.CREATED)
+            .withProcessDefinitionKey(processDefinitionKey)
+            .getFirst());
+
+    engineRule.increaseTime(Duration.ofSeconds(15));
+
+    RecordingExporter.processInstanceRecords(ProcessInstanceIntent.ELEMENT_COMPLETED)
+        .withProcessDefinitionKey(processDefinitionKey)
+        .withElementType(BpmnElementType.PROCESS)
+        .await();
+
+    // then
+    assertThatStateIsEmpty();
+  }
+
+  @Test
   public void testProcessWithTimerStartEventRedeployment() {
     // given
     final var deployment =

diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {

diff --git a/.gitattributes b/.gitattributes
deleted file mode 100644
index 00b39fd..0000000
--- a/.gitattributes
+++ /dev/null
@@ -1,3 +0,0 @@
-*.secret filter=git-crypt diff=git-crypt
-*.key filter=git-crypt diff=git-crypt
-*.secret.* filter=git-crypt diff=git-crypt
diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml
index 8b6209f..47ec885 100644
--- a/.github/workflows/ci.yml
+++ b/.github/workflows/ci.yml
@@ -14,26 +14,31 @@ jobs:
       - name: Check out
         uses: actions/checkout@v2
 
+      - name: Set up Go
+        uses: actions/setup-go@v1
+        with:
+          go-version: 1.16
+
       - name: Install Dependencies
         run: |
-          sudo apt-get update
-          sudo apt-get install -y --no-install-recommends shellcheck git-crypt
-
+          # Cue
           export CUE_VERSION=""$(grep cue ./go.mod | cut -d' ' -f2)""
           export CUE_TARBALL=""cue_${CUE_VERSION}_linux_amd64.tar.gz""
-
           echo ""Installing cue version $CUE_VERSION""
-          curl -sfL https://install.goreleaser.com/github.com/golangci/golangci-lint.sh | sudo sh -s -- -b /usr/local/bin v1.23.8
-
           curl -L https://github.com/cuelang/cue/releases/download/${CUE_VERSION}/${CUE_TARBALL} | sudo tar zxf - -C /usr/local/bin
 
-      - name: Unlock secrets
+          # SOPS
+          sudo curl -L -o /usr/local/bin/sops https://github.com/mozilla/sops/releases/download/v3.6.1/sops-v3.6.1.linux
+          sudo chmod +x /usr/local/bin/sops
+
+          # golangci
+          curl -sfL https://install.goreleaser.com/github.com/golangci/golangci-lint.sh | sudo sh -s -- -b /usr/local/bin v1.23.8
+
+      - name: Import PGP private key
         env:
-          GIT_CRYPT_KEY: ${{ secrets.GIT_CRYPT_KEY }}
+          SOPS_PGP_KEY: ${{ secrets.SOPS_PGP_KEY }}
         run: |
-          echo ""$GIT_CRYPT_KEY"" | base64  -d > /tmp/git-crypt-key
-          git-crypt unlock /tmp/git-crypt-key
-          rm -f /tmp/git-crypt-key
+          echo ""$SOPS_PGP_KEY"" | base64 -d | gpg --import
 
       - name: Login to Docker Hub
         uses: docker/login-action@v1
@@ -41,12 +46,6 @@ jobs:
           username: ${{ secrets.DOCKERHUB_USERNAME }}
           password: ${{ secrets.DOCKERHUB_TOKEN }}
 
-      - name: Set up Go
-        uses: actions/setup-go@v1
-        with:
-          go-version: 1.16
-        id: go
-
       - name: Lint
         run: |
           make lint
diff --git a/tests/test-lib.sh b/tests/test-lib.sh
index 242ee92..4b2858d 100644
--- a/tests/test-lib.sh
+++ b/tests/test-lib.sh
@@ -127,14 +127,18 @@ test::one(){
   return ""$ret""
 }
 
-disable(){
-  logger::warning ""Test \""$2\"" has been disabled.""
-}
+# Similar to test::one, however tests will be skipped if secrets cannot be decrypted
+test::secret(){
+  local inputFile=""$1""
+  shift
 
-secret(){
-  if [ -z ""${DAGGER_SECRETS_LOADED+x}"" ] || [ ""$DAGGER_SECRETS_LOADED"" != ""1"" ]; then
-    logger::warning ""Skip \""$2\"": secrets not available""
+  if sops exec-file ""$inputFile"" echo  > /dev/null 2>&1; then
+    test::one ""$@"" --input-yaml ""$inputFile""
   else
-    ""$@""
+    logger::warning ""Skip \""$1\"": secrets not available""
   fi
 }
+
+disable(){
+  logger::warning ""Test \""$2\"" has been disabled.""
+}
diff --git a/tests/test.secret b/tests/test.secret
deleted file mode 100644
index 17fca19..0000000
Binary files a/tests/test.secret and /dev/null differ
diff --git a/tests/test.sh b/tests/test.sh
index ce5d936..3f54136 100755
--- a/tests/test.sh
+++ b/tests/test.sh
@@ -6,11 +6,6 @@ readonly d=$(cd ""$(dirname ""${BASH_SOURCE[0]:-$PWD}"")"" 2>/dev/null 1>&2 && pwd)
 # shellcheck source=/dev/null
 . ""$d/test-lib.sh""
 
-# shellcheck source=/dev/null
-if grep -q ""DAGGER_SECRETS"" ""$d/test.secret""; then
-    source ""$d/test.secret""
-fi
-
 # Point this to your dagger binary
 readonly DAGGER_BINARY=""${DAGGER_BINARY:-$d/../cmd/dagger/dagger}""
 # The default arguments are a no-op, but having ""anything"" is a little cheat necessary for ""${DAGGER_BINARY_ARGS[@]}"" to not be empty down there
",3,"[""aa746b764e6c54bbbd631210fce35df842d09b12"", ""933ab6bb86372913c992567cf9660009900911a7"", ""87d576e936e234d0429ad753267a2760c5dfd314""]","[""test"", ""fix"", ""cicd""]"
added vue3 readme,"diff --git a/core/main/README.md b/core/main/README.md
index e5e4c93..e9cfda9 100644
--- a/core/main/README.md
+++ b/core/main/README.md
@@ -217,7 +217,7 @@ You can find the instructions [here](https://github.com/matteobruni/tsparticles/
 
 You can find the instructions [here](https://github.com/matteobruni/tsparticles/blob/master/components/svelte/README.md)
 
-### VueJS
+### VueJS 2.x
 
 #### `particles.vue`
 
@@ -225,6 +225,14 @@ You can find the instructions [here](https://github.com/matteobruni/tsparticles/
 
 You can find the instructions [here](https://github.com/matteobruni/tsparticles/blob/master/components/vue/README.md)
 
+### VueJS 3.x
+
+#### `particles.vue3`
+
+[![npm](https://img.shields.io/npm/v/particles.vue3)](https://www.npmjs.com/package/particles.vue3) [![npm](https://img.shields.io/npm/dm/particles.vue3)](https://www.npmjs.com/package/particles.vue3)
+
+You can find the instructions [here](https://github.com/matteobruni/tsparticles/blob/master/components/vue3/README.md)
+
 ---
 
 ## **_Demo / Generator_**
diff --git a/core/main/tsconfig.json b/core/main/tsconfig.json
index 7916bc5..72399c0 100644
--- a/core/main/tsconfig.json
+++ b/core/main/tsconfig.json
@@ -107,10 +107,14 @@
               ""source"": ""../../components/react/README.md""
             },
             {
-              ""title"": ""Vue"",
+              ""title"": ""Vue 2.x"",
               ""source"": ""../../components/vue/README.md""
             },
             {
+              ""title"": ""Vue 3.x"",
+              ""source"": ""../../components/vue3/README.md""
+            },
+            {
               ""title"": ""Svelte"",
               ""source"": ""../../components/svelte/README.md""
             },
",1,"[""e4c3e2cff769ce46d22d5c8f7dd527510443a8a7""]","[""docs""]"
"add test for spurious cross join | use `regexp_instr != 0` instead of `REGEXP` keyword | remove deprecated settings

Removes deprecated ZEEBE_HOST environment variable, and removes
unnecessary log level environment variable, since it's already the
default in the log file","diff --git a/ibis/tests/sql/test_sqlalchemy.py b/ibis/tests/sql/test_sqlalchemy.py
index 4ad32a6..b2e5d72 100644
--- a/ibis/tests/sql/test_sqlalchemy.py
+++ b/ibis/tests/sql/test_sqlalchemy.py
@@ -841,3 +841,63 @@ def test_filter_group_by_agg_with_same_name():
     )
     ex = sa.select([t0]).where(t0.c.bigint_col == 60)
     _check(expr, ex)
+
+
+@pytest.fixture
+def person():
+    return ibis.table(
+        dict(id=""string"", personal=""string"", family=""string""),
+        name=""person"",
+    )
+
+
+@pytest.fixture
+def visited():
+    return ibis.table(
+        dict(id=""int32"", site=""string"", dated=""string""),
+        name=""visited"",
+    )
+
+
+@pytest.fixture
+def survey():
+    return ibis.table(
+        dict(
+            taken=""int32"",
+            person=""string"",
+            quant=""string"",
+            reading=""float32"",
+        ),
+        name=""survey"",
+    )
+
+
+def test_no_cross_join(person, visited, survey):
+    expr = person.join(survey, person.id == survey.person).join(
+        visited,
+        visited.id == survey.taken,
+    )
+
+    context = AlchemyContext(compiler=AlchemyCompiler)
+    _ = AlchemyCompiler.to_sql(expr, context)
+
+    t0 = context.get_ref(person)
+    t1 = context.get_ref(survey)
+    t2 = context.get_ref(visited)
+
+    from_ = t0.join(t1, t0.c.id == t1.c.person).join(t2, t2.c.id == t1.c.taken)
+    ex = sa.select(
+        [
+            t0.c.id.label(""id_x""),
+            t0.c.personal,
+            t0.c.family,
+            t1.c.taken,
+            t1.c.person,
+            t1.c.quant,
+            t1.c.reading,
+            t2.c.id.label(""id_y""),
+            t2.c.site,
+            t2.c.dated,
+        ]
+    ).select_from(from_)
+    _check(expr, ex)

diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(

diff --git a/Dockerfile b/Dockerfile
index 6762a39..7f380cd 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -34,7 +34,6 @@ RUN wget -O - https://github.com/jvm-profiling-tools/async-profiler/releases/dow
 FROM ${APP_ENV} as app
 
 ENV ZB_HOME=/usr/local/zeebe \
-    ZEEBE_LOG_LEVEL=info \
     ZEEBE_BROKER_GATEWAY_NETWORK_HOST=0.0.0.0 \
     ZEEBE_STANDALONE_GATEWAY=false
 ENV PATH ""${ZB_HOME}/bin:${PATH}""
diff --git a/docker/utils/startup.sh b/docker/utils/startup.sh
index bc8d2fc..0fcde2b 100755
--- a/docker/utils/startup.sh
+++ b/docker/utils/startup.sh
@@ -1,17 +1,14 @@
 #!/bin/bash -xeu
 
-# legacy support
-# This environment variable was used to set the gatewway cluster host in standalone and embedded mode.
-# Now, there are two dedicated environment variables for the two different deployment scenarios.
-export ZEEBE_HOST=${ZEEBE_HOST:-$(hostname -i)}
-# Legacy support
+HOST=$(hostname -i)
 
 if [ ""$ZEEBE_STANDALONE_GATEWAY"" = ""true"" ]; then
-    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_GATEWAY_NETWORK_HOST=${ZEEBE_GATEWAY_NETWORK_HOST:-${HOST}}
+    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${HOST}}
 
     exec /usr/local/zeebe/bin/gateway
 else
-    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${HOST}}
     export ZEEBE_BROKER_GATEWAY_CLUSTER_HOST=${ZEEBE_BROKER_GATEWAY_CLUSTER_HOST:-${ZEEBE_BROKER_NETWORK_HOST}}
 
     exec /usr/local/zeebe/bin/broker
",3,"[""8dac3fe5a7a56356ca95547fcf7925bec8d9c1dd"", ""06e2be4e2019b6fa714e1fcb34485860ef1ede79"", ""e4a11fd5c34942ba12737f1c8c084489428ee274""]","[""test"", ""fix"", ""build""]"
"permission check | move group logical op outside

Signed-off-by: Pranav C <pranavxc@gmail.com>","diff --git a/server/src/routes/course/index.ts b/server/src/routes/course/index.ts
index 557f5fb..bc0e490 100644
--- a/server/src/routes/course/index.ts
+++ b/server/src/routes/course/index.ts
@@ -209,7 +209,7 @@ function addStudentApi(router: Router, logger: ILogger) {
   router.post('/student/:githubId/status', ...mentorValidators, updateStudentStatus(logger));
   router.post('/student/:githubId/status-self', courseGuard, selfUpdateStudentStatus(logger));
   router.get('/student/:githubId/score', courseGuard, getScoreByStudent(logger));
-  router.post('/student/:githubId/certificate', courseManagerGuard, ...validators, postStudentCertificate(logger));
+  router.post('/student/:githubId/certificate', courseManagerGuard, validateGithubId, postStudentCertificate(logger));
 
   router.get('/students', courseSupervisorGuard, getStudents(logger));
   router.get('/students/csv', courseSupervisorGuard, getStudentsCsv(logger));

diff --git a/packages/nc-gui/components/project/spreadsheet/components/ColumnFilter.vue b/packages/nc-gui/components/project/spreadsheet/components/ColumnFilter.vue
index 5138589..f756981 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/ColumnFilter.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/ColumnFilter.vue
@@ -2,40 +2,46 @@
   <div
     class=""backgroundColor pa-2 menu-filter-dropdown""
     :class=""{ nested }""
-    :style=""{ width: nested ? '100%' : '530px' }""
+    :style=""{ width: nested ? '100%' : '630px' }""
   >
     <div class=""grid"" @click.stop>
       <template v-for=""(filter, i) in filters"" dense>
         <template v-if=""filter.status !== 'delete'"">
-          <div v-if=""filter.is_group"" :key=""i"" style=""grid-column: span 5; padding: 6px"" class=""elevation-4"">
-            <div class=""d-flex"" style=""gap: 6px; padding: 0 6px"">
-              <v-icon
-                v-if=""!filter.readOnly""
-                small
-                class=""nc-filter-item-remove-btn""
-                @click.stop=""deleteFilter(filter, i)""
-              >
-                mdi-close-box
-              </v-icon>
-              <span v-if=""!i"" class=""caption d-flex align-center"">{{ $t('labels.where') }}</span>
-              <v-select
-                v-else
-                v-model=""filter.logical_op""
-                class=""flex-shrink-1 flex-grow-0 elevation-0 caption""
-                :items=""['and', 'or']""
-                solo
-                flat
-                dense
-                hide-details
-                placeholder=""Group op""
-                @click.stop
-                @change=""saveOrUpdate(filter, i)""
-              >
-                <template #item=""{ item }"">
-                  <span class=""caption font-weight-regular"">{{ item }}</span>
-                </template>
-              </v-select>
-            </div>
+          <template v-if=""filter.is_group"">
+            <v-icon
+              v-if=""!filter.readOnly""
+              small
+              class=""nc-filter-item-remove-btn""
+              @click.stop=""deleteFilter(filter, i)""
+              :key=""i + '_1'""
+            >
+              mdi-close-box
+            </v-icon>
+            <span v-else :key=""i + '_1'"" />
+
+            <span :key=""i + '_2'"" v-if=""!i"" class=""caption d-flex align-center"">{{ $t('labels.where') }}</span>
+            <v-select
+              v-else
+              :key=""i + '_2'""
+              v-model=""filter.logical_op""
+              class=""flex-shrink-1 flex-grow-0 elevation-0 caption""
+              :items=""['and', 'or']""
+              solo
+              flat
+              dense
+              hide-details
+              placeholder=""Group op""
+              @click.stop
+              @change=""saveOrUpdate(filter, i)""
+            >
+              <template #item=""{ item }"">
+                <span class=""caption font-weight-regular"">{{ item }}</span>
+              </template>
+            </v-select>
+            <span :key=""i + '_3'"" style=""grid-column: span 3""></span>
+          </template>
+
+          <div v-if=""filter.is_group"" :key=""i + '_4'"" style=""grid-column: span 5; padding: 6px"" class=""elevation-4"">
             <column-filter
               v-if=""filter.id || shared""
               ref=""nestedFilter""
@@ -54,19 +60,19 @@
           <template v-else>
             <v-icon
               v-if=""!filter.readOnly""
-              :key=""i + '_1'""
+              :key=""i + '_5'""
               small
               class=""nc-filter-item-remove-btn""
               @click.stop=""deleteFilter(filter, i)""
             >
               mdi-close-box
             </v-icon>
-            <span v-else :key=""i + '_1'"" />
-            <span v-if=""!i"" :key=""i + '_2'"" class=""caption d-flex align-center"">{{ $t('labels.where') }}</span>
+            <span v-else :key=""i + '_5'"" />
+            <span v-if=""!i"" :key=""i + '_6'"" class=""caption d-flex align-center"">{{ $t('labels.where') }}</span>
 
             <v-select
               v-else
-              :key=""i + '_2'""
+              :key=""i + '_6'""
               v-model=""filter.logical_op""
               class=""flex-shrink-1 flex-grow-0 elevation-0 caption""
               :items=""['and', 'or']""
@@ -84,7 +90,7 @@
             </v-select>
 
             <field-list-auto-complete-dropdown
-              :key=""i + '_3'""
+              :key=""i + '_7'""
               v-model=""filter.fk_column_id""
               class=""caption nc-filter-field-select""
               :columns=""columns""
@@ -94,7 +100,7 @@
             />
 
             <v-select
-              :key=""i + '_4'""
+              :key=""i + '_8'""
               v-model=""filter.comparison_op""
               class=""flex-shrink-1 flex-grow-0 caption nc-filter-operation-select""
               :items=""filterComparisonOp(filter)""
@@ -114,11 +120,11 @@
                 <span class=""caption font-weight-regular"">{{ item.text }}</span>
               </template>
             </v-select>
-            <span v-else :key=""i + '_4'""></span>
+            <span v-else :key=""i + '_8'""></span>
             <span v-if=""['null', 'notnull', 'empty', 'notempty'].includes(filter.comparison_op)"" :key=""i + '_5'"" />
             <v-checkbox
               v-else-if=""types[filter.field] === 'boolean'""
-              :key=""i + '_5'""
+              :key=""i + '_9'""
               v-model=""filter.value""
               dense
               :disabled=""filter.readOnly""
@@ -126,7 +132,7 @@
             />
             <v-text-field
               v-else-if=""filter && filter.fk_column_id""
-              :key=""i + '_5'""
+              :key=""i + '_9'""
               v-model=""filter.value""
               solo
               flat
@@ -137,7 +143,7 @@
               @click.stop
               @input=""saveOrUpdate(filter, i)""
             />
-            <span v-else :key=""i + '_5'""></span>
+            <span v-else :key=""i + '_9'""></span>
           </template>
         </template>
       </template>
@@ -411,6 +417,7 @@ export default {
         parentId: this.parentId,
         is_group: true,
         status: 'update',
+        logical_op: 'and',
       });
       this.filters = this.filters.slice();
       const index = this.filters.length - 1;
@@ -478,4 +485,8 @@ export default {
   column-gap: 6px;
   row-gap: 6px;
 }
+
+.nc-filter-value-select {
+  min-width: 100px;
+}
 </style>
",2,"[""33c25b2f59c931a7f4af994365522221a7821dca"", ""4f86f2570b274c45605cc59d9adb38f7ed30cd17""]","[""fix"", ""refactor""]"
"set cursor position in setHorizontalRule correctly, fix #2429 | fix `get-deploy-tags.sh`","diff --git a/packages/extension-horizontal-rule/src/horizontal-rule.ts b/packages/extension-horizontal-rule/src/horizontal-rule.ts
index 6f583e1..c905b63 100644
--- a/packages/extension-horizontal-rule/src/horizontal-rule.ts
+++ b/packages/extension-horizontal-rule/src/horizontal-rule.ts
@@ -49,15 +49,14 @@ export const HorizontalRule = Node.create<HorizontalRuleOptions>({
           // set cursor after horizontal rule
           .command(({ tr, dispatch }) => {
             if (dispatch) {
-              const { parent, pos } = tr.selection.$from
-              const posAfter = pos + 1
-              const nodeAfter = tr.doc.nodeAt(posAfter)
+              const { $to } = tr.selection
+              const posAfter = $to.end()
 
-              if (nodeAfter) {
-                tr.setSelection(TextSelection.create(tr.doc, posAfter))
+              if ($to.nodeAfter) {
+                tr.setSelection(TextSelection.create(tr.doc, $to.pos))
               } else {
                 // add node after horizontal rule if its the end of the document
-                const node = parent.type.contentMatch.defaultType?.create()
+                const node = $to.parent.type.contentMatch.defaultType?.create()
 
                 if (node) {
                   tr.insert(posAfter, node)

diff --git a/.circleci/get-deploy-tags.sh b/.circleci/get-deploy-tags.sh
index f80c8cb..7ddfa62 100755
--- a/.circleci/get-deploy-tags.sh
+++ b/.circleci/get-deploy-tags.sh
@@ -20,7 +20,7 @@
 set -euo pipefail
 
 DOCKER_IMAGE_TAG=${1}
-DOCKER_IMAGE=""quay.io/influxdb/fusion""
+DOCKER_IMAGE=""quay.io/influxdb/iox""
 APP_NAME=""IOx""
 
 DOCKER_IMAGE_DIGEST=""$(docker image inspect ""${DOCKER_IMAGE}:${DOCKER_IMAGE_TAG}"" --format '{{ if eq (len .RepoDigests) 1 }}{{index .RepoDigests 0}}{{ end }}')""
",2,"[""34d80114704679118e9bb6058e0d6c7aa03fd4b5"", ""6786fd5955b064021f5b6d6a630453351d683fae""]","[""fix"", ""cicd""]"
fixed start types for size and opacity,"diff --git a/core/main/src/Core/Particle.ts b/core/main/src/Core/Particle.ts
index 1aa6fba..6ea6ffc 100644
--- a/core/main/src/Core/Particle.ts
+++ b/core/main/src/Core/Particle.ts
@@ -271,7 +271,7 @@ export class Particle implements IParticle {
             }
         }
 
-        const sizeAnimation = this.options.size.animation;
+        const sizeAnimation = sizeOptions.animation;
 
         if (sizeAnimation.enable) {
             this.size.status = AnimationStatus.increasing;
@@ -279,7 +279,8 @@ export class Particle implements IParticle {
             if (!randomSize) {
                 switch (sizeAnimation.startValue) {
                     case StartValueType.min:
-                        this.size.value = sizeAnimation.minimumValue * pxRatio;
+                        this.size.value = NumberUtils.getRangeMin(sizeOptions.value) * pxRatio;
+                        this.size.status = AnimationStatus.increasing;
 
                         break;
 
@@ -287,11 +288,14 @@ export class Particle implements IParticle {
                         this.size.value = NumberUtils.randomInRange(
                             NumberUtils.setRangeValue(sizeAnimation.minimumValue * pxRatio, this.size.value)
                         );
+                        this.size.status =
+                            Math.random() >= 0.5 ? AnimationStatus.increasing : AnimationStatus.decreasing;
 
                         break;
 
                     case StartValueType.max:
                     default:
+                        this.size.value = NumberUtils.getRangeMax(sizeOptions.value) * pxRatio;
                         this.size.status = AnimationStatus.decreasing;
 
                         break;
@@ -393,7 +397,8 @@ export class Particle implements IParticle {
             if (!randomOpacity) {
                 switch (opacityAnimation.startValue) {
                     case StartValueType.min:
-                        this.opacity.value = opacityAnimation.minimumValue;
+                        this.opacity.value = NumberUtils.getRangeMin(this.opacity.value);
+                        this.opacity.status = AnimationStatus.increasing;
 
                         break;
 
@@ -401,11 +406,14 @@ export class Particle implements IParticle {
                         this.opacity.value = NumberUtils.randomInRange(
                             NumberUtils.setRangeValue(opacityAnimation.minimumValue, this.opacity.value)
                         );
+                        this.opacity.status =
+                            Math.random() >= 0.5 ? AnimationStatus.increasing : AnimationStatus.decreasing;
 
                         break;
 
                     case StartValueType.max:
                     default:
+                        this.opacity.value = NumberUtils.getRangeMax(this.opacity.value);
                         this.opacity.status = AnimationStatus.decreasing;
 
                         break;
diff --git a/presets/confetti/src/options.ts b/presets/confetti/src/options.ts
index 7fc6225..a713425 100644
--- a/presets/confetti/src/options.ts
+++ b/presets/confetti/src/options.ts
@@ -28,7 +28,7 @@ export const loadOptions = (confettiOptions: RecursivePartial<IConfettiOptions>)
                 animation: {
                     enable: true,
                     minimumValue: 0,
-                    speed: 2,
+                    speed: 0.5,
                     startValue: ""max"",
                     destroy: ""min"",
                 },
",1,"[""06960183db42cba1b1f1a8077660ba8c801c9e18""]","[""fix""]"
"change notice from 'danger' > 'info'

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com> | import flux-lsp v0.5.21 | add test case with multiple partitions for message","diff --git a/packages/noco-docs/docs/030.workspaces/040.actions-on-workspace.md b/packages/noco-docs/docs/030.workspaces/040.actions-on-workspace.md
index 17a1d85..b8c3f52 100644
--- a/packages/noco-docs/docs/030.workspaces/040.actions-on-workspace.md
+++ b/packages/noco-docs/docs/030.workspaces/040.actions-on-workspace.md
@@ -20,7 +20,7 @@ To update the workspace name:
 ## Delete workspace
 If you determine that a workspace is no longer necessary, you have the option to permanently remove it from your settings. Deleting a workspace will delete all the bases and data associated with it.
 
-:::danger
+:::info
 **This action cannot be undone.**
 :::
 
diff --git a/packages/noco-docs/docs/040.bases/070.actions-on-base.md b/packages/noco-docs/docs/040.bases/070.actions-on-base.md
index b8e5723..7207971 100644
--- a/packages/noco-docs/docs/040.bases/070.actions-on-base.md
+++ b/packages/noco-docs/docs/040.bases/070.actions-on-base.md
@@ -69,7 +69,7 @@ To duplicate a base, you can follow these straightforward steps:
 
 If you determine that a base is no longer necessary, you have the option to permanently remove it from your workspace. Deleting a base will delete all the tables and data associated with it.
 
-:::danger
+:::info
 **This action cannot be undone.**
 :::
 
diff --git a/packages/noco-docs/docs/050.tables/060.actions-on-table.md b/packages/noco-docs/docs/050.tables/060.actions-on-table.md
index 3cf03d3..8ae9ade 100644
--- a/packages/noco-docs/docs/050.tables/060.actions-on-table.md
+++ b/packages/noco-docs/docs/050.tables/060.actions-on-table.md
@@ -46,7 +46,7 @@ A new table will be generated, mirroring the original table's schema and content
 
 ## Delete table
 
-:::danger
+:::info
 **This action cannot be undone.**
 :::
 
diff --git a/packages/noco-docs/docs/070.fields/060.actions-on-field.md b/packages/noco-docs/docs/070.fields/060.actions-on-field.md
index 600c6fd..fe2cfa8 100644
--- a/packages/noco-docs/docs/070.fields/060.actions-on-field.md
+++ b/packages/noco-docs/docs/070.fields/060.actions-on-field.md
@@ -83,7 +83,7 @@ New field will be created to the right of the original field.
 New field will be created to the left of the original field.
 
 ### Delete field
-:::danger
+:::info
 **This action cannot be undone.**
 :::
 
diff --git a/packages/noco-docs/docs/080.records/070.actions-on-record.md b/packages/noco-docs/docs/080.records/070.actions-on-record.md
index a9245ff..6d4774a 100644
--- a/packages/noco-docs/docs/080.records/070.actions-on-record.md
+++ b/packages/noco-docs/docs/080.records/070.actions-on-record.md
@@ -54,8 +54,8 @@ On the bulk update modal,
 5. Click on the `Bulk Update all` button
 6. A confirmation dialog will be displayed. Click on `Confirm` to update the records.
 
-:::danger
-This operation cannot be undone.
+:::info
+**This action cannot be undone.**
 :::
 
 ![Bulk Update](/img/v2/records/bulk-update-1.png)
diff --git a/packages/noco-docs/docs/090.views/090.actions-on-view.md b/packages/noco-docs/docs/090.views/090.actions-on-view.md
index c6c6ab2..7d23959 100644
--- a/packages/noco-docs/docs/090.views/090.actions-on-view.md
+++ b/packages/noco-docs/docs/090.views/090.actions-on-view.md
@@ -41,7 +41,7 @@ The view context menu provides a set of tools to interact with the view. The vie
 
 ## Delete view
 
-:::danger
+:::info
 **This action cannot be undone.**
 :::
 

diff --git a/ui/package.json b/ui/package.json
index 7a44aad..a36fc3d 100644
--- a/ui/package.json
+++ b/ui/package.json
@@ -134,7 +134,7 @@
   ""dependencies"": {
     ""@influxdata/clockface"": ""2.3.4"",
     ""@influxdata/flux"": ""^0.5.1"",
-    ""@influxdata/flux-lsp-browser"": ""0.5.20"",
+    ""@influxdata/flux-lsp-browser"": ""0.5.21"",
     ""@influxdata/giraffe"": ""0.29.0"",
     ""@influxdata/influx"": ""0.5.5"",
     ""@influxdata/influxdb-templates"": ""0.9.0"",
diff --git a/ui/yarn.lock b/ui/yarn.lock
index 99ae766..e6e2a47 100644
--- a/ui/yarn.lock
+++ b/ui/yarn.lock
@@ -752,10 +752,10 @@
   resolved ""https://registry.yarnpkg.com/@influxdata/clockface/-/clockface-2.3.4.tgz#9c496601253e1d49cbeae29a7b9cfb54862785f6""
   integrity sha512-mmz3YElK8Ho+1onEafuas6sVhIT638JA4NbDTO3bVJgK1TG7AnU4rQP+c6fj7vZSfvrIwtOwGaMONJTaww5o6w==
 
-""@influxdata/flux-lsp-browser@0.5.20"":
-  version ""0.5.20""
-  resolved ""https://registry.yarnpkg.com/@influxdata/flux-lsp-browser/-/flux-lsp-browser-0.5.20.tgz#150d261bab869e130f6d00ee73ea4e859e8969e4""
-  integrity sha512-gUy19t/QndkJPmyv7Lb56zXxaW5v7R9TslTHt0hB0GJjo7lmYkRfkD7DELdFHrD2e/CLtcNQBnczIMIGkII8Bw==
+""@influxdata/flux-lsp-browser@0.5.21"":
+  version ""0.5.21""
+  resolved ""https://registry.yarnpkg.com/@influxdata/flux-lsp-browser/-/flux-lsp-browser-0.5.21.tgz#d5632f45e925c09bae9501a00fbef2ed55567f9e""
+  integrity sha512-lcUwKX1yj0QqGiusQFOVi7UPsvp6+qNX7Cwf9qqS5/dRwoh7c++nFVRdGNrSWlsbyRrPaAWBoZWEnghSnIf6DQ==
 
 ""@influxdata/flux@^0.5.1"":
   version ""0.5.1""

diff --git a/broker-core/src/main/java/io/zeebe/broker/subscription/command/SubscriptionCommandSender.java b/broker-core/src/main/java/io/zeebe/broker/subscription/command/SubscriptionCommandSender.java
index 693d1da..e3552d4 100644
--- a/broker-core/src/main/java/io/zeebe/broker/subscription/command/SubscriptionCommandSender.java
+++ b/broker-core/src/main/java/io/zeebe/broker/subscription/command/SubscriptionCommandSender.java
@@ -74,7 +74,7 @@ public class SubscriptionCommandSender {
       new CloseWorkflowInstanceSubscriptionCommand();
 
   private final ClientTransport subscriptionClient;
-  private final IntArrayList partitionIds;
+  private final IntArrayList partitionIds = new IntArrayList();
 
   private int partitionId;
   private TopologyPartitionListenerImpl partitionListener;
@@ -82,7 +82,6 @@ public class SubscriptionCommandSender {
   public SubscriptionCommandSender(
       final ClusterCfg clusterCfg, final ClientTransport subscriptionClient) {
     this.subscriptionClient = subscriptionClient;
-    partitionIds = new IntArrayList();
     partitionIds.addAll(clusterCfg.getPartitionIds());
   }
 
@@ -100,7 +99,8 @@ public class SubscriptionCommandSender {
       final DirectBuffer messageName,
       final DirectBuffer correlationKey) {
 
-    final int subscriptionPartitionId = getSubscriptionPartitionId(correlationKey);
+    final int subscriptionPartitionId =
+        SubscriptionUtil.getSubscriptionPartitionId(correlationKey, partitionIds.size());
 
     openMessageSubscriptionCommand.setSubscriptionPartitionId(subscriptionPartitionId);
     openMessageSubscriptionCommand.setWorkflowInstanceKey(workflowInstanceKey);
@@ -111,14 +111,6 @@ public class SubscriptionCommandSender {
     return sendSubscriptionCommand(subscriptionPartitionId, openMessageSubscriptionCommand);
   }
 
-  private int getSubscriptionPartitionId(final DirectBuffer correlationKey) {
-    if (partitionIds == null) {
-      throw new IllegalStateException(""no partition ids available"");
-    }
-
-    return SubscriptionUtil.getSubscriptionPartitionId(correlationKey, partitionIds.size());
-  }
-
   public boolean openWorkflowInstanceSubscription(
       final long workflowInstanceKey,
       final long elementInstanceKey,
diff --git a/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCatchElementTest.java b/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCatchElementTest.java
index 4baed4f..838c9ca 100644
--- a/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCatchElementTest.java
+++ b/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCatchElementTest.java
@@ -36,7 +36,6 @@ import io.zeebe.model.bpmn.Bpmn;
 import io.zeebe.model.bpmn.BpmnModelInstance;
 import io.zeebe.protocol.clientapi.RecordType;
 import io.zeebe.protocol.clientapi.ValueType;
-import io.zeebe.protocol.impl.SubscriptionUtil;
 import io.zeebe.protocol.intent.DeploymentIntent;
 import io.zeebe.protocol.intent.MessageSubscriptionIntent;
 import io.zeebe.protocol.intent.WorkflowInstanceIntent;
@@ -44,7 +43,6 @@ import io.zeebe.protocol.intent.WorkflowInstanceSubscriptionIntent;
 import io.zeebe.test.broker.protocol.clientapi.ClientApiRule;
 import io.zeebe.test.broker.protocol.clientapi.PartitionTestClient;
 import io.zeebe.test.util.record.RecordingExporter;
-import io.zeebe.util.buffer.BufferUtil;
 import java.util.List;
 import java.util.stream.Collectors;
 import org.agrona.DirectBuffer;
@@ -171,39 +169,6 @@ public class MessageCatchElementTest {
   }
 
   @Test
-  public void shouldOpenMessageSubscriptionsOnSamePartition() {
-    // given
-    final List<Integer> partitionIds = apiRule.getPartitionIds();
-
-    final String correlationKey = ""order-123"";
-
-    final PartitionTestClient workflowPartition = apiRule.partitionClient(partitionIds.get(0));
-    final PartitionTestClient subscriptionPartition =
-        apiRule.partitionClient(getPartitionId(correlationKey));
-
-    testClient.deploy(CATCH_EVENT_WORKFLOW);
-
-    // when
-    final long workflowInstanceKey1 =
-        workflowPartition.createWorkflowInstance(PROCESS_ID, asMsgPack(""orderId"", correlationKey));
-
-    final long workflowInstanceKey2 =
-        workflowPartition.createWorkflowInstance(PROCESS_ID, asMsgPack(""orderId"", correlationKey));
-
-    // then
-    final List<Record<MessageSubscriptionRecordValue>> subscriptions =
-        subscriptionPartition
-            .receiveMessageSubscriptions()
-            .withIntent(MessageSubscriptionIntent.OPENED)
-            .limit(2)
-            .collect(Collectors.toList());
-
-    assertThat(subscriptions)
-        .extracting(s -> s.getValue().getWorkflowInstanceKey())
-        .contains(workflowInstanceKey1, workflowInstanceKey2);
-  }
-
-  @Test
   public void shouldOpenWorkflowInstanceSubscription() {
     final long workflowInstanceKey =
         testClient.createWorkflowInstance(PROCESS_ID, asMsgPack(""orderId"", ""order-123""));
@@ -352,10 +317,4 @@ public class MessageCatchElementTest {
                 .exists())
         .isTrue();
   }
-
-  private int getPartitionId(final String correlationKey) {
-    final List<Integer> partitionIds = apiRule.getPartitionIds();
-    return SubscriptionUtil.getSubscriptionPartitionId(
-        BufferUtil.wrapString(correlationKey), partitionIds.size());
-  }
 }
diff --git a/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCorrelationMultiplePartitionsTest.java b/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCorrelationMultiplePartitionsTest.java
new file mode 100644
index 0000000..cf8261a
--- /dev/null
+++ b/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCorrelationMultiplePartitionsTest.java
@@ -0,0 +1,134 @@
+/*
+ * Zeebe Broker Core
+ * Copyright  2017 camunda services GmbH (info@camunda.com)
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+package io.zeebe.broker.workflow.message;
+
+import static io.zeebe.broker.test.EmbeddedBrokerConfigurator.setPartitionCount;
+import static io.zeebe.test.util.MsgPackUtil.asMsgPack;
+import static org.assertj.core.api.Assertions.assertThat;
+import static org.assertj.core.api.Assertions.tuple;
+
+import io.zeebe.broker.test.EmbeddedBrokerRule;
+import io.zeebe.model.bpmn.Bpmn;
+import io.zeebe.model.bpmn.BpmnModelInstance;
+import io.zeebe.protocol.impl.SubscriptionUtil;
+import io.zeebe.protocol.intent.MessageSubscriptionIntent;
+import io.zeebe.protocol.intent.WorkflowInstanceIntent;
+import io.zeebe.test.broker.protocol.clientapi.ClientApiRule;
+import io.zeebe.test.broker.protocol.clientapi.PartitionTestClient;
+import io.zeebe.test.util.record.RecordingExporter;
+import io.zeebe.util.buffer.BufferUtil;
+import java.util.List;
+import java.util.stream.IntStream;
+import org.junit.Before;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.RuleChain;
+
+public class MessageCorrelationMultiplePartitionsTest {
+
+  private static final String CORRELATION_KEY_PARTITION_0 = ""item-2"";
+  private static final String CORRELATION_KEY_PARTITION_1 = ""item-1"";
+  private static final String CORRELATION_KEY_PARTITION_2 = ""item-0"";
+
+  private static final String PROCESS_ID = ""process"";
+
+  private static final BpmnModelInstance WORKFLOW =
+      Bpmn.createExecutableProcess(PROCESS_ID)
+          .startEvent()
+          .intermediateCatchEvent(""receive-message"")
+          .message(m -> m.name(""message"").zeebeCorrelationKey(""$.key""))
+          .endEvent(""end"")
+          .done();
+
+  public EmbeddedBrokerRule brokerRule = new EmbeddedBrokerRule(setPartitionCount(3));
+
+  public ClientApiRule apiRule = new ClientApiRule(brokerRule::getClientAddress);
+
+  @Rule public RuleChain ruleChain = RuleChain.outerRule(brokerRule).around(apiRule);
+
+  private PartitionTestClient testClient;
+
+  @Before
+  public void init() {
+    assertThat(getPartitionId(CORRELATION_KEY_PARTITION_0)).isEqualTo(0);
+    assertThat(getPartitionId(CORRELATION_KEY_PARTITION_1)).isEqualTo(1);
+    assertThat(getPartitionId(CORRELATION_KEY_PARTITION_2)).isEqualTo(2);
+
+    testClient = apiRule.partitionClient();
+
+    testClient.deploy(WORKFLOW);
+  }
+
+  @Test
+  public void shouldOpenMessageSubscriptionsOnDifferentPartitions() {
+    // when
+    IntStream.range(0, 10)
+        .forEach(
+            i -> {
+              testClient.createWorkflowInstance(
+                  PROCESS_ID, asMsgPack(""key"", CORRELATION_KEY_PARTITION_0));
+              testClient.createWorkflowInstance(
+                  PROCESS_ID, asMsgPack(""key"", CORRELATION_KEY_PARTITION_1));
+              testClient.createWorkflowInstance(
+                  PROCESS_ID, asMsgPack(""key"", CORRELATION_KEY_PARTITION_2));
+            });
+
+    // then
+    assertThat(
+            RecordingExporter.messageSubscriptionRecords(MessageSubscriptionIntent.OPENED)
+                .limit(30))
+        .extracting(r -> tuple(r.getMetadata().getPartitionId(), r.getValue().getCorrelationKey()))
+        .containsOnly(
+            tuple(0, CORRELATION_KEY_PARTITION_0),
+            tuple(1, CORRELATION_KEY_PARTITION_1),
+            tuple(2, CORRELATION_KEY_PARTITION_2));
+  }
+
+  @Test
+  public void shouldCorrelateMessageOnDifferentPartitions() {
+    // given
+    apiRule
+        .partitionClient(0)
+        .publishMessage(""message"", CORRELATION_KEY_PARTITION_0, asMsgPack(""p"", ""p0""));
+    apiRule
+        .partitionClient(1)
+        .publishMessage(""message"", CORRELATION_KEY_PARTITION_1, asMsgPack(""p"", ""p1""));
+    apiRule
+        .partitionClient(2)
+        .publishMessage(""message"", CORRELATION_KEY_PARTITION_2, asMsgPack(""p"", ""p2""));
+
+    // when
+    testClient.createWorkflowInstance(PROCESS_ID, asMsgPack(""key"", CORRELATION_KEY_PARTITION_0));
+    testClient.createWorkflowInstance(PROCESS_ID, asMsgPack(""key"", CORRELATION_KEY_PARTITION_1));
+    testClient.createWorkflowInstance(PROCESS_ID, asMsgPack(""key"", CORRELATION_KEY_PARTITION_2));
+
+    // then
+    assertThat(
+            RecordingExporter.workflowInstanceRecords(WorkflowInstanceIntent.END_EVENT_OCCURRED)
+                .withElementId(""end"")
+                .limit(3))
+        .extracting(r -> r.getValue().getPayloadAsMap().get(""p""))
+        .contains(""p0"", ""p1"", ""p2"");
+  }
+
+  private int getPartitionId(final String correlationKey) {
+    final List<Integer> partitionIds = apiRule.getPartitionIds();
+    return SubscriptionUtil.getSubscriptionPartitionId(
+        BufferUtil.wrapString(correlationKey), partitionIds.size());
+  }
+}
diff --git a/protocol-test-util/src/main/java/io/zeebe/test/broker/protocol/clientapi/PartitionTestClient.java b/protocol-test-util/src/main/java/io/zeebe/test/broker/protocol/clientapi/PartitionTestClient.java
index dac11a2..e2b8397 100644
--- a/protocol-test-util/src/main/java/io/zeebe/test/broker/protocol/clientapi/PartitionTestClient.java
+++ b/protocol-test-util/src/main/java/io/zeebe/test/broker/protocol/clientapi/PartitionTestClient.java
@@ -329,6 +329,7 @@ public class PartitionTestClient {
       final String messageName, final String correlationKey, final byte[] payload, final long ttl) {
     return apiRule
         .createCmdRequest()
+        .partitionId(partitionId)
         .type(ValueType.MESSAGE, MessageIntent.PUBLISH)
         .command()
         .put(""name"", messageName)
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerReprocessingTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerReprocessingTest.java
index 9a122d9..b7db67e 100644
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerReprocessingTest.java
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerReprocessingTest.java
@@ -619,14 +619,9 @@ public class BrokerReprocessingTest {
   }
 
   @Test
-  public void shouldCorrelateMessageAfterRestartIfEnteredBeforeA() throws Exception {
+  public void shouldCorrelateMessageAfterRestartIfEnteredBefore() throws Exception {
     // given
-    clientRule
-        .getWorkflowClient()
-        .newDeployCommand()
-        .addWorkflowModel(WORKFLOW_MESSAGE, ""message.bpmn"")
-        .send()
-        .join();
+    deploy(WORKFLOW_MESSAGE, ""message.bpmn"");
 
     final long workflowInstanceKey =
         startWorkflowInstance(PROCESS_ID, singletonMap(""orderId"", ""order-123""))
@@ -658,12 +653,7 @@ public class BrokerReprocessingTest {
   @Test
   public void shouldCorrelateMessageAfterRestartIfPublishedBefore() throws Exception {
     // given
-    clientRule
-        .getWorkflowClient()
-        .newDeployCommand()
-        .addWorkflowModel(WORKFLOW_MESSAGE, ""message.bpmn"")
-        .send()
-        .join();
+    deploy(WORKFLOW_MESSAGE, ""message.bpmn"");
 
     publishMessage(""order canceled"", ""order-123"", singletonMap(""foo"", ""bar""));
     reprocessingTrigger.accept(this);
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/MessageCorrelationTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/MessageCorrelationTest.java
deleted file mode 100644
index c6a05fb..0000000
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/MessageCorrelationTest.java
+++ /dev/null
@@ -1,176 +0,0 @@
-/*
- * Copyright  2017 camunda services GmbH (info@camunda.com)
- *
- * Licensed under the Apache License, Version 2.0 (the ""License"");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an ""AS IS"" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package io.zeebe.broker.it.workflow;
-
-import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertElementActivated;
-import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertElementCompleted;
-import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertWorkflowInstanceCompleted;
-import static org.assertj.core.api.Assertions.assertThat;
-import static org.assertj.core.api.Assertions.entry;
-
-import io.zeebe.broker.it.GrpcClientRule;
-import io.zeebe.broker.test.EmbeddedBrokerRule;
-import io.zeebe.client.api.events.DeploymentEvent;
-import io.zeebe.model.bpmn.Bpmn;
-import io.zeebe.model.bpmn.BpmnModelInstance;
-import java.util.Collections;
-import org.junit.Before;
-import org.junit.Rule;
-import org.junit.Test;
-import org.junit.rules.RuleChain;
-import org.junit.runner.RunWith;
-import org.junit.runners.Parameterized;
-import org.junit.runners.Parameterized.Parameter;
-import org.junit.runners.Parameterized.Parameters;
-
-@RunWith(Parameterized.class)
-public class MessageCorrelationTest {
-
-  public EmbeddedBrokerRule brokerRule = new EmbeddedBrokerRule();
-  public GrpcClientRule clientRule = new GrpcClientRule(brokerRule);
-
-  @Rule public RuleChain ruleChain = RuleChain.outerRule(brokerRule).around(clientRule);
-
-  private static final BpmnModelInstance CATCH_EVENT_WORKFLOW =
-      Bpmn.createExecutableProcess(""wf"")
-          .startEvent()
-          .intermediateCatchEvent(""receive-message"")
-          .message(m -> m.name(""order canceled"").zeebeCorrelationKey(""$.orderId""))
-          .sequenceFlowId(""to-end"")
-          .endEvent()
-          .done();
-
-  private static final BpmnModelInstance RECEIVE_TASK_WORKFLOW =
-      Bpmn.createExecutableProcess(""wf"")
-          .startEvent()
-          .receiveTask(""receive-message"")
-          .message(m -> m.name(""order canceled"").zeebeCorrelationKey(""$.orderId""))
-          .sequenceFlowId(""to-end"")
-          .endEvent()
-          .done();
-
-  @Parameter(0)
-  public String elementType;
-
-  @Parameter(1)
-  public BpmnModelInstance workflow;
-
-  @Parameters(name = ""{0}"")
-  public static final Object[][] parameters() {
-    return new Object[][] {
-      {""intermediate message catch event"", CATCH_EVENT_WORKFLOW},
-      {""receive task"", RECEIVE_TASK_WORKFLOW}
-    };
-  }
-
-  @Before
-  public void init() {
-    final DeploymentEvent deploymentEvent =
-        clientRule
-            .getWorkflowClient()
-            .newDeployCommand()
-            .addWorkflowModel(workflow, ""wf.bpmn"")
-            .send()
-            .join();
-
-    clientRule.waitUntilDeploymentIsDone(deploymentEvent.getKey());
-  }
-
-  @Test
-  public void shouldCorrelateMessageIfEnteredBefore() {
-    // given
-    clientRule
-        .getWorkflowClient()
-        .newCreateInstanceCommand()
-        .bpmnProcessId(""wf"")
-        .latestVersion()
-        .payload(""{\""orderId\"":\""order-123\""}"")
-        .send()
-        .join();
-
-    assertElementActivated(""receive-message"");
-
-    // when
-    clientRule
-        .getWorkflowClient()
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .send()
-        .join();
-
-    // then
-    assertWorkflowInstanceCompleted(""wf"");
-  }
-
-  @Test
-  public void shouldCorrelateMessageIfPublishedBefore() {
-    // given
-    clientRule
-        .getWorkflowClient()
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .send()
-        .join();
-
-    // when
-    clientRule
-        .getWorkflowClient()
-        .newCreateInstanceCommand()
-        .bpmnProcessId(""wf"")
-        .latestVersion()
-        .payload(""{\""orderId\"":\""order-123\""}"")
-        .send()
-        .join();
-
-    // then
-    assertWorkflowInstanceCompleted(""wf"");
-  }
-
-  @Test
-  public void shouldCorrelateMessageAndMergePayload() {
-    // given
-    clientRule
-        .getWorkflowClient()
-        .newCreateInstanceCommand()
-        .bpmnProcessId(""wf"")
-        .latestVersion()
-        .payload(""{\""orderId\"":\""order-123\""}"")
-        .send()
-        .join();
-
-    // when
-    clientRule
-        .getWorkflowClient()
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .payload(Collections.singletonMap(""foo"", ""bar""))
-        .send()
-        .join();
-
-    // then
-    assertWorkflowInstanceCompleted(""wf"");
-
-    assertElementCompleted(
-        ""wf"",
-        ""receive-message"",
-        (catchEventOccurredEvent) ->
-            assertThat(catchEventOccurredEvent.getPayloadAsMap())
-                .containsExactly(entry(""orderId"", ""order-123""), entry(""foo"", ""bar"")));
-  }
-}
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/PublishMessageTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/PublishMessageTest.java
deleted file mode 100644
index 7845eec..0000000
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/PublishMessageTest.java
+++ /dev/null
@@ -1,234 +0,0 @@
-/*
- * Copyright  2017 camunda services GmbH (info@camunda.com)
- *
- * Licensed under the Apache License, Version 2.0 (the ""License"");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an ""AS IS"" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package io.zeebe.broker.it.workflow;
-
-import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertElementActivated;
-import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertElementCompleted;
-import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertWorkflowInstanceCompleted;
-import static io.zeebe.broker.test.EmbeddedBrokerConfigurator.setPartitionCount;
-import static org.assertj.core.api.Assertions.assertThat;
-import static org.assertj.core.api.Assertions.assertThatThrownBy;
-import static org.assertj.core.api.Assertions.entry;
-
-import io.zeebe.broker.it.GrpcClientRule;
-import io.zeebe.broker.test.EmbeddedBrokerRule;
-import io.zeebe.client.api.ZeebeFuture;
-import io.zeebe.client.api.clients.WorkflowClient;
-import io.zeebe.client.api.events.DeploymentEvent;
-import io.zeebe.client.api.events.WorkflowInstanceEvent;
-import io.zeebe.client.cmd.ClientException;
-import io.zeebe.model.bpmn.Bpmn;
-import io.zeebe.model.bpmn.BpmnModelInstance;
-import java.time.Duration;
-import java.util.Collections;
-import org.junit.Before;
-import org.junit.Rule;
-import org.junit.Test;
-import org.junit.rules.RuleChain;
-
-public class PublishMessageTest {
-
-  private static final BpmnModelInstance WORKFLOW =
-      Bpmn.createExecutableProcess(""wf"")
-          .startEvent()
-          .intermediateCatchEvent(""catch-event"")
-          .message(c -> c.name(""order canceled"").zeebeCorrelationKey(""$.orderId""))
-          .endEvent()
-          .done();
-  public EmbeddedBrokerRule brokerRule = new EmbeddedBrokerRule(setPartitionCount(3));
-  public GrpcClientRule clientRule = new GrpcClientRule(brokerRule);
-
-  @Rule public RuleChain ruleChain = RuleChain.outerRule(brokerRule).around(clientRule);
-
-  private WorkflowClient workflowClient;
-
-  @Before
-  public void init() {
-
-    workflowClient = clientRule.getClient().workflowClient();
-
-    final DeploymentEvent deploymentEvent =
-        workflowClient.newDeployCommand().addWorkflowModel(WORKFLOW, ""wf.bpmn"").send().join();
-
-    clientRule.waitUntilDeploymentIsDone(deploymentEvent.getKey());
-  }
-
-  @Test
-  public void shouldCorrelateMessageToAllSubscriptions() {
-    // given
-    final WorkflowInstanceEvent wf =
-        workflowClient
-            .newCreateInstanceCommand()
-            .bpmnProcessId(""wf"")
-            .latestVersion()
-            .payload(""{\""orderId\"":\""order-123\""}"")
-            .send()
-            .join();
-
-    final WorkflowInstanceEvent wf2 =
-        workflowClient
-            .newCreateInstanceCommand()
-            .bpmnProcessId(""wf"")
-            .latestVersion()
-            .payload(""{\""orderId\"":\""order-123\""}"")
-            .send()
-            .join();
-
-    // when
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .send()
-        .join();
-
-    // then
-    assertWorkflowInstanceCompleted(""wf"", wf.getWorkflowInstanceKey());
-    assertWorkflowInstanceCompleted(""wf"", wf2.getWorkflowInstanceKey());
-  }
-
-  @Test
-  public void shouldCorrelateMessageWithZeroTTL() {
-    // given
-    workflowClient
-        .newCreateInstanceCommand()
-        .bpmnProcessId(""wf"")
-        .latestVersion()
-        .payload(""{\""orderId\"":\""order-123\""}"")
-        .send()
-        .join();
-
-    assertElementActivated(""catch-event"");
-
-    // when
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .timeToLive(Duration.ZERO)
-        .send()
-        .join();
-
-    // then
-    assertElementCompleted(""wf"", ""catch-event"");
-  }
-
-  @Test
-  public void shouldNotCorrelateMessageAfterTTL() {
-    // given
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .timeToLive(Duration.ZERO)
-        .payload(Collections.singletonMap(""msg"", ""failure""))
-        .send()
-        .join();
-
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .timeToLive(Duration.ofMinutes(1))
-        .payload(Collections.singletonMap(""msg"", ""expected""))
-        .send()
-        .join();
-
-    // when
-    workflowClient
-        .newCreateInstanceCommand()
-        .bpmnProcessId(""wf"")
-        .latestVersion()
-        .payload(""{\""orderId\"":\""order-123\""}"")
-        .send()
-        .join();
-
-    // then
-
-    assertElementCompleted(
-        ""wf"",
-        ""catch-event"",
-        (catchEventOccurred) ->
-            assertThat(catchEventOccurred.getPayloadAsMap()).contains(entry(""msg"", ""expected"")));
-  }
-
-  @Test
-  public void shouldCorrelateMessageOnDifferentPartitions() {
-    // given
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .send()
-        .join();
-
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-124"")
-        .send()
-        .join();
-
-    // when
-    final WorkflowInstanceEvent wf =
-        workflowClient
-            .newCreateInstanceCommand()
-            .bpmnProcessId(""wf"")
-            .latestVersion()
-            .payload(""{\""orderId\"":\""order-123\""}"")
-            .send()
-            .join();
-
-    final WorkflowInstanceEvent wf2 =
-        workflowClient
-            .newCreateInstanceCommand()
-            .bpmnProcessId(""wf"")
-            .latestVersion()
-            .payload(""{\""orderId\"":\""order-124\""}"")
-            .send()
-            .join();
-
-    // then
-    assertWorkflowInstanceCompleted(""wf"", wf.getWorkflowInstanceKey());
-    assertWorkflowInstanceCompleted(""wf"", wf2.getWorkflowInstanceKey());
-  }
-
-  @Test
-  public void shouldRejectMessageWithSameId() {
-    // given
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .messageId(""foo"")
-        .send()
-        .join();
-
-    // when
-    final ZeebeFuture<Void> future =
-        workflowClient
-            .newPublishMessageCommand()
-            .messageName(""order canceled"")
-            .correlationKey(""order-123"")
-            .messageId(""foo"")
-            .send();
-
-    // then
-    assertThatThrownBy(future::join)
-        .isInstanceOf(ClientException.class)
-        .hasMessageContaining(""message with id 'foo' is already published"");
-  }
-}
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/message/MessageCorrelationMultiplePartitionsTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/message/MessageCorrelationMultiplePartitionsTest.java
new file mode 100644
index 0000000..0e37c95
--- /dev/null
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/message/MessageCorrelationMultiplePartitionsTest.java
@@ -0,0 +1,196 @@
+/*
+ * Copyright  2017 camunda services GmbH (info@camunda.com)
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package io.zeebe.broker.it.workflow.message;
+
+import static io.zeebe.broker.test.EmbeddedBrokerConfigurator.setPartitionCount;
+import static org.assertj.core.api.Assertions.assertThat;
+import static org.assertj.core.api.Assertions.tuple;
+
+import io.zeebe.broker.it.GrpcClientRule;
+import io.zeebe.broker.test.EmbeddedBrokerRule;
+import io.zeebe.client.api.events.DeploymentEvent;
+import io.zeebe.model.bpmn.Bpmn;
+import io.zeebe.model.bpmn.BpmnModelInstance;
+import io.zeebe.protocol.intent.MessageIntent;
+import io.zeebe.protocol.intent.MessageSubscriptionIntent;
+import io.zeebe.protocol.intent.WorkflowInstanceIntent;
+import io.zeebe.test.util.record.RecordingExporter;
+import java.util.Collections;
+import java.util.stream.IntStream;
+import org.junit.Before;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.RuleChain;
+
+public class MessageCorrelationMultiplePartitionsTest {
+
+  private static final String CORRELATION_KEY_PARTITION_0 = ""item-2"";
+  private static final String CORRELATION_KEY_PARTITION_1 = ""item-1"";
+  private static final String CORRELATION_KEY_PARTITION_2 = ""item-0"";
+
+  private static final String PROCESS_ID = ""process"";
+
+  public EmbeddedBrokerRule brokerRule = new EmbeddedBrokerRule(setPartitionCount(3));
+  public GrpcClientRule clientRule = new GrpcClientRule(brokerRule);
+
+  @Rule public RuleChain ruleChain = RuleChain.outerRule(brokerRule).around(clientRule);
+
+  private static final BpmnModelInstance WORKFLOW =
+      Bpmn.createExecutableProcess(PROCESS_ID)
+          .startEvent()
+          .intermediateCatchEvent()
+          .message(m -> m.name(""message"").zeebeCorrelationKey(""$.key""))
+          .endEvent(""end"")
+          .done();
+
+  @Before
+  public void init() {
+    final DeploymentEvent deploymentEvent =
+        clientRule
+            .getWorkflowClient()
+            .newDeployCommand()
+            .addWorkflowModel(WORKFLOW, ""wf.bpmn"")
+            .send()
+            .join();
+
+    clientRule.waitUntilDeploymentIsDone(deploymentEvent.getKey());
+  }
+
+  @Test
+  public void shouldOpenMessageSubscriptionsOnDifferentPartitions() {
+    // when
+    IntStream.range(0, 10)
+        .forEach(
+            i -> {
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_0));
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_1));
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_2));
+            });
+
+    // then
+    assertThat(
+            RecordingExporter.messageSubscriptionRecords(MessageSubscriptionIntent.OPENED)
+                .limit(30))
+        .extracting(r -> tuple(r.getMetadata().getPartitionId(), r.getValue().getCorrelationKey()))
+        .containsOnly(
+            tuple(0, CORRELATION_KEY_PARTITION_0),
+            tuple(1, CORRELATION_KEY_PARTITION_1),
+            tuple(2, CORRELATION_KEY_PARTITION_2));
+  }
+
+  @Test
+  public void shouldPublishMessageOnDifferentPartitions() {
+    // when
+    IntStream.range(0, 10)
+        .forEach(
+            i -> {
+              publishMessage(CORRELATION_KEY_PARTITION_0, Collections.singletonMap(""p"", ""p0""));
+              publishMessage(CORRELATION_KEY_PARTITION_1, Collections.singletonMap(""p"", ""p1""));
+              publishMessage(CORRELATION_KEY_PARTITION_2, Collections.singletonMap(""p"", ""p2""));
+            });
+
+    // then
+    assertThat(RecordingExporter.messageRecords(MessageIntent.PUBLISHED).limit(30))
+        .extracting(r -> tuple(r.getMetadata().getPartitionId(), r.getValue().getCorrelationKey()))
+        .containsOnly(
+            tuple(0, CORRELATION_KEY_PARTITION_0),
+            tuple(1, CORRELATION_KEY_PARTITION_1),
+            tuple(2, CORRELATION_KEY_PARTITION_2));
+  }
+
+  @Test
+  public void shouldCorrelateMessageOnDifferentPartitions() {
+    // given
+    publishMessage(CORRELATION_KEY_PARTITION_0, Collections.singletonMap(""p"", ""p0""));
+    publishMessage(CORRELATION_KEY_PARTITION_1, Collections.singletonMap(""p"", ""p1""));
+    publishMessage(CORRELATION_KEY_PARTITION_2, Collections.singletonMap(""p"", ""p2""));
+
+    // when
+    createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_0));
+    createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_1));
+    createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_2));
+
+    // then
+    assertThat(
+            RecordingExporter.workflowInstanceRecords(WorkflowInstanceIntent.END_EVENT_OCCURRED)
+                .withElementId(""end"")
+                .limit(3))
+        .extracting(r -> r.getValue().getPayloadAsMap().get(""p""))
+        .contains(""p0"", ""p1"", ""p2"");
+  }
+
+  @Test
+  public void shouldOpenMessageSubscriptionsOnSamePartitionsAfterRestart() {
+    // given
+    IntStream.range(0, 5)
+        .forEach(
+            i -> {
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_0));
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_1));
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_2));
+            });
+
+    assertThat(
+            RecordingExporter.messageSubscriptionRecords(MessageSubscriptionIntent.OPENED)
+                .limit(15)
+                .exists())
+        .isTrue();
+
+    // when
+    brokerRule.stopBroker();
+    brokerRule.startBroker();
+
+    IntStream.range(0, 5)
+        .forEach(
+            i -> {
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_0));
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_1));
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_2));
+            });
+
+    // then
+    assertThat(
+            RecordingExporter.messageSubscriptionRecords(MessageSubscriptionIntent.OPENED)
+                .limit(30))
+        .extracting(r -> tuple(r.getMetadata().getPartitionId(), r.getValue().getCorrelationKey()))
+        .containsOnly(
+            tuple(0, CORRELATION_KEY_PARTITION_0),
+            tuple(1, CORRELATION_KEY_PARTITION_1),
+            tuple(2, CORRELATION_KEY_PARTITION_2));
+  }
+
+  private void createWorkflowInstance(Object payload) {
+    clientRule
+        .getWorkflowClient()
+        .newCreateInstanceCommand()
+        .bpmnProcessId(PROCESS_ID)
+        .latestVersion()
+        .payload(payload)
+        .send()
+        .join();
+  }
+
+  private void publishMessage(String correlationKey, Object payload) {
+    clientRule
+        .getWorkflowClient()
+        .newPublishMessageCommand()
+        .messageName(""message"")
+        .correlationKey(correlationKey)
+        .payload(payload)
+        .send()
+        .join();
+  }
+}
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/message/MessageCorrelationTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/message/MessageCorrelationTest.java
new file mode 100644
index 0000000..3b08572
--- /dev/null
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/message/MessageCorrelationTest.java
@@ -0,0 +1,198 @@
+/*
+ * Copyright  2017 camunda services GmbH (info@camunda.com)
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package io.zeebe.broker.it.workflow.message;
+
+import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertElementActivated;
+import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertElementCompleted;
+import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertWorkflowInstanceCompleted;
+import static org.assertj.core.api.Assertions.assertThat;
+import static org.assertj.core.api.Assertions.assertThatThrownBy;
+import static org.assertj.core.api.Assertions.entry;
+
+import io.zeebe.broker.it.GrpcClientRule;
+import io.zeebe.broker.test.EmbeddedBrokerRule;
+import io.zeebe.client.api.ZeebeFuture;
+import io.zeebe.client.api.events.DeploymentEvent;
+import io.zeebe.client.cmd.ClientException;
+import io.zeebe.model.bpmn.Bpmn;
+import io.zeebe.model.bpmn.BpmnModelInstance;
+import java.time.Duration;
+import java.util.Collections;
+import org.junit.Before;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.RuleChain;
+
+public class MessageCorrelationTest {
+
+  private static final String PROCESS_ID = ""process"";
+
+  public EmbeddedBrokerRule brokerRule = new EmbeddedBrokerRule();
+  public GrpcClientRule clientRule = new GrpcClientRule(brokerRule);
+
+  @Rule public RuleChain ruleChain = RuleChain.outerRule(brokerRule).around(clientRule);
+
+  private static final BpmnModelInstance WORKFLOW =
+      Bpmn.createExecutableProcess(PROCESS_ID)
+          .startEvent()
+          .intermediateCatchEvent(""catch-event"")
+          .message(c -> c.name(""order canceled"").zeebeCorrelationKey(""$.orderId""))
+          .endEvent()
+          .done();
+
+  @Before
+  public void init() {
+    final DeploymentEvent deploymentEvent =
+        clientRule
+            .getWorkflowClient()
+            .newDeployCommand()
+            .addWorkflowModel(WORKFLOW, ""wf.bpmn"")
+            .send()
+            .join();
+
+    clientRule.waitUntilDeploymentIsDone(deploymentEvent.getKey());
+  }
+
+  @Test
+  public void shouldCorrelateMessage() {
+    // given
+    clientRule
+        .getWorkflowClient()
+        .newCreateInstanceCommand()
+        .bpmnProcessId(PROCESS_ID)
+        .latestVersion()
+        .payload(Collections.singletonMap(""orderId"", ""order-123""))
+        .send()
+        .join();
+
+    // when
+    clientRule
+        .getWorkflowClient()
+        .newPublishMessageCommand()
+        .messageName(""order canceled"")
+        .correlationKey(""order-123"")
+        .payload(Collections.singletonMap(""foo"", ""bar""))
+        .send()
+        .join();
+
+    // then
+    assertWorkflowInstanceCompleted(PROCESS_ID);
+
+    assertElementCompleted(
+        PROCESS_ID,
+        ""catch-event"",
+        (catchEventOccurredEvent) ->
+            assertThat(catchEventOccurredEvent.getPayloadAsMap())
+                .containsExactly(entry(""orderId"", ""order-123""), entry(""foo"", ""bar"")));
+  }
+
+  @Test
+  public void shouldCorrelateMessageWithZeroTTL() {
+    // given
+    clientRule
+        .getWorkflowClient()
+        .newCreateInstanceCommand()
+        .bpmnProcessId(PROCESS_ID)
+        .latestVersion()
+        .payload(Collections.singletonMap(""orderId"", ""order-123""))
+        .send()
+        .join();
+
+    assertElementActivated(""catch-event"");
+
+    // when
+    clientRule
+        .getWorkflowClient()
+        .newPublishMessageCommand()
+        .messageName(""order canceled"")
+        .correlationKey(""order-123"")
+        .timeToLive(Duration.ZERO)
+        .send()
+        .join();
+
+    // then
+    assertElementCompleted(PROCESS_ID, ""catch-event"");
+  }
+
+  @Test
+  public void shouldNotCorrelateMessageAfterTTL() {
+    // given
+    clientRule
+        .getWorkflowClient()
+        .newPublishMessageCommand()
+        .messageName(""order canceled"")
+        .correlationKey(""order-123"")
+        .timeToLive(Duration.ZERO)
+        .payload(Collections.singletonMap(""msg"", ""failure""))
+        .send()
+        .join();
+
+    clientRule
+        .getWorkflowClient()
+        .newPublishMessageCommand()
+        .messageName(""order canceled"")
+        .correlationKey(""order-123"")
+        .timeToLive(Duration.ofMinutes(1))
+        .payload(Collections.singletonMap(""msg"", ""expected""))
+        .send()
+        .join();
+
+    // when
+    clientRule
+        .getWorkflowClient()
+        .newCreateInstanceCommand()
+        .bpmnProcessId(PROCESS_ID)
+        .latestVersion()
+        .payload(Collections.singletonMap(""orderId"", ""order-123""))
+        .send()
+        .join();
+
+    // then
+    assertElementCompleted(
+        PROCESS_ID,
+        ""catch-event"",
+        (catchEventOccurred) ->
+            assertThat(catchEventOccurred.getPayloadAsMap()).contains(entry(""msg"", ""expected"")));
+  }
+
+  @Test
+  public void shouldRejectMessageWithSameId() {
+    // given
+    clientRule
+        .getWorkflowClient()
+        .newPublishMessageCommand()
+        .messageName(""order canceled"")
+        .correlationKey(""order-123"")
+        .messageId(""foo"")
+        .send()
+        .join();
+
+    // when
+    final ZeebeFuture<Void> future =
+        clientRule
+            .getWorkflowClient()
+            .newPublishMessageCommand()
+            .messageName(""order canceled"")
+            .correlationKey(""order-123"")
+            .messageId(""foo"")
+            .send();
+
+    // then
+    assertThatThrownBy(future::join)
+        .isInstanceOf(ClientException.class)
+        .hasMessageContaining(""message with id 'foo' is already published"");
+  }
+}
",3,"[""2ba752d45350a676babe553dd68f019af81b512b"", ""bfe32bf10e9b6d699f694fbd095af0b3f2e6275f"", ""2d416be63eeec9e7fdb90a62c40c8ad8f0672efa""]","[""docs"", ""build"", ""test""]"
"allow disabling dynamic queue | added resize observer, this will replace window.resize if available | use an action for issue assignment","diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);

diff --git a/engine/src/Utils/EventListeners.ts b/engine/src/Utils/EventListeners.ts
index 9e7b189..a29cab4 100644
--- a/engine/src/Utils/EventListeners.ts
+++ b/engine/src/Utils/EventListeners.ts
@@ -47,6 +47,7 @@ export class EventListeners {
 
     private canPush: boolean;
     private resizeTimeout?: NodeJS.Timeout;
+    private resizeObserver?: ResizeObserver;
 
     /**
      * Events listener constructor
@@ -144,7 +145,31 @@ export class EventListeners {
         }
 
         if (options.interactivity.events.resize) {
-            manageListener(window, Constants.resizeEvent, this.resizeHandler, add);
+            if (typeof ResizeObserver !== ""undefined"") {
+                if (this.resizeObserver && !add) {
+                    if (container.canvas.element) {
+                        this.resizeObserver.unobserve(container.canvas.element);
+                    }
+
+                    this.resizeObserver.disconnect();
+
+                    delete this.resizeObserver;
+                } else if (!this.resizeObserver && add && container.canvas.element) {
+                    this.resizeObserver = new ResizeObserver((entries) => {
+                        const entry = entries.find((e) => e.target === container.canvas.element);
+
+                        if (!entry) {
+                            return;
+                        }
+
+                        this.handleWindowResize();
+                    });
+
+                    this.resizeObserver.observe(container.canvas.element);
+                }
+            } else {
+                manageListener(window, Constants.resizeEvent, this.resizeHandler, add);
+            }
         }
 
         if (document) {

diff --git a/.github/workflows/assign.yml b/.github/workflows/assign.yml
index 29d92a8..758874e 100644
--- a/.github/workflows/assign.yml
+++ b/.github/workflows/assign.yml
@@ -8,8 +8,6 @@ jobs:
     runs-on: ubuntu-latest
     if: ${{ github.event.comment.body == '/take' }}
     steps:
-      - uses: actions/checkout@v2
-      - name: Assign issue ${{ github.event.issue.number }} to ${{ github.event.comment.user.login }}
-        run: gh issue edit ${{ github.event.issue.number }} --add-assignee ""${{ github.event.comment.user.login }}""
-        env:
-          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+      - uses: pozil/auto-assign-issue@v1.1.0
+        with:
+          assignees: ${{ github.event.comment.user.login }}
",3,"[""9ef5c0d14193a9abb09b39856f58477d1f4b0d77"", ""4197f2654e8767039dbfd66eca34f261ee3d88c8"", ""fb3a231b29bc8bff9270b99dd4aff9dad599f21f""]","[""fix"", ""feat"", ""cicd""]"
fix cypress on windows,"diff --git a/packages/cypress/src/builders/cypress/cypress.impl.spec.ts b/packages/cypress/src/builders/cypress/cypress.impl.spec.ts
index 22851fb..c9296fe 100644
--- a/packages/cypress/src/builders/cypress/cypress.impl.spec.ts
+++ b/packages/cypress/src/builders/cypress/cypress.impl.spec.ts
@@ -77,7 +77,7 @@ describe('Cypress builder', () => {
     await run.result;
     await run.stop();
     expect(fork).toHaveBeenCalledWith(
-      '/root/node_modules/.bin/tsc',
+      '/root/node_modules/typescript/bin/tsc',
       ['-p', '/root/apps/my-app-e2e/tsconfig.json'],
       { stdio: [0, 1, 2, 'ipc'] }
     );
diff --git a/packages/cypress/src/builders/cypress/cypress.impl.ts b/packages/cypress/src/builders/cypress/cypress.impl.ts
index 9d9ded3..d3917c2 100644
--- a/packages/cypress/src/builders/cypress/cypress.impl.ts
+++ b/packages/cypress/src/builders/cypress/cypress.impl.ts
@@ -115,7 +115,7 @@ function compileTypescriptFiles(
       let args = ['-p', path.join(context.workspaceRoot, tsConfigPath)];
       const tscPath = path.join(
         context.workspaceRoot,
-        '/node_modules/.bin/tsc'
+        '/node_modules/typescript/bin/tsc'
       );
       if (isWatching) {
         args.push('--watch');
",1,"[""eebee9ab0bb6d4255ad0402d8422364e96bfef61""]","[""fix""]"
"use new freespace config for disk space recory test | set Opensearch version to 2.5.0

We use Opensearch 2.5.0 in our dependencies. This is tied to the
Opensearch versions of other component of the platform.

This Docker compose file is only used for local testing. Let's make sure
 we test on the actual version we support. | apply element migrated events

This is a very straightforward event applier. All it needs to do is
update the persisted data for the element instance using the data in the
event.","diff --git a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/health/DiskSpaceRecoveryIT.java b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/health/DiskSpaceRecoveryIT.java
index 0854323..bfc7b7e 100644
--- a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/health/DiskSpaceRecoveryIT.java
+++ b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/health/DiskSpaceRecoveryIT.java
@@ -47,7 +47,8 @@ final class DiskSpaceRecoveryIT {
           .withZeebeData(volume)
           .withEnv(""ZEEBE_BROKER_DATA_LOGSEGMENTSIZE"", ""1MB"")
           .withEnv(""ZEEBE_BROKER_NETWORK_MAXMESSAGESIZE"", ""1MB"")
-          .withEnv(""ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK"", ""0.5"");
+          .withEnv(""ZEEBE_BROKER_DATA_DISK_FREESPACE_PROCESSING"", ""10MB"")
+          .withEnv(""ZEEBE_BROKER_DATA_DISK_FREESPACE_REPLICATION"", ""1MB"");
 
   private ZeebeClient client;
 
@@ -127,7 +128,9 @@ final class DiskSpaceRecoveryIT {
         ContainerEngine.builder()
             .withDebugReceiverPort(SocketUtil.getNextAddress().getPort())
             .withContainer(
-                container.withEnv(""ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK"", ""0.0001""))
+                container
+                    .withEnv(""ZEEBE_BROKER_DATA_DISK_FREESPACE_PROCESSING"", ""16MB"")
+                    .withEnv(""ZEEBE_BROKER_DATA_DISK_FREESPACE_REPLICATION"", ""10MB""))
             .build();
 
     @BeforeEach

diff --git a/exporters/opensearch-exporter/docker-compose.yml b/exporters/opensearch-exporter/docker-compose.yml
index 8fe84b3..647afa1 100644
--- a/exporters/opensearch-exporter/docker-compose.yml
+++ b/exporters/opensearch-exporter/docker-compose.yml
@@ -2,7 +2,7 @@ version: '3'
 
 services:
   opensearch:
-    image: opensearchproject/opensearch:2.6.0
+    image: opensearchproject/opensearch:2.5.0
     ports:
       - ""9200:9200""
       - ""9600:9600""
@@ -14,7 +14,7 @@ services:
       - opensearch-net
 
   opensearch-dashboards:
-    image: opensearchproject/opensearch-dashboards:2.6.0
+    image: opensearchproject/opensearch-dashboards:2.5.0
     ports:
       - ""5601:5601""
     expose:

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/EventAppliers.java b/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/EventAppliers.java
index da05e13..9231df3 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/EventAppliers.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/EventAppliers.java
@@ -154,6 +154,9 @@ public final class EventAppliers implements EventApplier {
     register(
         ProcessInstanceIntent.SEQUENCE_FLOW_TAKEN,
         new ProcessInstanceSequenceFlowTakenApplier(elementInstanceState, processState));
+    register(
+        ProcessInstanceIntent.ELEMENT_MIGRATED,
+        new ProcessInstanceElementMigratedApplier(elementInstanceState));
   }
 
   private void registerProcessInstanceCreationAppliers(final MutableProcessingState state) {
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/ProcessInstanceElementMigratedApplier.java b/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/ProcessInstanceElementMigratedApplier.java
index e5a0f3a..d38358f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/ProcessInstanceElementMigratedApplier.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/ProcessInstanceElementMigratedApplier.java
@@ -24,5 +24,16 @@ final class ProcessInstanceElementMigratedApplier
   }
 
   @Override
-  public void applyState(final long elementInstanceKey, final ProcessInstanceRecord value) {}
+  public void applyState(final long elementInstanceKey, final ProcessInstanceRecord value) {
+    elementInstanceState.updateInstance(
+        elementInstanceKey,
+        elementInstance ->
+            elementInstance
+                .getValue()
+                .setProcessDefinitionKey(value.getProcessDefinitionKey())
+                .setBpmnProcessId(value.getBpmnProcessId())
+                .setVersion(value.getVersion())
+                .setElementId(value.getElementId())
+                .setFlowScopeKey(value.getFlowScopeKey()));
+  }
 }
",3,"[""672cd2b9775fb6dac2d522cb3f4469db47c0556b"", ""b7beb4d8cf19bbb7b72997a8276300a786e4fb5e"", ""39d5d1cfe8d2210305df2c8fab4a4ae430732cf7""]","[""test"", ""build"", ""feat""]"
`worktree::encode_to_worktree()` to turn UTf-8 into the worktree encoding.,"diff --git a/gix-filter/src/worktree.rs b/gix-filter/src/worktree.rs
deleted file mode 100644
index cda7640..0000000
--- a/gix-filter/src/worktree.rs
+++ /dev/null
@@ -1,132 +0,0 @@
-//! Worktree encodings are powered by the `encoding_rs` crate, which has a narrower focus than the `iconv` library. Thus this implementation
-//! is inherently more limited but will handle the common cases.
-//!  
-//! Note that for encoding to legacy formats, [additional normalization steps](https://docs.rs/encoding_rs/0.8.32/encoding_rs/#preparing-text-for-the-encoders)
-//! can be taken, which we do not yet take unless there is specific examples or problems to solve.
-
-use crate::clear_and_set_capacity;
-use crate::worktree::encode_to_git::RoundTrip;
-use encoding_rs::DecoderResult;
-
-///
-pub mod encoding {
-    use bstr::BStr;
-    use encoding_rs::Encoding;
-
-    ///
-    pub mod for_label {
-        use bstr::BString;
-
-        /// The error returned by [for_label()][super::for_label()].
-        #[derive(Debug, thiserror::Error)]
-        #[allow(missing_docs)]
-        pub enum Error {
-            #[error(""An encoding named '{name}' is not known"")]
-            Unknown { name: BString },
-        }
-    }
-    /// Try to produce a new `Encoding` for `label` or report an error if it is not known.
-    ///
-    /// ### Deviation
-    ///
-    /// * There is no special handling of UTF-16LE/BE with checks if data contains a BOM or not, like `git` as we don't expect to have
-    ///   data available here.
-    /// * Special `-BOM` suffixed versions of `UTF-16` encodings are not supported.
-    pub fn for_label<'a>(label: impl Into<&'a BStr>) -> Result<&'static Encoding, for_label::Error> {
-        let mut label = label.into();
-        if label == ""latin-1"" {
-            label = ""ISO-8859-1"".into();
-        }
-        let enc =
-            Encoding::for_label(label.as_ref()).ok_or_else(|| for_label::Error::Unknown { name: label.into() })?;
-        Ok(enc)
-    }
-}
-
-///
-pub mod encode_to_git {
-    /// Whether or not to perform round-trip checks.
-    #[derive(Debug, Copy, Clone)]
-    pub enum RoundTrip {
-        /// Assure that we can losslessly convert the UTF-8 result back to the original encoding.
-        Validate,
-        /// Do not check if the encoding is round-trippable.
-        Ignore,
-    }
-
-    /// The error returned by [`encode_to_git()][super::encode_to_git()].
-    #[derive(Debug, thiserror::Error)]
-    #[allow(missing_docs)]
-    pub enum Error {
-        #[error(""Cannot convert input of {input_len} bytes to UTF-8 without overflowing"")]
-        Overflow { input_len: usize },
-        #[error(""The input was malformed and could not be decoded as '{encoding}'"")]
-        Malformed { encoding: &'static str },
-        #[error(""Encoding from '{src_encoding}' to '{dest_encoding}' and back is not the same"")]
-        RoundTrip {
-            src_encoding: &'static str,
-            dest_encoding: &'static str,
-        },
-    }
-}
-
-/// Decode `src` according to `src_encoding` to `UTF-8` for storage in git.
-/// Note that the encoding is always applied, there is no conditional even if `src_encoding` already is `UTF-8`.
-pub fn encode_to_git(
-    src: &[u8],
-    src_encoding: &'static encoding_rs::Encoding,
-    buf: &mut Vec<u8>,
-    round_trip: encode_to_git::RoundTrip,
-) -> Result<(), encode_to_git::Error> {
-    let mut decoder = src_encoding.new_decoder_with_bom_removal();
-    let buf_len = decoder
-        .max_utf8_buffer_length_without_replacement(src.len())
-        .ok_or_else(|| encode_to_git::Error::Overflow { input_len: src.len() })?;
-    clear_and_set_capacity(buf, buf_len);
-    // SAFETY: `clear_and_set_capacity` assure that we have the given `buf_len` allocated, so setting its length is only making available
-    //          what is allocated. Later we will truncate to the amount of actually written bytes.
-    #[allow(unsafe_code)]
-    unsafe {
-        buf.set_len(buf_len);
-    }
-    let (res, read, written) = decoder.decode_to_utf8_without_replacement(src, buf, true);
-    match res {
-        DecoderResult::InputEmpty => {
-            assert!(
-                buf_len >= written,
-                ""encoding_rs estimates the maximum amount of bytes written correctly""
-            );
-            assert_eq!(read, src.len(), ""input buffer should be fully consumed"");
-            // SAFETY: we trust that `encoding_rs` reports this number correctly, and truncate everything else.
-            #[allow(unsafe_code)]
-            unsafe {
-                buf.set_len(written);
-            }
-        }
-        DecoderResult::OutputFull => {
-            unreachable!(""we assure that the output buffer is big enough as per the encoder's estimate"")
-        }
-        DecoderResult::Malformed(_, _) => {
-            return Err(encode_to_git::Error::Malformed {
-                encoding: src_encoding.name(),
-            })
-        }
-    }
-
-    match round_trip {
-        RoundTrip::Validate => {
-            // SAFETY: we trust `encoding_rs` to output valid UTF-8 only if we ask it to.
-            #[allow(unsafe_code)]
-            let str = unsafe { std::str::from_utf8_unchecked(&buf) };
-            let (should_equal_src, _actual_encoding, _had_errors) = src_encoding.encode(str);
-            if should_equal_src != src {
-                return Err(encode_to_git::Error::RoundTrip {
-                    src_encoding: src_encoding.name(),
-                    dest_encoding: ""UTF-8"",
-                });
-            }
-        }
-        RoundTrip::Ignore => {}
-    }
-    Ok(())
-}
diff --git a/gix-filter/src/worktree/encode_to_git.rs b/gix-filter/src/worktree/encode_to_git.rs
new file mode 100644
index 0000000..da1bbf7
--- /dev/null
+++ b/gix-filter/src/worktree/encode_to_git.rs
@@ -0,0 +1,90 @@
+/// Whether or not to perform round-trip checks.
+#[derive(Debug, Copy, Clone)]
+pub enum RoundTrip {
+    /// Assure that we can losslessly convert the UTF-8 result back to the original encoding.
+    Validate,
+    /// Do not check if the encoding is round-trippable.
+    Ignore,
+}
+
+/// The error returned by [`encode_to_git()][super::encode_to_git()].
+#[derive(Debug, thiserror::Error)]
+#[allow(missing_docs)]
+pub enum Error {
+    #[error(""Cannot convert input of {input_len} bytes to UTF-8 without overflowing"")]
+    Overflow { input_len: usize },
+    #[error(""The input was malformed and could not be decoded as '{encoding}'"")]
+    Malformed { encoding: &'static str },
+    #[error(""Encoding from '{src_encoding}' to '{dest_encoding}' and back is not the same"")]
+    RoundTrip {
+        src_encoding: &'static str,
+        dest_encoding: &'static str,
+    },
+}
+
+pub(crate) mod function {
+    use super::{Error, RoundTrip};
+    use crate::clear_and_set_capacity;
+    use encoding_rs::DecoderResult;
+
+    /// Decode `src` according to `src_encoding` to `UTF-8` for storage in git and place it in `buf`.
+    /// Note that the encoding is always applied, there is no conditional even if `src_encoding` already is `UTF-8`.
+    pub fn encode_to_git(
+        src: &[u8],
+        src_encoding: &'static encoding_rs::Encoding,
+        buf: &mut Vec<u8>,
+        round_trip: RoundTrip,
+    ) -> Result<(), Error> {
+        let mut decoder = src_encoding.new_decoder_with_bom_removal();
+        let buf_len = decoder
+            .max_utf8_buffer_length_without_replacement(src.len())
+            .ok_or(Error::Overflow { input_len: src.len() })?;
+        clear_and_set_capacity(buf, buf_len);
+        // SAFETY: `clear_and_set_capacity` assure that we have the given `buf_len` allocated, so setting its length is only making available
+        //          what is allocated. Later we will truncate to the amount of actually written bytes.
+        #[allow(unsafe_code)]
+        unsafe {
+            buf.set_len(buf_len);
+        }
+        let (res, read, written) = decoder.decode_to_utf8_without_replacement(src, buf, true);
+        match res {
+            DecoderResult::InputEmpty => {
+                assert!(
+                    buf_len >= written,
+                    ""encoding_rs estimates the maximum amount of bytes written correctly""
+                );
+                assert_eq!(read, src.len(), ""input buffer should be fully consumed"");
+                // SAFETY: we trust that `encoding_rs` reports this number correctly, and truncate everything else.
+                #[allow(unsafe_code)]
+                unsafe {
+                    buf.set_len(written);
+                }
+            }
+            DecoderResult::OutputFull => {
+                unreachable!(""we assure that the output buffer is big enough as per the encoder's estimate"")
+            }
+            DecoderResult::Malformed(_, _) => {
+                return Err(Error::Malformed {
+                    encoding: src_encoding.name(),
+                })
+            }
+        }
+
+        match round_trip {
+            RoundTrip::Validate => {
+                // SAFETY: we trust `encoding_rs` to output valid UTF-8 only if we ask it to.
+                #[allow(unsafe_code)]
+                let str = unsafe { std::str::from_utf8_unchecked(buf) };
+                let (should_equal_src, _actual_encoding, _had_errors) = src_encoding.encode(str);
+                if should_equal_src != src {
+                    return Err(Error::RoundTrip {
+                        src_encoding: src_encoding.name(),
+                        dest_encoding: ""UTF-8"",
+                    });
+                }
+            }
+            RoundTrip::Ignore => {}
+        }
+        Ok(())
+    }
+}
diff --git a/gix-filter/src/worktree/encode_to_worktree.rs b/gix-filter/src/worktree/encode_to_worktree.rs
new file mode 100644
index 0000000..0a53419
--- /dev/null
+++ b/gix-filter/src/worktree/encode_to_worktree.rs
@@ -0,0 +1,69 @@
+/// The error returned by [`encode_to_worktree()][super::encode_to_worktree()].
+#[derive(Debug, thiserror::Error)]
+#[allow(missing_docs)]
+pub enum Error {
+    #[error(""Cannot convert input of {input_len} UTF-8 bytes to target encoding without overflowing"")]
+    Overflow { input_len: usize },
+    #[error(""Input was not UTF-8 encoded"")]
+    InputAsUtf8(#[from] std::str::Utf8Error),
+    #[error(""The character '{character}' could not be mapped to the {worktree_encoding}"")]
+    Unmappable {
+        character: char,
+        worktree_encoding: &'static str,
+    },
+}
+
+pub(crate) mod function {
+    use super::Error;
+    use crate::clear_and_set_capacity;
+    use encoding_rs::EncoderResult;
+
+    /// Encode `src_utf8`, which is assumed to be UTF-8 encoded, according to `worktree_encoding` for placement in the working directory,
+    /// and write it to `buf`, possibly resizing it.
+    /// Note that the encoding is always applied, there is no conditional even if `worktree_encoding` and the `src` encoding are the same.
+    pub fn encode_to_worktree(
+        src_utf8: &[u8],
+        worktree_encoding: &'static encoding_rs::Encoding,
+        buf: &mut Vec<u8>,
+    ) -> Result<(), Error> {
+        let mut encoder = worktree_encoding.new_encoder();
+        let buf_len = encoder
+            .max_buffer_length_from_utf8_if_no_unmappables(src_utf8.len())
+            .ok_or(Error::Overflow {
+                input_len: src_utf8.len(),
+            })?;
+        clear_and_set_capacity(buf, buf_len);
+        // SAFETY: `clear_and_set_capacity` assure that we have the given `buf_len` allocated, so setting its length is only making available
+        //          what is allocated. Later we will truncate to the amount of actually written bytes.
+        #[allow(unsafe_code)]
+        unsafe {
+            buf.set_len(buf_len);
+        }
+        let src = std::str::from_utf8(src_utf8)?;
+        let (res, read, written) = encoder.encode_from_utf8_without_replacement(src, buf, true);
+        match res {
+            EncoderResult::InputEmpty => {
+                assert!(
+                    buf_len >= written,
+                    ""encoding_rs estimates the maximum amount of bytes written correctly""
+                );
+                assert_eq!(read, src_utf8.len(), ""input buffer should be fully consumed"");
+                // SAFETY: we trust that `encoding_rs` reports this number correctly, and truncate everything else.
+                #[allow(unsafe_code)]
+                unsafe {
+                    buf.set_len(written);
+                }
+            }
+            EncoderResult::OutputFull => {
+                unreachable!(""we assure that the output buffer is big enough as per the encoder's estimate"")
+            }
+            EncoderResult::Unmappable(c) => {
+                return Err(Error::Unmappable {
+                    worktree_encoding: worktree_encoding.name(),
+                    character: c,
+                })
+            }
+        }
+        Ok(())
+    }
+}
diff --git a/gix-filter/src/worktree/encoding.rs b/gix-filter/src/worktree/encoding.rs
new file mode 100644
index 0000000..0b75adc
--- /dev/null
+++ b/gix-filter/src/worktree/encoding.rs
@@ -0,0 +1,31 @@
+use bstr::BStr;
+use encoding_rs::Encoding;
+
+///
+pub mod for_label {
+    use bstr::BString;
+
+    /// The error returned by [for_label()][super::for_label()].
+    #[derive(Debug, thiserror::Error)]
+    #[allow(missing_docs)]
+    pub enum Error {
+        #[error(""An encoding named '{name}' is not known"")]
+        Unknown { name: BString },
+    }
+}
+
+/// Try to produce a new `Encoding` for `label` or report an error if it is not known.
+///
+/// ### Deviation
+///
+/// * There is no special handling of UTF-16LE/BE with checks if data contains a BOM or not, like `git` as we don't expect to have
+///   data available here.
+/// * Special `-BOM` suffixed versions of `UTF-16` encodings are not supported.
+pub fn for_label<'a>(label: impl Into<&'a BStr>) -> Result<&'static Encoding, for_label::Error> {
+    let mut label = label.into();
+    if label == ""latin-1"" {
+        label = ""ISO-8859-1"".into();
+    }
+    let enc = Encoding::for_label(label.as_ref()).ok_or_else(|| for_label::Error::Unknown { name: label.into() })?;
+    Ok(enc)
+}
diff --git a/gix-filter/src/worktree/mod.rs b/gix-filter/src/worktree/mod.rs
new file mode 100644
index 0000000..3b13ea4
--- /dev/null
+++ b/gix-filter/src/worktree/mod.rs
@@ -0,0 +1,16 @@
+//! Worktree encodings are powered by the `encoding_rs` crate, which has a narrower focus than the `iconv` library. Thus this implementation
+//! is inherently more limited but will handle the common cases.
+//!  
+//! Note that for encoding to legacy formats, [additional normalization steps](https://docs.rs/encoding_rs/0.8.32/encoding_rs/#preparing-text-for-the-encoders)
+//! can be taken, which we do not yet take unless there is specific examples or problems to solve.
+
+///
+pub mod encoding;
+
+///
+pub mod encode_to_git;
+pub use encode_to_git::function::encode_to_git;
+
+///
+pub mod encode_to_worktree;
+pub use encode_to_worktree::function::encode_to_worktree;
diff --git a/gix-filter/tests/worktree/mod.rs b/gix-filter/tests/worktree/mod.rs
index cc2c6f1..1eb1a8e 100644
--- a/gix-filter/tests/worktree/mod.rs
+++ b/gix-filter/tests/worktree/mod.rs
@@ -74,13 +74,28 @@ mod encode_to_git {
         let input = &b""hello""[..];
         for round_trip in [RoundTrip::Ignore, RoundTrip::Validate] {
             let mut buf = Vec::new();
-            worktree::encode_to_git(input, encoding(""UTF-8""), &mut buf, round_trip)?;
+            worktree::encode_to_git(input, encoding_rs::UTF_8, &mut buf, round_trip)?;
             assert_eq!(buf.as_bstr(), input)
         }
         Ok(())
     }
+}
+
+mod encode_to_worktree {
+    use bstr::ByteSlice;
+    use gix_filter::worktree;
+    use gix_filter::worktree::encode_to_git::RoundTrip;
 
-    fn encoding(label: &str) -> &'static encoding_rs::Encoding {
-        worktree::encoding::for_label(label).expect(""encoding is valid and known at compile time"")
+    #[test]
+    fn shift_jis() -> crate::Result {
+        let input = """";
+        let mut buf = Vec::new();
+        worktree::encode_to_worktree(input.as_bytes(), encoding_rs::SHIFT_JIS, &mut buf)?;
+
+        let mut re_encoded = Vec::new();
+        worktree::encode_to_git(&buf, encoding_rs::SHIFT_JIS, &mut re_encoded, RoundTrip::Validate)?;
+
+        assert_eq!(re_encoded.as_bstr(), input, ""this should be round-trippable too"");
+        Ok(())
     }
 }
",1,"[""d1fed3e9907d0a9e3fe45dbfe2ff27bd10b3e1f4""]","[""feat""]"
update flushed index before truncating,"diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {
",1,"[""933ab6bb86372913c992567cf9660009900911a7""]","[""fix""]"
"add `to_sql`

Co-authored-by: Gil Forsyth <gforsyth@users.noreply.github.com> | fixed start types for size and opacity","diff --git a/docs/api/expressions/top_level.md b/docs/api/expressions/top_level.md
index efaffbd..34b529e 100644
--- a/docs/api/expressions/top_level.md
+++ b/docs/api/expressions/top_level.md
@@ -28,7 +28,7 @@ These methods and objects are available directly in the `ibis` module.
 ::: ibis.or_
 ::: ibis.param
 ::: ibis.show_sql
-::: ibis.sql
+::: ibis.to_sql
 ::: ibis.random
 ::: ibis.range_window
 ::: ibis.row_number

diff --git a/core/main/src/Core/Particle.ts b/core/main/src/Core/Particle.ts
index 1aa6fba..6ea6ffc 100644
--- a/core/main/src/Core/Particle.ts
+++ b/core/main/src/Core/Particle.ts
@@ -271,7 +271,7 @@ export class Particle implements IParticle {
             }
         }
 
-        const sizeAnimation = this.options.size.animation;
+        const sizeAnimation = sizeOptions.animation;
 
         if (sizeAnimation.enable) {
             this.size.status = AnimationStatus.increasing;
@@ -279,7 +279,8 @@ export class Particle implements IParticle {
             if (!randomSize) {
                 switch (sizeAnimation.startValue) {
                     case StartValueType.min:
-                        this.size.value = sizeAnimation.minimumValue * pxRatio;
+                        this.size.value = NumberUtils.getRangeMin(sizeOptions.value) * pxRatio;
+                        this.size.status = AnimationStatus.increasing;
 
                         break;
 
@@ -287,11 +288,14 @@ export class Particle implements IParticle {
                         this.size.value = NumberUtils.randomInRange(
                             NumberUtils.setRangeValue(sizeAnimation.minimumValue * pxRatio, this.size.value)
                         );
+                        this.size.status =
+                            Math.random() >= 0.5 ? AnimationStatus.increasing : AnimationStatus.decreasing;
 
                         break;
 
                     case StartValueType.max:
                     default:
+                        this.size.value = NumberUtils.getRangeMax(sizeOptions.value) * pxRatio;
                         this.size.status = AnimationStatus.decreasing;
 
                         break;
@@ -393,7 +397,8 @@ export class Particle implements IParticle {
             if (!randomOpacity) {
                 switch (opacityAnimation.startValue) {
                     case StartValueType.min:
-                        this.opacity.value = opacityAnimation.minimumValue;
+                        this.opacity.value = NumberUtils.getRangeMin(this.opacity.value);
+                        this.opacity.status = AnimationStatus.increasing;
 
                         break;
 
@@ -401,11 +406,14 @@ export class Particle implements IParticle {
                         this.opacity.value = NumberUtils.randomInRange(
                             NumberUtils.setRangeValue(opacityAnimation.minimumValue, this.opacity.value)
                         );
+                        this.opacity.status =
+                            Math.random() >= 0.5 ? AnimationStatus.increasing : AnimationStatus.decreasing;
 
                         break;
 
                     case StartValueType.max:
                     default:
+                        this.opacity.value = NumberUtils.getRangeMax(this.opacity.value);
                         this.opacity.status = AnimationStatus.decreasing;
 
                         break;
diff --git a/presets/confetti/src/options.ts b/presets/confetti/src/options.ts
index 7fc6225..a713425 100644
--- a/presets/confetti/src/options.ts
+++ b/presets/confetti/src/options.ts
@@ -28,7 +28,7 @@ export const loadOptions = (confettiOptions: RecursivePartial<IConfettiOptions>)
                 animation: {
                     enable: true,
                     minimumValue: 0,
-                    speed: 2,
+                    speed: 0.5,
                     startValue: ""max"",
                     destroy: ""min"",
                 },
",2,"[""e2821a56c7d867b8b591f1777019843a2ffca797"", ""06960183db42cba1b1f1a8077660ba8c801c9e18""]","[""docs"", ""fix""]"
increment failing test retries | use new freespace config for disk space recory test | add react ecosystem,"diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 

diff --git a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/health/DiskSpaceRecoveryIT.java b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/health/DiskSpaceRecoveryIT.java
index 0854323..bfc7b7e 100644
--- a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/health/DiskSpaceRecoveryIT.java
+++ b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/health/DiskSpaceRecoveryIT.java
@@ -47,7 +47,8 @@ final class DiskSpaceRecoveryIT {
           .withZeebeData(volume)
           .withEnv(""ZEEBE_BROKER_DATA_LOGSEGMENTSIZE"", ""1MB"")
           .withEnv(""ZEEBE_BROKER_NETWORK_MAXMESSAGESIZE"", ""1MB"")
-          .withEnv(""ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK"", ""0.5"");
+          .withEnv(""ZEEBE_BROKER_DATA_DISK_FREESPACE_PROCESSING"", ""10MB"")
+          .withEnv(""ZEEBE_BROKER_DATA_DISK_FREESPACE_REPLICATION"", ""1MB"");
 
   private ZeebeClient client;
 
@@ -127,7 +128,9 @@ final class DiskSpaceRecoveryIT {
         ContainerEngine.builder()
             .withDebugReceiverPort(SocketUtil.getNextAddress().getPort())
             .withContainer(
-                container.withEnv(""ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK"", ""0.0001""))
+                container
+                    .withEnv(""ZEEBE_BROKER_DATA_DISK_FREESPACE_PROCESSING"", ""16MB"")
+                    .withEnv(""ZEEBE_BROKER_DATA_DISK_FREESPACE_REPLICATION"", ""10MB""))
             .build();
 
     @BeforeEach

diff --git a/package.json b/package.json
index 1ba8c4f..d1de9a0 100644
--- a/package.json
+++ b/package.json
@@ -36,14 +36,19 @@
     ""@types/node"": ""^9.3.0"",
     ""@types/react"": ""^16.0.34"",
     ""@types/react-dom"": ""^16.0.3"",
+    ""@types/react-motion"": ""^0.0.25"",
     ""bootstrap-sass"": ""^3.3.7"",
     ""highcharts"": ""^6.0.4"",
     ""html2canvas"": ""^1.0.0-alpha.9"",
+    ""immer"": ""^1.2.1"",
     ""lodash"": ""^4.17.4"",
     ""moment"": ""^2.20.1"",
     ""normalize.css"": ""^8.0.0"",
-    ""react"": ""^16.2.0"",
-    ""react-dom"": ""^16.2.0"",
+    ""react"": ""^16.3.1"",
+    ""react-dom"": ""^16.3.1"",
+    ""react-motion"": ""^0.5.2"",
+    ""react-redux"": ""^5.0.7"",
+    ""redux"": ""^3.7.2"",
     ""rxjs"": ""^5.5.6"",
     ""vue"": ""^2.5.13"",
     ""vue-plugin-webextension-i18n"": ""^0.1.0"",
diff --git a/yarn.lock b/yarn.lock
index c8898d8..5d0fc9f 100644
--- a/yarn.lock
+++ b/yarn.lock
@@ -187,6 +187,12 @@
     ""@types/node"" ""*""
     ""@types/react"" ""*""
 
+""@types/react-motion@^0.0.25"":
+  version ""0.0.25""
+  resolved ""https://registry.npmjs.org/@types/react-motion/-/react-motion-0.0.25.tgz#2445745ee8e8e6149faa47a36ff6b0d4c21dbf94""
+  dependencies:
+    ""@types/react"" ""*""
+
 ""@types/react@*"", ""@types/react@^16.0.34"":
   version ""16.0.40""
   resolved ""https://registry.npmjs.org/@types/react/-/react-16.0.40.tgz#caabc2296886f40b67f6fc80f0f3464476461df9""
@@ -3837,6 +3843,10 @@ hoek@4.x.x:
   version ""4.2.1""
   resolved ""https://registry.npmjs.org/hoek/-/hoek-4.2.1.tgz#9634502aa12c445dd5a7c5734b572bb8738aacbb""
 
+hoist-non-react-statics@^2.5.0:
+  version ""2.5.0""
+  resolved ""https://registry.npmjs.org/hoist-non-react-statics/-/hoist-non-react-statics-2.5.0.tgz#d2ca2dfc19c5a91c5a6615ce8e564ef0347e2a40""
+
 home-or-tmp@^2.0.0:
   version ""2.0.0""
   resolved ""https://registry.npmjs.org/home-or-tmp/-/home-or-tmp-2.0.0.tgz#e36c3f2d2cae7d746a857e38d18d5f32a7882db8""
@@ -4004,6 +4014,10 @@ ignore@^3.3.5:
   version ""3.3.7""
   resolved ""https://registry.npmjs.org/ignore/-/ignore-3.3.7.tgz#612289bfb3c220e186a58118618d5be8c1bab021""
 
+immer@^1.2.1:
+  version ""1.2.1""
+  resolved ""https://registry.npmjs.org/immer/-/immer-1.2.1.tgz#96e2ae29cdfc428f28120b832701931b92fa597c""
+
 import-local@^1.0.0:
   version ""1.0.0""
   resolved ""https://registry.npmjs.org/import-local/-/import-local-1.0.0.tgz#5e4ffdc03f4fe6c009c6729beb29631c2f8227bc""
@@ -4104,7 +4118,7 @@ interpret@^1.0.0:
   version ""1.1.0""
   resolved ""https://registry.npmjs.org/interpret/-/interpret-1.1.0.tgz#7ed1b1410c6a0e0f78cf95d3b8440c63f78b8614""
 
-invariant@^2.2.2:
+invariant@^2.0.0, invariant@^2.2.2:
   version ""2.2.4""
   resolved ""https://registry.npmjs.org/invariant/-/invariant-2.2.4.tgz#610f3c92c9359ce1db616e538008d23ff35158e6""
   dependencies:
@@ -5040,6 +5054,10 @@ locate-path@^2.0.0:
     p-locate ""^2.0.0""
     path-exists ""^3.0.0""
 
+lodash-es@^4.17.5, lodash-es@^4.2.1:
+  version ""4.17.8""
+  resolved ""https://registry.npmjs.org/lodash-es/-/lodash-es-4.17.8.tgz#6fa8c8c5d337481df0bdf1c0d899d42473121e45""
+
 lodash._reinterpolate@~3.0.0:
   version ""3.0.0""
   resolved ""https://registry.npmjs.org/lodash._reinterpolate/-/lodash._reinterpolate-3.0.0.tgz#0ccf2d89166af03b3663c796538b75ac6e114d9d""
@@ -5149,7 +5167,7 @@ lodash@4.17.2:
   version ""4.17.2""
   resolved ""https://registry.npmjs.org/lodash/-/lodash-4.17.2.tgz#34a3055babe04ce42467b607d700072c7ff6bf42""
 
-lodash@4.x, lodash@^4.0.0, lodash@^4.13.1, lodash@^4.14.0, lodash@^4.16.3, lodash@^4.17.2, lodash@^4.17.3, lodash@^4.17.4, lodash@^4.2.0, lodash@^4.2.1, lodash@^4.3.0, lodash@~4.17.4:
+lodash@4.x, lodash@^4.0.0, lodash@^4.13.1, lodash@^4.14.0, lodash@^4.16.3, lodash@^4.17.2, lodash@^4.17.3, lodash@^4.17.4, lodash@^4.17.5, lodash@^4.2.0, lodash@^4.2.1, lodash@^4.3.0, lodash@~4.17.4:
   version ""4.17.5""
   resolved ""https://registry.npmjs.org/lodash/-/lodash-4.17.5.tgz#99a92d65c0272debe8c96b6057bc8fbfa3bed511""
 
@@ -6467,7 +6485,7 @@ promise@^7.1.1:
   dependencies:
     asap ""~2.0.3""
 
-prop-types@^15.6.0:
+prop-types@^15.5.8, prop-types@^15.6.0:
   version ""15.6.1""
   resolved ""https://registry.npmjs.org/prop-types/-/prop-types-15.6.1.tgz#36644453564255ddda391191fb3a125cbdf654ca""
   dependencies:
@@ -6574,7 +6592,7 @@ quick-lru@^1.0.0:
   version ""1.1.0""
   resolved ""https://registry.npmjs.org/quick-lru/-/quick-lru-1.1.0.tgz#4360b17c61136ad38078397ff11416e186dcfbb8""
 
-raf@3.4.0:
+raf@3.4.0, raf@^3.1.0:
   version ""3.4.0""
   resolved ""https://registry.npmjs.org/raf/-/raf-3.4.0.tgz#a28876881b4bc2ca9117d4138163ddb80f781575""
   dependencies:
@@ -6645,9 +6663,9 @@ react-dev-utils@^5.0.0:
     strip-ansi ""3.0.1""
     text-table ""0.2.0""
 
-react-dom@^16.2.0:
-  version ""16.2.0""
-  resolved ""https://registry.npmjs.org/react-dom/-/react-dom-16.2.0.tgz#69003178601c0ca19b709b33a83369fe6124c044""
+react-dom@^16.3.1:
+  version ""16.3.1""
+  resolved ""https://registry.npmjs.org/react-dom/-/react-dom-16.3.1.tgz#6a3c90a4fb62f915bdbcf6204422d93a7d4ca573""
   dependencies:
     fbjs ""^0.8.16""
     loose-envify ""^1.1.0""
@@ -6658,9 +6676,28 @@ react-error-overlay@^4.0.0:
   version ""4.0.0""
   resolved ""https://registry.npmjs.org/react-error-overlay/-/react-error-overlay-4.0.0.tgz#d198408a85b4070937a98667f500c832f86bd5d4""
 
-react@^16.2.0:
-  version ""16.2.0""
-  resolved ""https://registry.npmjs.org/react/-/react-16.2.0.tgz#a31bd2dab89bff65d42134fa187f24d054c273ba""
+react-motion@^0.5.2:
+  version ""0.5.2""
+  resolved ""https://registry.npmjs.org/react-motion/-/react-motion-0.5.2.tgz#0dd3a69e411316567927917c6626551ba0607316""
+  dependencies:
+    performance-now ""^0.2.0""
+    prop-types ""^15.5.8""
+    raf ""^3.1.0""
+
+react-redux@^5.0.7:
+  version ""5.0.7""
+  resolved ""https://registry.npmjs.org/react-redux/-/react-redux-5.0.7.tgz#0dc1076d9afb4670f993ffaef44b8f8c1155a4c8""
+  dependencies:
+    hoist-non-react-statics ""^2.5.0""
+    invariant ""^2.0.0""
+    lodash ""^4.17.5""
+    lodash-es ""^4.17.5""
+    loose-envify ""^1.1.0""
+    prop-types ""^15.6.0""
+
+react@^16.3.1:
+  version ""16.3.1""
+  resolved ""https://registry.npmjs.org/react/-/react-16.3.1.tgz#4a2da433d471251c69b6033ada30e2ed1202cfd8""
   dependencies:
     fbjs ""^0.8.16""
     loose-envify ""^1.1.0""
@@ -6788,6 +6825,15 @@ reduce-function-call@^1.0.1:
   dependencies:
     balanced-match ""^0.4.2""
 
+redux@^3.7.2:
+  version ""3.7.2""
+  resolved ""https://registry.npmjs.org/redux/-/redux-3.7.2.tgz#06b73123215901d25d065be342eb026bc1c8537b""
+  dependencies:
+    lodash ""^4.2.1""
+    lodash-es ""^4.2.1""
+    loose-envify ""^1.1.0""
+    symbol-observable ""^1.0.3""
+
 regenerate@^1.2.1:
   version ""1.3.3""
   resolved ""https://registry.npmjs.org/regenerate/-/regenerate-1.3.3.tgz#0c336d3980553d755c39b586ae3b20aa49c82b7f""
@@ -7811,6 +7857,10 @@ symbol-observable@1.0.1:
   version ""1.0.1""
   resolved ""https://registry.npmjs.org/symbol-observable/-/symbol-observable-1.0.1.tgz#8340fc4702c3122df5d22288f88283f513d3fdd4""
 
+symbol-observable@^1.0.3:
+  version ""1.2.0""
+  resolved ""https://registry.npmjs.org/symbol-observable/-/symbol-observable-1.2.0.tgz#c22688aed4eab3cdc2dfeacbb561660560a00804""
+
 symbol-tree@^3.2.2:
   version ""3.2.2""
   resolved ""https://registry.npmjs.org/symbol-tree/-/symbol-tree-3.2.2.tgz#ae27db38f660a7ae2e1c3b7d1bc290819b8519e6""
",3,"[""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57"", ""672cd2b9775fb6dac2d522cb3f4469db47c0556b"", ""7e04a5e829d7416e312ac342a00a11787745753b""]","[""cicd"", ""test"", ""build""]"
"fix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run. | update build","diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 

diff --git a/bootstrap/scripts/publish-patch.sh b/bootstrap/scripts/publish-patch.sh
index a1b6f12..0d849a5 100755
--- a/bootstrap/scripts/publish-patch.sh
+++ b/bootstrap/scripts/publish-patch.sh
@@ -5,4 +5,4 @@ lerna version patch
 lerna publish from-package -y
 git push
 
-./pack_and_install.sh
\ No newline at end of file
+./bootstrap/scripts/pack_and_install.sh
\ No newline at end of file
",2,"[""9be725fa3906323d4bc9788f54eccf74109d632b"", ""3fcfb20b0feb371b357edc42fcb7c87085c9b82a""]","[""fix"", ""build""]"
"support react@17 in peer deps

resolves #1478 | add comments for the Handler | switch to throwing errors","diff --git a/packages/animated/package.json b/packages/animated/package.json
index 2249a2f..e35a1fd 100644
--- a/packages/animated/package.json
+++ b/packages/animated/package.json
@@ -33,6 +33,6 @@
     ""react-layout-effect"": ""^1.0.1""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8""
+    ""react"": ""^16.8.0  || ^17.0.0""
   }
 }
diff --git a/packages/core/package.json b/packages/core/package.json
index 584bbc2..c934253 100644
--- a/packages/core/package.json
+++ b/packages/core/package.json
@@ -36,7 +36,7 @@
     ""react-layout-effect"": ""^1.0.1""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8""
+    ""react"": ""^16.8.0  || ^17.0.0""
   },
   ""devDependencies"": {
     ""rafz"": ""^0.1.13""
diff --git a/packages/parallax/package.json b/packages/parallax/package.json
index 49f8391..5a181fe 100644
--- a/packages/parallax/package.json
+++ b/packages/parallax/package.json
@@ -31,6 +31,6 @@
     ""@react-spring/web"": ""~9.2.0-beta.0""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8""
+    ""react"": ""^16.8.0  || ^17.0.0""
   }
 }
diff --git a/packages/shared/package.json b/packages/shared/package.json
index 67d286c..12f7db3 100644
--- a/packages/shared/package.json
+++ b/packages/shared/package.json
@@ -33,6 +33,6 @@
     ""rafz"": ""^0.1.13""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8""
+    ""react"": ""^16.8.0  || ^17.0.0""
   }
 }
diff --git a/targets/konva/package.json b/targets/konva/package.json
index 17675ac..271d58c 100644
--- a/targets/konva/package.json
+++ b/targets/konva/package.json
@@ -34,7 +34,7 @@
   },
   ""peerDependencies"": {
     ""konva"": "">=2.6"",
-    ""react"": "">=16.8"",
+    ""react"": ""^16.8.0  || ^17.0.0"",
     ""react-konva"": "">=16.8""
   },
   ""devDependencies"": {
diff --git a/targets/native/package.json b/targets/native/package.json
index e97aa97..802a66c 100644
--- a/targets/native/package.json
+++ b/targets/native/package.json
@@ -33,7 +33,7 @@
     ""@react-spring/types"": ""~9.2.0-beta.0""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8"",
+    ""react"": ""^16.8.0  || ^17.0.0"",
     ""react-native"": "">=0.58""
   },
   ""devDependencies"": {
diff --git a/targets/web/package.json b/targets/web/package.json
index d74c25c..f7ac000 100644
--- a/targets/web/package.json
+++ b/targets/web/package.json
@@ -33,7 +33,7 @@
     ""@react-spring/types"": ""~9.2.0-beta.0""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8"",
+    ""react"": ""^16.8.0  || ^17.0.0"",
     ""react-dom"": "">=16.8""
   }
 }
diff --git a/targets/zdog/package.json b/targets/zdog/package.json
index aa57890..f65945a 100644
--- a/targets/zdog/package.json
+++ b/targets/zdog/package.json
@@ -33,7 +33,7 @@
     ""@react-spring/types"": ""~9.2.0-beta.0""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8"",
+    ""react"": ""^16.8.0  || ^17.0.0"",
     ""react-dom"": "">=16.8"",
     ""react-zdog"": "">=1.0"",
     ""zdog"": "">=1.0""

diff --git a/packages/core/src/nodes.rs b/packages/core/src/nodes.rs
index 93d4c8b..80de929 100644
--- a/packages/core/src/nodes.rs
+++ b/packages/core/src/nodes.rs
@@ -357,12 +357,14 @@ pub struct EventHandler<'bump, T = ()> {
 }
 
 impl<T> EventHandler<'_, T> {
+    /// Call this event handler with the appropriate event type
     pub fn call(&self, event: T) {
         if let Some(callback) = self.callback.borrow_mut().as_mut() {
             callback(event);
         }
     }
 
+    /// Forcibly drop the internal handler callback, releasing memory
     pub fn release(&self) {
         self.callback.replace(None);
     }

diff --git a/src/background/sync-manager/services/shanbay/index.ts b/src/background/sync-manager/services/shanbay/index.ts
index 651fd1b..de17a45 100644
--- a/src/background/sync-manager/services/shanbay/index.ts
+++ b/src/background/sync-manager/services/shanbay/index.ts
@@ -24,7 +24,7 @@ export class Service extends SyncService<SyncConfig> {
 
   async init() {
     if (!(await this.isLogin())) {
-      return Promise.reject('login')
+      throw new Error('login')
     }
 
     await setSyncConfig<SyncConfig>(Service.id, this.config)
@@ -85,11 +85,11 @@ export class Service extends SyncService<SyncConfig> {
         encodeURIComponent(text)
       var resSearch = await fetch(url).then(r => r.json())
     } catch (e) {
-      return Promise.reject('network')
+      throw new Error('network')
     }
 
     if (!resSearch || !resSearch.data) {
-      return Promise.reject('word')
+      throw new Error('word')
     }
 
     try {
@@ -104,11 +104,14 @@ export class Service extends SyncService<SyncConfig> {
         }
       ).then(r => r.json())
     } catch (e) {
-      return Promise.reject('network')
+      if (process.env.DEBUG) {
+        console.error(e)
+      }
+      throw new Error('network')
     }
 
     if (!resLearning || resLearning.status_code !== 0) {
-      return Promise.reject('word')
+      throw new Error('word')
     }
   }
 
",3,"[""27169897c0e58bc4fbca724f290ad54fa39abec7"", ""036a0ff49a7dade0e04c9c07071a1ff49133ee24"", ""c527037074641064d267f46c1350bb2afc48320e""]","[""build"", ""docs"", ""refactor""]"
"small error msg improvement

refs #1005 | add getting started gitlab ci configuration

Signed-off-by: Adrien Brault <adrien.brault@gmail.com>","diff --git a/internal/pipe/git/errors.go b/internal/pipe/git/errors.go
index a8c15d5..13dfb56 100644
--- a/internal/pipe/git/errors.go
+++ b/internal/pipe/git/errors.go
@@ -11,7 +11,7 @@ type ErrDirty struct {
 }
 
 func (e ErrDirty) Error() string {
-	return fmt.Sprintf(""git is currently in a dirty state:\n%v"", e.status)
+	return fmt.Sprintf(""git is currently in a dirty state, please check in your pipeline what can be changing the following files:\n%v"", e.status)
 }
 
 // ErrWrongRef happens when the HEAD reference is different from the tag being built

diff --git a/docs/getting-started/1201-ci-environment.md b/docs/getting-started/1201-ci-environment.md
index 6c72b15..2313e30 100644
--- a/docs/getting-started/1201-ci-environment.md
+++ b/docs/getting-started/1201-ci-environment.md
@@ -46,7 +46,60 @@ If you would like us to document CircleCI next, vote for it here: [dagger#1677](
 
 <TabItem value=""gitlab"">
 
-If you would like us to document GitLab next, vote for it here: [dagger#1677](https://github.com/dagger/dagger/discussions/1677)
+```yaml
+.docker:
+    image: docker:${DOCKER_VERSION}-git
+    services:
+        - docker:${DOCKER_VERSION}-dind
+    variables:
+        # See https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#docker-in-docker-with-tls-enabled-in-the-docker-executor
+        DOCKER_HOST: tcp://docker:2376
+
+        DOCKER_TLS_VERIFY: '1'
+        DOCKER_TLS_CERTDIR: '/certs'
+        DOCKER_CERT_PATH: '/certs/client'
+
+        # Faster than the default, apparently
+        DOCKER_DRIVER: overlay2
+
+        DOCKER_VERSION: '20.10'
+
+.dagger:
+    extends: [.docker]
+    variables:
+        DAGGER_VERSION: 0.2.4
+        DAGGER_LOG_FORMAT: plain
+        DAGGER_CACHE_PATH: .dagger-cache
+
+        ARGS: ''
+    cache:
+        key: dagger-${CI_JOB_NAME}
+        paths:
+            - ${DAGGER_CACHE_PATH}
+    before_script:
+        - apk add --no-cache curl
+        - |
+            # install dagger
+            cd /usr/local
+            curl -L https://dl.dagger.io/dagger/install.sh | sh
+            cd -
+
+            dagger version
+    script:
+        - dagger project update
+        - |
+            dagger \
+                do \
+                --cache-from type=local,src=${DAGGER_CACHE_PATH} \
+                --cache-to type=local,mode=max,dest=${DAGGER_CACHE_PATH} \
+                ${ARGS}
+
+build:
+    extends: [.dagger]
+    variables:
+        ARGS: build
+
+```
 
 </TabItem>
 
",2,"[""a62314d9bb632be6af026686615d14b912250512"", ""12257ce53f94dc902df4ba087de90f52d2840ad4""]","[""refactor"", ""docs""]"
remove unnecessary import | disable getGPUInfo() tests on Linux (#14875) | add react ecosystem,"diff --git a/transport/src/main/java/io/camunda/zeebe/transport/stream/impl/LogicalId.java b/transport/src/main/java/io/camunda/zeebe/transport/stream/impl/LogicalId.java
index 14c6f30..ebaef60 100644
--- a/transport/src/main/java/io/camunda/zeebe/transport/stream/impl/LogicalId.java
+++ b/transport/src/main/java/io/camunda/zeebe/transport/stream/impl/LogicalId.java
@@ -8,7 +8,6 @@
 package io.camunda.zeebe.transport.stream.impl;
 
 import io.camunda.zeebe.util.buffer.BufferUtil;
-import org.agrona.BitUtil;
 import org.agrona.concurrent.UnsafeBuffer;
 
 /**

diff --git a/spec/api-app-spec.js b/spec/api-app-spec.js
index 4ca1fa3..6ab6bd0 100644
--- a/spec/api-app-spec.js
+++ b/spec/api-app-spec.js
@@ -805,6 +805,14 @@ describe('app module', () => {
   })
 
   describe('getGPUInfo() API', () => {
+    before(function () {
+      // TODO(alexeykuzmoin): Fails on linux. Enable them back.
+      // https://github.com/electron/electron/pull/14863
+      if (process.platform === 'linux') {
+        this.skip()
+      }
+    })
+
     it('succeeds with basic GPUInfo', (done) => {
       app.getGPUInfo('basic').then((gpuInfo) => {
         // Devices information is always present in the available info

diff --git a/package.json b/package.json
index 1ba8c4f..d1de9a0 100644
--- a/package.json
+++ b/package.json
@@ -36,14 +36,19 @@
     ""@types/node"": ""^9.3.0"",
     ""@types/react"": ""^16.0.34"",
     ""@types/react-dom"": ""^16.0.3"",
+    ""@types/react-motion"": ""^0.0.25"",
     ""bootstrap-sass"": ""^3.3.7"",
     ""highcharts"": ""^6.0.4"",
     ""html2canvas"": ""^1.0.0-alpha.9"",
+    ""immer"": ""^1.2.1"",
     ""lodash"": ""^4.17.4"",
     ""moment"": ""^2.20.1"",
     ""normalize.css"": ""^8.0.0"",
-    ""react"": ""^16.2.0"",
-    ""react-dom"": ""^16.2.0"",
+    ""react"": ""^16.3.1"",
+    ""react-dom"": ""^16.3.1"",
+    ""react-motion"": ""^0.5.2"",
+    ""react-redux"": ""^5.0.7"",
+    ""redux"": ""^3.7.2"",
     ""rxjs"": ""^5.5.6"",
     ""vue"": ""^2.5.13"",
     ""vue-plugin-webextension-i18n"": ""^0.1.0"",
diff --git a/yarn.lock b/yarn.lock
index c8898d8..5d0fc9f 100644
--- a/yarn.lock
+++ b/yarn.lock
@@ -187,6 +187,12 @@
     ""@types/node"" ""*""
     ""@types/react"" ""*""
 
+""@types/react-motion@^0.0.25"":
+  version ""0.0.25""
+  resolved ""https://registry.npmjs.org/@types/react-motion/-/react-motion-0.0.25.tgz#2445745ee8e8e6149faa47a36ff6b0d4c21dbf94""
+  dependencies:
+    ""@types/react"" ""*""
+
 ""@types/react@*"", ""@types/react@^16.0.34"":
   version ""16.0.40""
   resolved ""https://registry.npmjs.org/@types/react/-/react-16.0.40.tgz#caabc2296886f40b67f6fc80f0f3464476461df9""
@@ -3837,6 +3843,10 @@ hoek@4.x.x:
   version ""4.2.1""
   resolved ""https://registry.npmjs.org/hoek/-/hoek-4.2.1.tgz#9634502aa12c445dd5a7c5734b572bb8738aacbb""
 
+hoist-non-react-statics@^2.5.0:
+  version ""2.5.0""
+  resolved ""https://registry.npmjs.org/hoist-non-react-statics/-/hoist-non-react-statics-2.5.0.tgz#d2ca2dfc19c5a91c5a6615ce8e564ef0347e2a40""
+
 home-or-tmp@^2.0.0:
   version ""2.0.0""
   resolved ""https://registry.npmjs.org/home-or-tmp/-/home-or-tmp-2.0.0.tgz#e36c3f2d2cae7d746a857e38d18d5f32a7882db8""
@@ -4004,6 +4014,10 @@ ignore@^3.3.5:
   version ""3.3.7""
   resolved ""https://registry.npmjs.org/ignore/-/ignore-3.3.7.tgz#612289bfb3c220e186a58118618d5be8c1bab021""
 
+immer@^1.2.1:
+  version ""1.2.1""
+  resolved ""https://registry.npmjs.org/immer/-/immer-1.2.1.tgz#96e2ae29cdfc428f28120b832701931b92fa597c""
+
 import-local@^1.0.0:
   version ""1.0.0""
   resolved ""https://registry.npmjs.org/import-local/-/import-local-1.0.0.tgz#5e4ffdc03f4fe6c009c6729beb29631c2f8227bc""
@@ -4104,7 +4118,7 @@ interpret@^1.0.0:
   version ""1.1.0""
   resolved ""https://registry.npmjs.org/interpret/-/interpret-1.1.0.tgz#7ed1b1410c6a0e0f78cf95d3b8440c63f78b8614""
 
-invariant@^2.2.2:
+invariant@^2.0.0, invariant@^2.2.2:
   version ""2.2.4""
   resolved ""https://registry.npmjs.org/invariant/-/invariant-2.2.4.tgz#610f3c92c9359ce1db616e538008d23ff35158e6""
   dependencies:
@@ -5040,6 +5054,10 @@ locate-path@^2.0.0:
     p-locate ""^2.0.0""
     path-exists ""^3.0.0""
 
+lodash-es@^4.17.5, lodash-es@^4.2.1:
+  version ""4.17.8""
+  resolved ""https://registry.npmjs.org/lodash-es/-/lodash-es-4.17.8.tgz#6fa8c8c5d337481df0bdf1c0d899d42473121e45""
+
 lodash._reinterpolate@~3.0.0:
   version ""3.0.0""
   resolved ""https://registry.npmjs.org/lodash._reinterpolate/-/lodash._reinterpolate-3.0.0.tgz#0ccf2d89166af03b3663c796538b75ac6e114d9d""
@@ -5149,7 +5167,7 @@ lodash@4.17.2:
   version ""4.17.2""
   resolved ""https://registry.npmjs.org/lodash/-/lodash-4.17.2.tgz#34a3055babe04ce42467b607d700072c7ff6bf42""
 
-lodash@4.x, lodash@^4.0.0, lodash@^4.13.1, lodash@^4.14.0, lodash@^4.16.3, lodash@^4.17.2, lodash@^4.17.3, lodash@^4.17.4, lodash@^4.2.0, lodash@^4.2.1, lodash@^4.3.0, lodash@~4.17.4:
+lodash@4.x, lodash@^4.0.0, lodash@^4.13.1, lodash@^4.14.0, lodash@^4.16.3, lodash@^4.17.2, lodash@^4.17.3, lodash@^4.17.4, lodash@^4.17.5, lodash@^4.2.0, lodash@^4.2.1, lodash@^4.3.0, lodash@~4.17.4:
   version ""4.17.5""
   resolved ""https://registry.npmjs.org/lodash/-/lodash-4.17.5.tgz#99a92d65c0272debe8c96b6057bc8fbfa3bed511""
 
@@ -6467,7 +6485,7 @@ promise@^7.1.1:
   dependencies:
     asap ""~2.0.3""
 
-prop-types@^15.6.0:
+prop-types@^15.5.8, prop-types@^15.6.0:
   version ""15.6.1""
   resolved ""https://registry.npmjs.org/prop-types/-/prop-types-15.6.1.tgz#36644453564255ddda391191fb3a125cbdf654ca""
   dependencies:
@@ -6574,7 +6592,7 @@ quick-lru@^1.0.0:
   version ""1.1.0""
   resolved ""https://registry.npmjs.org/quick-lru/-/quick-lru-1.1.0.tgz#4360b17c61136ad38078397ff11416e186dcfbb8""
 
-raf@3.4.0:
+raf@3.4.0, raf@^3.1.0:
   version ""3.4.0""
   resolved ""https://registry.npmjs.org/raf/-/raf-3.4.0.tgz#a28876881b4bc2ca9117d4138163ddb80f781575""
   dependencies:
@@ -6645,9 +6663,9 @@ react-dev-utils@^5.0.0:
     strip-ansi ""3.0.1""
     text-table ""0.2.0""
 
-react-dom@^16.2.0:
-  version ""16.2.0""
-  resolved ""https://registry.npmjs.org/react-dom/-/react-dom-16.2.0.tgz#69003178601c0ca19b709b33a83369fe6124c044""
+react-dom@^16.3.1:
+  version ""16.3.1""
+  resolved ""https://registry.npmjs.org/react-dom/-/react-dom-16.3.1.tgz#6a3c90a4fb62f915bdbcf6204422d93a7d4ca573""
   dependencies:
     fbjs ""^0.8.16""
     loose-envify ""^1.1.0""
@@ -6658,9 +6676,28 @@ react-error-overlay@^4.0.0:
   version ""4.0.0""
   resolved ""https://registry.npmjs.org/react-error-overlay/-/react-error-overlay-4.0.0.tgz#d198408a85b4070937a98667f500c832f86bd5d4""
 
-react@^16.2.0:
-  version ""16.2.0""
-  resolved ""https://registry.npmjs.org/react/-/react-16.2.0.tgz#a31bd2dab89bff65d42134fa187f24d054c273ba""
+react-motion@^0.5.2:
+  version ""0.5.2""
+  resolved ""https://registry.npmjs.org/react-motion/-/react-motion-0.5.2.tgz#0dd3a69e411316567927917c6626551ba0607316""
+  dependencies:
+    performance-now ""^0.2.0""
+    prop-types ""^15.5.8""
+    raf ""^3.1.0""
+
+react-redux@^5.0.7:
+  version ""5.0.7""
+  resolved ""https://registry.npmjs.org/react-redux/-/react-redux-5.0.7.tgz#0dc1076d9afb4670f993ffaef44b8f8c1155a4c8""
+  dependencies:
+    hoist-non-react-statics ""^2.5.0""
+    invariant ""^2.0.0""
+    lodash ""^4.17.5""
+    lodash-es ""^4.17.5""
+    loose-envify ""^1.1.0""
+    prop-types ""^15.6.0""
+
+react@^16.3.1:
+  version ""16.3.1""
+  resolved ""https://registry.npmjs.org/react/-/react-16.3.1.tgz#4a2da433d471251c69b6033ada30e2ed1202cfd8""
   dependencies:
     fbjs ""^0.8.16""
     loose-envify ""^1.1.0""
@@ -6788,6 +6825,15 @@ reduce-function-call@^1.0.1:
   dependencies:
     balanced-match ""^0.4.2""
 
+redux@^3.7.2:
+  version ""3.7.2""
+  resolved ""https://registry.npmjs.org/redux/-/redux-3.7.2.tgz#06b73123215901d25d065be342eb026bc1c8537b""
+  dependencies:
+    lodash ""^4.2.1""
+    lodash-es ""^4.2.1""
+    loose-envify ""^1.1.0""
+    symbol-observable ""^1.0.3""
+
 regenerate@^1.2.1:
   version ""1.3.3""
   resolved ""https://registry.npmjs.org/regenerate/-/regenerate-1.3.3.tgz#0c336d3980553d755c39b586ae3b20aa49c82b7f""
@@ -7811,6 +7857,10 @@ symbol-observable@1.0.1:
   version ""1.0.1""
   resolved ""https://registry.npmjs.org/symbol-observable/-/symbol-observable-1.0.1.tgz#8340fc4702c3122df5d22288f88283f513d3fdd4""
 
+symbol-observable@^1.0.3:
+  version ""1.2.0""
+  resolved ""https://registry.npmjs.org/symbol-observable/-/symbol-observable-1.2.0.tgz#c22688aed4eab3cdc2dfeacbb561660560a00804""
+
 symbol-tree@^3.2.2:
   version ""3.2.2""
   resolved ""https://registry.npmjs.org/symbol-tree/-/symbol-tree-3.2.2.tgz#ae27db38f660a7ae2e1c3b7d1bc290819b8519e6""
",3,"[""84529bcb10c6fe02e2c0079d069ab6c6ac7683d6"", ""60ac03c08f942a8dda49b9f9f7d2ce7a63535414"", ""7e04a5e829d7416e312ac342a00a11787745753b""]","[""refactor"", ""test"", ""build""]"
add test for clickhouse-specific `create_table` parameters | convert to record | add descriptions to buttons on hover,"diff --git a/ibis/backends/clickhouse/tests/test_client.py b/ibis/backends/clickhouse/tests/test_client.py
index 678683d..c4e2aec 100644
--- a/ibis/backends/clickhouse/tests/test_client.py
+++ b/ibis/backends/clickhouse/tests/test_client.py
@@ -224,6 +224,21 @@ def test_create_table_data(con, data, engine, temp_table):
     assert len(t.execute()) == 3
 
 
+def test_create_table_with_properties(con, temp_table):
+    data = pd.DataFrame({""a"": list(""abcde"" * 20), ""b"": [1, 2, 3, 4, 5] * 20})
+    n = len(data)
+    t = con.create_table(
+        temp_table,
+        data,
+        schema=ibis.schema(dict(a=""string"", b=""!uint32"")),
+        order_by=[""a"", ""b""],
+        partition_by=[""a""],
+        sample_by=[""b""],
+        settings={""allow_nullable_key"": ""1""},
+    )
+    assert t.count().execute() == n
+
+
 @pytest.mark.parametrize(
     ""engine"",
     [

diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
index cc998c6..65c8550 100755
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
@@ -167,13 +167,8 @@ public final class ExporterDirectorDistributionTest {
    * <p>This makes sure that even if we miss one export position event, we distribute the event
    * later again, which makes tests less flaky.
    */
-  private static final class ClockShifter implements ConditionEvaluationListener<Void> {
-
-    private final ControlledActorClock clock;
-
-    public ClockShifter(final ControlledActorClock clock) {
-      this.clock = clock;
-    }
+  private record ClockShifter(ControlledActorClock clock)
+      implements ConditionEvaluationListener<Void> {
 
     @Override
     public void conditionEvaluated(final EvaluatedCondition<Void> condition) {

diff --git a/benchmarks/main.mjs b/benchmarks/main.mjs
index 0c2dc6b..e2f79d4 100644
--- a/benchmarks/main.mjs
+++ b/benchmarks/main.mjs
@@ -65,8 +65,9 @@ const vnode = () =>
           },
           style: style({ margin: '5px' }),
           disabled,
+          title: suite.name.split(' | ')[1],
         },
-        [suite.name],
+        [suite.name.split(' | ')[0]],
       ),
     ),
     m(
diff --git a/benchmarks/suites/appendManyRowsToLargeTable.mjs b/benchmarks/suites/appendManyRowsToLargeTable.mjs
index e6a034e..7e34ca3 100644
--- a/benchmarks/suites/appendManyRowsToLargeTable.mjs
+++ b/benchmarks/suites/appendManyRowsToLargeTable.mjs
@@ -31,7 +31,9 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(tr);
 });
 
-const suite = new benchmark.Suite('append many rows to large table');
+const suite = new benchmark.Suite(
+  'append many rows to large table | appending 1,000 to a table of 10,000 rows.',
+);
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/clearRows.mjs b/benchmarks/suites/clearRows.mjs
index ad47036..2a7711b 100644
--- a/benchmarks/suites/clearRows.mjs
+++ b/benchmarks/suites/clearRows.mjs
@@ -27,7 +27,7 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(row);
 });
 
-const suite = new benchmark.Suite('clear rows');
+const suite = new benchmark.Suite('clear rows | clearing a table with 1,000 rows');
 
 const hoistedVNode = m('table', undefined, [], VFlags.NO_CHILDREN);
 
diff --git a/benchmarks/suites/createManyRows.mjs b/benchmarks/suites/createManyRows.mjs
index 578f511..96c7b02 100644
--- a/benchmarks/suites/createManyRows.mjs
+++ b/benchmarks/suites/createManyRows.mjs
@@ -7,7 +7,7 @@ import benchmark from '../benchmark';
 import { m, patch } from '../../src/index';
 import { buildData } from '../data';
 
-const suite = new benchmark.Suite('create many rows');
+const suite = new benchmark.Suite('create many rows | creating 10,000 rows');
 
 const hoistedVNode = m(
   'div',
diff --git a/benchmarks/suites/createRows.mjs b/benchmarks/suites/createRows.mjs
index bfcc876..4d9ff57 100644
--- a/benchmarks/suites/createRows.mjs
+++ b/benchmarks/suites/createRows.mjs
@@ -7,7 +7,7 @@ import benchmark from '../benchmark';
 import { m, patch } from '../../src/index';
 import { buildData } from '../data';
 
-const suite = new benchmark.Suite('create rows');
+const suite = new benchmark.Suite('create rows | creating 1,000 rows');
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/partialUpdate.mjs b/benchmarks/suites/partialUpdate.mjs
index 55948a9..c5f1de3 100644
--- a/benchmarks/suites/partialUpdate.mjs
+++ b/benchmarks/suites/partialUpdate.mjs
@@ -34,7 +34,7 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(tr);
 });
 
-const suite = new benchmark.Suite('partial update');
+const suite = new benchmark.Suite('partial update | updating every 10th row for 1,000 rows');
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/removeRow.mjs b/benchmarks/suites/removeRow.mjs
index aeb1e9a..31c7599 100644
--- a/benchmarks/suites/removeRow.mjs
+++ b/benchmarks/suites/removeRow.mjs
@@ -30,7 +30,7 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(tr);
 });
 
-const suite = new benchmark.Suite('remove row');
+const suite = new benchmark.Suite('remove row | removing one row');
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/replaceAllRows.mjs b/benchmarks/suites/replaceAllRows.mjs
index 9555ae4..7001667 100644
--- a/benchmarks/suites/replaceAllRows.mjs
+++ b/benchmarks/suites/replaceAllRows.mjs
@@ -41,7 +41,7 @@ data2.forEach(({ id, label }) => {
 
 shuffleArray(data2);
 
-const suite = new benchmark.Suite('replace all rows');
+const suite = new benchmark.Suite('replace all rows | updating all 1,000 rows');
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/selectRow.mjs b/benchmarks/suites/selectRow.mjs
index 76be216..de69359 100644
--- a/benchmarks/suites/selectRow.mjs
+++ b/benchmarks/suites/selectRow.mjs
@@ -30,7 +30,7 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(tr);
 });
 
-const suite = new benchmark.Suite('select row');
+const suite = new benchmark.Suite('select row | highlighting a selected row');
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/swapRows.mjs b/benchmarks/suites/swapRows.mjs
index 2a91e74..ce52036 100644
--- a/benchmarks/suites/swapRows.mjs
+++ b/benchmarks/suites/swapRows.mjs
@@ -36,7 +36,7 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(tr);
 });
 
-const suite = new benchmark.Suite('swap rows');
+const suite = new benchmark.Suite('swap rows | swap 2 rows for table with 1,000 rows');
 
 const hoistedVNode = m(
   'table',
",3,"[""7e1ece7d3fd41d1e3ee38e479c119494bb269966"", ""3346331a963766c8193170fb130adad2e658ada2"", ""d8d0ba8ea17ed43a04f90213851d2f27056d8cf0""]","[""test"", ""refactor"", ""feat""]"
get ip from forwarded header,"diff --git a/kousa/lib/broth/socket_handler.ex b/kousa/lib/broth/socket_handler.ex
index d142135..5828f30 100644
--- a/kousa/lib/broth/socket_handler.ex
+++ b/kousa/lib/broth/socket_handler.ex
@@ -22,7 +22,7 @@ defmodule Broth.SocketHandler do
   ## initialization boilerplate
 
   @impl true
-  def init(request = %{peer: {ip, _reverse_port}}, _state) do
+  def init(request, _state) do
     props = :cowboy_req.parse_qs(request)
 
     compression =
@@ -37,10 +37,16 @@ defmodule Broth.SocketHandler do
         _ -> :json
       end
 
+    ip =
+      case request.headers do
+        %{""x-forwarded-for"" => v} -> v
+        _ -> nil
+      end
+
     state = %__MODULE__{
       awaiting_init: true,
       user_id: nil,
-      ip: IP.to_string(ip),
+      ip: ip,
       encoding: encoding,
       compression: compression,
       callers: get_callers(request)
diff --git a/kousa/test/_support/ws_client.ex b/kousa/test/_support/ws_client.ex
index aeca704..125da17 100644
--- a/kousa/test/_support/ws_client.ex
+++ b/kousa/test/_support/ws_client.ex
@@ -19,7 +19,9 @@ defmodule BrothTest.WsClient do
 
     @api_url
     |> Path.join(""socket"")
-    |> WebSockex.start_link(__MODULE__, nil, extra_headers: [{""user-agent"", ancestors}])
+    |> WebSockex.start_link(__MODULE__, nil,
+      extra_headers: [{""user-agent"", ancestors}, {""x-forwarded-for"", ""127.0.0.1""}]
+    )
   end
 
   ###########################################################################
",1,"[""2f5718743a830d40ddf272ad46f253dbb6d08cff""]","[""fix""]"
add a branch name to Slack notifications (#14793) | implement array flatten support,"diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'

diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 2373dd7..4ce03b0 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -422,6 +422,7 @@ operation_registry.update(
         ops.ArrayZip: _array_zip,
         ops.ArraySort: unary(sa.func.array_sort),
         ops.ArrayRepeat: fixed_arity(sa.func.ibis_udfs.public.array_repeat, 2),
+        ops.ArrayFlatten: fixed_arity(sa.func.array_flatten, 1),
         ops.StringSplit: fixed_arity(sa.func.split, 2),
         # snowflake typeof only accepts VARIANT, so we cast
         ops.TypeOf: unary(lambda arg: sa.func.typeof(sa.func.to_variant(arg))),
",2,"[""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da"", ""d3c754f09502be979e5dcc79f968b15052590bd0""]","[""cicd"", ""feat""]"
switch to callback ref | updates the readme to improve the readability and contributing sections,"diff --git a/src/notebook/components/transforms/html.js b/src/notebook/components/transforms/html.js
index 83fc1fb..021cc65 100644
--- a/src/notebook/components/transforms/html.js
+++ b/src/notebook/components/transforms/html.js
@@ -8,16 +8,16 @@ type Props = {
 
 export default class HTMLDisplay extends React.Component {
   props: Props;
+  el: HTMLElement;
 
   componentDidMount(): void {
-    if (this.refs.here) {
-      if (document.createRange && Range && Range.prototype.createContextualFragment) {
-        const range = document.createRange();
-        const fragment = range.createContextualFragment(this.props.data);
-        ReactDOM.findDOMNode(this.refs.here).appendChild(fragment);
-      } else {
-        ReactDOM.findDOMNode(this.refs.here).innerHTML = this.props.data;
-      }
+    // Create a range to ensure that scripts are invoked from within the HTML
+    if (document.createRange && Range && Range.prototype.createContextualFragment) {
+      const range = document.createRange();
+      const fragment = range.createContextualFragment(this.props.data);
+      this.el.appendChild(fragment);
+    } else {
+      this.el.innerHTML = this.props.data;
     }
   }
 
@@ -27,7 +27,7 @@ export default class HTMLDisplay extends React.Component {
 
   render(): ?React.Element<any> {
     return (
-      <div ref=""here"" />
+      <div ref={(el) => { this.el = el; }} />
     );
   }
 }

diff --git a/.github/CONTRIBUTING.md b/.github/CONTRIBUTING.md
index 3c4dd8d..f8b8514 100644
--- a/.github/CONTRIBUTING.md
+++ b/.github/CONTRIBUTING.md
@@ -21,7 +21,8 @@ Contributions are always welcome! Please use the following guidelines when contr
     - `chore` - Catch all or things that have to do with the build system, etc
     - `examples` - Changes to existing example, or a new example
  * The `COMPONENT` is optional, and may be a single file, directory, or logical component. Can be omitted if commit applies globally
-5. Run the tests (`cargo test --no-std-features && cargo test --features yaml`)
+5. Run the tests (`cargo test --features ""yaml unstable""`)
+5. Run the lints (`cargo build --features lints`) (requires a nightly compiler)
 6. `git rebase` into concise commits and remove `--fixup`s (`git rebase -i HEAD~NUM` where `NUM` is number of commits back)
 7. Push your changes back to your fork (`git push origin $your-branch`)
 8. Create a pull request! (You can also create the pull request first, and we'll merge when ready. This a good way to discuss proposed changes.)
diff --git a/README.md b/README.md
index 9e6efce..b74405d 100644
--- a/README.md
+++ b/README.md
@@ -31,7 +31,9 @@ Table of Contents
   * [More Information](#more-information)
     * [Video Tutorials](#video-tutorials)
 * [How to Contribute](#how-to-contribute)
-  * [Running the tests](#running-the-tests)
+  * [Testing Code](#testing-code)
+  * [Linting Code](#linting-code)
+  * [Debugging Code](#debugging-code)
   * [Goals](#goals)
   * [Compatibility Policy](#compatibility-policy)
     * [Minimum Version of Rust](#minimum-version-of-rust)
@@ -43,288 +45,83 @@ Created by [gh-md-toc](https://github.com/ekalinin/github-markdown-toc)
 
 ## What's New
 
-Here's what's new in v2.18.0
+Here's the highlights from v2.0.0 to v2.18.0
 
 * **Completions:**  Adds completion support for Microsoft PowerShell! (Thanks to @Arnavion)
-
-Here's what's new in v2.17.1
-
-* Fixes a bug where using low index multiples was propagated to subcommands
-
-Here's what's new in v2.17.0
-
 * Allows specifying the second to last positional argument as `multiple(true)` (i.e. things such as `mv <files>... <target>`)
 * Adds an `App::get_name` and `App::get_bin_name`
-
-Here's what's new in v2.16.4
-
-* Fixes bug that caused panic on subcommands with aliases
 * Conflicting argument errors are now symetrical, meaning more consistent and better usage suggestions
-* Fixes typo in example `13a_enum_values_automatic`
-* Fixes failing yaml example (#715)
-* Fixes the `debug` feature (#716)
-
-Here's the highlights for v2.16.3
-
-* Fixes a bug where the derived display order isn't propagated
-* **yaml-example:**  fixes some inconsistent args in the example
-
-Here's the highlights for v2.16.2
-
-* Fixes a bug where single quotes are not escaped
-
-Here's the highlights for v2.16.1
-
-* **Help Message:**  fixes a regression bug where args with multiple(true) threw off alignment
-
-Here's the highlights for v2.16.0
-
 * **Completions:**  adds automatic ZSH completion script generation support! :tada: :tada:
-
-Here's a gif of them in action!
-
-![zsh-comppletions](http://i.imgur.com/rwlMbAv.gif)
-
-Here's the highlights for v2.15.0
-
 * **AppSettings:**  adds new setting `AppSettings::AllowNegativeNumbers` which functions like `AllowLeadingHyphen` except only allows undefined negative numbers to pass parsing.
-* Improves some of the documentation of `AppSettings` by moving variants into roughly alphabetical order
-
-Here's the highlights for v2.14.1 (Huge thanks to all the contributors who put in a lot of work this cycle! Especially @tormol @nabijaczleweli and @wdv4758h)
-
 * Stabilize `clap_app!` macro (i.e. no longer need to use `unstable` feature)
-* Fixes a bug that made determining when to auto-wrap long help messages inconsistent
-* Fixes fish completions for nested subcommands
-* Improve documentation around features
-* Reword docs for `ErrorKind` and `App::settings`
-* Fix tests that fail when the `suggestions` feature is disabled
-* Fix the `OsString`-using doc-tests
-* Tag non-rust code blocks as such instead of ignoring them
-* Improve some errors about subcommands
-* Makes sure the doc-tests don't fail before ""missing file"" in YAML tests
 * Deprecate `App::with_defaults`
-* Make lints not enable other nightly-requiring features
-
-Here's the highlights for v2.14.0
-
-* One can now alias arguments either visibly (whichc appears in the help text) or invisibly just like subcommands!
+* One can now alias arguments either visibly (which appears in the help text) or invisibly just like subcommands!
 * The `from_usage` parser now correctly handles non-ascii names / options and help!
-* Fixes a bug in the `require_delimiter` code which caused some incorrect parses
-* Fixes various typos in the docs
-* Various other small performance improvements and enhancements
-
-Here's the highlights for v2.13.0
-
 * **Value Delimiters:**  fixes the confusion around implicitly setting value delimiters. (The default is to *not* use a delimiter unless explicitly set)
-* **Docs:** Updates README.md with new website information and updated video tutorials info
-* **Docs:** Updates the docs about removing implicit `value_delimiter(true)`
-* **Docs:** Adds better examples on using default values
-
-
-Here's the highlights for v2.12.1
-
-* Fixes a regression-bug where the old `{n}` newline char stopped being replaced a properly re-aligned newline
-
-Here's the highlights for v2.12.0
-
 * Changes the default value delimiter rules (i.e. the default is `use_delimiter(false)` *unless* a setting/method that implies multiple values was used) **[Bugfix that *may* ""break"" code]**
  * If code breaks, simply add `Arg::use_delimiter(true)` to the affected args
-* Updates the docs for the `Arg::multiple` method WRT value delimiters and default settings
 * Adds ability to hide the possible values from the help text on a per argument basis, instead of command wide
 * Allows for limiting detected terminal width (i.e. wrap at `x` length, unless the terminal width is *smaller*)
-* Removes some redundant `contains()` checks for minor performance improvements
-* Fixes a bug where valid args aren't recognized with the `AppSettings::AllowLeadingHyphen` setting
 * `clap` now ignores hard newlines in help messages and properly re-aligns text, but still wraps if the term width is too small
-* Makes some minor changes to when next line help is automatically used
 * Adds support for the setting `Arg::require_delimiter` from YAML
-* Removes the verbage about using `'{n}'` to insert newlines in help text from the docs (the normal `\n` can now be used)
-* Documents `AppSetting::DisableVersion`
-
-Here's the highlights for v2.11.3
-
 * `clap` no longer requires one to use `{n}` inside help text to insert a newline that is properly aligned. One can now use the normal `\n`.
 * `clap` now ignores hard newlines in help messages and properly re-aligns text, but still wraps if the term width is too small
-* Supports setting `Arg::require_delimiter` from YAML
-
-Here's the highlights for v2.11.2
-
-* Makes some minor changes to when next line help is automatically used for improved wrapping
-
-Here's the highlights for v2.11.1
-
-* Fixes an issue where settings weren't propogated down through grand-child subcommands
 * Errors can now have custom description
 * Uses `term_size` instead of home-grown solution on Windows
-* Updates deps with some minor bug fixes
-
-
-Here's the highlights for v2.11.0
-
 * Adds the ability to wrap help text intelligently on Windows!
-* Moves docs to [docs.rs!](https://docs.rs/clap/)
-* Fixes some usage strings that contain both args in groups and ones that conflict with each other
-* Uses standard conventions for bash completion files, namely `{bin}.bash-completion`
+* Moves docs to [docs.rs!](https://docs.rs/clap/)!
 * Automatically moves help text to the next line and wraps when term width is determined to be too small, or help text is too long
 * Vastly improves *development* error messages when using YAML
-* Adds `App::with_defaults` to automatically use `crate_authors!` and `crate_version!` macros
-* Other minor improvements and bug fixes
-
-Here's the highlights for v2.10.4
-
-* Fixes a bug where help is wrapped incorrectly and causing a panic with some non-English characters
-
-Here's the highlights for v2.10.3
-
-* Fixes a bug with non-English characters in help text wrapping, where the character is stripped or causes a panic
-* Fixes an issue with `strsim` which caused a panic in some scenarios
 * Adds a shorthand way to ignore help text wrapping and use source formatting (i.e. `App::set_term_width(0)`)
-
-Here's the highlights for v2.10.2
-
-* Fixes a critical bug where the help message is printed twice
-
-Here's the highlights for v2.10.1
-
 * **Help Subcommand:**  fixes misleading usage string when using multi-level subcommmands such as `myprog help subcmd1 subcmd2`
 * **YAML:**  allows using lists or single values with certain arg declarations for increased ergonomics
-
-
-Here's the highlights for v2.10.0
-
-
 * **Fish Shell Completions:**  one can generate a basic fish completions script at compile time!
-* **External SubCommands:**  fixes a bug which now correctly preserves external subcommand name along with args to said command (Minor breaking change that breaks no known real world code)
-* **YAML Documentation:**  fixes example 17's incorrect reference to arg_groups instead of groups
-
-
-Here's the highlights for v2.9.3
-
 * Adds the ability to generate completions to an `io::Write` object
 * Adds an `App::unset_setting` and `App::unset_settings`
-* Fixes bug where only first arg in list of `required_unless_one` is recognized
-* Fixes a typo bug `SubcommandsRequired`->`SubcommandRequired`
-
-
-Here's the highlights for v2.9.2
-
-
-* fixes bug where --help and --version short weren't added to the completion list
-* improves completions allowing multiple bins to have seperate completion files
-
-Here's the highlights for v2.9.0
-
 * **Completions:**  one can now [generate a bash completions](https://docs.rs/clap/2.9.0/clap/struct.App.html#method.gen_completions) script at compile time! These completions work with options using [possible values](https://docs.rs/clap/2.9.0/clap/struct.Arg.html#method.possible_values), [subcommand aliases](https://docs.rs/clap/2.9.0/clap/struct.App.html#method.aliases), and even multiple levels of subcommands
-* Minor bug fixes when using `AppSettings::TrailingVarArg` and `AppSettings::AllowLeadingHyphen`
-
-Here's the highlights for v2.8.0
-
 * **Arg:**  adds new optional setting [`Arg::require_delimiter`](https://docs.rs/clap/2.8.0/clap/struct.Arg.html#method.require_delimiter) which requires val delimiter to parse multiple values
 * The terminal sizing portion has been factored out into a separate crate, [term_size](https://crates.io/crates/term_size)
-* Minor bug fixes
-
-
-Here's the highlights for v2.7.1
-
-* **Options:**
-  *  options using multiple values and delimiters no longer parse additional values after a trailing space (i.e. `prog -o 1,2 file.txt` parses as `1,2` for `-o` and `file.txt` for a positional arg)
-  *  using options using multiple values and with an `=` no longer parse args after the trailing space as values (i.e. `prog -o=1 file.txt` parses as `1` for `-o` and `file.txt` for a positional arg)
-
-Here's the highlights for v2.7.0
-
+* Options using multiple values and delimiters no longer parse additional values after a trailing space (i.e. `prog -o 1,2 file.txt` parses as `1,2` for `-o` and `file.txt` for a positional arg)
+* Using options using multiple values and with an `=` no longer parse args after the trailing space as values (i.e. `prog -o=1 file.txt` parses as `1` for `-o` and `file.txt` for a positional arg)
 * **Usage Strings:**  `[FLAGS]` and `[ARGS]` are no longer blindly added to usage strings, instead only when applicable
 * `arg_enum!`:  allows using more than one meta item, or things like `#[repr(C)]` with `arg_enum!`s
 * `App::print_help`: now prints the same as would have been printed by `--help` or the like
-* **Help Messages:**
- *  prevents invoking `<cmd> help help` and displaying incorrect help message
- *  subcommand help messages requested via `<cmd> help <sub>` now correctly match `<cmd> <sub> --help`
-* **`ArgGroup`s:**
- *  one can now specify groups which require AT LEAST one of the args
- *  allows adding multiple ArgGroups per Arg
- * **Documentation:**  vastly improves `ArgGroup` docs by adding better examples
-* **Documentation:**  fixes a bunch of typos in the documentation
-
-Here's the highlights for v2.6.0
-
+* Prevents invoking `<cmd> help help` and displaying incorrect help message
+* Subcommand help messages requested via `<cmd> help <sub>` now correctly match `<cmd> <sub> --help`
+* One can now specify groups which require AT LEAST one of the args
+* Allows adding multiple ArgGroups per Arg
 * **Global Settings:** One can now set an `AppSetting` which is propogated down through child subcommands
 * **Terminal Wrapping:**  Allows wrapping at specified term width (Even on Windows!) (can now set an absolute width to ""smart"" wrap at)
 * **SubCommands/Aliases:**  adds support for visible aliases for subcommands (i.e. aliases that are dipslayed in the help message)
 * **Subcommands/Aliases:**  when viewing the help of an alias, it now display help of the aliased subcommand
-* Improves the default usage string when only a single positional arg is present
 * Adds new setting to stop delimiting values with `--` or `AppSettings::TrailingVarArg`
-* `App::before_help` and `App::after_help` now correctly wrap
-* Fixes bug where positional args are printed out of order when using templates
-* Fixes bug where one can't override the auto-generated version or help flags
-* Fixes issue where `App::before_help` wasn't printed
-* Fixes a failing windows build
-* Fixes bug where new color settings couldn't be converted from strings
-* Adds missing YAML methods for App and Arg
-* Allows printing version to any io::Write object
-* Removes extra newline from help and version output
-
-Here's what's new in v.2.5.2
-
-*   Removes trailing newlines from help and version output
-*   Allows printing version to any io::Write object
-*   Inter-links all types and pages
-*   Makes all publicly available types viewable in docs
-*   Fixes bug where one can't override version or help flags
-*   Fixes bug where args are printed out of order when using templates
-*   Fixes issue where `App::before_help` wasn't printed properly
-
-Here's what's new in v.2.5.0
-
 * Subcommands now support aliases - think of them as hidden subcommands that dispatch to said subcommand automatically
-
-Here's what's new in v2.4.3
-
-* Bug Fixes
- * Usage strings get de-deuplicated when there are args which are also part ``ArgGroup`s`
- * Fixed times when `ArgGroup`s are duplicated in usage strings
-* Improvements
- * Positional arguments which are part of a group are now formatted in a more readable way (fewer brackets)
- * Positional arguments use the standard `<>` brackets to reduce confusion
- * The default help string for the `help` subcommand has been shortened to fit in 80 columns
-
-Here's the highlights from v2.4.0
-
+* Fixed times when `ArgGroup`s are duplicated in usage strings
 * **Before Help:**  adds support for displaying info before help message
 * **Required Unless:**  adds support for allowing args that are required unless certain other args are present
-* Bug fixes
-
-Here's the highlights from v2.3.0
-
 * **New Help Template Engine!**: Now you have full control over the layout of your help message. Major thanks to @hgrecco
 * **Pull crate Authors from Cargo.toml**: One can now use the `crate_authors!` macro to automatically pull the crate authors from their Cargo.toml file
 * **Colored Help Messages**: Help messages can now be optionally colored (See the `AppSettings::ColoredHelp` setting). Screenshot below.
-* A bunch of bug fixes
-
-Here's the highlights from v2.2.1
-
 * **Help text auto wraps and aligns at for subcommands too!** - Long help strings of subcommands will now properly wrap and align to term width on Linux and OS X. This can be turned off as well.
-* Bug fixes
-
-An example of the optional colored help:
-
-![screenshot](http://i.imgur.com/7fs2h5j.png)
-
-Here's the highlights from v2.2.0
-
 * **Help text auto wraps and aligns at term width!** - Long help strings will now properly wrap and align to term width on Linux and OS X (and presumably Unix too). This can be turned off as well.
 * **Can customize the order of opts, flags, and subcommands in help messages**  - Instead of using the default alphabetical order, you can now re-arrange the order of your args and subcommands in help message. This helps to emphasize more popular or important options.
- * **Can auto-derive the order from declaration order** - Have a bunch of args or subcommmands to re-order? You can now just derive the order from the declaration order!
+* **Can auto-derive the order from declaration order** - Have a bunch of args or subcommmands to re-order? You can now just derive the order from the declaration order!
 * **Help subcommand now accepts other subcommands as arguments!** - Similar to other CLI precedents, the `help` subcommand can now accept other subcommands as arguments to display their help message. i.e. `$ myprog help mysubcmd` (*Note* these can even be nested heavily such as `$ myprog help subcmd1 subcmd2 subcmd3` etc.)
+* **Default Values**: Args can now specify default values
+* **Next Line Help**: Args can have help strings on the line following the argument (useful for long arguments, or those with many values). This can be set command-wide or for individual args
 
-* Other minor bug fixes
+Here's a gif of them in action!
+
+![zsh-comppletions](http://i.imgur.com/rwlMbAv.gif)
 
 An example of the help text wrapping at term width:
 
 ![screenshot](http://i.imgur.com/PAJzJJG.png)
 
-In v2.1.2
+An example of the optional colored help:
+
+![screenshot](http://i.imgur.com/7fs2h5j.png)
 
- * **Default Values**: Args can now specify default values
- * **Next Line Help**: Args can have help strings on the line following the argument (useful for long arguments, or those with many values). This can be set command-wide or for individual args
- * **Documentation Examples**: The examples in the documentation have been vastly improved
 
 For full details, see [CHANGELOG.md](https://github.com/kbknapp/clap-rs/blob/master/CHANGELOG.md)
 
@@ -697,6 +494,7 @@ features = [ ""suggestions"", ""color"" ]
 #### Opt-in features
 
 * **""yaml""**: Enables building CLIs from YAML documents. (builds dependency `yaml-rust`)
+* **""unstable""**: Enables unstable `clap` features that may change from release to release
 
 ### Dependencies Tree
 
@@ -707,6 +505,7 @@ The following graphic depicts `clap`s dependency graph (generated using [cargo-g
  * **Blue** Color: Dev dependency, only used while developing.
 
 ![clap dependencies](clap_dep_graph.png)
+
 ### More Information
 
 You can find complete documentation on the [docs.rs](https://docs.rs/clap/) for this project.
@@ -727,20 +526,65 @@ Another really great way to help is if you find an interesting, or helpful way i
 
 Please read [CONTRIBUTING.md](.github/CONTRIBUTING.md) before you start contributing.
 
+
+### Testing Code
+
 To test with all features both enabled and disabled, you can run theese commands:
 
 ```sh
 $ cargo test --no-default-features
-$ cargo test --features yaml
+$ cargo test --features ""yaml unstable""
 ```
 
-If you have a nightly compiler you can append `--features lints` to both commands
-to get style warnings and code smells; If you get one from code you think is fine,
-you can ignore it by prepending `#[cfg_attr(feature=""lints"", allow(lint_name))]`
-to the function or impl block.
+Alternatively, if you have [`just`](https://github.com/casey/just) installed you can run the prebuilt recipies. *Not* using `just` is prfeclty fine as well, it simply bundles commands automatically.
+
+For example, to test the code, as above simply run:
+
+```sh
+$ just run-tests`
+```
+
+From here on, I will lis the appropriate `cargo` command as well as the `just` command.
+
+Sometimes it's helpful to only run a subset of the tests, which can be done via:
+
+```sh
+$ cargo test --test <test_name>
+
+# Or
+
+$ just run-test <test_name>
+```
 
-If you are debugging (or just trying to understand the code) you can enable the
-""debug"" feature which will trace function calls and brances in some parts of the code.
+### Linting Code
+
+During the CI process `clap` runs against many different lints using [`clippy`](https://github.com/Manishearth/rust-clippy). In order to check if these lints pass on your own computer prior to submitting a PR you'll need a nightly compiler.
+
+In order to check the code for lints run either:
+
+```sh
+$ rustup override add nightly
+$ cargo build --features lints
+$ rustup override remove
+
+# Or
+
+$ just lint
+```
+
+### Debugging Code
+
+Another helpful technique is to see the `clap` debug output while developing features. In order to see the debug output while running the full test suite or individual tests, run:
+
+```sh
+$ cargo test --features debug
+
+# Or for individual tests
+$ cargo test --test <test_name> --features debug
+
+# The corresponding just command for individual debugging tests is:
+$ just debug <test_name>
+```
 
 ### Goals
 
",2,"[""ee4bf61fb8836e249fb4ef3507dc938e70696b3f"", ""eb51316cdfdc7258d287ba13b67ef2f42bd2b8f6""]","[""refactor"", ""docs""]"
"add hardware back button

Closes #5071","diff --git a/ionic/components/app/app.ts b/ionic/components/app/app.ts
index 04d8c57..08aab92 100644
--- a/ionic/components/app/app.ts
+++ b/ionic/components/app/app.ts
@@ -3,8 +3,7 @@ import {Title} from 'angular2/platform/browser';
 
 import {Config} from '../../config/config';
 import {ClickBlock} from '../../util/click-block';
-import {Nav} from '../nav/nav';
-import {Tabs} from '../tabs/tabs';
+import {Platform} from '../../platform/platform';
 
 
 /**
@@ -23,8 +22,20 @@ export class IonicApp {
 
   constructor(
     private _config: Config,
-    private _clickBlock: ClickBlock
-  ) {}
+    private _clickBlock: ClickBlock,
+    platform: Platform
+  ) {
+    platform.backButton.subscribe(() => {
+      let activeNav = this.getActiveNav();
+      if (activeNav) {
+        if (activeNav.length() === 1) {
+          platform.exitApp();
+        } else {
+          activeNav.pop();
+        }
+      }
+    });
+  }
 
   /**
    * Sets the document title.
@@ -102,7 +113,7 @@ export class IonicApp {
   /**
    * @private
    */
-  getActiveNav(): Nav | Tabs {
+  getActiveNav(): any {
     var nav = this._rootNav || null;
     var activeChildNav;
 
",1,"[""68278b00450f2679761a2999500f6d87a579376b""]","[""feat""]"
"add workflow to release branches | never call ""onStart"" prop when idle | common routine for browser timezone

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>","diff --git a/.github/workflows/release-pr.yml b/.github/workflows/release-pr.yml
new file mode 100644
index 0000000..697ca8e
--- /dev/null
+++ b/.github/workflows/release-pr.yml
@@ -0,0 +1,48 @@
+name: release
+
+on:
+  issue_comment:
+    types: [created]
+    contains: ""/trigger release""
+
+env:
+  # 7 GiB by default on GitHub, setting to 6 GiB
+  NODE_OPTIONS: --max-old-space-size=6144
+
+jobs:
+  release-pr:
+    permissions:
+      id-token: write
+    runs-on: ubuntu-latest
+    timeout-minutes: 20
+
+    steps:
+      - name: Ensure action is by maintainer
+        uses: octokit/request-action@v2.x
+        id: check_role
+        with:
+          route: GET /repos/danielroe/roe.dev/collaborators/${{ github.event.comment.user.login }}
+        env:
+          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+
+      - uses: actions/checkout@v3
+        with:
+          fetch-depth: 0
+
+      - run: corepack enable
+      - uses: actions/setup-node@v3
+        with:
+          node-version: 20
+          cache: ""pnpm""
+
+      - name: Install dependencies
+        run: pnpm install
+
+      - name: Build
+        run: pnpm build
+
+      - name: Release Edge
+        run: ./scripts/release-edge.sh
+        env:
+          NODE_AUTH_TOKEN: ${{ secrets.NODE_AUTH_TOKEN }}
+          NPM_CONFIG_PROVENANCE: true
diff --git a/package.json b/package.json
index 1074dcd..48bb566 100644
--- a/package.json
+++ b/package.json
@@ -5,7 +5,7 @@
   ""license"": ""MIT"",
   ""type"": ""module"",
   ""scripts"": {
-    ""build"": ""FORCE_COLOR=1 pnpm --filter './packages/**' prepack"",
+    ""build"": ""pnpm --filter './packages/**' prepack"",
     ""build:stub"": ""pnpm --filter './packages/**' prepack --stub"",
     ""cleanup"": ""rimraf 'packages/**/node_modules' 'examples/**/node_modules' 'docs/node_modules' 'playground/node_modules' 'node_modules'"",
     ""dev"": ""pnpm play"",

diff --git a/packages/core/src/SpringValue.ts b/packages/core/src/SpringValue.ts
index 18494a8..cbc4f27 100644
--- a/packages/core/src/SpringValue.ts
+++ b/packages/core/src/SpringValue.ts
@@ -596,11 +596,11 @@ export class SpringValue<T = any> extends AnimationValue<T> {
   /** Notify change observers */
   protected _onChange(value: T, idle = false) {
     const anim = this.animation
-    if (!anim.changed) {
+    if (!anim.changed && !idle) {
       anim.changed = true
       // The ""onStart"" prop is called on the first change after entering the
       // frameloop, but never for immediate animations.
-      if (anim.onStart && !anim.immediate) {
+      if (anim.onStart) {
         anim.onStart(this)
       }
     }

diff --git a/tests/playwright/tests/db/timezone.spec.ts b/tests/playwright/tests/db/timezone.spec.ts
index c966c2b..a30c7e4 100644
--- a/tests/playwright/tests/db/timezone.spec.ts
+++ b/tests/playwright/tests/db/timezone.spec.ts
@@ -6,6 +6,7 @@ import { Api, UITypes } from 'nocodb-sdk';
 import { ProjectsPage } from '../../pages/ProjectsPage';
 import { isMysql, isPg, isSqlite } from '../../setup/db';
 import { getKnexConfig } from '../utils/config';
+import { getBrowserTimezoneOffset } from '../utils/general';
 let api: Api<any>, records: any[];
 
 const columns = [
@@ -680,11 +681,7 @@ test.describe.serial('External DB - DateTime column', async () => {
     await dashboard.rootPage.waitForTimeout(2000);
 
     // get timezone offset
-    const timezoneOffset = new Date().getTimezoneOffset();
-    const hours = Math.floor(Math.abs(timezoneOffset) / 60);
-    const minutes = Math.abs(timezoneOffset % 60);
-    const sign = timezoneOffset <= 0 ? '+' : '-';
-    const formattedOffset = `${sign}${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}`;
+    const formattedOffset = getBrowserTimezoneOffset();
 
     await dashboard.treeView.openBase({ title: 'datetimetable' });
     await dashboard.treeView.openTable({ title: 'MyTable' });
@@ -844,11 +841,7 @@ test.describe('Ext DB MySQL : DB Timezone configured as HKT', () => {
     }
 
     // get timezone offset
-    const timezoneOffset = new Date().getTimezoneOffset();
-    const hours = Math.floor(Math.abs(timezoneOffset) / 60);
-    const minutes = Math.abs(timezoneOffset % 60);
-    const sign = timezoneOffset <= 0 ? '+' : '-';
-    const formattedOffset = `${sign}${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}`;
+    const formattedOffset = getBrowserTimezoneOffset();
 
     // connect after timezone is set
     await connectToExtDb(context);
diff --git a/tests/playwright/tests/utils/general.ts b/tests/playwright/tests/utils/general.ts
index 56a9e1a..45e9c6c 100644
--- a/tests/playwright/tests/utils/general.ts
+++ b/tests/playwright/tests/utils/general.ts
@@ -50,4 +50,14 @@ function getDefaultPwd() {
   return 'Password123.';
 }
 
-export { getTextExcludeIconText, isSubset, getIconText, getDefaultPwd };
+function getBrowserTimezoneOffset() {
+  // get timezone offset
+  const timezoneOffset = new Date().getTimezoneOffset();
+  const hours = Math.floor(Math.abs(timezoneOffset) / 60);
+  const minutes = Math.abs(timezoneOffset % 60);
+  const sign = timezoneOffset <= 0 ? '+' : '-';
+  const formattedOffset = `${sign}${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}`;
+  return formattedOffset;
+}
+
+export { getTextExcludeIconText, isSubset, getIconText, getDefaultPwd, getBrowserTimezoneOffset };
",3,"[""bc28d536c0dd1061ac96cea0241857c1d4e4e0f2"", ""c8e0ae8612df3d6f2831acc004aaac332f6105e4"", ""7d3e9b3a98b02f6cb1f3444dc7e3a0459aeb26a7""]","[""cicd"", ""fix"", ""test""]"
use module path alias | add activatedElementInstanceKeys to modification record | increment failing test retries,"diff --git a/src/background/audio-manager.ts b/src/background/audio-manager.ts
index 54e8b24..11c5fba 100644
--- a/src/background/audio-manager.ts
+++ b/src/background/audio-manager.ts
@@ -2,7 +2,7 @@
  * To make sure only one audio plays at a time
  */
 
-import { timeout } from '../_helpers/promise-more'
+import { timeout } from '@/_helpers/promise-more'
 
 declare global {
   interface Window {
diff --git a/src/background/context-menus.ts b/src/background/context-menus.ts
index 994b59e..7036362 100644
--- a/src/background/context-menus.ts
+++ b/src/background/context-menus.ts
@@ -1,5 +1,5 @@
-import { storage, openURL } from '../_helpers/browser-api'
-import { AppConfig } from '../app-config'
+import { storage, openURL } from '@/_helpers/browser-api'
+import { AppConfig } from '@/app-config'
 
 import { Observable } from 'rxjs/Observable'
 import { fromPromise } from 'rxjs/observable/fromPromise'
diff --git a/src/background/initialization.ts b/src/background/initialization.ts
index 0e5b3ad..001ee73 100644
--- a/src/background/initialization.ts
+++ b/src/background/initialization.ts
@@ -1,6 +1,6 @@
-import { storage, openURL } from '../_helpers/browser-api'
-import checkUpdate from '../_helpers/check-update'
-import { AppConfig } from '../app-config'
+import { storage, openURL } from '@/_helpers/browser-api'
+import checkUpdate from '@/_helpers/check-update'
+import { AppConfig } from '@/app-config'
 import { mergeConfig } from './merge-config'
 import { init as initMenus } from './context-menus'
 import { init as initPdf } from './pdf-sniffer'
diff --git a/src/background/merge-config.ts b/src/background/merge-config.ts
index afa1800..afdbd63 100644
--- a/src/background/merge-config.ts
+++ b/src/background/merge-config.ts
@@ -1,4 +1,4 @@
-import { appConfigFactory, AppConfig } from '../app-config'
+import { appConfigFactory, AppConfig } from '@/app-config'
 import _ from 'lodash'
 
 /**
@@ -24,7 +24,7 @@ function initConfig (): Promise<AppConfig> {
   const storageObj = { config: appConfigFactory() }
 
   Object.keys(storageObj.config.dicts.all).forEach(id => {
-    storageObj[id] = require('../components/dictionaries/' + id + '/config')
+    storageObj[id] = require('@/components/dictionaries/' + id + '/config')
   })
 
   return browser.storage.sync.set(storageObj)
@@ -70,7 +70,7 @@ function mergeHistorical (config): Promise<AppConfig> {
 
   const storageObj = { config: base }
   Object.keys(base.dicts.all).forEach(id => {
-    storageObj[id] = config.dicts.all[id] || require('../components/dictionaries/' + id + '/config')
+    storageObj[id] = config.dicts.all[id] || require('@/components/dictionaries/' + id + '/config')
   })
 
   return browser.storage.sync.set(storageObj)
diff --git a/src/background/pdf-sniffer.ts b/src/background/pdf-sniffer.ts
index 6ba27cf..70aa38f 100644
--- a/src/background/pdf-sniffer.ts
+++ b/src/background/pdf-sniffer.ts
@@ -2,8 +2,8 @@
  * Open pdf link directly
  */
 
-import { storage } from '../_helpers/browser-api'
-import { AppConfig } from '../app-config'
+import { storage } from '@/_helpers/browser-api'
+import { AppConfig } from '@/app-config'
 
 export function init (pdfSniff: boolean) {
   if (browser.webRequest.onBeforeRequest.hasListener(otherPdfListener)) {
diff --git a/src/background/server.ts b/src/background/server.ts
index 73b34b6..66ed5c0 100644
--- a/src/background/server.ts
+++ b/src/background/server.ts
@@ -1,7 +1,7 @@
-import { DictID } from '../app-config'
-import { message, openURL } from '../_helpers/browser-api'
+import { DictID } from '@/app-config'
+import { message, openURL } from '@/_helpers/browser-api'
 import { play } from './audio-manager'
-import { chsToChz } from '../_helpers/chs-to-chz'
+import { chsToChz } from '@/_helpers/chs-to-chz'
 
 interface MessageOpenUrlWithEscape {
   type: 'OPEN_URL'
@@ -63,7 +63,7 @@ function fetchDictResult (data: MessageFetchDictResult): Promise<void> {
   let search
 
   try {
-    search = require('../components/dictionaries/' + data.dict + '/engine.js')
+    search = require('@/components/dictionaries/' + data.dict + '/engine.js')
   } catch (err) {
     return Promise.reject(err)
   }
diff --git a/test/unit/_helpers/browser-api.spec.ts b/test/unit/_helpers/browser-api.spec.ts
index 1f39145..e327169 100644
--- a/test/unit/_helpers/browser-api.spec.ts
+++ b/test/unit/_helpers/browser-api.spec.ts
@@ -1,4 +1,4 @@
-import { message, storage, openURL } from '../../../src/_helpers/browser-api'
+import { message, storage, openURL } from '@/_helpers/browser-api'
 
 beforeEach(() => {
   browser.flush()
diff --git a/test/unit/_helpers/check-update.spec.ts b/test/unit/_helpers/check-update.spec.ts
index 2abfc57..fd0b678 100644
--- a/test/unit/_helpers/check-update.spec.ts
+++ b/test/unit/_helpers/check-update.spec.ts
@@ -1,4 +1,4 @@
-import checkUpdate from '../../../src/_helpers/check-update'
+import checkUpdate from '@/_helpers/check-update'
 import fetchMock from 'jest-fetch-mock'
 
 describe('Check Update', () => {
diff --git a/test/unit/_helpers/chs-to-chz.spec.ts b/test/unit/_helpers/chs-to-chz.spec.ts
index 295c6ad..21d5229 100644
--- a/test/unit/_helpers/chs-to-chz.spec.ts
+++ b/test/unit/_helpers/chs-to-chz.spec.ts
@@ -1,4 +1,4 @@
-import chsToChz from '../../../src/_helpers/chs-to-chz'
+import chsToChz from '@/_helpers/chs-to-chz'
 
 describe('Chs to Chz', () => {
   it('should convert chs to chz', () => {
diff --git a/test/unit/_helpers/fetch-dom.spec.ts b/test/unit/_helpers/fetch-dom.spec.ts
index a79dda0..bbfbf10 100644
--- a/test/unit/_helpers/fetch-dom.spec.ts
+++ b/test/unit/_helpers/fetch-dom.spec.ts
@@ -1,4 +1,4 @@
-import fetchDom from '../../../src/_helpers/fetch-dom'
+import fetchDom from '@/_helpers/fetch-dom'
 
 class XMLHttpRequestMock {
   static queue: XMLHttpRequestMock[] = []
diff --git a/test/unit/_helpers/lang-check.spec.ts b/test/unit/_helpers/lang-check.spec.ts
index f3e668a..09f30bb 100644
--- a/test/unit/_helpers/lang-check.spec.ts
+++ b/test/unit/_helpers/lang-check.spec.ts
@@ -1,4 +1,4 @@
-import { isContainChinese, isContainEnglish } from '../../../src/_helpers/lang-check'
+import { isContainChinese, isContainEnglish } from '@/_helpers/lang-check'
 
 describe('Language Check', () => {
   it('isContainChinese should return ture if text contains Chinese', () => {
diff --git a/test/unit/_helpers/promise-more.spec.ts b/test/unit/_helpers/promise-more.spec.ts
index 9601c7d..66dc8d9 100644
--- a/test/unit/_helpers/promise-more.spec.ts
+++ b/test/unit/_helpers/promise-more.spec.ts
@@ -1,4 +1,4 @@
-import * as pm from '../../../src/_helpers/promise-more'
+import * as pm from '@/_helpers/promise-more'
 
 describe('Promise More', () => {
   beforeAll(() => {
diff --git a/test/unit/_helpers/selection.spec.ts b/test/unit/_helpers/selection.spec.ts
index 370239a..06812cf 100644
--- a/test/unit/_helpers/selection.spec.ts
+++ b/test/unit/_helpers/selection.spec.ts
@@ -1,4 +1,4 @@
-import selection from '../../../src/_helpers/selection'
+import selection from '@/_helpers/selection'
 
 describe('Selection', () => {
   const bakSelection = window.getSelection
diff --git a/test/unit/_helpers/strip-script.spec.ts b/test/unit/_helpers/strip-script.spec.ts
index cce558f..355b382 100644
--- a/test/unit/_helpers/strip-script.spec.ts
+++ b/test/unit/_helpers/strip-script.spec.ts
@@ -1,4 +1,4 @@
-import stripScript from '../../../src/_helpers/strip-script'
+import stripScript from '@/_helpers/strip-script'
 
 describe('Strip Script', () => {
   const expectedEl = document.createElement('div') as HTMLDivElement
diff --git a/test/unit/background/audio-manager.spec.ts b/test/unit/background/audio-manager.spec.ts
index b0096a6..b1266d7 100644
--- a/test/unit/background/audio-manager.spec.ts
+++ b/test/unit/background/audio-manager.spec.ts
@@ -1,4 +1,4 @@
-import audio from '../../../src/background/audio-manager'
+import audio from '@/background/audio-manager'
 
 describe('Audio Manager', () => {
   const bakAudio = (window as any).Audio
diff --git a/test/unit/background/context-menus.spec.ts b/test/unit/background/context-menus.spec.ts
index 39e249c..d9049dc 100644
--- a/test/unit/background/context-menus.spec.ts
+++ b/test/unit/background/context-menus.spec.ts
@@ -1,4 +1,4 @@
-import { appConfigFactory, AppConfig } from '../../../src/app-config'
+import { appConfigFactory, AppConfig } from '@/app-config'
 import sinon from 'sinon'
 
 function specialConfig () {
@@ -11,7 +11,7 @@ describe('Context Menus', () => {
   beforeAll(() => {
     browser.flush()
     jest.resetModules()
-    require('../../../src/background/context-menus')
+    require('@/background/context-menus')
   })
   afterAll(() => browser.flush())
 
@@ -93,7 +93,7 @@ describe('Context Menus', () => {
       browser.contextMenus.create.callsFake((_, cb) => cb())
       config = specialConfig()
       jest.resetModules()
-      const { init } = require('../../../src/background/context-menus')
+      const { init } = require('@/background/context-menus')
       init(config.contextMenus)
     })
 
@@ -110,7 +110,7 @@ describe('Context Menus', () => {
     it('should not init setup when called multiple times', () => {
       expect(browser.contextMenus.removeAll.calledOnce).toBeTruthy()
 
-      const { init } = require('../../../src/background/context-menus')
+      const { init } = require('@/background/context-menus')
       init(config.contextMenus)
       init(config.contextMenus)
 
diff --git a/test/unit/background/initialization.spec.ts b/test/unit/background/initialization.spec.ts
index 7bc0972..56a6389 100644
--- a/test/unit/background/initialization.spec.ts
+++ b/test/unit/background/initialization.spec.ts
@@ -1,4 +1,4 @@
-import { appConfigFactory, AppConfig } from '../../../src/app-config'
+import { appConfigFactory, AppConfig } from '@/app-config'
 import fetchMock from 'jest-fetch-mock'
 import sinon from 'sinon'
 
@@ -11,12 +11,12 @@ describe('Initialization', () => {
   const checkUpdate = jest.fn().mockReturnValue(Promise.resolve())
 
   beforeAll(() => {
-    const { message, storage } = require('../../../src/_helpers/browser-api')
+    const { message, storage } = require('@/_helpers/browser-api')
     window.fetch = fetchMock
 
     browser.flush()
     jest.resetModules()
-    jest.doMock('../../../src/background/merge-config', () => {
+    jest.doMock('@/background/merge-config', () => {
       return {
         mergeConfig (config) {
           mergeConfig(config)
@@ -24,16 +24,16 @@ describe('Initialization', () => {
         }
       }
     })
-    jest.doMock('../../../src/background/context-menus', () => {
+    jest.doMock('@/background/context-menus', () => {
       return { init: initMenus }
     })
-    jest.doMock('../../../src/background/pdf-sniffer', () => {
+    jest.doMock('@/background/pdf-sniffer', () => {
       return { init: initPdf }
     })
-    jest.doMock('../../../src/_helpers/check-update', () => {
+    jest.doMock('@/_helpers/check-update', () => {
       return checkUpdate
     })
-    jest.doMock('../../../src/_helpers/browser-api', () => {
+    jest.doMock('@/_helpers/browser-api', () => {
       return {
         message,
         storage,
@@ -41,13 +41,13 @@ describe('Initialization', () => {
       }
     })
 
-    require('../../../src/background/initialization')
+    require('@/background/initialization')
   })
   afterAll(() => {
     browser.flush()
-    jest.dontMock('../../../src/background/merge-config')
-    jest.dontMock('../../../src/background/context-menus')
-    jest.dontMock('../../../src/_helpers/browser-api')
+    jest.dontMock('@/background/merge-config')
+    jest.dontMock('@/background/context-menus')
+    jest.dontMock('@/_helpers/browser-api')
     window.fetch = bakFetch
   })
 
diff --git a/test/unit/background/merge-config.spec.ts b/test/unit/background/merge-config.spec.ts
index 73c047d..c0dce26 100644
--- a/test/unit/background/merge-config.spec.ts
+++ b/test/unit/background/merge-config.spec.ts
@@ -1,5 +1,5 @@
-import { appConfigFactory, AppConfig, AppConfigMutable } from '../../../src/app-config'
-import mergeConfig from '../../../src/background/merge-config'
+import { appConfigFactory, AppConfig, AppConfigMutable } from '@/app-config'
+import mergeConfig from '@/background/merge-config'
 import sinon from 'sinon'
 
 describe('Merge Config', () => {
diff --git a/test/unit/background/pdf-sniffer.spec.ts b/test/unit/background/pdf-sniffer.spec.ts
index a0219d2..bb7726f 100644
--- a/test/unit/background/pdf-sniffer.spec.ts
+++ b/test/unit/background/pdf-sniffer.spec.ts
@@ -1,5 +1,5 @@
-import { appConfigFactory, AppConfig } from '../../../src/app-config'
-import { init as initPdf } from '../../../src/background/pdf-sniffer'
+import { appConfigFactory, AppConfig } from '@/app-config'
+import { init as initPdf } from '@/background/pdf-sniffer'
 import sinon from 'sinon'
 
 function hasListenerPatch (fn) {
diff --git a/test/unit/background/server.spec.ts b/test/unit/background/server.spec.ts
index b8ef065..aa04525 100644
--- a/test/unit/background/server.spec.ts
+++ b/test/unit/background/server.spec.ts
@@ -1,5 +1,5 @@
-import { appConfigFactory, AppConfig } from '../../../src/app-config'
-import * as browserWrap from '../../../src/_helpers/browser-api'
+import { appConfigFactory, AppConfig } from '@/app-config'
+import * as browserWrap from '@/_helpers/browser-api'
 import sinon from 'sinon'
 
 describe('Server', () => {
@@ -13,26 +13,26 @@ describe('Server', () => {
   browserWrap.openURL = openURL
 
   beforeAll(() => {
-    jest.doMock('../../../src/_helpers/chs-to-chz', () => {
+    jest.doMock('@/_helpers/chs-to-chz', () => {
       return { chsToChz }
     })
-    jest.doMock('../../../src/background/audio-manager', () => {
+    jest.doMock('@/background/audio-manager', () => {
       return { play }
     })
-    jest.doMock('../../../src/_helpers/browser-api', () => {
+    jest.doMock('@/_helpers/browser-api', () => {
       return browserWrap
     })
-    jest.doMock('../../../src/components/dictionaries/bing/engine.js', () => {
+    jest.doMock('@/components/dictionaries/bing/engine.js', () => {
       return bingSearch
     })
   })
 
   afterAll(() => {
     browser.flush()
-    jest.dontMock('../../../src/_helpers/chs-to-chz')
-    jest.dontMock('../../../src/background/audio-manager')
-    jest.dontMock('../../../src/_helpers/browser-api')
-    jest.dontMock('../../../src/components/dictionaries/bing/engine.js')
+    jest.dontMock('@/_helpers/chs-to-chz')
+    jest.dontMock('@/background/audio-manager')
+    jest.dontMock('@/_helpers/browser-api')
+    jest.dontMock('@/components/dictionaries/bing/engine.js')
   })
 
   beforeEach(() => {
@@ -46,7 +46,7 @@ describe('Server', () => {
     bingSearch.mockReset()
     bingSearch.mockImplementation(() => Promise.resolve())
     jest.resetModules()
-    require('../../../src/background/server')
+    require('@/background/server')
   })
 
   it('should properly init', () => {

diff --git a/protocol-impl/src/test/java/io/camunda/zeebe/protocol/impl/JsonSerializableToJsonTest.java b/protocol-impl/src/test/java/io/camunda/zeebe/protocol/impl/JsonSerializableToJsonTest.java
index 33410da..edd0588 100644
--- a/protocol-impl/src/test/java/io/camunda/zeebe/protocol/impl/JsonSerializableToJsonTest.java
+++ b/protocol-impl/src/test/java/io/camunda/zeebe/protocol/impl/JsonSerializableToJsonTest.java
@@ -787,7 +787,8 @@ final class JsonSerializableToJsonTest {
               }
             }],
             ""elementId"": ""activity""
-          }]
+          }],
+          ""activatedElementInstanceKeys"": []
         }
         """"""
       },
@@ -803,7 +804,8 @@ final class JsonSerializableToJsonTest {
         {
           ""processInstanceKey"": 1,
           ""terminateInstructions"": [],
-          ""activateInstructions"": []
+          ""activateInstructions"": [],
+          ""activatedElementInstanceKeys"": []
         }
         """"""
       },

diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
",3,"[""8246d024f21d93cc092e19bede5f7b3a5325c8dc"", ""f7cc7b263afeb27eef393b7497db8dad8ebb0518"", ""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57""]","[""refactor"", ""test"", ""cicd""]"
add instruction for finding version | ignore all markdown files for backend and main test suites,"diff --git a/.github/ISSUE_TEMPLATE/_bug_report_chs.md b/.github/ISSUE_TEMPLATE/_bug_report_chs.md
index 42a2e0f..44a33db 100644
--- a/.github/ISSUE_TEMPLATE/_bug_report_chs.md
+++ b/.github/ISSUE_TEMPLATE/_bug_report_chs.md
@@ -36,7 +36,7 @@ assignees: ''
 ## 
 - : [] <!--  [Window10] -->
 - : [] <!--  [Chrome77] -->
-- : [] <!--  [v7.0.0] -->
+- : [] <!--  [v7.0.0]  -->
 
 <!--  ##  -->
 

diff --git a/.github/workflows/ibis-backends-skip-helper.yml b/.github/workflows/ibis-backends-skip-helper.yml
index efd0953..058f8b6 100644
--- a/.github/workflows/ibis-backends-skip-helper.yml
+++ b/.github/workflows/ibis-backends-skip-helper.yml
@@ -7,6 +7,7 @@ on:
     paths:
       - ""docs/**""
       - ""mkdocs.yml""
+      - ""**/*.md""
     branches:
       - master
       - ""*.x.x""
@@ -14,6 +15,7 @@ on:
     paths:
       - ""docs/**""
       - ""mkdocs.yml""
+      - ""**/*.md""
     branches:
       - master
       - ""*.x.x""
diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index d18e62d..144562c 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -3,18 +3,20 @@ name: Backends
 
 on:
   push:
-    # Skip the backend suite if all changes are in the docs directory
+    # Skip the backend suite if all changes are docs
     paths-ignore:
       - ""docs/**""
       - ""mkdocs.yml""
+      - ""**/*.md""
     branches:
       - master
       - ""*.x.x""
   pull_request:
-    # Skip the backend suite if all changes are in the docs directory
+    # Skip the backend suite if all changes are docs
     paths-ignore:
       - ""docs/**""
       - ""mkdocs.yml""
+      - ""**/*.md""
     branches:
       - master
       - ""*.x.x""
diff --git a/.github/workflows/ibis-main-skip-helper.yml b/.github/workflows/ibis-main-skip-helper.yml
index f6086e1..7d79af7 100644
--- a/.github/workflows/ibis-main-skip-helper.yml
+++ b/.github/workflows/ibis-main-skip-helper.yml
@@ -7,6 +7,7 @@ on:
     paths:
       - ""docs/**""
       - ""mkdocs.yml""
+      - ""**/*.md""
     branches:
       - master
       - ""*.x.x""
@@ -14,6 +15,7 @@ on:
     paths:
       - ""docs/**""
       - ""mkdocs.yml""
+      - ""**/*.md""
     branches:
       - master
       - ""*.x.x""
diff --git a/.github/workflows/ibis-main.yml b/.github/workflows/ibis-main.yml
index d5b0735..3d22bff 100644
--- a/.github/workflows/ibis-main.yml
+++ b/.github/workflows/ibis-main.yml
@@ -7,6 +7,7 @@ on:
     paths-ignore:
       - ""docs/**""
       - ""mkdocs.yml""
+      - ""**/*.md""
     branches:
       - master
       - ""*.x.x""
@@ -15,6 +16,7 @@ on:
     paths-ignore:
       - ""docs/**""
       - ""mkdocs.yml""
+      - ""**/*.md""
     branches:
       - master
       - ""*.x.x""
",2,"[""af0a5f7ab9d71fe20aa0888f682368f32b26fe18"", ""370830b8c9f971fa537f42308ab5e3ff356919f8""]","[""docs"", ""cicd""]"
update README.md about the NPM package | i18n for Time Picker | run nix macos jobs on macos-13 to try and avoid SIP,"diff --git a/README.md b/README.md
index 9faf168..bbb5b5c 100644
--- a/README.md
+++ b/README.md
@@ -126,23 +126,24 @@ pacman -S git-cliff
 
 ### From NPM
 
-[git-cliff](https://www.npmjs.com/package/git-cliff) can be installed from NPM:
+
+You can install and run [git-cliff](https://www.npmjs.com/package/git-cliff) with a single command:
 
 ```sh
-yarn add -D git-cliff
+npx git-cliff@latest
 ```
 
-or:
+Also, if you want to add `git-cliff` to your project:
 
 ```sh
+# with yarn
+yarn add -D git-cliff
+
+# with npm
 npm install git-cliff --save-dev
 ```
 
-You can also use `git-cliff` directly with `npx`:
-
-```sh
-npx git-cliff
-```
+Afterwards, you can run `git-cliff` via `npm exec git-cliff` or `npx git-cliff@latest`.
 
 ### From MacPorts
 

diff --git a/packages/nc-gui/components/cell/TimePicker.vue b/packages/nc-gui/components/cell/TimePicker.vue
index 619ab45..7f66828 100644
--- a/packages/nc-gui/components/cell/TimePicker.vue
+++ b/packages/nc-gui/components/cell/TimePicker.vue
@@ -38,6 +38,8 @@ const isTimeInvalid = ref(false)
 
 const dateFormat = isMysql(column.value.base_id) ? 'YYYY-MM-DD HH:mm:ss' : 'YYYY-MM-DD HH:mm:ssZ'
 
+const { t } = useI18n()
+
 const localState = computed({
   get() {
     if (!modelValue) {
@@ -89,11 +91,11 @@ watch(
 
 const placeholder = computed(() => {
   if (isEditColumn.value && (modelValue === '' || modelValue === null)) {
-    return '(Optional)'
+    return t('labels.optional')
   } else if (modelValue === null && showNull.value) {
-    return 'NULL'
+    return t('general.null')
   } else if (isTimeInvalid.value) {
-    return 'Invalid time'
+    return t('msg.invalidTime')
   } else {
     return ''
   }

diff --git a/.github/actionlint.yaml b/.github/actionlint.yaml
new file mode 100644
index 0000000..5be7d17
--- /dev/null
+++ b/.github/actionlint.yaml
@@ -0,0 +1,7 @@
+self-hosted-runner:
+  # Labels of self-hosted runner in array of strings.
+  labels: [macos-13]
+# Configuration variables in array of strings defined in your repository or
+# organization. `null` means disabling configuration variables check.
+# Empty array means no configuration variable is allowed.
+config-variables: null
diff --git a/.github/workflows/nix.yml b/.github/workflows/nix.yml
index e37346c..dce77e1 100644
--- a/.github/workflows/nix.yml
+++ b/.github/workflows/nix.yml
@@ -37,7 +37,7 @@ jobs:
           - ""3.10""
           - ""3.11""
         include:
-          - os: macos-latest
+          - os: macos-13
             python-version: ""3.10""
     steps:
       - name: checkout
diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 005a850..8db22e2 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -3,7 +3,7 @@ ci:
   autofix_prs: false
   autoupdate_commit_msg: ""chore(deps): pre-commit.ci autoupdate""
   skip:
-    - actionlint
+    - actionlint-system
     - deadnix
     - just
     - nixpkgs-fmt
@@ -17,9 +17,9 @@ default_stages:
   - commit
 repos:
   - repo: https://github.com/rhysd/actionlint
-    rev: v1.6.24
+    rev: v1.6.25
     hooks:
-      - id: actionlint
+      - id: actionlint-system
   - repo: https://github.com/psf/black
     rev: 23.3.0
     hooks:
@@ -30,7 +30,7 @@ repos:
       - id: nbstripout
         exclude: .+/rendered/.+
   - repo: https://github.com/codespell-project/codespell
-    rev: v2.2.4
+    rev: v2.2.5
     hooks:
       - id: codespell
         additional_dependencies:
",3,"[""e0177c25e13812306aab0b0991562d58b6d14767"", ""48806e3675c7b18327e7629827454d7c29be25a9"", ""54cb6d4643b4a072ff997592a7fa14a69a6c068d""]","[""docs"", ""fix"", ""cicd""]"
post installers compatiblity with Windows #2520,"diff --git a/packages/cubejs-databricks-jdbc-driver/package.json b/packages/cubejs-databricks-jdbc-driver/package.json
index cc164f0..fd7ad45 100644
--- a/packages/cubejs-databricks-jdbc-driver/package.json
+++ b/packages/cubejs-databricks-jdbc-driver/package.json
@@ -14,13 +14,16 @@
   },
   ""main"": ""dist/src/index.js"",
   ""typings"": ""dist/src/index.d.ts"",
+  ""bin"": {
+    ""databricks-jdbc-installer"": ""bin/post-install""
+  },
   ""scripts"": {
     ""build"": ""rm -rf dist && npm run tsc"",
     ""tsc"": ""tsc"",
     ""watch"": ""tsc -w"",
     ""lint"": ""eslint src/* --ext .ts"",
     ""lint:fix"": ""eslint --fix src/* --ext .ts"",
-    ""postinstall"": ""bin/post-install""
+    ""postinstall"": ""databricks-jdbc-installer""
   },
   ""files"": [
     ""README.md"",
diff --git a/rust/package.json b/rust/package.json
index b139279..5bf6446 100644
--- a/rust/package.json
+++ b/rust/package.json
@@ -8,7 +8,8 @@
     ""node"": "">=10.8.0""
   },
   ""bin"": {
-    ""cubestore-dev"": ""bin/cubestore-dev""
+    ""cubestore-dev"": ""bin/cubestore-dev"",
+    ""cubestore-installer"": ""bin/post-install""
   },
   ""scripts"": {
     ""build"": ""rm -rf dist && npm run tsc"",
@@ -18,7 +19,7 @@
     ""lint:fix"": ""eslint --fix js-wrapper/* --ext .ts,js"",
     ""unit"": ""jest"",
     ""unit:debug"": ""jest --runInBand"",
-    ""postinstall"": ""bin/post-install""
+    ""postinstall"": ""cubestore-installer""
   },
   ""files"": [
     ""dist"",
diff --git a/yarn.lock b/yarn.lock
index d2a4038..b59bb77 100644
--- a/yarn.lock
+++ b/yarn.lock
@@ -4036,9 +4036,9 @@
   integrity sha512-7btbphLrKvo5yl/5CC2OCxUSMx1wV1wvGT1qDXkSt7yi00/YW7E8k6qzXqJHsp+WU0eoG7r6MTQQXI9lIvd0qA==
 
 ""@types/fs-extra@^9.0.1"", ""@types/fs-extra@^9.0.2"", ""@types/fs-extra@^9.0.8"":
-  version ""9.0.10""
-  resolved ""https://registry.yarnpkg.com/@types/fs-extra/-/fs-extra-9.0.10.tgz#8023a72e3d06cf54929ea47ec7634e47f33f4046""
-  integrity sha512-O9T2LLkRDiTlalOBdjEkcnT0MRdT2+wglCl7pJUJ3mkWkR8hX4K+5bg2raQNJcLv4V8zGuTXe7Ud3wSqkTyuyQ==
+  version ""9.0.11""
+  resolved ""https://registry.yarnpkg.com/@types/fs-extra/-/fs-extra-9.0.11.tgz#8cc99e103499eab9f347dbc6ca4e99fb8d2c2b87""
+  integrity sha512-mZsifGG4QeQ7hlkhO56u7zt/ycBgGxSVsFI/6lGTU34VtwkiqrrSDgw0+ygs8kFGWcXnFQWMrzF2h7TtDFNixA==
   dependencies:
     ""@types/node"" ""*""
 
@@ -5306,9 +5306,9 @@ acorn@^7.0.0, acorn@^7.1.0, acorn@^7.1.1, acorn@^7.4.0:
   integrity sha512-nQyp0o1/mNdbTO1PO6kHkwSrmgZ0MT/jCCpNiwbUjGoRN4dlBhqJtoQuCnEOKzgTVwg0ZWiCoQy6SxMebQVh8A==
 
 acorn@^8.1.0:
-  version ""8.1.0""
-  resolved ""https://registry.yarnpkg.com/acorn/-/acorn-8.1.0.tgz#52311fd7037ae119cbb134309e901aa46295b3fe""
-  integrity sha512-LWCF/Wn0nfHOmJ9rzQApGnxnvgfROzGilS8936rqN/lfcYkY9MYZzdMqN+2NJ4SlTc+m5HiSa+kNfDtI64dwUA==
+  version ""8.1.1""
+  resolved ""https://registry.yarnpkg.com/acorn/-/acorn-8.1.1.tgz#fb0026885b9ac9f48bac1e185e4af472971149ff""
+  integrity sha512-xYiIVjNuqtKXMxlRMDc6mZUhXehod4a3gbZ1qRlM7icK4EbxUFNLhWoPblCvFtB2Y9CIqHP3CF/rdxLItaQv8g==
 
 adal-node@^0.1.28:
   version ""0.1.28""
@@ -5441,9 +5441,9 @@ ajv@^6.1.0, ajv@^6.10.0, ajv@^6.10.2, ajv@^6.12.2, ajv@^6.12.3, ajv@^6.12.4, ajv
     uri-js ""^4.2.2""
 
 ajv@^8.0.1:
-  version ""8.0.5""
-  resolved ""https://registry.yarnpkg.com/ajv/-/ajv-8.0.5.tgz#f07d6fdeffcdbb80485570ce3f1bc845fcc812b9""
-  integrity sha512-RkiLa/AeJx7+9OvniQ/qeWu0w74A8DiPPBclQ6ji3ZQkv5KamO+QGpqmi7O4JIw3rHGUXZ6CoP9tsAkn3gyazg==
+  version ""8.1.0""
+  resolved ""https://registry.yarnpkg.com/ajv/-/ajv-8.1.0.tgz#45d5d3d36c7cdd808930cc3e603cf6200dbeb736""
+  integrity sha512-B/Sk2Ix7A36fs/ZkuGLIR86EdjbgR6fsAcbx9lOP/QBSXujDNbVmIS/U4Itz5k8fPFDeVZl/zQ/gJW4Jrq6XjQ==
   dependencies:
     fast-deep-equal ""^3.1.1""
     json-schema-traverse ""^1.0.0""
@@ -6828,15 +6828,15 @@ browserslist@4.14.2:
     node-releases ""^1.1.61""
 
 browserslist@^4.0.0, browserslist@^4.11.1, browserslist@^4.12.0, browserslist@^4.14.5, browserslist@^4.16.3, browserslist@^4.3.4, browserslist@^4.6.2, browserslist@^4.6.4, browserslist@^4.7.0, browserslist@^4.9.1:
-  version ""4.16.3""
-  resolved ""https://registry.yarnpkg.com/browserslist/-/browserslist-4.16.3.tgz#340aa46940d7db878748567c5dea24a48ddf3717""
-  integrity sha512-vIyhWmIkULaq04Gt93txdh+j02yX/JzlyhLYbV3YQCn/zvES3JnY7TifHHvvr1w5hTDluNKMkV05cs4vy8Q7sw==
+  version ""4.16.4""
+  resolved ""https://registry.yarnpkg.com/browserslist/-/browserslist-4.16.4.tgz#7ebf913487f40caf4637b892b268069951c35d58""
+  integrity sha512-d7rCxYV8I9kj41RH8UKYnvDYCRENUlHRgyXy/Rhr/1BaeLGfiCptEdFE8MIrvGfWbBFNjVYx76SQWvNX1j+/cQ==
   dependencies:
-    caniuse-lite ""^1.0.30001181""
-    colorette ""^1.2.1""
-    electron-to-chromium ""^1.3.649""
+    caniuse-lite ""^1.0.30001208""
+    colorette ""^1.2.2""
+    electron-to-chromium ""^1.3.712""
     escalade ""^3.1.1""
-    node-releases ""^1.1.70""
+    node-releases ""^1.1.71""
 
 bs-logger@0.x:
   version ""0.2.6""
@@ -7217,7 +7217,7 @@ caniuse-api@^3.0.0:
     lodash.memoize ""^4.1.2""
     lodash.uniq ""^4.5.0""
 
-caniuse-lite@^1.0.0, caniuse-lite@^1.0.30000981, caniuse-lite@^1.0.30001032, caniuse-lite@^1.0.30001061, caniuse-lite@^1.0.30001109, caniuse-lite@^1.0.30001125, caniuse-lite@^1.0.30001181:
+caniuse-lite@^1.0.0, caniuse-lite@^1.0.30000981, caniuse-lite@^1.0.30001032, caniuse-lite@^1.0.30001061, caniuse-lite@^1.0.30001109, caniuse-lite@^1.0.30001125, caniuse-lite@^1.0.30001208:
   version ""1.0.30001208""
   resolved ""https://registry.yarnpkg.com/caniuse-lite/-/caniuse-lite-1.0.30001208.tgz#a999014a35cebd4f98c405930a057a0d75352eb9""
   integrity sha512-OE5UE4+nBOro8Dyvv0lfx+SRtfVIOM9uhKqFmJeUbGriqhhStgp1A0OyBpgy3OUF8AhYCT+PVwPC1gMl2ZcQMA==
@@ -9549,10 +9549,10 @@ ejs@^2.6.1:
   resolved ""https://registry.yarnpkg.com/ejs/-/ejs-2.7.4.tgz#48661287573dcc53e366c7a1ae52c3a120eec9ba""
   integrity sha512-7vmuyh5+kuUyJKePhQfRQBhXV5Ce+RnaeeQArKu1EAMpL3WbgMt5WG6uQZpEVvYSSsxMXRKOewtDk9RaTKXRlA==
 
-electron-to-chromium@^1.3.564, electron-to-chromium@^1.3.649:
-  version ""1.3.711""
-  resolved ""https://registry.yarnpkg.com/electron-to-chromium/-/electron-to-chromium-1.3.711.tgz#92c3caf7ffed5e18bf63f66b4b57b4db2409c450""
-  integrity sha512-XbklBVCDiUeho0PZQCjC25Ha6uBwqqJeyDhPLwLwfWRAo4x+FZFsmu1pPPkXT+B4MQMQoQULfyaMltDopfeiHQ==
+electron-to-chromium@^1.3.564, electron-to-chromium@^1.3.712:
+  version ""1.3.712""
+  resolved ""https://registry.yarnpkg.com/electron-to-chromium/-/electron-to-chromium-1.3.712.tgz#ae467ffe5f95961c6d41ceefe858fc36eb53b38f""
+  integrity sha512-3kRVibBeCM4vsgoHHGKHmPocLqtFAGTrebXxxtgKs87hNUzXrX2NuS3jnBys7IozCnw7viQlozxKkmty2KNfrw==
 
 elegant-spinner@^1.0.1:
   version ""1.0.1""
@@ -9945,9 +9945,9 @@ eslint-plugin-import@^2.16.0, eslint-plugin-import@^2.18.2, eslint-plugin-import
     tsconfig-paths ""^3.9.0""
 
 eslint-plugin-jest@^24.1.0:
-  version ""24.3.4""
-  resolved ""https://registry.yarnpkg.com/eslint-plugin-jest/-/eslint-plugin-jest-24.3.4.tgz#6d90c3554de0302e879603dd6405474c98849f19""
-  integrity sha512-3n5oY1+fictanuFkTWPwSlehugBTAgwLnYLFsCllzE3Pl1BwywHl5fL0HFxmMjoQY8xhUDk8uAWc3S4JOHGh3A==
+  version ""24.3.5""
+  resolved ""https://registry.yarnpkg.com/eslint-plugin-jest/-/eslint-plugin-jest-24.3.5.tgz#71f0b580f87915695c286c3f0eb88cf23664d044""
+  integrity sha512-XG4rtxYDuJykuqhsOqokYIR84/C8pRihRtEpVskYLbIIKGwPNW2ySxdctuVzETZE+MbF/e7wmsnbNVpzM0rDug==
   dependencies:
     ""@typescript-eslint/experimental-utils"" ""^4.0.1""
 
@@ -12140,12 +12140,11 @@ http-proxy-middleware@0.19.1:
     micromatch ""^3.1.10""
 
 http-proxy-middleware@^1.0.0:
-  version ""1.1.0""
-  resolved ""https://registry.yarnpkg.com/http-proxy-middleware/-/http-proxy-middleware-1.1.0.tgz#b896b2cc6836019af4a4f2d5f7b21b99c77ea13f""
-  integrity sha512-OnjU5vyVgcZVe2AjLJyMrk8YLNOC2lspCHirB5ldM+B/dwEfZ5bgVTrFyzE9R7xRWAP/i/FXtvIqKjTNEZBhBg==
+  version ""1.1.1""
+  resolved ""https://registry.yarnpkg.com/http-proxy-middleware/-/http-proxy-middleware-1.1.1.tgz#48900a68cd9d388c735d1dd97302c919b7e94a13""
+  integrity sha512-FIDg9zPvOwMhQ3XKB2+vdxK6WWbVAH7s5QpqQCif7a1TNL76GNAATWA1sy6q2gSfss8UJ/Nwza3N6QnFkKclpA==
   dependencies:
     ""@types/http-proxy"" ""^1.17.5""
-    camelcase ""^6.2.0""
     http-proxy ""^1.18.1""
     is-glob ""^4.0.1""
     is-plain-obj ""^3.0.0""
@@ -14341,9 +14340,9 @@ jsdom@^15.2.1:
     xml-name-validator ""^3.0.0""
 
 jsdom@^16.4.0:
-  version ""16.5.2""
-  resolved ""https://registry.yarnpkg.com/jsdom/-/jsdom-16.5.2.tgz#583fac89a0aea31dbf6237e7e4bedccd9beab472""
-  integrity sha512-JxNtPt9C1ut85boCbJmffaQ06NBnzkQY/MWO3YxPW8IWS38A26z+B1oBvA9LwKrytewdfymnhi4UNH3/RAgZrg==
+  version ""16.5.3""
+  resolved ""https://registry.yarnpkg.com/jsdom/-/jsdom-16.5.3.tgz#13a755b3950eb938b4482c407238ddf16f0d2136""
+  integrity sha512-Qj1H+PEvUsOtdPJ056ewXM4UJPCi4hhLA8wpiz9F2YvsRBhuFsXxtrIFAgGBDynQA9isAMGE91PfUYbdMPXuTA==
   dependencies:
     abab ""^2.0.5""
     acorn ""^8.1.0""
@@ -15590,12 +15589,12 @@ micromatch@^3.1.10, micromatch@^3.1.4:
     to-regex ""^3.0.2""
 
 micromatch@^4.0.2:
-  version ""4.0.3""
-  resolved ""https://registry.yarnpkg.com/micromatch/-/micromatch-4.0.3.tgz#fdad8352bf0cbeb89b391b5d244bc22ff3dd4ec8""
-  integrity sha512-ueuSaP4i67F/FAUac9zzZ0Dz/5KeKDkITYIS/k4fps+9qeh1SkeH6gbljcqz97mNBOsaWZ+iv2UobMKK/yD+aw==
+  version ""4.0.4""
+  resolved ""https://registry.yarnpkg.com/micromatch/-/micromatch-4.0.4.tgz#896d519dfe9db25fce94ceb7a500919bf881ebf9""
+  integrity sha512-pRmzw/XUcwXGpD9aI9q/0XOwLNygjETJ8y0ao0wdqprrzDa4YnxLcz7fQRZr8voh8V10kGhABbNcHVk5wHgWwg==
   dependencies:
     braces ""^3.0.1""
-    picomatch ""^2.2.1""
+    picomatch ""^2.2.3""
 
 miller-rabin@^4.0.0:
   version ""4.0.1""
@@ -16356,7 +16355,7 @@ node-pre-gyp@^0.11.0:
     semver ""^5.3.0""
     tar ""^4""
 
-node-releases@^1.1.61, node-releases@^1.1.70:
+node-releases@^1.1.61, node-releases@^1.1.71:
   version ""1.1.71""
   resolved ""https://registry.yarnpkg.com/node-releases/-/node-releases-1.1.71.tgz#cb1334b179896b1c89ecfdd4b725fb7bbdfc7dbb""
   integrity sha512-zR6HoT6LrLCRBwukmrVbHv0EpEQjksO6GmFcZQQuCAy139BEsoVKPYnf3jongYW83fAa1torLGYwxxky/p28sg==
@@ -17571,10 +17570,10 @@ pgpass@1.x:
   dependencies:
     split2 ""^3.1.1""
 
-picomatch@^2.0.4, picomatch@^2.2.1, picomatch@^2.2.2:
-  version ""2.2.2""
-  resolved ""https://registry.yarnpkg.com/picomatch/-/picomatch-2.2.2.tgz#21f333e9b6b8eaff02468f5146ea406d345f4dad""
-  integrity sha512-q0M/9eZHzmr0AulXyPwNfZjtwZ/RBZlbN3K3CErVrk50T2ASYI7Bye0EvekFY3IP1Nt2DHu0re+V2ZHIpMkuWg==
+picomatch@^2.0.4, picomatch@^2.2.1, picomatch@^2.2.2, picomatch@^2.2.3:
+  version ""2.2.3""
+  resolved ""https://registry.yarnpkg.com/picomatch/-/picomatch-2.2.3.tgz#465547f359ccc206d3c48e46a1bcb89bf7ee619d""
+  integrity sha512-KpELjfwcCDUb9PeigTs2mBJzXUPzAuP2oPcA989He8Rte0+YUAjw1JVedDhuTKPkHjSYzMN3npC9luThGYEKdg==
 
 pify@^2.0.0, pify@^2.2.0, pify@^2.3.0:
   version ""2.3.0""
@@ -18446,9 +18445,9 @@ postcss@^7, postcss@^7.0.0, postcss@^7.0.1, postcss@^7.0.14, postcss@^7.0.17, po
     supports-color ""^6.1.0""
 
 postcss@^8.1.0, postcss@^8.2.8:
-  version ""8.2.9""
-  resolved ""https://registry.yarnpkg.com/postcss/-/postcss-8.2.9.tgz#fd95ff37b5cee55c409b3fdd237296ab4096fba3""
-  integrity sha512-b+TmuIL4jGtCHtoLi+G/PisuIl9avxs8IZMSmlABRwNz5RLUUACrC+ws81dcomz1nRezm5YPdXiMEzBEKgYn+Q==
+  version ""8.2.10""
+  resolved ""https://registry.yarnpkg.com/postcss/-/postcss-8.2.10.tgz#ca7a042aa8aff494b334d0ff3e9e77079f6f702b""
+  integrity sha512-b/h7CPV7QEdrqIxtAf2j31U5ef05uBDuvoXv6L51Q4rcS1jdlXAVKJv+atCFdUXYl9dyTHGyoMzIepwowRJjFw==
   dependencies:
     colorette ""^1.2.2""
     nanoid ""^3.1.22""
@@ -19318,9 +19317,9 @@ rc-tree@^4.0.0, rc-tree@~4.1.0:
     rc-virtual-list ""^3.0.1""
 
 rc-trigger@^5.0.0, rc-trigger@^5.0.4, rc-trigger@^5.1.2, rc-trigger@^5.2.1:
-  version ""5.2.3""
-  resolved ""https://registry.yarnpkg.com/rc-trigger/-/rc-trigger-5.2.3.tgz#8c55046ab432d7b52d51c69afb57ebb5bbe37e17""
-  integrity sha512-6Fokao07HUbqKIDkDRFEM0AGZvsvK0Fbp8A/KFgl1ngaqfO1nY037cISCG1Jm5fxImVsXp9awdkP7Vu5cxjjog==
+  version ""5.2.4""
+  resolved ""https://registry.yarnpkg.com/rc-trigger/-/rc-trigger-5.2.4.tgz#f1cca4a6c1f378a5d6fadec010292250772069d3""
+  integrity sha512-nLZa4XYo3hOAVauQr7HsGrBtE8/pyoIWhHZnpr7x/H/dd6pPeRzH0//+1TzaBAXylbFgsY6hogKAMeJwaKeDFw==
   dependencies:
     ""@babel/runtime"" ""^7.11.2""
     classnames ""^2.2.6""
@@ -20516,9 +20515,9 @@ rollup@^1.31.1:
     acorn ""^7.1.0""
 
 rollup@^2.40.0, rollup@^2.8.0:
-  version ""2.45.0""
-  resolved ""https://registry.yarnpkg.com/rollup/-/rollup-2.45.0.tgz#bfcce2347c96f15f5c78ac860bc38e3349ba27c9""
-  integrity sha512-JJznbtGIsHZfKH0Sa9RpCAy5JarH8SWvBzRAGuRkgzAafb8e8D7VSMJ0O1Bsix1nn91koN/Ecvl2+ZWhljcuTw==
+  version ""2.45.1""
+  resolved ""https://registry.yarnpkg.com/rollup/-/rollup-2.45.1.tgz#eae2b94dc2088b4e0a3b7197a5a1ee0bdd589d5c""
+  integrity sha512-vPD+JoDj3CY8k6m1bLcAFttXMe78P4CMxoau0iLVS60+S9kLsv2379xaGy4NgYWu+h2WTlucpoLPAoUoixFBag==
   optionalDependencies:
     fsevents ""~2.3.1""
 
@@ -22971,9 +22970,9 @@ typescript@~4.1.5:
   integrity sha512-6OSu9PTIzmn9TCDiovULTnET6BgXtDYL4Gg4szY+cGsc3JP1dQL8qvE8kShTRx1NIw4Q9IBHlwODjkjWEtMUyA==
 
 ua-parser-js@^0.7.18:
-  version ""0.7.27""
-  resolved ""https://registry.yarnpkg.com/ua-parser-js/-/ua-parser-js-0.7.27.tgz#b54f8ce9eb6c7abf3584edeaf9a3d8b3bd92edba""
-  integrity sha512-eXMaRYK2skomGocoX0x9sBXzx5A1ZVQgXfrW4mTc8dT0zS7olEcyfudAzRC5tIIRgLxQ69B6jut3DI+n5hslPA==
+  version ""0.7.28""
+  resolved ""https://registry.yarnpkg.com/ua-parser-js/-/ua-parser-js-0.7.28.tgz#8ba04e653f35ce210239c64661685bf9121dec31""
+  integrity sha512-6Gurc1n//gjp9eQNXjD9O3M/sMwVtN5S8Lv9bvOYBfKfDNiIIhqiyi01vMBO45u4zkDE420w/e0se7Vs+sIg+g==
 
 uglify-js@3.4.x:
   version ""3.4.10""
@@ -22984,9 +22983,9 @@ uglify-js@3.4.x:
     source-map ""~0.6.1""
 
 uglify-js@^3.1.4, uglify-js@^3.4.9:
-  version ""3.13.3""
-  resolved ""https://registry.yarnpkg.com/uglify-js/-/uglify-js-3.13.3.tgz#ce72a1ad154348ea2af61f50933c76cc8802276e""
-  integrity sha512-otIc7O9LyxpUcQoXzj2hL4LPWKklO6LJWoJUzNa8A17Xgi4fOeDC8FBDOLHnC/Slo1CQgsZMcM6as0M76BZaig==
+  version ""3.13.4""
+  resolved ""https://registry.yarnpkg.com/uglify-js/-/uglify-js-3.13.4.tgz#592588bb9f47ae03b24916e2471218d914955574""
+  integrity sha512-kv7fCkIXyQIilD5/yQy8O+uagsYIOt5cZvs890W40/e/rvjMSzJw81o9Bg0tkURxzZBROtDQhW2LFjOGoK3RZw==
 
 uid-number@0.0.6:
   version ""0.0.6""
",1,"[""7e9bd7c86df1032d53e752654fe4a446951480bb""]","[""build""]"
publish sdks after docs/build,"diff --git a/.circleci/config.yml b/.circleci/config.yml
index 4ac01cf..cfea1ae 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -213,6 +213,7 @@ workflows:
             - test-e2e-mysql
             - test-e2e-cockroach
             - test-e2e-plugin
+            - docs/build
 #            - test-legacy-migrations-mysql
 #            - test-legacy-migrations-cockroach
           filters:
@@ -246,6 +247,7 @@ workflows:
             - golangci/lint
             - sdk/generate
             - goreleaser/release
+            - docs/build
           filters:
             tags:
               only: /.*/
",1,"[""6c9cb638cb4d1ecc42632fcf389c24898c5b3244""]","[""cicd""]"
"move group logical op outside

Signed-off-by: Pranav C <pranavxc@gmail.com>","diff --git a/packages/nc-gui/components/project/spreadsheet/components/ColumnFilter.vue b/packages/nc-gui/components/project/spreadsheet/components/ColumnFilter.vue
index 5138589..f756981 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/ColumnFilter.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/ColumnFilter.vue
@@ -2,40 +2,46 @@
   <div
     class=""backgroundColor pa-2 menu-filter-dropdown""
     :class=""{ nested }""
-    :style=""{ width: nested ? '100%' : '530px' }""
+    :style=""{ width: nested ? '100%' : '630px' }""
   >
     <div class=""grid"" @click.stop>
       <template v-for=""(filter, i) in filters"" dense>
         <template v-if=""filter.status !== 'delete'"">
-          <div v-if=""filter.is_group"" :key=""i"" style=""grid-column: span 5; padding: 6px"" class=""elevation-4"">
-            <div class=""d-flex"" style=""gap: 6px; padding: 0 6px"">
-              <v-icon
-                v-if=""!filter.readOnly""
-                small
-                class=""nc-filter-item-remove-btn""
-                @click.stop=""deleteFilter(filter, i)""
-              >
-                mdi-close-box
-              </v-icon>
-              <span v-if=""!i"" class=""caption d-flex align-center"">{{ $t('labels.where') }}</span>
-              <v-select
-                v-else
-                v-model=""filter.logical_op""
-                class=""flex-shrink-1 flex-grow-0 elevation-0 caption""
-                :items=""['and', 'or']""
-                solo
-                flat
-                dense
-                hide-details
-                placeholder=""Group op""
-                @click.stop
-                @change=""saveOrUpdate(filter, i)""
-              >
-                <template #item=""{ item }"">
-                  <span class=""caption font-weight-regular"">{{ item }}</span>
-                </template>
-              </v-select>
-            </div>
+          <template v-if=""filter.is_group"">
+            <v-icon
+              v-if=""!filter.readOnly""
+              small
+              class=""nc-filter-item-remove-btn""
+              @click.stop=""deleteFilter(filter, i)""
+              :key=""i + '_1'""
+            >
+              mdi-close-box
+            </v-icon>
+            <span v-else :key=""i + '_1'"" />
+
+            <span :key=""i + '_2'"" v-if=""!i"" class=""caption d-flex align-center"">{{ $t('labels.where') }}</span>
+            <v-select
+              v-else
+              :key=""i + '_2'""
+              v-model=""filter.logical_op""
+              class=""flex-shrink-1 flex-grow-0 elevation-0 caption""
+              :items=""['and', 'or']""
+              solo
+              flat
+              dense
+              hide-details
+              placeholder=""Group op""
+              @click.stop
+              @change=""saveOrUpdate(filter, i)""
+            >
+              <template #item=""{ item }"">
+                <span class=""caption font-weight-regular"">{{ item }}</span>
+              </template>
+            </v-select>
+            <span :key=""i + '_3'"" style=""grid-column: span 3""></span>
+          </template>
+
+          <div v-if=""filter.is_group"" :key=""i + '_4'"" style=""grid-column: span 5; padding: 6px"" class=""elevation-4"">
             <column-filter
               v-if=""filter.id || shared""
               ref=""nestedFilter""
@@ -54,19 +60,19 @@
           <template v-else>
             <v-icon
               v-if=""!filter.readOnly""
-              :key=""i + '_1'""
+              :key=""i + '_5'""
               small
               class=""nc-filter-item-remove-btn""
               @click.stop=""deleteFilter(filter, i)""
             >
               mdi-close-box
             </v-icon>
-            <span v-else :key=""i + '_1'"" />
-            <span v-if=""!i"" :key=""i + '_2'"" class=""caption d-flex align-center"">{{ $t('labels.where') }}</span>
+            <span v-else :key=""i + '_5'"" />
+            <span v-if=""!i"" :key=""i + '_6'"" class=""caption d-flex align-center"">{{ $t('labels.where') }}</span>
 
             <v-select
               v-else
-              :key=""i + '_2'""
+              :key=""i + '_6'""
               v-model=""filter.logical_op""
               class=""flex-shrink-1 flex-grow-0 elevation-0 caption""
               :items=""['and', 'or']""
@@ -84,7 +90,7 @@
             </v-select>
 
             <field-list-auto-complete-dropdown
-              :key=""i + '_3'""
+              :key=""i + '_7'""
               v-model=""filter.fk_column_id""
               class=""caption nc-filter-field-select""
               :columns=""columns""
@@ -94,7 +100,7 @@
             />
 
             <v-select
-              :key=""i + '_4'""
+              :key=""i + '_8'""
               v-model=""filter.comparison_op""
               class=""flex-shrink-1 flex-grow-0 caption nc-filter-operation-select""
               :items=""filterComparisonOp(filter)""
@@ -114,11 +120,11 @@
                 <span class=""caption font-weight-regular"">{{ item.text }}</span>
               </template>
             </v-select>
-            <span v-else :key=""i + '_4'""></span>
+            <span v-else :key=""i + '_8'""></span>
             <span v-if=""['null', 'notnull', 'empty', 'notempty'].includes(filter.comparison_op)"" :key=""i + '_5'"" />
             <v-checkbox
               v-else-if=""types[filter.field] === 'boolean'""
-              :key=""i + '_5'""
+              :key=""i + '_9'""
               v-model=""filter.value""
               dense
               :disabled=""filter.readOnly""
@@ -126,7 +132,7 @@
             />
             <v-text-field
               v-else-if=""filter && filter.fk_column_id""
-              :key=""i + '_5'""
+              :key=""i + '_9'""
               v-model=""filter.value""
               solo
               flat
@@ -137,7 +143,7 @@
               @click.stop
               @input=""saveOrUpdate(filter, i)""
             />
-            <span v-else :key=""i + '_5'""></span>
+            <span v-else :key=""i + '_9'""></span>
           </template>
         </template>
       </template>
@@ -411,6 +417,7 @@ export default {
         parentId: this.parentId,
         is_group: true,
         status: 'update',
+        logical_op: 'and',
       });
       this.filters = this.filters.slice();
       const index = this.filters.length - 1;
@@ -478,4 +485,8 @@ export default {
   column-gap: 6px;
   row-gap: 6px;
 }
+
+.nc-filter-value-select {
+  min-width: 100px;
+}
 </style>
",1,"[""4f86f2570b274c45605cc59d9adb38f7ed30cd17""]","[""refactor""]"
"fixed start types for size and opacity | Remove hasmany and belongsto from context menu

Signed-off-by: Pranav C <61551451+pranavxc@users.noreply.github.com> | add prewatch script to core","diff --git a/core/main/src/Core/Particle.ts b/core/main/src/Core/Particle.ts
index 1aa6fba..6ea6ffc 100644
--- a/core/main/src/Core/Particle.ts
+++ b/core/main/src/Core/Particle.ts
@@ -271,7 +271,7 @@ export class Particle implements IParticle {
             }
         }
 
-        const sizeAnimation = this.options.size.animation;
+        const sizeAnimation = sizeOptions.animation;
 
         if (sizeAnimation.enable) {
             this.size.status = AnimationStatus.increasing;
@@ -279,7 +279,8 @@ export class Particle implements IParticle {
             if (!randomSize) {
                 switch (sizeAnimation.startValue) {
                     case StartValueType.min:
-                        this.size.value = sizeAnimation.minimumValue * pxRatio;
+                        this.size.value = NumberUtils.getRangeMin(sizeOptions.value) * pxRatio;
+                        this.size.status = AnimationStatus.increasing;
 
                         break;
 
@@ -287,11 +288,14 @@ export class Particle implements IParticle {
                         this.size.value = NumberUtils.randomInRange(
                             NumberUtils.setRangeValue(sizeAnimation.minimumValue * pxRatio, this.size.value)
                         );
+                        this.size.status =
+                            Math.random() >= 0.5 ? AnimationStatus.increasing : AnimationStatus.decreasing;
 
                         break;
 
                     case StartValueType.max:
                     default:
+                        this.size.value = NumberUtils.getRangeMax(sizeOptions.value) * pxRatio;
                         this.size.status = AnimationStatus.decreasing;
 
                         break;
@@ -393,7 +397,8 @@ export class Particle implements IParticle {
             if (!randomOpacity) {
                 switch (opacityAnimation.startValue) {
                     case StartValueType.min:
-                        this.opacity.value = opacityAnimation.minimumValue;
+                        this.opacity.value = NumberUtils.getRangeMin(this.opacity.value);
+                        this.opacity.status = AnimationStatus.increasing;
 
                         break;
 
@@ -401,11 +406,14 @@ export class Particle implements IParticle {
                         this.opacity.value = NumberUtils.randomInRange(
                             NumberUtils.setRangeValue(opacityAnimation.minimumValue, this.opacity.value)
                         );
+                        this.opacity.status =
+                            Math.random() >= 0.5 ? AnimationStatus.increasing : AnimationStatus.decreasing;
 
                         break;
 
                     case StartValueType.max:
                     default:
+                        this.opacity.value = NumberUtils.getRangeMax(this.opacity.value);
                         this.opacity.status = AnimationStatus.decreasing;
 
                         break;
diff --git a/presets/confetti/src/options.ts b/presets/confetti/src/options.ts
index 7fc6225..a713425 100644
--- a/presets/confetti/src/options.ts
+++ b/presets/confetti/src/options.ts
@@ -28,7 +28,7 @@ export const loadOptions = (confettiOptions: RecursivePartial<IConfettiOptions>)
                 animation: {
                     enable: true,
                     minimumValue: 0,
-                    speed: 2,
+                    speed: 0.5,
                     startValue: ""max"",
                     destroy: ""min"",
                 },

diff --git a/packages/nc-gui/components/project/spreadsheet/rowsXcDataTable.vue b/packages/nc-gui/components/project/spreadsheet/rowsXcDataTable.vue
index 5bc6f67..aaa297c 100644
--- a/packages/nc-gui/components/project/spreadsheet/rowsXcDataTable.vue
+++ b/packages/nc-gui/components/project/spreadsheet/rowsXcDataTable.vue
@@ -261,37 +261,7 @@
             :size=""size""
             @input=""loadTableData""
           />
-          <!--  <v-pagination
-              v-if=""count !== Infinity""
-              style=""max-width: 100%""
-              v-model=""page""
-              :length=""Math.ceil(count / size)""
-              :total-visible=""8""
-              @input=""loadTableData""
-              color=""primary lighten-2""
-            ></v-pagination>
-            <div v-else class=""mx-auto d-flex align-center mt-n1 "" style=""max-width:250px"">
-              <span class=""caption"" style=""white-space: nowrap""> Change page:</span>
-              <v-text-field
-                class=""ml-1 caption""
-                :full-width=""false""
-                outlined
-                dense
-                hide-details
-                v-model=""page""
-                @keydown.enter=""loadTableData""
-                type=""number""
-              >
-                <template #append>
-                  <x-icon tooltip=""Change page"" small icon.class=""mt-1"" @click=""loadTableData"">mdi-keyboard-return
-                  </x-icon>
-                </template>
-              </v-text-field>
-            </div>-->
         </template>
-        <!--      <div v-else class=""d-flex justify-center py-4"">-->
-        <!--        <v-alert type=""info"" dense class=""ma-1 flex-shrink-1"">Table is empty</v-alert>-->
-        <!--      </div>-->
       </div>
 
       <spreadsheet-nav-drawer
@@ -414,9 +384,9 @@
             <span class=""caption"">Delete Selected Rows</span>
           </v-list-item>
         </template>
-        <template v-if=""meta.hasMany && meta.hasMany.length"">
+        <!--        <template v-if=""meta.hasMany && meta.hasMany.length"">
           <v-divider v-if=""isEditable && !isLocked"" />
-          <span class=""ml-3 grey--text "" style=""font-size: 9px"">Has Many</span>
+          <span class=""ml-3 grey&#45;&#45;text "" style=""font-size: 9px"">Has Many</span>
 
           <v-list-item v-for=""(hm,i) in meta.hasMany"" :key=""i"" @click=""addNewRelationTabCtxMenu(hm,'hm')"">
             <span class=""caption text-capitalize"">{{ hm._tn }}</span>
@@ -425,12 +395,12 @@
 
         <template v-if=""meta.belongsTo && meta.belongsTo.length"">
           <v-divider />
-          <span class=""ml-3 grey--text "" style=""font-size: 9px"">Belongs To</span>
+          <span class=""ml-3 grey&#45;&#45;text "" style=""font-size: 9px"">Belongs To</span>
 
           <v-list-item v-for=""(bt,i) in belongsTo"" :key=""i"" @click=""addNewRelationTabCtxMenu(bt,'bt')"">
             <span class=""caption text-capitalize"">{{ bt._rtn }}</span>
           </v-list-item>
-        </template>
+        </template>-->
       </v-list>
     </v-menu>
     <v-dialog

diff --git a/.gitignore b/.gitignore
index 3445558..72257cb 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1,4 +1,5 @@
 *.o
+.env
 settheory
 constraint
 Main
diff --git a/packages/core/package.json b/packages/core/package.json
index 9ba8b93..79bd532 100644
--- a/packages/core/package.json
+++ b/packages/core/package.json
@@ -14,6 +14,7 @@
     ""build:parsers"": ""nearleyc src/parser/Domain.ne > src/parser/DomainParser.ts && nearleyc src/parser/Substance.ne > src/parser/SubstanceParser.ts && nearleyc src/parser/Style.ne > src/parser/StyleParser.ts"",
     ""prebuild"": ""yarn build:parsers"",
     ""prestart"": ""yarn build:parsers"",
+    ""prewatch"": ""yarn build:parsers"",
     ""test"": ""jest --watchAll=false"",
     ""test:watch"": ""jest --watchAll"",
     ""build"": ""rollup -c"",
",3,"[""06960183db42cba1b1f1a8077660ba8c801c9e18"", ""7dbbb64c45506ef634180638db800b6d9535523d"", ""aa0152baa4376b1087c86499a7c289b668d5ad55""]","[""fix"", ""refactor"", ""build""]"
backup manager can mark inprogress backups as failed | run pyspark tests in parallel | correct width when --no-quotes is used,"diff --git a/backup/src/main/java/io/camunda/zeebe/backup/api/BackupManager.java b/backup/src/main/java/io/camunda/zeebe/backup/api/BackupManager.java
index b2dfb98..21eaf6d 100644
--- a/backup/src/main/java/io/camunda/zeebe/backup/api/BackupManager.java
+++ b/backup/src/main/java/io/camunda/zeebe/backup/api/BackupManager.java
@@ -42,4 +42,6 @@ public interface BackupManager {
 
   /** Close Backup manager */
   ActorFuture<Void> closeAsync();
+
+  void failInProgressBackup(long lastCheckpointId);
 }
diff --git a/backup/src/main/java/io/camunda/zeebe/backup/management/BackupService.java b/backup/src/main/java/io/camunda/zeebe/backup/management/BackupService.java
index a1e1319..33149ae 100644
--- a/backup/src/main/java/io/camunda/zeebe/backup/management/BackupService.java
+++ b/backup/src/main/java/io/camunda/zeebe/backup/management/BackupService.java
@@ -16,6 +16,7 @@ import io.camunda.zeebe.scheduler.future.ActorFuture;
 import io.camunda.zeebe.scheduler.future.CompletableActorFuture;
 import io.camunda.zeebe.snapshots.PersistedSnapshotStore;
 import java.nio.file.Path;
+import java.util.List;
 import java.util.function.Predicate;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -31,11 +32,13 @@ public final class BackupService extends Actor implements BackupManager {
   private final PersistedSnapshotStore snapshotStore;
   private final Path segmentsDirectory;
   private final Predicate<Path> isSegmentsFile;
+  private List<Integer> partitionMembers;
 
   public BackupService(
       final int nodeId,
       final int partitionId,
       final int numberOfPartitions,
+      final List<Integer> partitionMembers,
       final PersistedSnapshotStore snapshotStore,
       final Predicate<Path> isSegmentsFile,
       final Path segmentsDirectory) {
@@ -48,6 +51,7 @@ public final class BackupService extends Actor implements BackupManager {
         snapshotStore,
         segmentsDirectory,
         isSegmentsFile);
+    this.partitionMembers = partitionMembers;
   }
 
   public BackupService(
@@ -122,6 +126,12 @@ public final class BackupService extends Actor implements BackupManager {
         new UnsupportedOperationException(""Not implemented""));
   }
 
+  @Override
+  public void failInProgressBackup(final long lastCheckpointId) {
+    internalBackupManager.failInProgressBackups(
+        partitionId, lastCheckpointId, partitionMembers, actor);
+  }
+
   private BackupIdentifierImpl getBackupId(final long checkpointId) {
     return new BackupIdentifierImpl(nodeId, partitionId, checkpointId);
   }
diff --git a/backup/src/main/java/io/camunda/zeebe/backup/management/BackupServiceImpl.java b/backup/src/main/java/io/camunda/zeebe/backup/management/BackupServiceImpl.java
index e462dd5..f6d76b6 100644
--- a/backup/src/main/java/io/camunda/zeebe/backup/management/BackupServiceImpl.java
+++ b/backup/src/main/java/io/camunda/zeebe/backup/management/BackupServiceImpl.java
@@ -9,16 +9,23 @@ package io.camunda.zeebe.backup.management;
 
 import io.camunda.zeebe.backup.api.BackupIdentifier;
 import io.camunda.zeebe.backup.api.BackupStatus;
+import io.camunda.zeebe.backup.api.BackupStatusCode;
 import io.camunda.zeebe.backup.api.BackupStore;
+import io.camunda.zeebe.backup.common.BackupIdentifierImpl;
+import io.camunda.zeebe.backup.processing.state.CheckpointState;
 import io.camunda.zeebe.scheduler.ConcurrencyControl;
 import io.camunda.zeebe.scheduler.future.ActorFuture;
 import io.camunda.zeebe.scheduler.future.CompletableActorFuture;
+import java.util.Collection;
 import java.util.HashSet;
 import java.util.Set;
 import java.util.function.BiConsumer;
 import java.util.function.Consumer;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 
 final class BackupServiceImpl {
+  private static final Logger LOG = LoggerFactory.getLogger(BackupServiceImpl.class);
   private final Set<InProgressBackup> backupsInProgress = new HashSet<>();
   private final BackupStore backupStore;
   private ConcurrencyControl concurrencyControl;
@@ -138,4 +145,48 @@ final class BackupServiceImpl {
                     }));
     return future;
   }
+
+  void failInProgressBackups(
+      final int partitionId,
+      final long lastCheckpointId,
+      final Collection<Integer> brokers,
+      final ConcurrencyControl executor) {
+    if (lastCheckpointId != CheckpointState.NO_CHECKPOINT) {
+      executor.run(
+          () -> {
+            final var backupIds =
+                brokers.stream()
+                    .map(b -> new BackupIdentifierImpl(b, partitionId, lastCheckpointId))
+                    .toList();
+            // Fail backups initiated by previous leaders
+            backupIds.forEach(this::failInProgressBackup);
+          });
+    }
+  }
+
+  private void failInProgressBackup(final BackupIdentifier backupId) {
+    backupStore
+        .getStatus(backupId)
+        .thenAccept(
+            status -> {
+              if (status.statusCode() == BackupStatusCode.IN_PROGRESS) {
+                LOG.debug(
+                    ""The backup {} initiated by previous leader is still in progress. Marking it as failed."",
+                    backupId);
+                backupStore
+                    .markFailed(backupId)
+                    .thenAccept(ignore -> LOG.trace(""Marked backup {} as failed."", backupId))
+                    .exceptionally(
+                        failed -> {
+                          LOG.debug(""Failed to mark backup {} as failed"", backupId, failed);
+                          return null;
+                        });
+              }
+            })
+        .exceptionally(
+            error -> {
+              LOG.debug(""Failed to retrieve status of backup {}"", backupId);
+              return null;
+            });
+  }
 }
diff --git a/backup/src/main/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessor.java b/backup/src/main/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessor.java
index c83fdc1..2899d4d 100644
--- a/backup/src/main/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessor.java
+++ b/backup/src/main/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessor.java
@@ -14,20 +14,24 @@ import io.camunda.zeebe.backup.processing.state.DbCheckpointState;
 import io.camunda.zeebe.engine.api.ProcessingResult;
 import io.camunda.zeebe.engine.api.ProcessingResultBuilder;
 import io.camunda.zeebe.engine.api.ProcessingScheduleService;
+import io.camunda.zeebe.engine.api.ReadonlyStreamProcessorContext;
 import io.camunda.zeebe.engine.api.RecordProcessor;
 import io.camunda.zeebe.engine.api.RecordProcessorContext;
+import io.camunda.zeebe.engine.api.StreamProcessorLifecycleAware;
 import io.camunda.zeebe.engine.api.TypedRecord;
 import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.ValueType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.time.Duration;
+import java.util.List;
 import java.util.Set;
 import java.util.concurrent.CopyOnWriteArraySet;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 /** Process and replays records related to Checkpoint. */
-public final class CheckpointRecordsProcessor implements RecordProcessor {
+public final class CheckpointRecordsProcessor
+    implements RecordProcessor, StreamProcessorLifecycleAware {
 
   private static final Logger LOG = LoggerFactory.getLogger(CheckpointRecordsProcessor.class);
 
@@ -62,6 +66,8 @@ public final class CheckpointRecordsProcessor implements RecordProcessor {
       checkpointListeners.forEach(
           listener -> listener.onNewCheckpointCreated(checkpointState.getCheckpointId()));
     }
+
+    recordProcessorContext.addLifecycleListeners(List.of(this));
   }
 
   @Override
@@ -126,4 +132,12 @@ public final class CheckpointRecordsProcessor implements RecordProcessor {
           });
     }
   }
+
+  @Override
+  public void onRecovered(final ReadonlyStreamProcessorContext context) {
+    // After a leader change, the new leader will not continue taking the backup initiated by
+    // previous leader. So mark them as failed, so that the users do not wait forever for it to be
+    // completed.
+    backupManager.failInProgressBackup(checkpointState.getCheckpointId());
+  }
 }
diff --git a/broker/src/main/java/io/camunda/zeebe/broker/system/partitions/impl/steps/BackupServiceTransitionStep.java b/broker/src/main/java/io/camunda/zeebe/broker/system/partitions/impl/steps/BackupServiceTransitionStep.java
index 3424e19..591e17b 100644
--- a/broker/src/main/java/io/camunda/zeebe/broker/system/partitions/impl/steps/BackupServiceTransitionStep.java
+++ b/broker/src/main/java/io/camunda/zeebe/broker/system/partitions/impl/steps/BackupServiceTransitionStep.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.broker.system.partitions.impl.steps;
 
+import io.atomix.cluster.MemberId;
 import io.atomix.raft.RaftServer.Role;
 import io.camunda.zeebe.backup.api.BackupManager;
 import io.camunda.zeebe.backup.management.BackupService;
@@ -17,6 +18,7 @@ import io.camunda.zeebe.journal.file.SegmentFile;
 import io.camunda.zeebe.scheduler.future.ActorFuture;
 import io.camunda.zeebe.scheduler.future.CompletableActorFuture;
 import java.nio.file.Path;
+import java.util.List;
 import java.util.function.Predicate;
 
 public final class BackupServiceTransitionStep implements PartitionTransitionStep {
@@ -69,6 +71,7 @@ public final class BackupServiceTransitionStep implements PartitionTransitionSte
             context.getNodeId(),
             context.getPartitionId(),
             context.getBrokerCfg().getCluster().getPartitionsCount(),
+            getPartitionMembers(context),
             context.getPersistedSnapshotStore(),
             isSegmentsFile,
             context.getRaftPartition().dataDirectory().toPath());
@@ -90,4 +93,12 @@ public final class BackupServiceTransitionStep implements PartitionTransitionSte
             });
     return installed;
   }
+
+  // Brokers which are members of this partition's replication group
+  private static List<Integer> getPartitionMembers(final PartitionTransitionContext context) {
+    return context.getRaftPartition().members().stream()
+        .map(MemberId::id)
+        .map(Integer::parseInt)
+        .toList();
+  }
 }

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index e23088e..9708157 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -202,11 +202,11 @@ jobs:
         run: poetry install --without dev --without docs --extras ${{ matrix.backend.name }} --extras geospatial
 
       - name: ""run parallel tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name != 'pyspark' && matrix.backend.name != 'impala'
+        if: matrix.backend.name != 'impala'
         run: just ci-check -m ${{ matrix.backend.name }} --numprocesses auto --dist=loadgroup
 
       - name: ""run serial tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name == 'pyspark' || matrix.backend.name == 'impala'
+        if: matrix.backend.name == 'impala'
         run: just ci-check -m ${{ matrix.backend.name }}
         env:
           IBIS_TEST_NN_HOST: localhost

diff --git a/src/output/grid.rs b/src/output/grid.rs
index 37f6c57..ce989e5 100644
--- a/src/output/grid.rs
+++ b/src/output/grid.rs
@@ -8,6 +8,8 @@ use crate::output::file_name::{Classify, Options as FileStyle};
 use crate::output::file_name::{EmbedHyperlinks, ShowIcons};
 use crate::theme::Theme;
 
+use super::file_name::QuoteStyle;
+
 #[derive(PartialEq, Eq, Debug, Copy, Clone)]
 pub struct Options {
     pub across: bool,
@@ -55,27 +57,34 @@ impl<'a> Render<'a> {
                 } else {
                     0
                 };
-
-            let space_filename_offset = if file.name.contains(' ') || file.name.contains('\'') {
-                2
-            } else {
-                0
+            let space_filename_offset = match self.file_style.quote_style {
+                QuoteStyle::QuoteSpaces if file.name.contains(' ') => 2,
+                QuoteStyle::NoQuotes => 0,
+                _ => 0, // Default case
             };
-
             let contents = filename.paint();
-            #[rustfmt::skip]
             let width = match (
                 filename.options.embed_hyperlinks,
                 filename.options.show_icons,
             ) {
-                ( EmbedHyperlinks::On, ShowIcons::Always(spacing) | ShowIcons::Automatic(spacing) )
-                    => filename.bare_width() + classification_width + 1 + (spacing as usize) + space_filename_offset,
-                ( EmbedHyperlinks::On, ShowIcons::Never )
-                    => filename.bare_width() + classification_width + space_filename_offset,
-                ( EmbedHyperlinks::Off, ShowIcons::Always(spacing) | ShowIcons::Automatic(spacing) )
-                    => filename.bare_width() + 1 + (spacing as usize) + space_filename_offset,
-                ( EmbedHyperlinks::Off, _ )
-                    => *contents.width(),
+                (
+                    EmbedHyperlinks::On,
+                    ShowIcons::Always(spacing) | ShowIcons::Automatic(spacing),
+                ) => {
+                    filename.bare_width()
+                        + classification_width
+                        + 1
+                        + (spacing as usize)
+                        + space_filename_offset
+                }
+                (EmbedHyperlinks::On, ShowIcons::Never) => {
+                    filename.bare_width() + classification_width + space_filename_offset
+                }
+                (
+                    EmbedHyperlinks::Off,
+                    ShowIcons::Always(spacing) | ShowIcons::Automatic(spacing),
+                ) => filename.bare_width() + 1 + (spacing as usize) + space_filename_offset,
+                (EmbedHyperlinks::Off, _) => *contents.width(),
             };
 
             grid.add(tg::Cell {
",3,"[""fb83ef33b699fd966486a922ba1ade4cf8e55858"", ""4cbbd2552ba0de273e1dfe7d453c5b3efed751a3"", ""61eaa2d0cca9bd27d6c5f0a8f9b34200b77fdbb0""]","[""feat"", ""cicd"", ""fix""]"
"test AsyncAggregatingSubscriber | nginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>","diff --git a/backup-stores/s3/pom.xml b/backup-stores/s3/pom.xml
index 282a4dc..1db7a33 100644
--- a/backup-stores/s3/pom.xml
+++ b/backup-stores/s3/pom.xml
@@ -149,6 +149,12 @@
       <artifactId>aws-java-sdk-core</artifactId>
       <scope>test</scope>
     </dependency>
+
+    <dependency>
+      <groupId>org.mockito</groupId>
+      <artifactId>mockito-core</artifactId>
+      <scope>test</scope>
+    </dependency>
   </dependencies>
 
   <build>
diff --git a/backup-stores/s3/src/test/java/io/camunda/zeebe/backup/s3/util/AsyncAggregatingSubscriberTest.java b/backup-stores/s3/src/test/java/io/camunda/zeebe/backup/s3/util/AsyncAggregatingSubscriberTest.java
new file mode 100644
index 0000000..b83ec84
--- /dev/null
+++ b/backup-stores/s3/src/test/java/io/camunda/zeebe/backup/s3/util/AsyncAggregatingSubscriberTest.java
@@ -0,0 +1,97 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.backup.s3.util;
+
+import static org.assertj.core.api.Assertions.assertThat;
+import static org.mockito.Mockito.mock;
+
+import java.time.Duration;
+import java.util.Collection;
+import java.util.concurrent.CompletableFuture;
+import java.util.concurrent.ExecutionException;
+import org.junit.jupiter.api.Test;
+import org.reactivestreams.Subscription;
+import org.testcontainers.shaded.org.awaitility.Awaitility;
+
+final class AsyncAggregatingSubscriberTest {
+
+  @Test
+  void shouldCompleteOnlyAfterAllFuturesComplete() {
+    // given
+    final var aggregator = new AsyncAggregatingSubscriber<Integer>(16);
+    final var completed = CompletableFuture.completedFuture(1);
+    final var delayed = new CompletableFuture<Integer>();
+
+    aggregator.onSubscribe(mock(Subscription.class));
+    final CompletableFuture<Collection<Integer>> result = aggregator.result();
+
+    // when
+    aggregator.onNext(completed);
+    aggregator.onNext(delayed);
+    aggregator.onComplete();
+
+    // then
+    assertThat(result).isNotDone();
+
+    delayed.complete(2);
+    Awaitility.await().until(result::isDone);
+    assertThat(result.join()).containsExactlyInAnyOrder(1, 2);
+  }
+
+  @Test
+  void shouldFailIfOneFutureFails() {
+    // given
+    final var aggregator = new AsyncAggregatingSubscriber<Integer>(16);
+    final var completed = CompletableFuture.completedFuture(1);
+    final var failed = new CompletableFuture<Integer>();
+
+    aggregator.onSubscribe(mock(Subscription.class));
+    final CompletableFuture<Collection<Integer>> result = aggregator.result();
+
+    // when
+    aggregator.onNext(completed);
+    aggregator.onNext(failed);
+    aggregator.onComplete();
+
+    // then
+    failed.completeExceptionally(new RuntimeException(""Failed""));
+
+    Awaitility.await()
+        .untilAsserted(
+            () ->
+                assertThat(result)
+                    .failsWithin(Duration.ofMillis(100))
+                    .withThrowableOfType(ExecutionException.class)
+                    .withMessageContaining(""Failed""));
+  }
+
+  @Test
+  void shouldFailsIfSubscriptionFails() {
+    // given
+    final var aggregator = new AsyncAggregatingSubscriber<Integer>(16);
+    final var completed = CompletableFuture.completedFuture(1);
+    final var failed = new CompletableFuture<Integer>();
+
+    aggregator.onSubscribe(mock(Subscription.class));
+    final CompletableFuture<Collection<Integer>> result = aggregator.result();
+
+    // when
+    aggregator.onNext(completed);
+    aggregator.onNext(failed);
+    aggregator.onError(new RuntimeException(""Failed""));
+
+    // then
+    Awaitility.await()
+        .untilAsserted(
+            () ->
+                assertThat(result)
+                    .failsWithin(Duration.ofMillis(100))
+                    .withThrowableOfType(ExecutionException.class)
+                    .withMessageContaining(""Failed""));
+  }
+}

diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection
",2,"[""266706b864ff773dc67e04fa9df2fbf02d0c8b54"", ""e12d9e77a6fd531a22325337838a841b1c67f00d""]","[""test"", ""docs""]"
"add link to roadmap | cue linter: include all CUE files

Signed-off-by: Andrea Luzzardi <aluzzardi@gmail.com>","diff --git a/packages/plugin-core/README.md b/packages/plugin-core/README.md
index 3c25c9b..c7506d4 100644
--- a/packages/plugin-core/README.md
+++ b/packages/plugin-core/README.md
@@ -187,6 +187,10 @@ When the workspace opens, it will show dialogue to install the recommended exten
 
 See [[FAQ]] to answers for common questions.
 
+# Roadmap
+
+Check out our [public roadmap](https://github.com/orgs/dendronhq/projects/1) to see the features we're working on and to vote for what you want to see next. 
+
 
 # Contributing
 

diff --git a/ci/cue/lint.cue b/ci/cue/lint.cue
index cdda698..6aac265 100644
--- a/ci/cue/lint.cue
+++ b/ci/cue/lint.cue
@@ -39,7 +39,7 @@ import (
 			// CACHE: copy only *.cue files
 			docker.#Copy & {
 				contents: source
-				include: [""*.cue""]
+				include: [""*.cue"", ""**/*.cue""]
 				dest: ""/cue""
 			},
 
",2,"[""94202f01e44c58bee4419044f8a18ac5f1a50dff"", ""4c44543a3d9eea37e90a2316717feb01c0e0d83a""]","[""docs"", ""cicd""]"
set name for topology module | add .nullif() example,"diff --git a/topology/pom.xml b/topology/pom.xml
index 389508e..ee6239a 100644
--- a/topology/pom.xml
+++ b/topology/pom.xml
@@ -16,6 +16,7 @@
   </parent>
 
   <artifactId>zeebe-cluster-topology</artifactId>
+  <name>Zeebe Cluster Topology</name>
 
   <properties>
     <proto.dir>${maven.multiModuleProjectDirectory}/topology/src/main/resources/proto</proto.dir>

diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        
+         sex    
+        
+         string 
+        
+         male   
+         female 
+         female 
+         NULL   
+         female 
+        
+        >>> vals.nullif(""male"")
+        
+         NullIf(sex, 'male') 
+        
+         string              
+        
+         NULL                
+         female              
+         female              
+         NULL                
+         female              
+        
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 
",2,"[""8911a972222dc80a242f3f1d9b3596321b3fdeaa"", ""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21""]","[""build"", ""docs""]"
"fix test

Write another record so the commit position is updated and we can take a snapshot | remove unnecessary lines from verify-wal test | init environ cache","diff --git a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/clustering/ReaderCloseTest.java b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/clustering/ReaderCloseTest.java
index 24f1316..881c727 100644
--- a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/clustering/ReaderCloseTest.java
+++ b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/clustering/ReaderCloseTest.java
@@ -70,6 +70,14 @@ public class ReaderCloseTest {
             .getCluster()
             .getNodeId();
     clusteringRule.forceClusterToHaveNewLeader(followerId);
+    // because of https://github.com/camunda-cloud/zeebe/issues/8329
+    // we need to add another record so we can do a snapshot
+    clientRule
+        .getClient()
+        .newPublishMessageCommand()
+        .messageName(""test"")
+        .correlationKey(""test"")
+        .send();
 
     // when
     clusteringRule.triggerAndWaitForSnapshots();
@@ -78,6 +86,7 @@ public class ReaderCloseTest {
     for (final Broker broker : clusteringRule.getBrokers()) {
       assertThatFilesOfDeletedSegmentsDoesNotExist(broker);
     }
+    assertThat(leaderId).isNotEqualTo(clusteringRule.getLeaderForPartition(1).getNodeId());
   }
 
   private void assertThatFilesOfDeletedSegmentsDoesNotExist(final Broker leader)

diff --git a/storage/wal/verifier_test.go b/storage/wal/verifier_test.go
index 61e1536..a44755f 100644
--- a/storage/wal/verifier_test.go
+++ b/storage/wal/verifier_test.go
@@ -138,22 +138,13 @@ func writeCorruptEntries(file *os.File, t *testing.T, n int) {
 		}
 	}
 
-
 	// Write some random bytes to the file to simulate corruption.
 	if _, err := file.Write(corruption); err != nil {
 		fatal(t, ""corrupt WAL segment"", err)
 	}
-	corrupt := []byte{1, 255, 0, 3, 45, 26, 110}
-
-	wrote, err := file.Write(corrupt)
-	if err != nil {
-		t.Fatal(err)
-	} else if wrote != len(corrupt) {
-		t.Fatal(""Error writing corrupt data to file"")
-	}
 
 	if err := file.Close(); err != nil {
-		t.Fatalf(""Error: filed to close file: %v\n"", err)
+		t.Fatalf(""Error: failed to close file: %v\n"", err)
 	}
 }
 

diff --git a/src/environment.go b/src/environment.go
index ae5e26a..0c961c5 100644
--- a/src/environment.go
+++ b/src/environment.go
@@ -229,6 +229,7 @@ func (env *environment) environ() map[string]string {
 	if env.environCache != nil {
 		return env.environCache
 	}
+	env.environCache = make(map[string]string)
 	const separator = ""=""
 	values := os.Environ()
 	for value := range values {
",3,"[""47df74d40becf915a9d89cdb887abd259b77def0"", ""fba4326c72fc22d81aba6976a9fef1e4b6154fd9"", ""dc50bd35462a49058c91a939fc8830ae7a9eb692""]","[""test"", ""refactor"", ""fix""]"
autostart feature fixed | skip flaky test,"diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();

diff --git a/test/browser-pool/browser-pool.test.ts b/test/browser-pool/browser-pool.test.ts
index 9f21322..7a011b5 100644
--- a/test/browser-pool/browser-pool.test.ts
+++ b/test/browser-pool/browser-pool.test.ts
@@ -128,7 +128,8 @@ describe.each([
             expect(page.close).toBeDefined();
         });
 
-        test('should allow early aborting in case of outer timeout', async () => {
+        // TODO: this test is very flaky in the CI
+        test.skip('should allow early aborting in case of outer timeout', async () => {
             const timeout = browserPool.operationTimeoutMillis;
             browserPool.operationTimeoutMillis = 500;
             // @ts-expect-error mocking private method
",2,"[""bed78248c941d57ad4cc20a455147e186e97c7a1"", ""e2e8ad25854bd1e7cdbc7f50b50bbd99e04ad47d""]","[""fix"", ""test""]"
ecma 7 ready,"diff --git a/config/webpack.config.prod.js b/config/webpack.config.prod.js
index f7c6b23..4a00c65 100644
--- a/config/webpack.config.prod.js
+++ b/config/webpack.config.prod.js
@@ -266,7 +266,7 @@ module.exports = {
     : new UglifyJsPlugin({
       uglifyOptions: {
         ie8: false,
-        ecma: 6,
+        ecma: 7,
         compress: {
           warnings: false,
           // Disabled because of an issue with Uglify breaking seemingly valid code:
",1,"[""6aa63c9b8d4dcdbb401743adc3c9a1020d943250""]","[""build""]"
"unset DOCKER_HOST set to swarm by jenkins

- fixes issue where old images are pushed to registry","diff --git a/.ci/docker.dsl b/.ci/docker.dsl
index 4768cb8..9f6a4c9 100644
--- a/.ci/docker.dsl
+++ b/.ci/docker.dsl
@@ -8,6 +8,9 @@ def dockerHubUpload =
 '''\
 #!/bin/bash -xeu
 
+# clear docker host env set by jenkins job
+unset DOCKER_HOST
+
 VERSION=${RELEASE_VERSION}
 
 if [ ""${RELEASE_VERSION}"" = ""SNAPSHOT"" ]; then
@@ -26,9 +29,6 @@ docker login --username ${DOCKER_HUB_USERNAME} --password ${DOCKER_HUB_PASSWORD}
 docker push camunda/zeebe:${RELEASE_VERSION}
 
 if [ ""${IS_LATEST}"" = ""true"" ]; then
-    # to make sure we can tag latest, there were problems before
-    docker rmi camunda/zeebe:latest
-
     docker tag -f camunda/zeebe:${RELEASE_VERSION} camunda/zeebe:latest
     docker push camunda/zeebe:latest
 fi
",1,"[""8b18a58969ed2adf2df2a8bfe91aedacad3868f5""]","[""cicd""]"
update version (nightly.0) | set first-attempt to 5s and subsequent-attempt to 180s by default | fix golden tests for aws_vpn_connection,"diff --git a/Cargo.lock b/Cargo.lock
index f949506..6a10219 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -94,7 +94,7 @@ dependencies = [
 
 [[package]]
 name = ""els""
-version = ""0.1.22""
+version = ""0.1.23-nightly.0""
 dependencies = [
  ""erg_common"",
  ""erg_compiler"",
@@ -105,7 +105,7 @@ dependencies = [
 
 [[package]]
 name = ""erg""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""els"",
  ""erg_common"",
@@ -115,7 +115,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_common""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""backtrace-on-stack-overflow"",
  ""crossterm"",
@@ -126,7 +126,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_compiler""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""erg_common"",
  ""erg_parser"",
@@ -134,7 +134,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_parser""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""erg_common"",
  ""unicode-xid"",
diff --git a/Cargo.toml b/Cargo.toml
index 04fdad7..ecc45e5 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -20,7 +20,7 @@ members = [
 ]
 
 [workspace.package]
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 authors = [""erg-lang team <moderation.erglang@gmail.com>""]
 license = ""MIT OR Apache-2.0""
 edition = ""2021""
@@ -64,10 +64,10 @@ full-repl = [""erg_common/full-repl""]
 full = [""els"", ""full-repl"", ""unicode"", ""pretty""]
 
 [workspace.dependencies]
-erg_common = { version = ""0.6.10"", path = ""./crates/erg_common"" }
-erg_parser = { version = ""0.6.10"", path = ""./crates/erg_parser"" }
-erg_compiler = { version = ""0.6.10"", path = ""./crates/erg_compiler"" }
-els = { version = ""0.1.22"", path = ""./crates/els"" }
+erg_common = { version = ""0.6.11-nightly.0"", path = ""./crates/erg_common"" }
+erg_parser = { version = ""0.6.11-nightly.0"", path = ""./crates/erg_parser"" }
+erg_compiler = { version = ""0.6.11-nightly.0"", path = ""./crates/erg_compiler"" }
+els = { version = ""0.1.23-nightly.0"", path = ""./crates/els"" }
 
 [dependencies]
 erg_common = { workspace = true }
diff --git a/crates/els/Cargo.toml b/crates/els/Cargo.toml
index bc031e6..7c9455f 100644
--- a/crates/els/Cargo.toml
+++ b/crates/els/Cargo.toml
@@ -2,7 +2,7 @@
 name = ""els""
 description = ""An Erg compiler frontend for IDEs, implements LSP.""
 documentation = ""http://docs.rs/els""
-version = ""0.1.22""
+version = ""0.1.23-nightly.0""
 authors.workspace = true
 license.workspace = true
 edition.workspace = true

diff --git a/testnet/stacks-node/src/config.rs b/testnet/stacks-node/src/config.rs
index 24ca06c..d80f721 100644
--- a/testnet/stacks-node/src/config.rs
+++ b/testnet/stacks-node/src/config.rs
@@ -1414,8 +1414,8 @@ impl MinerConfig {
     pub fn default() -> MinerConfig {
         MinerConfig {
             min_tx_fee: 1,
-            first_attempt_time_ms: 1_000,
-            subsequent_attempt_time_ms: 30_000,
+            first_attempt_time_ms: 5_000,
+            subsequent_attempt_time_ms: 180_000,
             microblock_attempt_time_ms: 30_000,
             probability_pick_no_estimate_tx: 5,
         }

diff --git a/internal/providers/terraform/aws/testdata/vpn_connection_test/vpn_connection_test.tf b/internal/providers/terraform/aws/testdata/vpn_connection_test/vpn_connection_test.tf
index d895677..cf10e3f 100644
--- a/internal/providers/terraform/aws/testdata/vpn_connection_test/vpn_connection_test.tf
+++ b/internal/providers/terraform/aws/testdata/vpn_connection_test/vpn_connection_test.tf
@@ -12,6 +12,7 @@ provider ""aws"" {
 resource ""aws_vpn_connection"" ""vpn_connection"" {
   customer_gateway_id = ""dummy-customer-gateway-id""
   type                = ""ipsec.1""
+  vpn_gateway_id      = ""vpn-gateway-id""
 }
 
 resource ""aws_vpn_connection"" ""transit"" {
@@ -23,10 +24,11 @@ resource ""aws_vpn_connection"" ""transit"" {
 resource ""aws_vpn_connection"" ""vpn_connection_withUsage"" {
   customer_gateway_id = ""dummy-customer-gateway-id2""
   type                = ""ipsec.1""
+  vpn_gateway_id      = ""vpn-gateway-id""
 }
 
 resource ""aws_vpn_connection"" ""transit_withUsage"" {
   customer_gateway_id = ""dummy-customer-gateway-id2""
   type                = ""ipsec.1""
   transit_gateway_id  = ""dummy-transit-gateway-id2""
-}
\ No newline at end of file
+}
",3,"[""607ecc92b5f8c084304e406eec725b7dcfa0a562"", ""d35d302cadf355a169dca6636597183de6bbee23"", ""9b059dd8245e72f0bf8c40fc633f9ef6fccae405""]","[""build"", ""fix"", ""test""]"
remove unnecessary start argument from `range` | svg helper,"diff --git a/ibis/backends/dask/tests/execution/test_window.py b/ibis/backends/dask/tests/execution/test_window.py
index 75a7331..6bfc5e3 100644
--- a/ibis/backends/dask/tests/execution/test_window.py
+++ b/ibis/backends/dask/tests/execution/test_window.py
@@ -489,7 +489,7 @@ def test_project_list_scalar(npartitions):
     expr = table.mutate(res=table.ints.quantile([0.5, 0.95]))
     result = expr.execute()
 
-    expected = pd.Series([[1.0, 1.9] for _ in range(0, 3)], name=""res"")
+    expected = pd.Series([[1.0, 1.9] for _ in range(3)], name=""res"")
     tm.assert_series_equal(result.res, expected)
 
 
diff --git a/ibis/backends/pandas/tests/execution/test_window.py b/ibis/backends/pandas/tests/execution/test_window.py
index 8f292b3..effa372 100644
--- a/ibis/backends/pandas/tests/execution/test_window.py
+++ b/ibis/backends/pandas/tests/execution/test_window.py
@@ -436,7 +436,7 @@ def test_project_list_scalar():
     expr = table.mutate(res=table.ints.quantile([0.5, 0.95]))
     result = expr.execute()
 
-    expected = pd.Series([[1.0, 1.9] for _ in range(0, 3)], name=""res"")
+    expected = pd.Series([[1.0, 1.9] for _ in range(3)], name=""res"")
     tm.assert_series_equal(result.res, expected)
 
 
diff --git a/ibis/backends/pyspark/tests/test_basic.py b/ibis/backends/pyspark/tests/test_basic.py
index 3850919..14fe677 100644
--- a/ibis/backends/pyspark/tests/test_basic.py
+++ b/ibis/backends/pyspark/tests/test_basic.py
@@ -19,7 +19,7 @@ from ibis.backends.pyspark.compiler import _can_be_replaced_by_column_name  # no
 def test_basic(con):
     table = con.table(""basic_table"")
     result = table.compile().toPandas()
-    expected = pd.DataFrame({""id"": range(0, 10), ""str_col"": ""value""})
+    expected = pd.DataFrame({""id"": range(10), ""str_col"": ""value""})
 
     tm.assert_frame_equal(result, expected)
 
@@ -28,9 +28,7 @@ def test_projection(con):
     table = con.table(""basic_table"")
     result1 = table.mutate(v=table[""id""]).compile().toPandas()
 
-    expected1 = pd.DataFrame(
-        {""id"": range(0, 10), ""str_col"": ""value"", ""v"": range(0, 10)}
-    )
+    expected1 = pd.DataFrame({""id"": range(10), ""str_col"": ""value"", ""v"": range(10)})
 
     result2 = (
         table.mutate(v=table[""id""])
@@ -44,8 +42,8 @@ def test_projection(con):
         {
             ""id"": range(0, 20, 2),
             ""str_col"": ""value"",
-            ""v"": range(0, 10),
-            ""v2"": range(0, 10),
+            ""v"": range(10),
+            ""v2"": range(10),
         }
     )
 

diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index 0f9cb63..ff5e5f0 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -1,4 +1,4 @@
-import { className, m, ns, style } from '../m';
+import { className, m, ns, svg, style } from '../m';
 import { VNode, VProps } from '../structs';
 
 const h = (tag: string, props?: VProps, ...children: VNode[]) =>
@@ -173,6 +173,28 @@ describe('.m', () => {
     });
   });
 
+  it('should attach ns to props using svg helper', () => {
+    const vnode = {
+      tag: 'svg',
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    expect(svg(vnode)).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
+
   it('should move key to distinct property', () => {
     expect(h('div', { key: 'foo' }, 'foo', h('div'))).toEqual({
       tag: 'div',
",2,"[""15f8d95754a0b6865ea475ca9e515272a07bf6ba"", ""4aa3e4c438742ef0fe694ffaf6a181874366d777""]","[""refactor"", ""test""]"
correct width when --no-quotes is used,"diff --git a/src/output/grid.rs b/src/output/grid.rs
index 37f6c57..ce989e5 100644
--- a/src/output/grid.rs
+++ b/src/output/grid.rs
@@ -8,6 +8,8 @@ use crate::output::file_name::{Classify, Options as FileStyle};
 use crate::output::file_name::{EmbedHyperlinks, ShowIcons};
 use crate::theme::Theme;
 
+use super::file_name::QuoteStyle;
+
 #[derive(PartialEq, Eq, Debug, Copy, Clone)]
 pub struct Options {
     pub across: bool,
@@ -55,27 +57,34 @@ impl<'a> Render<'a> {
                 } else {
                     0
                 };
-
-            let space_filename_offset = if file.name.contains(' ') || file.name.contains('\'') {
-                2
-            } else {
-                0
+            let space_filename_offset = match self.file_style.quote_style {
+                QuoteStyle::QuoteSpaces if file.name.contains(' ') => 2,
+                QuoteStyle::NoQuotes => 0,
+                _ => 0, // Default case
             };
-
             let contents = filename.paint();
-            #[rustfmt::skip]
             let width = match (
                 filename.options.embed_hyperlinks,
                 filename.options.show_icons,
             ) {
-                ( EmbedHyperlinks::On, ShowIcons::Always(spacing) | ShowIcons::Automatic(spacing) )
-                    => filename.bare_width() + classification_width + 1 + (spacing as usize) + space_filename_offset,
-                ( EmbedHyperlinks::On, ShowIcons::Never )
-                    => filename.bare_width() + classification_width + space_filename_offset,
-                ( EmbedHyperlinks::Off, ShowIcons::Always(spacing) | ShowIcons::Automatic(spacing) )
-                    => filename.bare_width() + 1 + (spacing as usize) + space_filename_offset,
-                ( EmbedHyperlinks::Off, _ )
-                    => *contents.width(),
+                (
+                    EmbedHyperlinks::On,
+                    ShowIcons::Always(spacing) | ShowIcons::Automatic(spacing),
+                ) => {
+                    filename.bare_width()
+                        + classification_width
+                        + 1
+                        + (spacing as usize)
+                        + space_filename_offset
+                }
+                (EmbedHyperlinks::On, ShowIcons::Never) => {
+                    filename.bare_width() + classification_width + space_filename_offset
+                }
+                (
+                    EmbedHyperlinks::Off,
+                    ShowIcons::Always(spacing) | ShowIcons::Automatic(spacing),
+                ) => filename.bare_width() + 1 + (spacing as usize) + space_filename_offset,
+                (EmbedHyperlinks::Off, _) => *contents.width(),
             };
 
             grid.add(tg::Cell {
",1,"[""61eaa2d0cca9bd27d6c5f0a8f9b34200b77fdbb0""]","[""fix""]"
"unset DOCKER_HOST set to swarm by jenkins

- fixes issue where old images are pushed to registry | nginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com> | [gn] fix include_dirs ordering error","diff --git a/.ci/docker.dsl b/.ci/docker.dsl
index 4768cb8..9f6a4c9 100644
--- a/.ci/docker.dsl
+++ b/.ci/docker.dsl
@@ -8,6 +8,9 @@ def dockerHubUpload =
 '''\
 #!/bin/bash -xeu
 
+# clear docker host env set by jenkins job
+unset DOCKER_HOST
+
 VERSION=${RELEASE_VERSION}
 
 if [ ""${RELEASE_VERSION}"" = ""SNAPSHOT"" ]; then
@@ -26,9 +29,6 @@ docker login --username ${DOCKER_HUB_USERNAME} --password ${DOCKER_HUB_PASSWORD}
 docker push camunda/zeebe:${RELEASE_VERSION}
 
 if [ ""${IS_LATEST}"" = ""true"" ]; then
-    # to make sure we can tag latest, there were problems before
-    docker rmi camunda/zeebe:latest
-
     docker tag -f camunda/zeebe:${RELEASE_VERSION} camunda/zeebe:latest
     docker push camunda/zeebe:latest
 fi

diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection

diff --git a/BUILD.gn b/BUILD.gn
index 11adaa7..ed64b17 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -240,6 +240,14 @@ static_library(""electron_lib"") {
     ""brightray"",
     ""build/node"",
   ]
+  include_dirs = [
+    ""chromium_src"",
+    ""."",
+    ""$target_gen_dir"",
+    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
+    # API of blink, then delete this include dir.
+    ""//third_party/WebKit/Source"",
+  ]
   if (enable_desktop_capturer) {
     deps += [ ""//third_party/webrtc/modules/desktop_capture"" ]
   }
@@ -275,14 +283,6 @@ static_library(""electron_lib"") {
     # Disable warnings for g_settings_list_schemas.
     ""GLIB_DISABLE_DEPRECATION_WARNINGS"",
   ]
-  include_dirs = [
-    ""chromium_src"",
-    ""."",
-    ""$target_gen_dir"",
-    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
-    # API of blink, then delete this include dir.
-    ""//third_party/WebKit/Source"",
-  ]
   if (is_component_build) {
     defines += [
       # Import V8 symbols from shared library (node.dll / libnode.so)
",3,"[""8b18a58969ed2adf2df2a8bfe91aedacad3868f5"", ""e12d9e77a6fd531a22325337838a841b1c67f00d"", ""c44cf88a6ec54e5ddd99d8348bcc57b301ec7945""]","[""cicd"", ""docs"", ""build""]"
simplyfy statement,"diff --git a/src/Object/Merge.ts b/src/Object/Merge.ts
index 1f48efb..06caad1 100644
--- a/src/Object/Merge.ts
+++ b/src/Object/Merge.ts
@@ -96,9 +96,11 @@ type ChooseMergeDeep<OK, O1K, K extends Key, OOK extends Key, style extends Merg
 @hidden
 */
 export type _MergeDeep<O, O1, K extends Key, OOK extends Key, style extends MergeStyle> =
-    Or<Extends<[O], [never]>, Extends<[O1], [never]>> extends 1 // filter never
+    [O] extends [never]
     ? MergeProp<O, O1, K, OOK, style>
-    : LibStyle<ChooseMergeDeep<NoList<O>, NoList<O1>, K, OOK, style>, O, O1, style>
+    : [O1] extends [never]
+      ? MergeProp<O, O1, K, OOK, style>
+      : LibStyle<ChooseMergeDeep<NoList<O>, NoList<O1>, K, OOK, style>, O, O1, style>
 
 /**
 @hidden
diff --git a/src/Object/Patch.ts b/src/Object/Patch.ts
index 2d73784..2c8bd42 100644
--- a/src/Object/Patch.ts
+++ b/src/Object/Patch.ts
@@ -89,9 +89,11 @@ type ChoosePatchDeep<OK, O1K, K extends Key, OOK extends Key, style extends Merg
 @hidden
 */
 export type _PatchDeep<O, O1, K extends Key, OOK extends Key, style extends MergeStyle> =
-    Or<Extends<[O], [never]>, Extends<[O1], [never]>> extends 1 // filter never
+    [O] extends [never]
     ? PatchProp<O, O1, K, OOK>
-    : LibStyle<ChoosePatchDeep<NoList<O>, NoList<O1>, K, OOK, style>, O, O1, style>
+    : [O1] extends [never]
+      ? PatchProp<O, O1, K, OOK>
+      : LibStyle<ChoosePatchDeep<NoList<O>, NoList<O1>, K, OOK, style>, O, O1, style>
 
 /**
 @hidden
",1,"[""f86944ff00b970d7e2da48abbff43e58bdf29b99""]","[""refactor""]"
auto focus inputs in survey form,"diff --git a/packages/nc-gui/pages/[projectType]/form/[viewId]/index/survey.vue b/packages/nc-gui/pages/[projectType]/form/[viewId]/index/survey.vue
index b2a90d8..dbad824 100644
--- a/packages/nc-gui/pages/[projectType]/form/[viewId]/index/survey.vue
+++ b/packages/nc-gui/pages/[projectType]/form/[viewId]/index/survey.vue
@@ -6,6 +6,7 @@ import {
   DropZoneRef,
   computed,
   onKeyStroke,
+  onMounted,
   provide,
   ref,
   useEventListener,
@@ -85,6 +86,8 @@ function transition(direction: TransitionDirection) {
 
   setTimeout(() => {
     isTransitioning.value = false
+
+    setTimeout(focusInput, 100)
   }, 1000)
 }
 
@@ -113,6 +116,19 @@ async function goPrevious() {
   goToPrevious()
 }
 
+function focusInput() {
+  if (document && typeof document !== 'undefined') {
+    const inputEl =
+      (document.querySelector('.nc-cell input') as HTMLInputElement) ||
+      (document.querySelector('.nc-cell textarea') as HTMLTextAreaElement)
+
+    if (inputEl) {
+      inputEl.select()
+      inputEl.focus()
+    }
+  }
+}
+
 useEventListener('wheel', (event) => {
   if (Math.abs(event.deltaX) < Math.abs(event.deltaY)) {
     // Scrolling more vertically than horizontally
@@ -130,6 +146,8 @@ useEventListener('wheel', (event) => {
 
 onKeyStroke(['ArrowLeft', 'ArrowDown'], goPrevious)
 onKeyStroke(['ArrowRight', 'ArrowUp', 'Enter', 'Space'], goNext)
+
+onMounted(focusInput)
 </script>
 
 <template>
",1,"[""5373c3036866db58b322b424d3be9dedff57a376""]","[""feat""]"
setup jest and add m.ts tests,"diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });
",1,"[""229b53a632ea97d47c4be11f096bdd828fb415d8""]","[""test""]"
"Use arm64v8 postfix for Cube Store :dev build | ensure ""dist"" dirs exist","diff --git a/.github/workflows/rust-cubestore-master.yml b/.github/workflows/rust-cubestore-master.yml
index 4a84984..bb07cd7 100644
--- a/.github/workflows/rust-cubestore-master.yml
+++ b/.github/workflows/rust-cubestore-master.yml
@@ -115,9 +115,9 @@ jobs:
           if [[ $VERSION =~ ^v[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]]; then
             MINOR=${VERSION%.*}
             MAJOR=${MINOR%.*}
-            TAGS=""$TAGS,${DOCKER_IMAGE}:${MINOR},${DOCKER_IMAGE}:${MAJOR},${DOCKER_IMAGE}:latest""
+            TAGS=""$TAGS,${DOCKER_IMAGE}:${MINOR},${DOCKER_IMAGE}:${MAJOR}""
           elif [ ""${{ github.event_name }}"" = ""push"" ]; then
-            TAGS=""$TAGS,${DOCKER_IMAGE}:build-1${GITHUB_RUN_NUMBER}""
+            TAGS=""$TAGS,${DOCKER_IMAGE}:build-1${GITHUB_RUN_NUMBER}${{ matrix.postfix }}""
           fi
 
           echo ::set-output name=version::${VERSION}

diff --git a/scripts/prepare.js b/scripts/prepare.js
index 9eb8cb8..f285825 100644
--- a/scripts/prepare.js
+++ b/scripts/prepare.js
@@ -68,6 +68,9 @@ async function prepare() {
     names.push(json.name)
   }
 
+  // Ensure all ""dist"" directories exist.
+  dirs.forEach(dir => fs.ensureDirSync(join(dir, distId)))
+
   log(``)
   for (let i = 0; i < names.length; i++) {
     const dir = dirs[i]
",2,"[""10bdcb452ff9d2b884d45a9c43a4b8a20fc4a883"", ""ca060bf255a55b99000ddf0c67f7422f28b735a6""]","[""cicd"", ""build""]"
"new ShowDebug parameter

calculate each segment timing
new parameter to show/hide segment debug information
set-poshprompt updated with the new showDebug parameter

Force disabled segment to be visible for debug purpose | rebuild when environment variables change (#11471)","diff --git a/engine.go b/engine.go
index 6cc1ff3..4617ceb 100644
--- a/engine.go
+++ b/engine.go
@@ -67,6 +67,9 @@ func (e *engine) renderText(text string) {
 	prefix := e.activeSegment.getValue(Prefix, "" "")
 	postfix := e.activeSegment.getValue(Postfix, "" "")
 	e.renderer.write(e.activeSegment.Background, e.activeSegment.Foreground, fmt.Sprintf(""%s%s%s"", prefix, text, postfix))
+	if *e.env.getArgs().Debug {
+		e.renderer.write(e.activeSegment.Background, e.activeSegment.Foreground, fmt.Sprintf(""(%s:%s)"", e.activeSegment.Type, e.activeSegment.timing))
+	}
 }
 
 func (e *engine) renderSegmentText(text string) {
@@ -107,13 +110,11 @@ func (e *engine) setStringValues(segments []*Segment) {
 	wg.Add(len(segments))
 	defer wg.Wait()
 	cwd := e.env.getcwd()
+	debug := *e.env.getArgs().Debug
 	for _, segment := range segments {
 		go func(s *Segment) {
 			defer wg.Done()
-			err := s.mapSegmentWithWriter(e.env)
-			if err == nil && !s.hasValue(IgnoreFolders, cwd) && s.enabled() {
-				s.stringValue = s.string()
-			}
+			s.setStringValue(e.env, cwd, debug)
 		}(segment)
 	}
 }
diff --git a/main.go b/main.go
index 56ae8a5..d67a640 100644
--- a/main.go
+++ b/main.go
@@ -14,6 +14,7 @@ type args struct {
 	Config      *string
 	Shell       *string
 	PWD         *string
+	Debug       *bool
 }
 
 func main() {
@@ -42,6 +43,10 @@ func main() {
 			""pwd"",
 			"""",
 			""the path you are working in""),
+		Debug: flag.Bool(
+			""debug"",
+			false,
+			""Print debug information""),
 	}
 	flag.Parse()
 	env := &environment{
diff --git a/packages/powershell/oh-my-posh/oh-my-posh.psm1 b/packages/powershell/oh-my-posh/oh-my-posh.psm1
index 9234fc6..1450eb3 100644
--- a/packages/powershell/oh-my-posh/oh-my-posh.psm1
+++ b/packages/powershell/oh-my-posh/oh-my-posh.psm1
@@ -5,6 +5,7 @@
 
 $global:PoshSettings = New-Object -TypeName PSObject -Property @{
     Theme = ""$PSScriptRoot\themes\jandedobbeleer.json"";
+    ShowDebug = $false
 }
 
 function Get-PoshCommand {
@@ -36,9 +37,14 @@ function Set-PoshPrompt {
     param(
         [Parameter(Mandatory = $false)]
         [string]
-        $Theme
+        $Theme,
+        [Parameter(Mandatory = $false)]
+        [bool]
+        $ShowDebug = $false
     )
 
+    $global:PoshSettings.ShowDebug = $ShowDebug
+
     if (Test-Path ""$PSScriptRoot/themes/$Theme.json"") {
         $global:PoshSettings.Theme = ""$PSScriptRoot/themes/$Theme.json""
     }
@@ -68,8 +74,9 @@ function Set-PoshPrompt {
         $startInfo = New-Object System.Diagnostics.ProcessStartInfo
         $startInfo.FileName = Get-PoshCommand
         $config = $global:PoshSettings.Theme
+        $showDebug = $global:PoshSettings.ShowDebug
         $cleanPWD = $PWD.ProviderPath.TrimEnd(""\"")
-        $startInfo.Arguments = ""-config=""""$config"""" -error=$errorCode -pwd=""""$cleanPWD""""""
+        $startInfo.Arguments = ""-debug=""""$showDebug"""" -config=""""$config"""" -error=$errorCode -pwd=""""$cleanPWD""""""
         $startInfo.Environment[""TERM""] = ""xterm-256color""
         $startInfo.CreateNoWindow = $true
         $startInfo.StandardOutputEncoding = [System.Text.Encoding]::UTF8
diff --git a/segment.go b/segment.go
index 27dd416..4015dac 100644
--- a/segment.go
+++ b/segment.go
@@ -1,6 +1,9 @@
 package main
 
-import ""errors""
+import (
+	""errors""
+	""time""
+)
 
 // Segment represent a single segment and it's configuration
 type Segment struct {
@@ -17,6 +20,7 @@ type Segment struct {
 	writer          SegmentWriter
 	stringValue     string
 	active          bool
+	timing          time.Duration
 }
 
 // SegmentWriter is the interface used to define what and if to write to the prompt
@@ -149,3 +153,26 @@ func (segment *Segment) mapSegmentWithWriter(env environmentInfo) error {
 	}
 	return errors.New(""unable to map writer"")
 }
+
+func (segment *Segment) setStringValue(env environmentInfo, cwd string, debug bool) {
+	err := segment.mapSegmentWithWriter(env)
+	if err != nil || segment.hasValue(IgnoreFolders, cwd) {
+		return
+	}
+	// add timing only in debug
+	if debug {
+		start := time.Now()
+		defer (func() {
+			// force segment rendering to display the time it took
+			// to check if the segment is enabled or not
+			// depending on the segement, calling enabled()
+			// can be time consuming
+			segment.active = true
+			elapsed := time.Since(start)
+			segment.timing = elapsed
+		})()
+	}
+	if segment.enabled() {
+		segment.stringValue = segment.string()
+	}
+}

diff --git a/cli/build.rs b/cli/build.rs
index 548fbb5..d7bed21 100644
--- a/cli/build.rs
+++ b/cli/build.rs
@@ -269,8 +269,17 @@ fn main() {
   // To debug snapshot issues uncomment:
   // op_fetch_asset::trace_serializer();
 
-  println!(""cargo:rustc-env=TS_VERSION={}"", ts_version());
+  if let Ok(c) = env::var(""DENO_CANARY"") {
+    println!(""cargo:rustc-env=DENO_CANARY={}"", c);
+  }
+  println!(""cargo:rerun-if-env-changed=DENO_CANARY"");
+
   println!(""cargo:rustc-env=GIT_COMMIT_HASH={}"", git_commit_hash());
+  println!(""cargo:rerun-if-env-changed=GIT_COMMIT_HASH"");
+
+  println!(""cargo:rustc-env=TS_VERSION={}"", ts_version());
+  println!(""cargo:rerun-if-env-changed=TS_VERSION"");
+
   println!(
     ""cargo:rustc-env=DENO_CONSOLE_LIB_PATH={}"",
     deno_console::get_declaration().display()
@@ -322,9 +331,6 @@ fn main() {
 
   println!(""cargo:rustc-env=TARGET={}"", env::var(""TARGET"").unwrap());
   println!(""cargo:rustc-env=PROFILE={}"", env::var(""PROFILE"").unwrap());
-  if let Ok(c) = env::var(""DENO_CANARY"") {
-    println!(""cargo:rustc-env=DENO_CANARY={}"", c);
-  }
 
   let c = PathBuf::from(env::var_os(""CARGO_MANIFEST_DIR"").unwrap());
   let o = PathBuf::from(env::var_os(""OUT_DIR"").unwrap());
",2,"[""bea32587586ca08f390c901a95e9b9c25263f4df"", ""63546c15bfb1284ac6d956eee274e6d7cf263a8f""]","[""feat"", ""build""]"
avoid cancelling jobs,"diff --git a/.github/workflows/ibis-backends-cloud.yml b/.github/workflows/ibis-backends-cloud.yml
index 321708e..b990984 100644
--- a/.github/workflows/ibis-backends-cloud.yml
+++ b/.github/workflows/ibis-backends-cloud.yml
@@ -29,7 +29,9 @@ jobs:
     name: ${{ matrix.backend.title }} python-${{ matrix.python-version }}
     # only a single bigquery or snowflake run at a time, otherwise test data is
     # clobbered by concurrent runs
-    concurrency: ${{ matrix.backend.name }}
+    concurrency:
+      group: ${{ matrix.backend.name }}
+      cancel-in-progress: false
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
",1,"[""19514bc68624a964c63fc217f163f7b11f3dfe82""]","[""cicd""]"
dedup redundant imports,"diff --git a/ibis/backends/base/__init__.py b/ibis/backends/base/__init__.py
index effd44c..a59c0ec 100644
--- a/ibis/backends/base/__init__.py
+++ b/ibis/backends/base/__init__.py
@@ -31,7 +31,7 @@ import ibis.common.exceptions as exc
 import ibis.config
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 
 __all__ = ('BaseBackend', 'Database', 'connect')
 
diff --git a/ibis/backends/base/sql/__init__.py b/ibis/backends/base/sql/__init__.py
index e4f2129..7bbdaf9 100644
--- a/ibis/backends/base/sql/__init__.py
+++ b/ibis/backends/base/sql/__init__.py
@@ -12,7 +12,7 @@ import ibis.expr.analysis as an
 import ibis.expr.operations as ops
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.base import BaseBackend
 from ibis.backends.base.sql.compiler import Compiler
 
diff --git a/ibis/backends/base/sql/alchemy/__init__.py b/ibis/backends/base/sql/alchemy/__init__.py
index 71cc0e8..ab89d7d 100644
--- a/ibis/backends/base/sql/alchemy/__init__.py
+++ b/ibis/backends/base/sql/alchemy/__init__.py
@@ -11,7 +11,7 @@ import ibis
 import ibis.expr.operations as ops
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql import BaseSQLBackend
 from ibis.backends.base.sql.alchemy.database import AlchemyDatabase, AlchemyTable
 from ibis.backends.base.sql.alchemy.datatypes import (
diff --git a/ibis/backends/base/sql/alchemy/query_builder.py b/ibis/backends/base/sql/alchemy/query_builder.py
index 54c74ba..0ec432f 100644
--- a/ibis/backends/base/sql/alchemy/query_builder.py
+++ b/ibis/backends/base/sql/alchemy/query_builder.py
@@ -3,7 +3,7 @@ from __future__ import annotations
 import functools
 
 import sqlalchemy as sa
-import sqlalchemy.sql as sql
+from sqlalchemy import sql
 
 import ibis.expr.operations as ops
 import ibis.expr.schema as sch
diff --git a/ibis/backends/base/sql/compiler/base.py b/ibis/backends/base/sql/compiler/base.py
index 84102aa..fb44667 100644
--- a/ibis/backends/base/sql/compiler/base.py
+++ b/ibis/backends/base/sql/compiler/base.py
@@ -7,7 +7,7 @@ import toolz
 
 import ibis.expr.analysis as an
 import ibis.expr.operations as ops
-import ibis.util as util
+from ibis import util
 
 
 class DML(abc.ABC):
diff --git a/ibis/backends/base/sql/compiler/query_builder.py b/ibis/backends/base/sql/compiler/query_builder.py
index a2d5214..95f5e8d 100644
--- a/ibis/backends/base/sql/compiler/query_builder.py
+++ b/ibis/backends/base/sql/compiler/query_builder.py
@@ -8,7 +8,7 @@ import toolz
 import ibis.common.exceptions as com
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql.compiler.base import DML, QueryAST, SetOp
 from ibis.backends.base.sql.compiler.select_builder import SelectBuilder, _LimitSpec
 from ibis.backends.base.sql.compiler.translator import ExprTranslator, QueryContext
diff --git a/ibis/backends/base/sql/registry/main.py b/ibis/backends/base/sql/registry/main.py
index 77f70a5..586ace5 100644
--- a/ibis/backends/base/sql/registry/main.py
+++ b/ibis/backends/base/sql/registry/main.py
@@ -4,7 +4,7 @@ import ibis.common.exceptions as com
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql.registry import (
     aggregate,
     binary_infix,
diff --git a/ibis/backends/base/sql/registry/timestamp.py b/ibis/backends/base/sql/registry/timestamp.py
index 412eab1..3c8571f 100644
--- a/ibis/backends/base/sql/registry/timestamp.py
+++ b/ibis/backends/base/sql/registry/timestamp.py
@@ -3,7 +3,7 @@ from __future__ import annotations
 import ibis.common.exceptions as com
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
-import ibis.util as util
+from ibis import util
 
 
 def extract_field(sql_attr):
diff --git a/ibis/backends/clickhouse/tests/test_client.py b/ibis/backends/clickhouse/tests/test_client.py
index 8db6672..bb1b9ba 100644
--- a/ibis/backends/clickhouse/tests/test_client.py
+++ b/ibis/backends/clickhouse/tests/test_client.py
@@ -3,9 +3,9 @@ import pandas.testing as tm
 import pytest
 
 import ibis
-import ibis.config as config
 import ibis.expr.datatypes as dt
 import ibis.expr.types as ir
+from ibis import config
 from ibis.backends.clickhouse.tests.conftest import (
     CLICKHOUSE_HOST,
     CLICKHOUSE_PASS,
diff --git a/ibis/backends/conftest.py b/ibis/backends/conftest.py
index 3a974da..ba7ad75 100644
--- a/ibis/backends/conftest.py
+++ b/ibis/backends/conftest.py
@@ -20,7 +20,7 @@ if TYPE_CHECKING:
 import pytest
 
 import ibis
-import ibis.util as util
+from ibis import util
 from ibis.backends.base import _get_backend_names
 
 TEST_TABLES = {
diff --git a/ibis/backends/dask/execution/util.py b/ibis/backends/dask/execution/util.py
index 61bff7e..7ed0c10 100644
--- a/ibis/backends/dask/execution/util.py
+++ b/ibis/backends/dask/execution/util.py
@@ -9,13 +9,13 @@ import pandas as pd
 from dask.dataframe.groupby import SeriesGroupBy
 
 import ibis.backends.pandas.execution.util as pd_util
-import ibis.common.graph as graph
 import ibis.expr.analysis as an
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
 import ibis.util
 from ibis.backends.dask.core import execute
 from ibis.backends.pandas.trace import TraceTwoLevelDispatcher
+from ibis.common import graph
 from ibis.expr.scope import Scope
 
 if TYPE_CHECKING:
diff --git a/ibis/backends/duckdb/datatypes.py b/ibis/backends/duckdb/datatypes.py
index fd6b8f5..52c0719 100644
--- a/ibis/backends/duckdb/datatypes.py
+++ b/ibis/backends/duckdb/datatypes.py
@@ -3,7 +3,7 @@ from __future__ import annotations
 import parsy as p
 import toolz
 
-import ibis.util as util
+from ibis import util
 from ibis.common.parsing import (
     COMMA,
     FIELD,
diff --git a/ibis/backends/impala/__init__.py b/ibis/backends/impala/__init__.py
index 4ad2057..8299a28 100644
--- a/ibis/backends/impala/__init__.py
+++ b/ibis/backends/impala/__init__.py
@@ -20,7 +20,7 @@ import ibis.config
 import ibis.expr.datatypes as dt
 import ibis.expr.rules as rlz
 import ibis.expr.schema as sch
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql import BaseSQLBackend
 from ibis.backends.base.sql.ddl import (
     CTAS,
diff --git a/ibis/backends/impala/client.py b/ibis/backends/impala/client.py
index 6655ce7..78d526f 100644
--- a/ibis/backends/impala/client.py
+++ b/ibis/backends/impala/client.py
@@ -10,7 +10,7 @@ import sqlalchemy as sa
 import ibis.common.exceptions as com
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.base import Database
 from ibis.backends.base.sql.compiler import DDL, DML
 from ibis.backends.base.sql.ddl import (
diff --git a/ibis/backends/impala/pandas_interop.py b/ibis/backends/impala/pandas_interop.py
index f410a8b..e687884 100644
--- a/ibis/backends/impala/pandas_interop.py
+++ b/ibis/backends/impala/pandas_interop.py
@@ -22,7 +22,7 @@ from posixpath import join as pjoin
 import ibis.backends.pandas.client  # noqa: F401
 import ibis.common.exceptions as com
 import ibis.expr.schema as sch
-import ibis.util as util
+from ibis import util
 from ibis.config import options
 
 
diff --git a/ibis/backends/impala/tests/conftest.py b/ibis/backends/impala/tests/conftest.py
index 1075ebe..a815be5 100644
--- a/ibis/backends/impala/tests/conftest.py
+++ b/ibis/backends/impala/tests/conftest.py
@@ -13,8 +13,7 @@ import pytest
 
 import ibis
 import ibis.expr.types as ir
-import ibis.util as util
-from ibis import options
+from ibis import options, util
 from ibis.backends.base import BaseBackend
 from ibis.backends.conftest import TEST_TABLES, _random_identifier
 from ibis.backends.impala.compiler import ImpalaCompiler, ImpalaExprTranslator
diff --git a/ibis/backends/impala/tests/test_client.py b/ibis/backends/impala/tests/test_client.py
index 0b56054..3fcca3a 100644
--- a/ibis/backends/impala/tests/test_client.py
+++ b/ibis/backends/impala/tests/test_client.py
@@ -7,9 +7,9 @@ import pytz
 
 import ibis
 import ibis.common.exceptions as com
-import ibis.config as config
 import ibis.expr.datatypes as dt
 import ibis.expr.types as ir
+from ibis import config
 from ibis.tests.util import assert_equal
 
 pytest.importorskip(""impala"")
diff --git a/ibis/backends/impala/tests/test_ddl.py b/ibis/backends/impala/tests/test_ddl.py
index 870c4dc..2346a3d 100644
--- a/ibis/backends/impala/tests/test_ddl.py
+++ b/ibis/backends/impala/tests/test_ddl.py
@@ -6,7 +6,7 @@ import ibis
 import ibis.common.exceptions as com
 import ibis.expr.datatypes as dt
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql.ddl import fully_qualified_re
 from ibis.tests.util import assert_equal
 
diff --git a/ibis/backends/impala/tests/test_exprs.py b/ibis/backends/impala/tests/test_exprs.py
index cfc8552..1d6f44f 100644
--- a/ibis/backends/impala/tests/test_exprs.py
+++ b/ibis/backends/impala/tests/test_exprs.py
@@ -5,10 +5,10 @@ import pandas.testing as tm
 import pytest
 
 import ibis
-import ibis.expr.api as api
 import ibis.expr.types as ir
 from ibis import literal as L
 from ibis.backends.impala.compiler import ImpalaCompiler
+from ibis.expr import api
 from ibis.expr.datatypes import Category
 
 
diff --git a/ibis/backends/impala/tests/test_partition.py b/ibis/backends/impala/tests/test_partition.py
index 1f96e7d..44217a4 100644
--- a/ibis/backends/impala/tests/test_partition.py
+++ b/ibis/backends/impala/tests/test_partition.py
@@ -6,7 +6,7 @@ import pandas.testing as tm
 import pytest
 
 import ibis
-import ibis.util as util
+from ibis import util
 from ibis.tests.util import assert_equal
 
 pytest.importorskip(""impala"")
diff --git a/ibis/backends/impala/tests/test_udf.py b/ibis/backends/impala/tests/test_udf.py
index 895918b..fd950d5 100644
--- a/ibis/backends/impala/tests/test_udf.py
+++ b/ibis/backends/impala/tests/test_udf.py
@@ -9,11 +9,11 @@ import ibis
 import ibis.backends.impala as api
 import ibis.common.exceptions as com
 import ibis.expr.datatypes as dt
-import ibis.expr.rules as rules
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.impala import ddl
 from ibis.common.exceptions import IbisTypeError
+from ibis.expr import rules
 
 pytest.importorskip(""impala"")
 
diff --git a/ibis/backends/impala/udf.py b/ibis/backends/impala/udf.py
index c6f2ef6..8b8b552 100644
--- a/ibis/backends/impala/udf.py
+++ b/ibis/backends/impala/udf.py
@@ -21,7 +21,7 @@ import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.rules as rlz
 import ibis.udf.validate as v
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql.registry import fixed_arity, sql_type_names
 from ibis.backends.impala.compiler import ImpalaExprTranslator
 
diff --git a/ibis/backends/mysql/__init__.py b/ibis/backends/mysql/__init__.py
index c0ddacb..50b331a 100644
--- a/ibis/backends/mysql/__init__.py
+++ b/ibis/backends/mysql/__init__.py
@@ -8,7 +8,7 @@ import warnings
 from typing import Literal
 
 import sqlalchemy as sa
-import sqlalchemy.dialects.mysql as mysql
+from sqlalchemy.dialects import mysql
 
 import ibis.expr.datatypes as dt
 import ibis.expr.schema as sch
diff --git a/ibis/backends/mysql/compiler.py b/ibis/backends/mysql/compiler.py
index 13819cb..7456f71 100644
--- a/ibis/backends/mysql/compiler.py
+++ b/ibis/backends/mysql/compiler.py
@@ -1,7 +1,7 @@
 from __future__ import annotations
 
 import sqlalchemy as sa
-import sqlalchemy.dialects.mysql as mysql
+from sqlalchemy.dialects import mysql
 
 import ibis.expr.datatypes as dt
 from ibis.backends.base.sql.alchemy import AlchemyCompiler, AlchemyExprTranslator
diff --git a/ibis/backends/postgres/tests/test_functions.py b/ibis/backends/postgres/tests/test_functions.py
index 33c6d2e..0f377e3 100644
--- a/ibis/backends/postgres/tests/test_functions.py
+++ b/ibis/backends/postgres/tests/test_functions.py
@@ -11,9 +11,9 @@ import pytest
 from pytest import param
 
 import ibis
-import ibis.config as config
 import ibis.expr.datatypes as dt
 import ibis.expr.types as ir
+from ibis import config
 from ibis import literal as L
 from ibis.expr.window import rows_with_max_lookback
 
diff --git a/ibis/backends/pyspark/__init__.py b/ibis/backends/pyspark/__init__.py
index 1b42080..b994911 100644
--- a/ibis/backends/pyspark/__init__.py
+++ b/ibis/backends/pyspark/__init__.py
@@ -14,8 +14,7 @@ import ibis.config
 import ibis.expr.operations as ops
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
-import ibis.expr.types as types
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql import BaseSQLBackend
 from ibis.backends.base.sql.compiler import Compiler, TableSetFormatter
 from ibis.backends.base.sql.ddl import (
@@ -217,16 +216,16 @@ class Backend(BaseSQLBackend):
         **kwargs: Any,
     ) -> Any:
         """"""Execute an expression.""""""
-        if isinstance(expr, types.Table):
+        if isinstance(expr, ir.Table):
             return self.compile(expr, timecontext, params, **kwargs).toPandas()
-        elif isinstance(expr, types.Column):
+        elif isinstance(expr, ir.Column):
             # expression must be named for the projection
             if not expr.has_name():
                 expr = expr.name(""tmp"")
             return self.compile(
                 expr.to_projection(), timecontext, params, **kwargs
             ).toPandas()[expr.get_name()]
-        elif isinstance(expr, types.Scalar):
+        elif isinstance(expr, ir.Scalar):
             compiled = self.compile(expr, timecontext, params, **kwargs)
             if isinstance(compiled, Column):
                 # attach result column to a fake DataFrame and
diff --git a/ibis/backends/pyspark/tests/test_ddl.py b/ibis/backends/pyspark/tests/test_ddl.py
index 0288062..ccc8a97 100644
--- a/ibis/backends/pyspark/tests/test_ddl.py
+++ b/ibis/backends/pyspark/tests/test_ddl.py
@@ -5,7 +5,7 @@ import pytest
 
 import ibis
 import ibis.common.exceptions as com
-import ibis.util as util
+from ibis import util
 from ibis.tests.util import assert_equal
 
 pyspark = pytest.importorskip(""pyspark"")
diff --git a/ibis/backends/sqlite/tests/test_client.py b/ibis/backends/sqlite/tests/test_client.py
index 95aa24d..ad64700 100644
--- a/ibis/backends/sqlite/tests/test_client.py
+++ b/ibis/backends/sqlite/tests/test_client.py
@@ -5,8 +5,8 @@ import pandas.testing as tm
 import pytest
 
 import ibis
-import ibis.config as config
 import ibis.expr.types as ir
+from ibis import config
 
 pytest.importorskip(""sqlalchemy"")
 
diff --git a/ibis/expr/format.py b/ibis/expr/format.py
index e3d48cd..85fab3f 100644
--- a/ibis/expr/format.py
+++ b/ibis/expr/format.py
@@ -9,13 +9,13 @@ from typing import Any, Callable, Deque, Iterable, Mapping, Tuple
 import rich.pretty
 
 import ibis
-import ibis.common.graph as graph
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
 import ibis.expr.window as win
-import ibis.util as util
+from ibis import util
+from ibis.common import graph
 
 Aliases = Mapping[ops.TableNode, int]
 Deps = Deque[Tuple[int, ops.TableNode]]
diff --git a/ibis/expr/operations/relations.py b/ibis/expr/operations/relations.py
index 080ddcd..de44a15 100644
--- a/ibis/expr/operations/relations.py
+++ b/ibis/expr/operations/relations.py
@@ -11,7 +11,7 @@ import ibis.expr.operations as ops
 import ibis.expr.rules as rlz
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.common.annotations import attribute
 from ibis.expr.deferred import Deferred
 from ibis.expr.operations.core import Named, Node, Value
diff --git a/ibis/expr/rules.py b/ibis/expr/rules.py
index 9b1a3b7..d40700e 100644
--- a/ibis/expr/rules.py
+++ b/ibis/expr/rules.py
@@ -11,7 +11,7 @@ import ibis.common.exceptions as com
 import ibis.expr.datatypes as dt
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.common.annotations import attribute, optional
 from ibis.common.validators import (
     bool_,
diff --git a/ibis/expr/timecontext.py b/ibis/expr/timecontext.py
index 7ecd8e7..9620d6c 100644
--- a/ibis/expr/timecontext.py
+++ b/ibis/expr/timecontext.py
@@ -38,8 +38,8 @@ from typing import TYPE_CHECKING, Any
 import numpy as np
 
 import ibis.common.exceptions as com
-import ibis.config as config
 import ibis.expr.operations as ops
+from ibis import config
 
 if TYPE_CHECKING:
     import pandas as pd
diff --git a/ibis/expr/types/groupby.py b/ibis/expr/types/groupby.py
index 138f92e..97aaaa2 100644
--- a/ibis/expr/types/groupby.py
+++ b/ibis/expr/types/groupby.py
@@ -22,7 +22,7 @@ from typing import Iterable, Sequence
 import ibis.expr.analysis as an
 import ibis.expr.types as ir
 import ibis.expr.window as _window
-import ibis.util as util
+from ibis import util
 from ibis.expr.deferred import Deferred
 
 _function_types = tuple(
diff --git a/ibis/expr/window.py b/ibis/expr/window.py
index 5ef3bb1..3e0efdc 100644
--- a/ibis/expr/window.py
+++ b/ibis/expr/window.py
@@ -11,7 +11,7 @@ import toolz
 import ibis.expr.operations as ops
 import ibis.expr.rules as rlz
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.common.exceptions import IbisInputError
 from ibis.common.grounds import Comparable
 
diff --git a/ibis/tests/expr/test_decimal.py b/ibis/tests/expr/test_decimal.py
index 85d8eb2..12b809b 100644
--- a/ibis/tests/expr/test_decimal.py
+++ b/ibis/tests/expr/test_decimal.py
@@ -3,10 +3,10 @@ import operator
 import pytest
 
 import ibis
-import ibis.expr.api as api
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
+from ibis.expr import api
 
 
 def test_type_metadata(lineitem):
diff --git a/ibis/tests/expr/test_interactive.py b/ibis/tests/expr/test_interactive.py
index cea1945..0c5613b 100644
--- a/ibis/tests/expr/test_interactive.py
+++ b/ibis/tests/expr/test_interactive.py
@@ -14,7 +14,7 @@
 
 import pytest
 
-import ibis.config as config
+from ibis import config
 from ibis.tests.expr.mocks import MockBackend
 
 
diff --git a/ibis/tests/expr/test_table.py b/ibis/tests/expr/test_table.py
index 04f4a7d..3f77985 100644
--- a/ibis/tests/expr/test_table.py
+++ b/ibis/tests/expr/test_table.py
@@ -10,13 +10,13 @@ from pytest import param
 import ibis
 import ibis.common.exceptions as com
 import ibis.expr.analysis as an
-import ibis.expr.api as api
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
 from ibis import _
 from ibis import literal as L
 from ibis.common.exceptions import RelationError
+from ibis.expr import api
 from ibis.expr.types import Column, Table
 from ibis.tests.expr.mocks import MockAlchemyBackend, MockBackend
 from ibis.tests.util import assert_equal, assert_pickle_roundtrip
diff --git a/ibis/tests/expr/test_temporal.py b/ibis/tests/expr/test_temporal.py
index e76e71c..9a0f43f 100644
--- a/ibis/tests/expr/test_temporal.py
+++ b/ibis/tests/expr/test_temporal.py
@@ -5,10 +5,10 @@ import pytest
 from pytest import param
 
 import ibis
-import ibis.expr.api as api
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
+from ibis.expr import api
 
 
 def test_temporal_literals():
diff --git a/ibis/tests/expr/test_timestamp.py b/ibis/tests/expr/test_timestamp.py
index 6601c8b..7782787 100644
--- a/ibis/tests/expr/test_timestamp.py
+++ b/ibis/tests/expr/test_timestamp.py
@@ -5,11 +5,11 @@ import pandas as pd
 import pytest
 
 import ibis
-import ibis.expr.api as api
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.rules as rlz
 import ibis.expr.types as ir
+from ibis.expr import api
 
 
 def test_field_select(alltypes):
diff --git a/ibis/tests/expr/test_value_exprs.py b/ibis/tests/expr/test_value_exprs.py
index 4c3d475..9eb247c 100644
--- a/ibis/tests/expr/test_value_exprs.py
+++ b/ibis/tests/expr/test_value_exprs.py
@@ -15,13 +15,13 @@ from pytest import param
 import ibis
 import ibis.common.exceptions as com
 import ibis.expr.analysis as L
-import ibis.expr.api as api
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.rules as rlz
 import ibis.expr.types as ir
 from ibis import _, literal
 from ibis.common.exceptions import IbisTypeError
+from ibis.expr import api
 from ibis.tests.util import assert_equal
 
 
diff --git a/ibis/tests/expr/test_visualize.py b/ibis/tests/expr/test_visualize.py
index 5525944..253564f 100644
--- a/ibis/tests/expr/test_visualize.py
+++ b/ibis/tests/expr/test_visualize.py
@@ -9,8 +9,8 @@ import ibis.expr.types as ir
 
 pytest.importorskip('graphviz')
 
-import ibis.expr.api as api  # noqa: E402
 import ibis.expr.visualize as viz  # noqa: E402
+from ibis.expr import api  # noqa: E402
 
 pytestmark = pytest.mark.skipif(
     int(os.environ.get('CONDA_BUILD', 0)) == 1, reason='CONDA_BUILD defined'
diff --git a/ibis/tests/sql/test_sqlalchemy.py b/ibis/tests/sql/test_sqlalchemy.py
index 2ad5453..3aa8c3d 100644
--- a/ibis/tests/sql/test_sqlalchemy.py
+++ b/ibis/tests/sql/test_sqlalchemy.py
@@ -15,8 +15,8 @@
 import operator
 
 import pytest
-import sqlalchemy.sql as sql
 from sqlalchemy import func as F
+from sqlalchemy import sql
 from sqlalchemy import types as sat
 
 import ibis
diff --git a/ibis/tests/util.py b/ibis/tests/util.py
index f79d09a..025bfc7 100644
--- a/ibis/tests/util.py
+++ b/ibis/tests/util.py
@@ -5,7 +5,7 @@ from __future__ import annotations
 import pickle
 
 import ibis
-import ibis.util as util
+from ibis import util
 
 
 def assert_equal(left, right):
diff --git a/pyproject.toml b/pyproject.toml
index f2146d4..492ad9e 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -310,6 +310,7 @@ select = [
   ""PGH"", # pygrep-hooks
   ""PLC"", # pylint
   ""PLE"", # pylint
+  ""PLR"", # pylint import style
   ""PLW"", # pylint
   ""RET"", # flake8-return
   ""RUF"", # ruff-specific rules
",1,"[""8d53d724275ebe4b2a0bb0bd7e2c2dfc399e049b""]","[""refactor""]"
"fix monorepo.dir prop

Signed-off-by: Carlos Alexandro Becker <caarlos0@gmail.com> | skip if related view/hook/column of a filter is not found

Signed-off-by: Pranav C <pranavxc@gmail.com> | update CI images from docker buster to bullseye

This will break `perf_image` until the new CI image is built due to the
newly required `--all-tags` parameter to `docker push` that isn't
available for the docker version we run on buster.","diff --git a/www/docs/customization/monorepo.md b/www/docs/customization/monorepo.md
index 6d0e857..e45490f 100644
--- a/www/docs/customization/monorepo.md
+++ b/www/docs/customization/monorepo.md
@@ -18,7 +18,7 @@ project_name: subproj1
 
 monorepo:
   tag_prefix: subproject1/
-  folder: subproj1
+  dir: subproj1
 ```
 
 Then, you can release with (from the project's root directory):
@@ -30,11 +30,11 @@ goreleaser release --rm-dist -f ./subproj1/.goreleaser.yml
 Then, the following is different from a ""regular"" run:
 
 - GoReleaser will then look if current commit has a tag prefixed with `subproject1`, and also the previous tag with the same prefix;
-- Changelog will include only commits that contain changes to files within the `subproj1` folder;
+- Changelog will include only commits that contain changes to files within the `subproj1` directory;
 - Release name gets prefixed with `{{ .ProjectName }} ` if empty;
-- All build's `dir` setting get set to `monorepo.folder` if empty;
+- All build's `dir` setting get set to `monorepo.dir` if empty;
   - if yours is not, you might want to change that manually;
-- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.folder`;
+- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.dir`;
 - On templates, `{{.PrefixedTag}}` will be `monorepo.prefix/tag` (aka the actual tag name), and `{{.Tag}}` has the prefix stripped;
 
 The rest of the release process should work as usual.

diff --git a/packages/nocodb/src/lib/version-upgrader/ncFilterUpgrader.ts b/packages/nocodb/src/lib/version-upgrader/ncFilterUpgrader.ts
index 1515f88..6c250bd 100644
--- a/packages/nocodb/src/lib/version-upgrader/ncFilterUpgrader.ts
+++ b/packages/nocodb/src/lib/version-upgrader/ncFilterUpgrader.ts
@@ -21,7 +21,13 @@ export default async function ({ ncMeta }: NcUpgraderCtx) {
     } else {
       continue;
     }
-    if (filter.project_id != model.project_id) {
+
+    // skip if related model is not found
+    if (!model) {
+      continue;
+    }
+
+    if (filter.project_id !== model.project_id) {
       await ncMeta.metaUpdate(
         null,
         null,

diff --git a/.circleci/config.yml b/.circleci/config.yml
index f8a53ba..c378c7e 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -336,7 +336,7 @@ jobs:
           # Disabling for now, and tracked further investigations
           # in https://github.com/influxdata/k8s-idpe/issues/3038
           docker_layer_caching: false
-          version: 19.03.14
+          version: 20.10.7
       - run: |
           sudo apt-get update
           sudo apt-get install -y docker.io
@@ -355,7 +355,7 @@ jobs:
           BRANCH=$(git rev-parse --abbrev-ref HEAD | tr '/' '.')
           COMMIT_SHA=$(git rev-parse --short HEAD)
           docker build -t quay.io/influxdb/iox:$COMMIT_SHA -t quay.io/influxdb/iox:main -f docker/Dockerfile.iox .
-          docker push quay.io/influxdb/iox
+          docker push --all-tags quay.io/influxdb/iox
           echo ""export COMMIT_SHA=${COMMIT_SHA}"" >> $BASH_ENV
       - run:
           name: Deploy tags
diff --git a/Dockerfile b/Dockerfile
index 8c23ea2..1df1fd2 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -17,7 +17,7 @@ RUN \
   cp /influxdb_iox/target/release/influxdb_iox /root/influxdb_iox && \
   du -cshx /usr/local/cargo/registry /usr/local/cargo/git /influxdb_iox/target
 
-FROM debian:buster-slim
+FROM debian:bullseye-slim
 
 RUN apt-get update \
     && apt-get install -y libssl1.1 libgcc1 libc6 ca-certificates --no-install-recommends \
diff --git a/docker/Dockerfile.ci b/docker/Dockerfile.ci
index db0a8ca..cf9cd15 100644
--- a/docker/Dockerfile.ci
+++ b/docker/Dockerfile.ci
@@ -12,7 +12,7 @@
 
 ARG RUST_VERSION
 # Build actual image used for CI pipeline
-FROM rust:${RUST_VERSION}-slim-buster
+FROM rust:${RUST_VERSION}-slim-bullseye
 
 # When https://github.com/rust-lang/rustup/issues/2686 is fixed, run the command added that
 # will install everything in rust-toolchain.toml here so that components are in the container
@@ -42,7 +42,7 @@ COPY docker/redpanda.gpg /tmp/redpanda.gpg
 # Generated from https://packages.vectorized.io/nzc4ZYQK3WRGd9sy/redpanda/cfg/setup/bash.deb.sh
 RUN apt-key add /tmp/redpanda.gpg \
     && rm /tmp/redpanda.gpg \
-    && curl ${CURL_FLAGS} ""https://packages.vectorized.io/nzc4ZYQK3WRGd9sy/redpanda/config.deb.txt?distro=debian&codename=buster&version=10&arch=x86_64"" \
+    && curl ${CURL_FLAGS} ""https://packages.vectorized.io/nzc4ZYQK3WRGd9sy/redpanda/config.deb.txt?distro=debian&codename=bullseye&version=10&arch=x86_64"" \
       > /etc/apt/sources.list.d/vectorized-redpanda.list \
     && apt-get update \
     && apt-get install -y redpanda \
diff --git a/docker/Dockerfile.iox b/docker/Dockerfile.iox
index 42414db..ae1f38e 100644
--- a/docker/Dockerfile.iox
+++ b/docker/Dockerfile.iox
@@ -1,7 +1,7 @@
 ###
 # Dockerfile used for deploying IOx
 ##
-FROM debian:buster-slim
+FROM debian:bullseye-slim
 
 RUN apt-get update \
   && apt-get install -y libssl1.1 libgcc1 libc6 ca-certificates gettext-base --no-install-recommends \
",3,"[""9ed3c0c4a72af977fc9150512fb6538f20a94b22"", ""ab1e60a97c6d5c688dacbd23bca40cb8f20c4ac3"", ""640cd88df3069a97d8244398414338dd317c5470""]","[""docs"", ""fix"", ""cicd""]"
fix pagination spacing,"diff --git a/website/layouts/Base.tsx b/website/layouts/Base.tsx
index 22d36a2..40f7130 100644
--- a/website/layouts/Base.tsx
+++ b/website/layouts/Base.tsx
@@ -399,7 +399,7 @@ export function Base({ children, headings }: BaseProps) {
                     >
                       <a className=""flex items-center space-x-4 group"">
                         <ArrowLeftIcon className=""h-4 transition-transform duration-100 ease-in-out transform group-hover:-translate-x-1"" />
-                        <div className=""flex flex-col space-x-1"">
+                        <div className=""flex flex-col space-y-1"">
                           <span className=""text-sm text-gray-500 transition-colors duration-100 ease-in-out group-hover:text-gray-700"">
                             Previous
                           </span>
@@ -418,7 +418,7 @@ export function Base({ children, headings }: BaseProps) {
                       aria-label={`Go to ${next.resource?.label}`}
                     >
                       <a className=""flex items-center space-x-4 group"">
-                        <div className=""flex flex-col space-x-1"">
+                        <div className=""flex flex-col space-y-1"">
                           <span className=""text-sm text-gray-500 transition-colors duration-100 ease-in-out group-hover:text-gray-700"">
                             Next
                           </span>
",1,"[""1e05a24486f15889ddf6bf1c711ea2bbffc1a88e""]","[""fix""]"
fix build ordering | add descriptions to buttons on hover,"diff --git a/scripts/build.mjs b/scripts/build.mjs
index 204854f..b3cf067 100644
--- a/scripts/build.mjs
+++ b/scripts/build.mjs
@@ -3,8 +3,8 @@ import { write } from 'fsxx';
 import { info, success } from './helpers.mjs';
 
 await $`rm -rf dist/*`;
-await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 await $`unbuild`;
+await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 
 const packages = [
   'jsx-runtime',

diff --git a/benchmarks/main.mjs b/benchmarks/main.mjs
index 0c2dc6b..e2f79d4 100644
--- a/benchmarks/main.mjs
+++ b/benchmarks/main.mjs
@@ -65,8 +65,9 @@ const vnode = () =>
           },
           style: style({ margin: '5px' }),
           disabled,
+          title: suite.name.split(' | ')[1],
         },
-        [suite.name],
+        [suite.name.split(' | ')[0]],
       ),
     ),
     m(
diff --git a/benchmarks/suites/appendManyRowsToLargeTable.mjs b/benchmarks/suites/appendManyRowsToLargeTable.mjs
index e6a034e..7e34ca3 100644
--- a/benchmarks/suites/appendManyRowsToLargeTable.mjs
+++ b/benchmarks/suites/appendManyRowsToLargeTable.mjs
@@ -31,7 +31,9 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(tr);
 });
 
-const suite = new benchmark.Suite('append many rows to large table');
+const suite = new benchmark.Suite(
+  'append many rows to large table | appending 1,000 to a table of 10,000 rows.',
+);
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/clearRows.mjs b/benchmarks/suites/clearRows.mjs
index ad47036..2a7711b 100644
--- a/benchmarks/suites/clearRows.mjs
+++ b/benchmarks/suites/clearRows.mjs
@@ -27,7 +27,7 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(row);
 });
 
-const suite = new benchmark.Suite('clear rows');
+const suite = new benchmark.Suite('clear rows | clearing a table with 1,000 rows');
 
 const hoistedVNode = m('table', undefined, [], VFlags.NO_CHILDREN);
 
diff --git a/benchmarks/suites/createManyRows.mjs b/benchmarks/suites/createManyRows.mjs
index 578f511..96c7b02 100644
--- a/benchmarks/suites/createManyRows.mjs
+++ b/benchmarks/suites/createManyRows.mjs
@@ -7,7 +7,7 @@ import benchmark from '../benchmark';
 import { m, patch } from '../../src/index';
 import { buildData } from '../data';
 
-const suite = new benchmark.Suite('create many rows');
+const suite = new benchmark.Suite('create many rows | creating 10,000 rows');
 
 const hoistedVNode = m(
   'div',
diff --git a/benchmarks/suites/createRows.mjs b/benchmarks/suites/createRows.mjs
index bfcc876..4d9ff57 100644
--- a/benchmarks/suites/createRows.mjs
+++ b/benchmarks/suites/createRows.mjs
@@ -7,7 +7,7 @@ import benchmark from '../benchmark';
 import { m, patch } from '../../src/index';
 import { buildData } from '../data';
 
-const suite = new benchmark.Suite('create rows');
+const suite = new benchmark.Suite('create rows | creating 1,000 rows');
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/partialUpdate.mjs b/benchmarks/suites/partialUpdate.mjs
index 55948a9..c5f1de3 100644
--- a/benchmarks/suites/partialUpdate.mjs
+++ b/benchmarks/suites/partialUpdate.mjs
@@ -34,7 +34,7 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(tr);
 });
 
-const suite = new benchmark.Suite('partial update');
+const suite = new benchmark.Suite('partial update | updating every 10th row for 1,000 rows');
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/removeRow.mjs b/benchmarks/suites/removeRow.mjs
index aeb1e9a..31c7599 100644
--- a/benchmarks/suites/removeRow.mjs
+++ b/benchmarks/suites/removeRow.mjs
@@ -30,7 +30,7 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(tr);
 });
 
-const suite = new benchmark.Suite('remove row');
+const suite = new benchmark.Suite('remove row | removing one row');
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/replaceAllRows.mjs b/benchmarks/suites/replaceAllRows.mjs
index 9555ae4..7001667 100644
--- a/benchmarks/suites/replaceAllRows.mjs
+++ b/benchmarks/suites/replaceAllRows.mjs
@@ -41,7 +41,7 @@ data2.forEach(({ id, label }) => {
 
 shuffleArray(data2);
 
-const suite = new benchmark.Suite('replace all rows');
+const suite = new benchmark.Suite('replace all rows | updating all 1,000 rows');
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/selectRow.mjs b/benchmarks/suites/selectRow.mjs
index 76be216..de69359 100644
--- a/benchmarks/suites/selectRow.mjs
+++ b/benchmarks/suites/selectRow.mjs
@@ -30,7 +30,7 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(tr);
 });
 
-const suite = new benchmark.Suite('select row');
+const suite = new benchmark.Suite('select row | highlighting a selected row');
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/swapRows.mjs b/benchmarks/suites/swapRows.mjs
index 2a91e74..ce52036 100644
--- a/benchmarks/suites/swapRows.mjs
+++ b/benchmarks/suites/swapRows.mjs
@@ -36,7 +36,7 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(tr);
 });
 
-const suite = new benchmark.Suite('swap rows');
+const suite = new benchmark.Suite('swap rows | swap 2 rows for table with 1,000 rows');
 
 const hoistedVNode = m(
   'table',
",2,"[""c323d59c607cabc91f17a78528d998f376f30b10"", ""d8d0ba8ea17ed43a04f90213851d2f27056d8cf0""]","[""build"", ""feat""]"
"repository creation | lint source on ci | fix monorepo.dir prop

Signed-off-by: Carlos Alexandro Becker <caarlos0@gmail.com>","diff --git a/server/src/services/repository.service.ts b/server/src/services/repository.service.ts
index 3869c98..d675b30 100644
--- a/server/src/services/repository.service.ts
+++ b/server/src/services/repository.service.ts
@@ -19,6 +19,8 @@ export class RepositoryService {
       return;
     }
 
+    await this.createTeam(this.github, this.getTeamName(course), course.id);
+
     const studentRepo = getCustomRepository(StudentRepository);
     const students = await studentRepo.findActiveByCourseId(this.courseId);
 
@@ -31,8 +33,8 @@ export class RepositoryService {
         if (mentorGithubId) {
           await this.inviteMentor(mentorGithubId, course);
         }
-        await this.addTeamToRepository(this.github, course, student.githubId);
       }
+      await this.addTeamToRepository(this.github, course, student.githubId);
       if (record?.repository) {
         result.push({ repository: record.repository });
       }

diff --git a/.travis.yml b/.travis.yml
index d56185e..96510cb 100644
--- a/.travis.yml
+++ b/.travis.yml
@@ -2,5 +2,6 @@ language: node_js
 node_js:
   - 'stable'
 script:
+  - yarn lint
   - yarn build
   - yarn test

diff --git a/www/docs/customization/monorepo.md b/www/docs/customization/monorepo.md
index 6d0e857..e45490f 100644
--- a/www/docs/customization/monorepo.md
+++ b/www/docs/customization/monorepo.md
@@ -18,7 +18,7 @@ project_name: subproj1
 
 monorepo:
   tag_prefix: subproject1/
-  folder: subproj1
+  dir: subproj1
 ```
 
 Then, you can release with (from the project's root directory):
@@ -30,11 +30,11 @@ goreleaser release --rm-dist -f ./subproj1/.goreleaser.yml
 Then, the following is different from a ""regular"" run:
 
 - GoReleaser will then look if current commit has a tag prefixed with `subproject1`, and also the previous tag with the same prefix;
-- Changelog will include only commits that contain changes to files within the `subproj1` folder;
+- Changelog will include only commits that contain changes to files within the `subproj1` directory;
 - Release name gets prefixed with `{{ .ProjectName }} ` if empty;
-- All build's `dir` setting get set to `monorepo.folder` if empty;
+- All build's `dir` setting get set to `monorepo.dir` if empty;
   - if yours is not, you might want to change that manually;
-- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.folder`;
+- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.dir`;
 - On templates, `{{.PrefixedTag}}` will be `monorepo.prefix/tag` (aka the actual tag name), and `{{.Tag}}` has the prefix stripped;
 
 The rest of the release process should work as usual.
",3,"[""87d5d4e55ab7149b593d29410f1fe426ba2447d4"", ""2ac99c0a66a1adc18ee4ef660608f814823dd198"", ""9ed3c0c4a72af977fc9150512fb6538f20a94b22""]","[""fix"", ""cicd"", ""docs""]"
"do not pin time in tests but only skip ahead

related to #573 | [gn win] link comctl32.lib to fix component build","diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
index 636cd21..76afff7 100644
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
@@ -15,7 +15,9 @@
  */
 package io.zeebe.broker.it.startup;
 
-import static io.zeebe.broker.it.util.TopicEventRecorder.*;
+import static io.zeebe.broker.it.util.TopicEventRecorder.incidentEvent;
+import static io.zeebe.broker.it.util.TopicEventRecorder.taskEvent;
+import static io.zeebe.broker.it.util.TopicEventRecorder.wfInstanceEvent;
 import static io.zeebe.test.util.TestUtil.doRepeatedly;
 import static io.zeebe.test.util.TestUtil.waitUntil;
 import static org.assertj.core.api.Assertions.assertThat;
@@ -24,11 +26,18 @@ import java.io.File;
 import java.io.InputStream;
 import java.nio.charset.StandardCharsets;
 import java.time.Duration;
-import java.time.Instant;
 import java.util.Collections;
 import java.util.List;
 import java.util.regex.Pattern;
 
+import org.assertj.core.util.Files;
+import org.junit.After;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.ExpectedException;
+import org.junit.rules.RuleChain;
+import org.junit.rules.TemporaryFolder;
+
 import io.zeebe.broker.clustering.ClusterServiceNames;
 import io.zeebe.broker.it.ClientRule;
 import io.zeebe.broker.it.EmbeddedBrokerRule;
@@ -38,7 +47,9 @@ import io.zeebe.client.ZeebeClient;
 import io.zeebe.client.clustering.impl.TopicLeader;
 import io.zeebe.client.clustering.impl.TopologyResponse;
 import io.zeebe.client.cmd.ClientCommandRejectedException;
-import io.zeebe.client.event.*;
+import io.zeebe.client.event.DeploymentEvent;
+import io.zeebe.client.event.TaskEvent;
+import io.zeebe.client.event.WorkflowInstanceEvent;
 import io.zeebe.model.bpmn.Bpmn;
 import io.zeebe.model.bpmn.instance.WorkflowDefinition;
 import io.zeebe.raft.Raft;
@@ -48,9 +59,6 @@ import io.zeebe.test.util.TestFileUtil;
 import io.zeebe.test.util.TestUtil;
 import io.zeebe.transport.SocketAddress;
 import io.zeebe.util.time.ClockUtil;
-import org.assertj.core.util.Files;
-import org.junit.*;
-import org.junit.rules.*;
 
 public class BrokerRecoveryTest
 {
@@ -360,17 +368,12 @@ public class BrokerRecoveryTest
         waitUntil(() -> !recordingTaskHandler.getHandledTasks().isEmpty());
 
         // when
-        restartBroker(() ->
-        {
-            final Instant now = ClockUtil.getCurrentTime();
-            ClockUtil.setCurrentTime(now.plusSeconds(60));
-        });
+        restartBroker(() -> ClockUtil.addTime(Duration.ofSeconds(60)));
 
         // wait until stream processor and scheduler process the lock task event which is not re-processed on recovery
         doRepeatedly(() ->
         {
-            final Instant now = ClockUtil.getCurrentTime();
-            ClockUtil.setCurrentTime(now.plusSeconds(60));
+            ClockUtil.addTime(Duration.ofSeconds(60)); // retriggers lock expiration check in broker
             return null;
         }).until(t -> eventRecorder.hasTaskEvent(taskEvent(""LOCK_EXPIRED"")));
 
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRestartTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRestartTest.java
index 5ff1301..0ffe98d 100644
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRestartTest.java
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRestartTest.java
@@ -15,7 +15,9 @@
  */
 package io.zeebe.broker.it.startup;
 
-import static io.zeebe.broker.it.util.TopicEventRecorder.*;
+import static io.zeebe.broker.it.util.TopicEventRecorder.incidentEvent;
+import static io.zeebe.broker.it.util.TopicEventRecorder.taskEvent;
+import static io.zeebe.broker.it.util.TopicEventRecorder.wfInstanceEvent;
 import static io.zeebe.test.util.TestUtil.waitUntil;
 import static org.assertj.core.api.Assertions.assertThat;
 
@@ -23,11 +25,18 @@ import java.io.File;
 import java.io.InputStream;
 import java.nio.charset.StandardCharsets;
 import java.time.Duration;
-import java.time.Instant;
 import java.util.Collections;
 import java.util.List;
 import java.util.regex.Pattern;
 
+import org.junit.After;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.experimental.categories.Category;
+import org.junit.rules.ExpectedException;
+import org.junit.rules.RuleChain;
+import org.junit.rules.TemporaryFolder;
+
 import io.zeebe.broker.clustering.ClusterServiceNames;
 import io.zeebe.broker.it.ClientRule;
 import io.zeebe.broker.it.EmbeddedBrokerRule;
@@ -37,7 +46,9 @@ import io.zeebe.client.ZeebeClient;
 import io.zeebe.client.clustering.impl.TopicLeader;
 import io.zeebe.client.clustering.impl.TopologyResponse;
 import io.zeebe.client.cmd.ClientCommandRejectedException;
-import io.zeebe.client.event.*;
+import io.zeebe.client.event.DeploymentEvent;
+import io.zeebe.client.event.TaskEvent;
+import io.zeebe.client.event.WorkflowInstanceEvent;
 import io.zeebe.model.bpmn.Bpmn;
 import io.zeebe.model.bpmn.instance.WorkflowDefinition;
 import io.zeebe.raft.Raft;
@@ -47,9 +58,6 @@ import io.zeebe.test.util.TestFileUtil;
 import io.zeebe.test.util.TestUtil;
 import io.zeebe.transport.SocketAddress;
 import io.zeebe.util.time.ClockUtil;
-import org.junit.*;
-import org.junit.experimental.categories.Category;
-import org.junit.rules.*;
 
 public class BrokerRestartTest
 {
@@ -360,11 +368,7 @@ public class BrokerRestartTest
         waitUntil(() -> !recordingTaskHandler.getHandledTasks().isEmpty());
 
         // when
-        restartBroker(() ->
-        {
-            final Instant now = ClockUtil.getCurrentTime();
-            ClockUtil.setCurrentTime(now.plusSeconds(60));
-        });
+        restartBroker(() -> ClockUtil.addTime(Duration.ofSeconds(60)));
 
         waitUntil(() -> eventRecorder.hasTaskEvent(taskEvent(""LOCK_EXPIRED"")));
         recordingTaskHandler.clear();
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/task/TaskSubscriptionTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/task/TaskSubscriptionTest.java
index 49b527d..a322fbe 100644
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/task/TaskSubscriptionTest.java
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/task/TaskSubscriptionTest.java
@@ -353,7 +353,7 @@ public class TaskSubscriptionTest
         waitUntil(() -> taskHandler.getHandledTasks().size() == 1);
 
         // when
-        ClockUtil.setCurrentTime(Instant.now().plus(Duration.ofMinutes(5)));
+        ClockUtil.addTime(Duration.ofMinutes(5));
 
         // then
         waitUntil(() -> taskHandler.getHandledTasks().size() == 2);

diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]
",2,"[""7ece3a9a16780dc6c633bbd903d36ce0aefd6a8a"", ""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0""]","[""test"", ""build""]"
"add getting started gitlab ci configuration

Signed-off-by: Adrien Brault <adrien.brault@gmail.com> | updated react demo parcel command | removing automatic page push on nav","diff --git a/docs/getting-started/1201-ci-environment.md b/docs/getting-started/1201-ci-environment.md
index 6c72b15..2313e30 100644
--- a/docs/getting-started/1201-ci-environment.md
+++ b/docs/getting-started/1201-ci-environment.md
@@ -46,7 +46,60 @@ If you would like us to document CircleCI next, vote for it here: [dagger#1677](
 
 <TabItem value=""gitlab"">
 
-If you would like us to document GitLab next, vote for it here: [dagger#1677](https://github.com/dagger/dagger/discussions/1677)
+```yaml
+.docker:
+    image: docker:${DOCKER_VERSION}-git
+    services:
+        - docker:${DOCKER_VERSION}-dind
+    variables:
+        # See https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#docker-in-docker-with-tls-enabled-in-the-docker-executor
+        DOCKER_HOST: tcp://docker:2376
+
+        DOCKER_TLS_VERIFY: '1'
+        DOCKER_TLS_CERTDIR: '/certs'
+        DOCKER_CERT_PATH: '/certs/client'
+
+        # Faster than the default, apparently
+        DOCKER_DRIVER: overlay2
+
+        DOCKER_VERSION: '20.10'
+
+.dagger:
+    extends: [.docker]
+    variables:
+        DAGGER_VERSION: 0.2.4
+        DAGGER_LOG_FORMAT: plain
+        DAGGER_CACHE_PATH: .dagger-cache
+
+        ARGS: ''
+    cache:
+        key: dagger-${CI_JOB_NAME}
+        paths:
+            - ${DAGGER_CACHE_PATH}
+    before_script:
+        - apk add --no-cache curl
+        - |
+            # install dagger
+            cd /usr/local
+            curl -L https://dl.dagger.io/dagger/install.sh | sh
+            cd -
+
+            dagger version
+    script:
+        - dagger project update
+        - |
+            dagger \
+                do \
+                --cache-from type=local,src=${DAGGER_CACHE_PATH} \
+                --cache-to type=local,mode=max,dest=${DAGGER_CACHE_PATH} \
+                ${ARGS}
+
+build:
+    extends: [.dagger]
+    variables:
+        ARGS: build
+
+```
 
 </TabItem>
 

diff --git a/demo/react/package.json b/demo/react/package.json
index be28bf9..32d0952 100644
--- a/demo/react/package.json
+++ b/demo/react/package.json
@@ -12,7 +12,7 @@
   },
   ""scripts"": {
     ""start"": ""parcel serve public/index.html --no-cache --open"",
-    ""build"": ""parcel build -t browser -d dist public/index.html --no-source-maps""
+    ""build"": ""parcel build --target browser --dist-dir dist public/index.html --no-source-maps""
   },
   ""bugs"": {
     ""url"": ""https://github.com/matteobruni/tsparticles/issues""

diff --git a/ionic/components/nav/test/basic/index.ts b/ionic/components/nav/test/basic/index.ts
index 4b1a8ea..2834f68 100644
--- a/ionic/components/nav/test/basic/index.ts
+++ b/ionic/components/nav/test/basic/index.ts
@@ -63,12 +63,6 @@ class FirstPage {
     }
   }
 
-  onPageDidEnter() {
-    setTimeout(() => {
-      this.nav.push(PrimaryHeaderPage);
-    }, 1000);
-  }
-
   setPages() {
     let items = [
       PrimaryHeaderPage
",3,"[""12257ce53f94dc902df4ba087de90f52d2840ad4"", ""32b92cfa0b74a6c25990e32ac6aab12b8496794c"", ""cd9e6a2ab17c5961b0f977bb8a06f8545da49a97""]","[""docs"", ""build"", ""test""]"
auto focus inputs in survey form | remove duplicated variables,"diff --git a/packages/nc-gui/pages/[projectType]/form/[viewId]/index/survey.vue b/packages/nc-gui/pages/[projectType]/form/[viewId]/index/survey.vue
index b2a90d8..dbad824 100644
--- a/packages/nc-gui/pages/[projectType]/form/[viewId]/index/survey.vue
+++ b/packages/nc-gui/pages/[projectType]/form/[viewId]/index/survey.vue
@@ -6,6 +6,7 @@ import {
   DropZoneRef,
   computed,
   onKeyStroke,
+  onMounted,
   provide,
   ref,
   useEventListener,
@@ -85,6 +86,8 @@ function transition(direction: TransitionDirection) {
 
   setTimeout(() => {
     isTransitioning.value = false
+
+    setTimeout(focusInput, 100)
   }, 1000)
 }
 
@@ -113,6 +116,19 @@ async function goPrevious() {
   goToPrevious()
 }
 
+function focusInput() {
+  if (document && typeof document !== 'undefined') {
+    const inputEl =
+      (document.querySelector('.nc-cell input') as HTMLInputElement) ||
+      (document.querySelector('.nc-cell textarea') as HTMLTextAreaElement)
+
+    if (inputEl) {
+      inputEl.select()
+      inputEl.focus()
+    }
+  }
+}
+
 useEventListener('wheel', (event) => {
   if (Math.abs(event.deltaX) < Math.abs(event.deltaY)) {
     // Scrolling more vertically than horizontally
@@ -130,6 +146,8 @@ useEventListener('wheel', (event) => {
 
 onKeyStroke(['ArrowLeft', 'ArrowDown'], goPrevious)
 onKeyStroke(['ArrowRight', 'ArrowUp', 'Enter', 'Space'], goNext)
+
+onMounted(focusInput)
 </script>
 
 <template>

diff --git a/packages/core/src/components/item/item.ios.scss b/packages/core/src/components/item/item.ios.scss
index 4de5455..6c4d11a 100644
--- a/packages/core/src/components/item/item.ios.scss
+++ b/packages/core/src/components/item/item.ios.scss
@@ -47,15 +47,6 @@ $item-ios-detail-push-color:              $list-ios-border-color !default;
 /// @prop - Icon for the detail arrow
 $item-ios-detail-push-svg:                ""<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 12 20'><path d='M2,20l-2-2l8-8L0,2l2-2l10,10L2,20z' fill='#{$item-ios-detail-push-color}'/></svg>"" !default;
 
-/// @prop - Background for the divider
-$item-ios-divider-background:             #f7f7f7 !default;
-
-/// @prop - Color for the divider
-$item-ios-divider-color:                  #222 !default;
-
-/// @prop - Padding for the divider
-$item-ios-divider-padding:                5px 15px !default;
-
 
 // iOS Item
 // --------------------------------------------------
diff --git a/packages/core/src/components/item/item.md.scss b/packages/core/src/components/item/item.md.scss
index 1dd1800..3dadbc0 100644
--- a/packages/core/src/components/item/item.md.scss
+++ b/packages/core/src/components/item/item.md.scss
@@ -35,21 +35,6 @@ $item-md-detail-push-color:          $list-md-border-color !default;
 /// @prop - Icon for the detail arrow
 $item-md-detail-push-svg:            ""<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 12 20'><path d='M2,20l-2-2l8-8L0,2l2-2l10,10L2,20z' fill='#{$item-md-detail-push-color}'/></svg>"" !default;
 
-/// @prop - Color for the divider
-$item-md-divider-color:              #858585 !default;
-
-/// @prop - Background for the divider
-$item-md-divider-background:         #fff !default;
-
-/// @prop - Font size for the divider
-$item-md-divider-font-size:          $item-md-body-text-font-size !default;
-
-/// @prop - Border bottom for the divider
-$item-md-divider-border-bottom:      1px solid $list-md-border-color !default;
-
-/// @prop - Padding for the divider
-$item-md-divider-padding:            5px 15px !default;
-
 
 .item-md {
   @include padding-horizontal($item-md-padding-start, 0);
diff --git a/packages/core/src/components/item/item.wp.scss b/packages/core/src/components/item/item.wp.scss
index 2c4aae6..07b9266 100644
--- a/packages/core/src/components/item/item.wp.scss
+++ b/packages/core/src/components/item/item.wp.scss
@@ -41,21 +41,6 @@ $item-wp-detail-push-color:          $input-wp-border-color !default;
 /// @prop - Icon for the detail arrow
 $item-wp-detail-push-svg:            ""<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 12 20'><path d='M2,20l-2-2l8-8L0,2l2-2l10,10L2,20z' fill='#{$item-wp-detail-push-color}'/></svg>"" !default;
 
-/// @prop - Color for the divider
-$item-wp-divider-color:              $list-wp-text-color !default;
-
-/// @prop - Background for the divider
-$item-wp-divider-background:         #fff !default;
-
-/// @prop - Bodrer bottom for the divider
-$item-wp-divider-border-bottom:      1px solid $list-wp-border-color !default;
-
-/// @prop - Font size for the divider
-$item-wp-divider-font-size:          2rem !default;
-
-/// @prop - Padding for the divider
-$item-wp-divider-padding:            5px 15px !default;
-
 
 .item-wp {
   @include padding-horizontal($item-wp-padding-start, 0);
",2,"[""5373c3036866db58b322b424d3be9dedff57a376"", ""cd7e8c3d3549ea05115b3f02586eeba894d86906""]","[""feat"", ""refactor""]"
"add hardware back button

Closes #5071 | init environ cache | fix sonar integration","diff --git a/ionic/components/app/app.ts b/ionic/components/app/app.ts
index 04d8c57..08aab92 100644
--- a/ionic/components/app/app.ts
+++ b/ionic/components/app/app.ts
@@ -3,8 +3,7 @@ import {Title} from 'angular2/platform/browser';
 
 import {Config} from '../../config/config';
 import {ClickBlock} from '../../util/click-block';
-import {Nav} from '../nav/nav';
-import {Tabs} from '../tabs/tabs';
+import {Platform} from '../../platform/platform';
 
 
 /**
@@ -23,8 +22,20 @@ export class IonicApp {
 
   constructor(
     private _config: Config,
-    private _clickBlock: ClickBlock
-  ) {}
+    private _clickBlock: ClickBlock,
+    platform: Platform
+  ) {
+    platform.backButton.subscribe(() => {
+      let activeNav = this.getActiveNav();
+      if (activeNav) {
+        if (activeNav.length() === 1) {
+          platform.exitApp();
+        } else {
+          activeNav.pop();
+        }
+      }
+    });
+  }
 
   /**
    * Sets the document title.
@@ -102,7 +113,7 @@ export class IonicApp {
   /**
    * @private
    */
-  getActiveNav(): Nav | Tabs {
+  getActiveNav(): any {
     var nav = this._rootNav || null;
     var activeChildNav;
 

diff --git a/src/environment.go b/src/environment.go
index ae5e26a..0c961c5 100644
--- a/src/environment.go
+++ b/src/environment.go
@@ -229,6 +229,7 @@ func (env *environment) environ() map[string]string {
 	if env.environCache != nil {
 		return env.environCache
 	}
+	env.environCache = make(map[string]string)
 	const separator = ""=""
 	values := os.Environ()
 	for value := range values {

diff --git a/.ci/scripts/distribution/analyse-java.sh b/.ci/scripts/distribution/analyse-java.sh
index a0122f7..0e965df 100755
--- a/.ci/scripts/distribution/analyse-java.sh
+++ b/.ci/scripts/distribution/analyse-java.sh
@@ -23,12 +23,12 @@ else
   fi
 
   if [ ""${GIT_BRANCH}"" == ""master"" ] || [ ""${GIT_BRANCH}"" == ""develop"" ]; then
-    TARGET_BRANCH=""master""
+    TARGET_BRANCH=""${GIT_BRANCH}""
   else
     TARGET_BRANCH=""develop""
+    PROPERTIES+=(""-Dsonar.branch.target=${TARGET_BRANCH}"")
   fi
 
-  PROPERTIES+=(""-Dsonar.branch.target=${TARGET_BRANCH}"")
   git fetch --no-tags ""${GIT_URL}"" ""+refs/heads/${TARGET_BRANCH}:refs/remotes/origin/${TARGET_BRANCH}""
 fi
 
diff --git a/parent/pom.xml b/parent/pom.xml
index f4c3160..d34b41f 100644
--- a/parent/pom.xml
+++ b/parent/pom.xml
@@ -1570,7 +1570,7 @@
         <!-- sonarscanner integration -->
         <!-- sonar.login token must be passed at runtime to avoid sharing token -->
         <sonar.host.url>https://sonarcloud.io</sonar.host.url>
-        <sonar.organization>zeebe-io</sonar.organization>
+        <sonar.organization>camunda-cloud</sonar.organization>
         <sonar.login>${env.SONARCLOUD_TOKEN}</sonar.login>
         <sonar.links.issue>${project.scm.url}/issues</sonar.links.issue>
         <sonar.cpd.exclusions>
",3,"[""68278b00450f2679761a2999500f6d87a579376b"", ""dc50bd35462a49058c91a939fc8830ae7a9eb692"", ""6cbbd98dfe6c768dbe49f8d6d2448856a9a86089""]","[""feat"", ""fix"", ""build""]"
add --ignore-existing to all npx commands,"diff --git a/docs/getting-started/getting-started.md b/docs/getting-started/getting-started.md
index dc6db37..3ef9d0a 100644
--- a/docs/getting-started/getting-started.md
+++ b/docs/getting-started/getting-started.md
@@ -13,7 +13,7 @@ npm install -g @angular/cli
 **Using `npx`**
 
 ```bash
-npx create-nx-workspace myworkspace
+npx --ignore-existing create-nx-workspace myworkspace
 ```
 
 **Using `npm init`**
diff --git a/docs/guides/react-and-angular.md b/docs/guides/react-and-angular.md
index c1929a2..a5651ff 100644
--- a/docs/guides/react-and-angular.md
+++ b/docs/guides/react-and-angular.md
@@ -11,7 +11,7 @@ To show how Nx does it, let's build two applications (one in Angular, and one in
 Let's start by creating a new Nx workspace. The easiest way to do this is to use npx.
 
 ```bash
-npx create-nx-workspace happynrwl --preset=empty
+npx --ignore-existing create-nx-workspace happynrwl --preset=empty
 ```
 
 ## Creating an Angular Application
diff --git a/docs/guides/react.md b/docs/guides/react.md
index e1647fd..eac848e 100644
--- a/docs/guides/react.md
+++ b/docs/guides/react.md
@@ -16,13 +16,13 @@ Nx has first class support for React: you can create React applications and libr
 Create a new Nx workspace. The easiest way to do it is to use npx.
 
 ```bash
-npx create-nx-workspace happynrwl --preset=empty
+npx --ignore-existing create-nx-workspace happynrwl --preset=empty
 ```
 
 You can also create a workspace with a React application in place by running:
 
 ```bash
-npx create-nx-workspace happynrwl --preset=react
+npx --ignore-existing create-nx-workspace happynrwl --preset=react
 ```
 
 ## Generating a React Application
diff --git a/docs/tutorial/01-create-application.md b/docs/tutorial/01-create-application.md
index ea87ecf..967a56e 100644
--- a/docs/tutorial/01-create-application.md
+++ b/docs/tutorial/01-create-application.md
@@ -7,7 +7,7 @@ In this tutorial you will use Nx to build a full-stack application out of common
 **Start by creating a new workspace.**
 
 ```bash
-npx create-nx-workspace myorg
+npx --ignore-existing create-nx-workspace myorg
 ```
 
 When asked about 'preset', select `empty`.
",1,"[""fc9af4d0b93d69be4e201ffb18da04324e8a4a87""]","[""docs""]"
convert to record | pin version of actionlint used,"diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
index cc998c6..65c8550 100755
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
@@ -167,13 +167,8 @@ public final class ExporterDirectorDistributionTest {
    * <p>This makes sure that even if we miss one export position event, we distribute the event
    * later again, which makes tests less flaky.
    */
-  private static final class ClockShifter implements ConditionEvaluationListener<Void> {
-
-    private final ControlledActorClock clock;
-
-    public ClockShifter(final ControlledActorClock clock) {
-      this.clock = clock;
-    }
+  private record ClockShifter(ControlledActorClock clock)
+      implements ConditionEvaluationListener<Void> {
 
     @Override
     public void conditionEvaluated(final EvaluatedCondition<Void> condition) {

diff --git a/.github/workflows/introspect.yml b/.github/workflows/introspect.yml
index b6d9125..82d22a5 100644
--- a/.github/workflows/introspect.yml
+++ b/.github/workflows/introspect.yml
@@ -25,5 +25,5 @@ jobs:
       # From https://github.com/rhysd/actionlint/blob/main/docs/usage.md#use-actionlint-on-github-actions
       - name: Check workflow files
         run: |
-          bash <(curl https://raw.githubusercontent.com/rhysd/actionlint/590d3bd9dde0c91f7a66071d40eb84716526e5a6/scripts/download-actionlint.bash)
+          bash <(curl https://raw.githubusercontent.com/rhysd/actionlint/590d3bd9dde0c91f7a66071d40eb84716526e5a6/scripts/download-actionlint.bash) 1.6.25
           ./actionlint -color -shellcheck=""""
",2,"[""3346331a963766c8193170fb130adad2e658ada2"", ""b702adc245f679ae20d84de39f0d63b14aabed5d""]","[""refactor"", ""cicd""]"
"allow disabling dynamic queue | add classname and style props for Playground | use new, public `quay.io/influxdb/iox` image","diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);

diff --git a/packages/docz-theme-default/src/components/ui/Render.tsx b/packages/docz-theme-default/src/components/ui/Render.tsx
index 197359b..943f9ab 100644
--- a/packages/docz-theme-default/src/components/ui/Render.tsx
+++ b/packages/docz-theme-default/src/components/ui/Render.tsx
@@ -24,9 +24,16 @@ const Code = styled('div')`
   }
 `
 
-export const Render: RenderComponent = ({ component, code }) => (
+export const Render: RenderComponent = ({
+  component,
+  code,
+  className,
+  style,
+}) => (
   <Fragment>
-    <Playground>{component}</Playground>
+    <Playground className={className} style={style}>
+      {component}
+    </Playground>
     <Code>{code}</Code>
   </Fragment>
 )
diff --git a/packages/docz/src/components/DocPreview.tsx b/packages/docz/src/components/DocPreview.tsx
index ca2d88f..ee8f7c0 100644
--- a/packages/docz/src/components/DocPreview.tsx
+++ b/packages/docz/src/components/DocPreview.tsx
@@ -16,6 +16,8 @@ const DefaultLoading: SFC = () => null
 export type RenderComponent = ComponentType<{
   component: JSX.Element
   code: any
+  className?: string
+  style?: any
 }>
 
 export const DefaultRender: RenderComponent = ({ component, code }) => (
diff --git a/packages/docz/src/components/Playground.tsx b/packages/docz/src/components/Playground.tsx
index d6ff5a3..418c82e 100644
--- a/packages/docz/src/components/Playground.tsx
+++ b/packages/docz/src/components/Playground.tsx
@@ -9,15 +9,21 @@ export interface PlaygroundProps {
   __code: (components: ComponentsMap) => any
   children: any
   components: ComponentsMap
+  className?: string
+  style?: any
 }
 
 const BasePlayground: SFC<PlaygroundProps> = ({
   components,
   children,
   __code,
+  className,
+  style,
 }) => {
   return components && components.render ? (
     <components.render
+      className={className}
+      style={style}
       component={isFn(children) ? children() : children}
       code={__code(components)}
     />

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 3ae6728..a5f2d2f 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -12,7 +12,7 @@
 # The CI for every PR and merge to main runs tests, fmt, lints and compiles debug binaries
 #
 # On main if all these checks pass it will then additionally compile in ""release"" mode and
-# publish a docker image to quay.io/influxdb/fusion:$COMMIT_SHA
+# publish a docker image to quay.io/influxdb/iox:$COMMIT_SHA
 #
 # Manual CI Image:
 #
@@ -317,11 +317,11 @@ jobs:
   #
   # Uses the latest ci_image (influxdb/rust below) to build a release binary and
   # copies it to a minimal container image based upon `rust:slim-buster`. This
-  # minimal image is then pushed to `quay.io/influxdb/fusion:${BRANCH}` with '/'
+  # minimal image is then pushed to `quay.io/influxdb/iox:${BRANCH}` with '/'
   # repaced by '.' - as an example:
   #
   #   git branch: dom/my-awesome-feature/perf
-  #   container: quay.io/influxdb/fusion:dom.my-awesome-feature.perf
+  #   container: quay.io/influxdb/iox:dom.my-awesome-feature.perf
   #
   # Subsequent CI runs will overwrite the tag if you push more changes, so watch
   # out for parallel CI runs!
@@ -365,7 +365,7 @@ jobs:
           sudo apt-get update
           sudo apt-get install -y docker.io
       - run: |
-          echo ""$QUAY_PASS"" | docker login quay.io --username $QUAY_USER --password-stdin
+          echo ""$QUAY_INFLUXDB_IOX_PASS"" | docker login quay.io --username $QUAY_INFLUXDB_IOX_USER --password-stdin
       - run:
           # Docker has functionality to support per-Dockerfile .dockerignore
           # This was added in https://github.com/moby/buildkit/pull/901
@@ -379,8 +379,8 @@ jobs:
           echo sha256sum after build is
           sha256sum target/release/influxdb_iox
           COMMIT_SHA=$(git rev-parse --short HEAD)
-          docker build -t quay.io/influxdb/fusion:$COMMIT_SHA -f docker/Dockerfile.iox .
-          docker push quay.io/influxdb/fusion:$COMMIT_SHA
+          docker build -t quay.io/influxdb/iox:$COMMIT_SHA -f docker/Dockerfile.iox .
+          docker push quay.io/influxdb/iox:$COMMIT_SHA
           echo ""export COMMIT_SHA=${COMMIT_SHA}"" >> $BASH_ENV
       - run:
           name: Deploy tags
",3,"[""9ef5c0d14193a9abb09b39856f58477d1f4b0d77"", ""1b64ed30a2e3c41abf3976efee4c7463044b2ef1"", ""f751bb5426b87f82096d620f1cd6203badf45d58""]","[""fix"", ""feat"", ""cicd""]"
"add instruction for finding version | enable recovery test

related to camunda-tngp/zeebe#353","diff --git a/.github/ISSUE_TEMPLATE/_bug_report_chs.md b/.github/ISSUE_TEMPLATE/_bug_report_chs.md
index 42a2e0f..44a33db 100644
--- a/.github/ISSUE_TEMPLATE/_bug_report_chs.md
+++ b/.github/ISSUE_TEMPLATE/_bug_report_chs.md
@@ -36,7 +36,7 @@ assignees: ''
 ## 
 - : [] <!--  [Window10] -->
 - : [] <!--  [Chrome77] -->
-- : [] <!--  [v7.0.0] -->
+- : [] <!--  [v7.0.0]  -->
 
 <!--  ##  -->
 

diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
index 22b8590..db1b553 100644
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
@@ -116,7 +116,6 @@ public class BrokerRecoveryTest
         ClockUtil.reset();
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldCreateWorkflowInstanceAfterRestart()
     {
@@ -136,7 +135,6 @@ public class BrokerRecoveryTest
         waitUntil(() -> eventRecorder.hasWorkflowInstanceEvent(wfInstanceEvent(""WORKFLOW_INSTANCE_CREATED"")));
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldContinueWorkflowInstanceAtTaskAfterRestart()
     {
@@ -166,7 +164,6 @@ public class BrokerRecoveryTest
         waitUntil(() -> eventRecorder.hasWorkflowInstanceEvent(wfInstanceEvent(""WORKFLOW_INSTANCE_COMPLETED"")));
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldContinueWorkflowInstanceWithLockedTaskAfterRestart()
     {
@@ -200,7 +197,6 @@ public class BrokerRecoveryTest
         waitUntil(() -> eventRecorder.hasWorkflowInstanceEvent(wfInstanceEvent(""WORKFLOW_INSTANCE_COMPLETED"")));
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldContinueWorkflowInstanceAtSecondTaskAfterRestart()
     {
@@ -237,7 +233,6 @@ public class BrokerRecoveryTest
         waitUntil(() -> eventRecorder.hasWorkflowInstanceEvent(wfInstanceEvent(""WORKFLOW_INSTANCE_COMPLETED"")));
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldDeployNewWorkflowVersionAfterRestart()
     {
@@ -412,7 +407,6 @@ public class BrokerRecoveryTest
         waitUntil(() -> eventRecorder.hasTaskEvent(taskEvent(""COMPLETED"")));
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldResolveIncidentAfterRestart()
     {
@@ -443,7 +437,6 @@ public class BrokerRecoveryTest
         waitUntil(() -> eventRecorder.hasTaskEvent(taskEvent(""CREATED"")));
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldResolveFailedIncidentAfterRestart()
     {
",2,"[""af0a5f7ab9d71fe20aa0888f682368f32b26fe18"", ""f2cc48b74bf92fe22cc265cff4224565f910a921""]","[""docs"", ""test""]"
"return Animated nodes passed to ""getAnimated""

...instead of undefined.

Also, stop using instanceof in ""isAnimated"" for perf. | add test case with multiple partitions for message | Support ISNULL","diff --git a/packages/animated/src/Animated.ts b/packages/animated/src/Animated.ts
index 00daa96..05ff7f9 100644
--- a/packages/animated/src/Animated.ts
+++ b/packages/animated/src/Animated.ts
@@ -4,7 +4,7 @@ import { AnimatedValue } from './AnimatedValue'
 const $node: any = Symbol.for('Animated:node')
 
 export const isAnimated = (value: any): value is Animated =>
-  value instanceof Animated
+  !!value && value[$node] === value
 
 /** Get the owner's `Animated` node. */
 export const getAnimated = (owner: any): Animated | undefined =>
@@ -23,6 +23,10 @@ export abstract class Animated<T = any> {
   protected payload?: Payload
 
   /** Returns every value of the node. Pass true for only the animated values. */
+  constructor() {
+    setAnimated(this, this)
+  }
+
   abstract getValue(animated?: boolean): T
 
   abstract setValue(value: T): void

diff --git a/broker-core/src/main/java/io/zeebe/broker/subscription/command/SubscriptionCommandSender.java b/broker-core/src/main/java/io/zeebe/broker/subscription/command/SubscriptionCommandSender.java
index 693d1da..e3552d4 100644
--- a/broker-core/src/main/java/io/zeebe/broker/subscription/command/SubscriptionCommandSender.java
+++ b/broker-core/src/main/java/io/zeebe/broker/subscription/command/SubscriptionCommandSender.java
@@ -74,7 +74,7 @@ public class SubscriptionCommandSender {
       new CloseWorkflowInstanceSubscriptionCommand();
 
   private final ClientTransport subscriptionClient;
-  private final IntArrayList partitionIds;
+  private final IntArrayList partitionIds = new IntArrayList();
 
   private int partitionId;
   private TopologyPartitionListenerImpl partitionListener;
@@ -82,7 +82,6 @@ public class SubscriptionCommandSender {
   public SubscriptionCommandSender(
       final ClusterCfg clusterCfg, final ClientTransport subscriptionClient) {
     this.subscriptionClient = subscriptionClient;
-    partitionIds = new IntArrayList();
     partitionIds.addAll(clusterCfg.getPartitionIds());
   }
 
@@ -100,7 +99,8 @@ public class SubscriptionCommandSender {
       final DirectBuffer messageName,
       final DirectBuffer correlationKey) {
 
-    final int subscriptionPartitionId = getSubscriptionPartitionId(correlationKey);
+    final int subscriptionPartitionId =
+        SubscriptionUtil.getSubscriptionPartitionId(correlationKey, partitionIds.size());
 
     openMessageSubscriptionCommand.setSubscriptionPartitionId(subscriptionPartitionId);
     openMessageSubscriptionCommand.setWorkflowInstanceKey(workflowInstanceKey);
@@ -111,14 +111,6 @@ public class SubscriptionCommandSender {
     return sendSubscriptionCommand(subscriptionPartitionId, openMessageSubscriptionCommand);
   }
 
-  private int getSubscriptionPartitionId(final DirectBuffer correlationKey) {
-    if (partitionIds == null) {
-      throw new IllegalStateException(""no partition ids available"");
-    }
-
-    return SubscriptionUtil.getSubscriptionPartitionId(correlationKey, partitionIds.size());
-  }
-
   public boolean openWorkflowInstanceSubscription(
       final long workflowInstanceKey,
       final long elementInstanceKey,
diff --git a/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCatchElementTest.java b/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCatchElementTest.java
index 4baed4f..838c9ca 100644
--- a/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCatchElementTest.java
+++ b/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCatchElementTest.java
@@ -36,7 +36,6 @@ import io.zeebe.model.bpmn.Bpmn;
 import io.zeebe.model.bpmn.BpmnModelInstance;
 import io.zeebe.protocol.clientapi.RecordType;
 import io.zeebe.protocol.clientapi.ValueType;
-import io.zeebe.protocol.impl.SubscriptionUtil;
 import io.zeebe.protocol.intent.DeploymentIntent;
 import io.zeebe.protocol.intent.MessageSubscriptionIntent;
 import io.zeebe.protocol.intent.WorkflowInstanceIntent;
@@ -44,7 +43,6 @@ import io.zeebe.protocol.intent.WorkflowInstanceSubscriptionIntent;
 import io.zeebe.test.broker.protocol.clientapi.ClientApiRule;
 import io.zeebe.test.broker.protocol.clientapi.PartitionTestClient;
 import io.zeebe.test.util.record.RecordingExporter;
-import io.zeebe.util.buffer.BufferUtil;
 import java.util.List;
 import java.util.stream.Collectors;
 import org.agrona.DirectBuffer;
@@ -171,39 +169,6 @@ public class MessageCatchElementTest {
   }
 
   @Test
-  public void shouldOpenMessageSubscriptionsOnSamePartition() {
-    // given
-    final List<Integer> partitionIds = apiRule.getPartitionIds();
-
-    final String correlationKey = ""order-123"";
-
-    final PartitionTestClient workflowPartition = apiRule.partitionClient(partitionIds.get(0));
-    final PartitionTestClient subscriptionPartition =
-        apiRule.partitionClient(getPartitionId(correlationKey));
-
-    testClient.deploy(CATCH_EVENT_WORKFLOW);
-
-    // when
-    final long workflowInstanceKey1 =
-        workflowPartition.createWorkflowInstance(PROCESS_ID, asMsgPack(""orderId"", correlationKey));
-
-    final long workflowInstanceKey2 =
-        workflowPartition.createWorkflowInstance(PROCESS_ID, asMsgPack(""orderId"", correlationKey));
-
-    // then
-    final List<Record<MessageSubscriptionRecordValue>> subscriptions =
-        subscriptionPartition
-            .receiveMessageSubscriptions()
-            .withIntent(MessageSubscriptionIntent.OPENED)
-            .limit(2)
-            .collect(Collectors.toList());
-
-    assertThat(subscriptions)
-        .extracting(s -> s.getValue().getWorkflowInstanceKey())
-        .contains(workflowInstanceKey1, workflowInstanceKey2);
-  }
-
-  @Test
   public void shouldOpenWorkflowInstanceSubscription() {
     final long workflowInstanceKey =
         testClient.createWorkflowInstance(PROCESS_ID, asMsgPack(""orderId"", ""order-123""));
@@ -352,10 +317,4 @@ public class MessageCatchElementTest {
                 .exists())
         .isTrue();
   }
-
-  private int getPartitionId(final String correlationKey) {
-    final List<Integer> partitionIds = apiRule.getPartitionIds();
-    return SubscriptionUtil.getSubscriptionPartitionId(
-        BufferUtil.wrapString(correlationKey), partitionIds.size());
-  }
 }
diff --git a/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCorrelationMultiplePartitionsTest.java b/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCorrelationMultiplePartitionsTest.java
new file mode 100644
index 0000000..cf8261a
--- /dev/null
+++ b/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCorrelationMultiplePartitionsTest.java
@@ -0,0 +1,134 @@
+/*
+ * Zeebe Broker Core
+ * Copyright  2017 camunda services GmbH (info@camunda.com)
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+package io.zeebe.broker.workflow.message;
+
+import static io.zeebe.broker.test.EmbeddedBrokerConfigurator.setPartitionCount;
+import static io.zeebe.test.util.MsgPackUtil.asMsgPack;
+import static org.assertj.core.api.Assertions.assertThat;
+import static org.assertj.core.api.Assertions.tuple;
+
+import io.zeebe.broker.test.EmbeddedBrokerRule;
+import io.zeebe.model.bpmn.Bpmn;
+import io.zeebe.model.bpmn.BpmnModelInstance;
+import io.zeebe.protocol.impl.SubscriptionUtil;
+import io.zeebe.protocol.intent.MessageSubscriptionIntent;
+import io.zeebe.protocol.intent.WorkflowInstanceIntent;
+import io.zeebe.test.broker.protocol.clientapi.ClientApiRule;
+import io.zeebe.test.broker.protocol.clientapi.PartitionTestClient;
+import io.zeebe.test.util.record.RecordingExporter;
+import io.zeebe.util.buffer.BufferUtil;
+import java.util.List;
+import java.util.stream.IntStream;
+import org.junit.Before;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.RuleChain;
+
+public class MessageCorrelationMultiplePartitionsTest {
+
+  private static final String CORRELATION_KEY_PARTITION_0 = ""item-2"";
+  private static final String CORRELATION_KEY_PARTITION_1 = ""item-1"";
+  private static final String CORRELATION_KEY_PARTITION_2 = ""item-0"";
+
+  private static final String PROCESS_ID = ""process"";
+
+  private static final BpmnModelInstance WORKFLOW =
+      Bpmn.createExecutableProcess(PROCESS_ID)
+          .startEvent()
+          .intermediateCatchEvent(""receive-message"")
+          .message(m -> m.name(""message"").zeebeCorrelationKey(""$.key""))
+          .endEvent(""end"")
+          .done();
+
+  public EmbeddedBrokerRule brokerRule = new EmbeddedBrokerRule(setPartitionCount(3));
+
+  public ClientApiRule apiRule = new ClientApiRule(brokerRule::getClientAddress);
+
+  @Rule public RuleChain ruleChain = RuleChain.outerRule(brokerRule).around(apiRule);
+
+  private PartitionTestClient testClient;
+
+  @Before
+  public void init() {
+    assertThat(getPartitionId(CORRELATION_KEY_PARTITION_0)).isEqualTo(0);
+    assertThat(getPartitionId(CORRELATION_KEY_PARTITION_1)).isEqualTo(1);
+    assertThat(getPartitionId(CORRELATION_KEY_PARTITION_2)).isEqualTo(2);
+
+    testClient = apiRule.partitionClient();
+
+    testClient.deploy(WORKFLOW);
+  }
+
+  @Test
+  public void shouldOpenMessageSubscriptionsOnDifferentPartitions() {
+    // when
+    IntStream.range(0, 10)
+        .forEach(
+            i -> {
+              testClient.createWorkflowInstance(
+                  PROCESS_ID, asMsgPack(""key"", CORRELATION_KEY_PARTITION_0));
+              testClient.createWorkflowInstance(
+                  PROCESS_ID, asMsgPack(""key"", CORRELATION_KEY_PARTITION_1));
+              testClient.createWorkflowInstance(
+                  PROCESS_ID, asMsgPack(""key"", CORRELATION_KEY_PARTITION_2));
+            });
+
+    // then
+    assertThat(
+            RecordingExporter.messageSubscriptionRecords(MessageSubscriptionIntent.OPENED)
+                .limit(30))
+        .extracting(r -> tuple(r.getMetadata().getPartitionId(), r.getValue().getCorrelationKey()))
+        .containsOnly(
+            tuple(0, CORRELATION_KEY_PARTITION_0),
+            tuple(1, CORRELATION_KEY_PARTITION_1),
+            tuple(2, CORRELATION_KEY_PARTITION_2));
+  }
+
+  @Test
+  public void shouldCorrelateMessageOnDifferentPartitions() {
+    // given
+    apiRule
+        .partitionClient(0)
+        .publishMessage(""message"", CORRELATION_KEY_PARTITION_0, asMsgPack(""p"", ""p0""));
+    apiRule
+        .partitionClient(1)
+        .publishMessage(""message"", CORRELATION_KEY_PARTITION_1, asMsgPack(""p"", ""p1""));
+    apiRule
+        .partitionClient(2)
+        .publishMessage(""message"", CORRELATION_KEY_PARTITION_2, asMsgPack(""p"", ""p2""));
+
+    // when
+    testClient.createWorkflowInstance(PROCESS_ID, asMsgPack(""key"", CORRELATION_KEY_PARTITION_0));
+    testClient.createWorkflowInstance(PROCESS_ID, asMsgPack(""key"", CORRELATION_KEY_PARTITION_1));
+    testClient.createWorkflowInstance(PROCESS_ID, asMsgPack(""key"", CORRELATION_KEY_PARTITION_2));
+
+    // then
+    assertThat(
+            RecordingExporter.workflowInstanceRecords(WorkflowInstanceIntent.END_EVENT_OCCURRED)
+                .withElementId(""end"")
+                .limit(3))
+        .extracting(r -> r.getValue().getPayloadAsMap().get(""p""))
+        .contains(""p0"", ""p1"", ""p2"");
+  }
+
+  private int getPartitionId(final String correlationKey) {
+    final List<Integer> partitionIds = apiRule.getPartitionIds();
+    return SubscriptionUtil.getSubscriptionPartitionId(
+        BufferUtil.wrapString(correlationKey), partitionIds.size());
+  }
+}
diff --git a/protocol-test-util/src/main/java/io/zeebe/test/broker/protocol/clientapi/PartitionTestClient.java b/protocol-test-util/src/main/java/io/zeebe/test/broker/protocol/clientapi/PartitionTestClient.java
index dac11a2..e2b8397 100644
--- a/protocol-test-util/src/main/java/io/zeebe/test/broker/protocol/clientapi/PartitionTestClient.java
+++ b/protocol-test-util/src/main/java/io/zeebe/test/broker/protocol/clientapi/PartitionTestClient.java
@@ -329,6 +329,7 @@ public class PartitionTestClient {
       final String messageName, final String correlationKey, final byte[] payload, final long ttl) {
     return apiRule
         .createCmdRequest()
+        .partitionId(partitionId)
         .type(ValueType.MESSAGE, MessageIntent.PUBLISH)
         .command()
         .put(""name"", messageName)
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerReprocessingTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerReprocessingTest.java
index 9a122d9..b7db67e 100644
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerReprocessingTest.java
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerReprocessingTest.java
@@ -619,14 +619,9 @@ public class BrokerReprocessingTest {
   }
 
   @Test
-  public void shouldCorrelateMessageAfterRestartIfEnteredBeforeA() throws Exception {
+  public void shouldCorrelateMessageAfterRestartIfEnteredBefore() throws Exception {
     // given
-    clientRule
-        .getWorkflowClient()
-        .newDeployCommand()
-        .addWorkflowModel(WORKFLOW_MESSAGE, ""message.bpmn"")
-        .send()
-        .join();
+    deploy(WORKFLOW_MESSAGE, ""message.bpmn"");
 
     final long workflowInstanceKey =
         startWorkflowInstance(PROCESS_ID, singletonMap(""orderId"", ""order-123""))
@@ -658,12 +653,7 @@ public class BrokerReprocessingTest {
   @Test
   public void shouldCorrelateMessageAfterRestartIfPublishedBefore() throws Exception {
     // given
-    clientRule
-        .getWorkflowClient()
-        .newDeployCommand()
-        .addWorkflowModel(WORKFLOW_MESSAGE, ""message.bpmn"")
-        .send()
-        .join();
+    deploy(WORKFLOW_MESSAGE, ""message.bpmn"");
 
     publishMessage(""order canceled"", ""order-123"", singletonMap(""foo"", ""bar""));
     reprocessingTrigger.accept(this);
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/MessageCorrelationTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/MessageCorrelationTest.java
deleted file mode 100644
index c6a05fb..0000000
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/MessageCorrelationTest.java
+++ /dev/null
@@ -1,176 +0,0 @@
-/*
- * Copyright  2017 camunda services GmbH (info@camunda.com)
- *
- * Licensed under the Apache License, Version 2.0 (the ""License"");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an ""AS IS"" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package io.zeebe.broker.it.workflow;
-
-import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertElementActivated;
-import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertElementCompleted;
-import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertWorkflowInstanceCompleted;
-import static org.assertj.core.api.Assertions.assertThat;
-import static org.assertj.core.api.Assertions.entry;
-
-import io.zeebe.broker.it.GrpcClientRule;
-import io.zeebe.broker.test.EmbeddedBrokerRule;
-import io.zeebe.client.api.events.DeploymentEvent;
-import io.zeebe.model.bpmn.Bpmn;
-import io.zeebe.model.bpmn.BpmnModelInstance;
-import java.util.Collections;
-import org.junit.Before;
-import org.junit.Rule;
-import org.junit.Test;
-import org.junit.rules.RuleChain;
-import org.junit.runner.RunWith;
-import org.junit.runners.Parameterized;
-import org.junit.runners.Parameterized.Parameter;
-import org.junit.runners.Parameterized.Parameters;
-
-@RunWith(Parameterized.class)
-public class MessageCorrelationTest {
-
-  public EmbeddedBrokerRule brokerRule = new EmbeddedBrokerRule();
-  public GrpcClientRule clientRule = new GrpcClientRule(brokerRule);
-
-  @Rule public RuleChain ruleChain = RuleChain.outerRule(brokerRule).around(clientRule);
-
-  private static final BpmnModelInstance CATCH_EVENT_WORKFLOW =
-      Bpmn.createExecutableProcess(""wf"")
-          .startEvent()
-          .intermediateCatchEvent(""receive-message"")
-          .message(m -> m.name(""order canceled"").zeebeCorrelationKey(""$.orderId""))
-          .sequenceFlowId(""to-end"")
-          .endEvent()
-          .done();
-
-  private static final BpmnModelInstance RECEIVE_TASK_WORKFLOW =
-      Bpmn.createExecutableProcess(""wf"")
-          .startEvent()
-          .receiveTask(""receive-message"")
-          .message(m -> m.name(""order canceled"").zeebeCorrelationKey(""$.orderId""))
-          .sequenceFlowId(""to-end"")
-          .endEvent()
-          .done();
-
-  @Parameter(0)
-  public String elementType;
-
-  @Parameter(1)
-  public BpmnModelInstance workflow;
-
-  @Parameters(name = ""{0}"")
-  public static final Object[][] parameters() {
-    return new Object[][] {
-      {""intermediate message catch event"", CATCH_EVENT_WORKFLOW},
-      {""receive task"", RECEIVE_TASK_WORKFLOW}
-    };
-  }
-
-  @Before
-  public void init() {
-    final DeploymentEvent deploymentEvent =
-        clientRule
-            .getWorkflowClient()
-            .newDeployCommand()
-            .addWorkflowModel(workflow, ""wf.bpmn"")
-            .send()
-            .join();
-
-    clientRule.waitUntilDeploymentIsDone(deploymentEvent.getKey());
-  }
-
-  @Test
-  public void shouldCorrelateMessageIfEnteredBefore() {
-    // given
-    clientRule
-        .getWorkflowClient()
-        .newCreateInstanceCommand()
-        .bpmnProcessId(""wf"")
-        .latestVersion()
-        .payload(""{\""orderId\"":\""order-123\""}"")
-        .send()
-        .join();
-
-    assertElementActivated(""receive-message"");
-
-    // when
-    clientRule
-        .getWorkflowClient()
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .send()
-        .join();
-
-    // then
-    assertWorkflowInstanceCompleted(""wf"");
-  }
-
-  @Test
-  public void shouldCorrelateMessageIfPublishedBefore() {
-    // given
-    clientRule
-        .getWorkflowClient()
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .send()
-        .join();
-
-    // when
-    clientRule
-        .getWorkflowClient()
-        .newCreateInstanceCommand()
-        .bpmnProcessId(""wf"")
-        .latestVersion()
-        .payload(""{\""orderId\"":\""order-123\""}"")
-        .send()
-        .join();
-
-    // then
-    assertWorkflowInstanceCompleted(""wf"");
-  }
-
-  @Test
-  public void shouldCorrelateMessageAndMergePayload() {
-    // given
-    clientRule
-        .getWorkflowClient()
-        .newCreateInstanceCommand()
-        .bpmnProcessId(""wf"")
-        .latestVersion()
-        .payload(""{\""orderId\"":\""order-123\""}"")
-        .send()
-        .join();
-
-    // when
-    clientRule
-        .getWorkflowClient()
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .payload(Collections.singletonMap(""foo"", ""bar""))
-        .send()
-        .join();
-
-    // then
-    assertWorkflowInstanceCompleted(""wf"");
-
-    assertElementCompleted(
-        ""wf"",
-        ""receive-message"",
-        (catchEventOccurredEvent) ->
-            assertThat(catchEventOccurredEvent.getPayloadAsMap())
-                .containsExactly(entry(""orderId"", ""order-123""), entry(""foo"", ""bar"")));
-  }
-}
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/PublishMessageTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/PublishMessageTest.java
deleted file mode 100644
index 7845eec..0000000
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/PublishMessageTest.java
+++ /dev/null
@@ -1,234 +0,0 @@
-/*
- * Copyright  2017 camunda services GmbH (info@camunda.com)
- *
- * Licensed under the Apache License, Version 2.0 (the ""License"");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an ""AS IS"" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package io.zeebe.broker.it.workflow;
-
-import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertElementActivated;
-import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertElementCompleted;
-import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertWorkflowInstanceCompleted;
-import static io.zeebe.broker.test.EmbeddedBrokerConfigurator.setPartitionCount;
-import static org.assertj.core.api.Assertions.assertThat;
-import static org.assertj.core.api.Assertions.assertThatThrownBy;
-import static org.assertj.core.api.Assertions.entry;
-
-import io.zeebe.broker.it.GrpcClientRule;
-import io.zeebe.broker.test.EmbeddedBrokerRule;
-import io.zeebe.client.api.ZeebeFuture;
-import io.zeebe.client.api.clients.WorkflowClient;
-import io.zeebe.client.api.events.DeploymentEvent;
-import io.zeebe.client.api.events.WorkflowInstanceEvent;
-import io.zeebe.client.cmd.ClientException;
-import io.zeebe.model.bpmn.Bpmn;
-import io.zeebe.model.bpmn.BpmnModelInstance;
-import java.time.Duration;
-import java.util.Collections;
-import org.junit.Before;
-import org.junit.Rule;
-import org.junit.Test;
-import org.junit.rules.RuleChain;
-
-public class PublishMessageTest {
-
-  private static final BpmnModelInstance WORKFLOW =
-      Bpmn.createExecutableProcess(""wf"")
-          .startEvent()
-          .intermediateCatchEvent(""catch-event"")
-          .message(c -> c.name(""order canceled"").zeebeCorrelationKey(""$.orderId""))
-          .endEvent()
-          .done();
-  public EmbeddedBrokerRule brokerRule = new EmbeddedBrokerRule(setPartitionCount(3));
-  public GrpcClientRule clientRule = new GrpcClientRule(brokerRule);
-
-  @Rule public RuleChain ruleChain = RuleChain.outerRule(brokerRule).around(clientRule);
-
-  private WorkflowClient workflowClient;
-
-  @Before
-  public void init() {
-
-    workflowClient = clientRule.getClient().workflowClient();
-
-    final DeploymentEvent deploymentEvent =
-        workflowClient.newDeployCommand().addWorkflowModel(WORKFLOW, ""wf.bpmn"").send().join();
-
-    clientRule.waitUntilDeploymentIsDone(deploymentEvent.getKey());
-  }
-
-  @Test
-  public void shouldCorrelateMessageToAllSubscriptions() {
-    // given
-    final WorkflowInstanceEvent wf =
-        workflowClient
-            .newCreateInstanceCommand()
-            .bpmnProcessId(""wf"")
-            .latestVersion()
-            .payload(""{\""orderId\"":\""order-123\""}"")
-            .send()
-            .join();
-
-    final WorkflowInstanceEvent wf2 =
-        workflowClient
-            .newCreateInstanceCommand()
-            .bpmnProcessId(""wf"")
-            .latestVersion()
-            .payload(""{\""orderId\"":\""order-123\""}"")
-            .send()
-            .join();
-
-    // when
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .send()
-        .join();
-
-    // then
-    assertWorkflowInstanceCompleted(""wf"", wf.getWorkflowInstanceKey());
-    assertWorkflowInstanceCompleted(""wf"", wf2.getWorkflowInstanceKey());
-  }
-
-  @Test
-  public void shouldCorrelateMessageWithZeroTTL() {
-    // given
-    workflowClient
-        .newCreateInstanceCommand()
-        .bpmnProcessId(""wf"")
-        .latestVersion()
-        .payload(""{\""orderId\"":\""order-123\""}"")
-        .send()
-        .join();
-
-    assertElementActivated(""catch-event"");
-
-    // when
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .timeToLive(Duration.ZERO)
-        .send()
-        .join();
-
-    // then
-    assertElementCompleted(""wf"", ""catch-event"");
-  }
-
-  @Test
-  public void shouldNotCorrelateMessageAfterTTL() {
-    // given
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .timeToLive(Duration.ZERO)
-        .payload(Collections.singletonMap(""msg"", ""failure""))
-        .send()
-        .join();
-
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .timeToLive(Duration.ofMinutes(1))
-        .payload(Collections.singletonMap(""msg"", ""expected""))
-        .send()
-        .join();
-
-    // when
-    workflowClient
-        .newCreateInstanceCommand()
-        .bpmnProcessId(""wf"")
-        .latestVersion()
-        .payload(""{\""orderId\"":\""order-123\""}"")
-        .send()
-        .join();
-
-    // then
-
-    assertElementCompleted(
-        ""wf"",
-        ""catch-event"",
-        (catchEventOccurred) ->
-            assertThat(catchEventOccurred.getPayloadAsMap()).contains(entry(""msg"", ""expected"")));
-  }
-
-  @Test
-  public void shouldCorrelateMessageOnDifferentPartitions() {
-    // given
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .send()
-        .join();
-
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-124"")
-        .send()
-        .join();
-
-    // when
-    final WorkflowInstanceEvent wf =
-        workflowClient
-            .newCreateInstanceCommand()
-            .bpmnProcessId(""wf"")
-            .latestVersion()
-            .payload(""{\""orderId\"":\""order-123\""}"")
-            .send()
-            .join();
-
-    final WorkflowInstanceEvent wf2 =
-        workflowClient
-            .newCreateInstanceCommand()
-            .bpmnProcessId(""wf"")
-            .latestVersion()
-            .payload(""{\""orderId\"":\""order-124\""}"")
-            .send()
-            .join();
-
-    // then
-    assertWorkflowInstanceCompleted(""wf"", wf.getWorkflowInstanceKey());
-    assertWorkflowInstanceCompleted(""wf"", wf2.getWorkflowInstanceKey());
-  }
-
-  @Test
-  public void shouldRejectMessageWithSameId() {
-    // given
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .messageId(""foo"")
-        .send()
-        .join();
-
-    // when
-    final ZeebeFuture<Void> future =
-        workflowClient
-            .newPublishMessageCommand()
-            .messageName(""order canceled"")
-            .correlationKey(""order-123"")
-            .messageId(""foo"")
-            .send();
-
-    // then
-    assertThatThrownBy(future::join)
-        .isInstanceOf(ClientException.class)
-        .hasMessageContaining(""message with id 'foo' is already published"");
-  }
-}
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/message/MessageCorrelationMultiplePartitionsTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/message/MessageCorrelationMultiplePartitionsTest.java
new file mode 100644
index 0000000..0e37c95
--- /dev/null
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/message/MessageCorrelationMultiplePartitionsTest.java
@@ -0,0 +1,196 @@
+/*
+ * Copyright  2017 camunda services GmbH (info@camunda.com)
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package io.zeebe.broker.it.workflow.message;
+
+import static io.zeebe.broker.test.EmbeddedBrokerConfigurator.setPartitionCount;
+import static org.assertj.core.api.Assertions.assertThat;
+import static org.assertj.core.api.Assertions.tuple;
+
+import io.zeebe.broker.it.GrpcClientRule;
+import io.zeebe.broker.test.EmbeddedBrokerRule;
+import io.zeebe.client.api.events.DeploymentEvent;
+import io.zeebe.model.bpmn.Bpmn;
+import io.zeebe.model.bpmn.BpmnModelInstance;
+import io.zeebe.protocol.intent.MessageIntent;
+import io.zeebe.protocol.intent.MessageSubscriptionIntent;
+import io.zeebe.protocol.intent.WorkflowInstanceIntent;
+import io.zeebe.test.util.record.RecordingExporter;
+import java.util.Collections;
+import java.util.stream.IntStream;
+import org.junit.Before;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.RuleChain;
+
+public class MessageCorrelationMultiplePartitionsTest {
+
+  private static final String CORRELATION_KEY_PARTITION_0 = ""item-2"";
+  private static final String CORRELATION_KEY_PARTITION_1 = ""item-1"";
+  private static final String CORRELATION_KEY_PARTITION_2 = ""item-0"";
+
+  private static final String PROCESS_ID = ""process"";
+
+  public EmbeddedBrokerRule brokerRule = new EmbeddedBrokerRule(setPartitionCount(3));
+  public GrpcClientRule clientRule = new GrpcClientRule(brokerRule);
+
+  @Rule public RuleChain ruleChain = RuleChain.outerRule(brokerRule).around(clientRule);
+
+  private static final BpmnModelInstance WORKFLOW =
+      Bpmn.createExecutableProcess(PROCESS_ID)
+          .startEvent()
+          .intermediateCatchEvent()
+          .message(m -> m.name(""message"").zeebeCorrelationKey(""$.key""))
+          .endEvent(""end"")
+          .done();
+
+  @Before
+  public void init() {
+    final DeploymentEvent deploymentEvent =
+        clientRule
+            .getWorkflowClient()
+            .newDeployCommand()
+            .addWorkflowModel(WORKFLOW, ""wf.bpmn"")
+            .send()
+            .join();
+
+    clientRule.waitUntilDeploymentIsDone(deploymentEvent.getKey());
+  }
+
+  @Test
+  public void shouldOpenMessageSubscriptionsOnDifferentPartitions() {
+    // when
+    IntStream.range(0, 10)
+        .forEach(
+            i -> {
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_0));
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_1));
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_2));
+            });
+
+    // then
+    assertThat(
+            RecordingExporter.messageSubscriptionRecords(MessageSubscriptionIntent.OPENED)
+                .limit(30))
+        .extracting(r -> tuple(r.getMetadata().getPartitionId(), r.getValue().getCorrelationKey()))
+        .containsOnly(
+            tuple(0, CORRELATION_KEY_PARTITION_0),
+            tuple(1, CORRELATION_KEY_PARTITION_1),
+            tuple(2, CORRELATION_KEY_PARTITION_2));
+  }
+
+  @Test
+  public void shouldPublishMessageOnDifferentPartitions() {
+    // when
+    IntStream.range(0, 10)
+        .forEach(
+            i -> {
+              publishMessage(CORRELATION_KEY_PARTITION_0, Collections.singletonMap(""p"", ""p0""));
+              publishMessage(CORRELATION_KEY_PARTITION_1, Collections.singletonMap(""p"", ""p1""));
+              publishMessage(CORRELATION_KEY_PARTITION_2, Collections.singletonMap(""p"", ""p2""));
+            });
+
+    // then
+    assertThat(RecordingExporter.messageRecords(MessageIntent.PUBLISHED).limit(30))
+        .extracting(r -> tuple(r.getMetadata().getPartitionId(), r.getValue().getCorrelationKey()))
+        .containsOnly(
+            tuple(0, CORRELATION_KEY_PARTITION_0),
+            tuple(1, CORRELATION_KEY_PARTITION_1),
+            tuple(2, CORRELATION_KEY_PARTITION_2));
+  }
+
+  @Test
+  public void shouldCorrelateMessageOnDifferentPartitions() {
+    // given
+    publishMessage(CORRELATION_KEY_PARTITION_0, Collections.singletonMap(""p"", ""p0""));
+    publishMessage(CORRELATION_KEY_PARTITION_1, Collections.singletonMap(""p"", ""p1""));
+    publishMessage(CORRELATION_KEY_PARTITION_2, Collections.singletonMap(""p"", ""p2""));
+
+    // when
+    createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_0));
+    createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_1));
+    createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_2));
+
+    // then
+    assertThat(
+            RecordingExporter.workflowInstanceRecords(WorkflowInstanceIntent.END_EVENT_OCCURRED)
+                .withElementId(""end"")
+                .limit(3))
+        .extracting(r -> r.getValue().getPayloadAsMap().get(""p""))
+        .contains(""p0"", ""p1"", ""p2"");
+  }
+
+  @Test
+  public void shouldOpenMessageSubscriptionsOnSamePartitionsAfterRestart() {
+    // given
+    IntStream.range(0, 5)
+        .forEach(
+            i -> {
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_0));
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_1));
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_2));
+            });
+
+    assertThat(
+            RecordingExporter.messageSubscriptionRecords(MessageSubscriptionIntent.OPENED)
+                .limit(15)
+                .exists())
+        .isTrue();
+
+    // when
+    brokerRule.stopBroker();
+    brokerRule.startBroker();
+
+    IntStream.range(0, 5)
+        .forEach(
+            i -> {
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_0));
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_1));
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_2));
+            });
+
+    // then
+    assertThat(
+            RecordingExporter.messageSubscriptionRecords(MessageSubscriptionIntent.OPENED)
+                .limit(30))
+        .extracting(r -> tuple(r.getMetadata().getPartitionId(), r.getValue().getCorrelationKey()))
+        .containsOnly(
+            tuple(0, CORRELATION_KEY_PARTITION_0),
+            tuple(1, CORRELATION_KEY_PARTITION_1),
+            tuple(2, CORRELATION_KEY_PARTITION_2));
+  }
+
+  private void createWorkflowInstance(Object payload) {
+    clientRule
+        .getWorkflowClient()
+        .newCreateInstanceCommand()
+        .bpmnProcessId(PROCESS_ID)
+        .latestVersion()
+        .payload(payload)
+        .send()
+        .join();
+  }
+
+  private void publishMessage(String correlationKey, Object payload) {
+    clientRule
+        .getWorkflowClient()
+        .newPublishMessageCommand()
+        .messageName(""message"")
+        .correlationKey(correlationKey)
+        .payload(payload)
+        .send()
+        .join();
+  }
+}
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/message/MessageCorrelationTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/message/MessageCorrelationTest.java
new file mode 100644
index 0000000..3b08572
--- /dev/null
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/message/MessageCorrelationTest.java
@@ -0,0 +1,198 @@
+/*
+ * Copyright  2017 camunda services GmbH (info@camunda.com)
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package io.zeebe.broker.it.workflow.message;
+
+import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertElementActivated;
+import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertElementCompleted;
+import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertWorkflowInstanceCompleted;
+import static org.assertj.core.api.Assertions.assertThat;
+import static org.assertj.core.api.Assertions.assertThatThrownBy;
+import static org.assertj.core.api.Assertions.entry;
+
+import io.zeebe.broker.it.GrpcClientRule;
+import io.zeebe.broker.test.EmbeddedBrokerRule;
+import io.zeebe.client.api.ZeebeFuture;
+import io.zeebe.client.api.events.DeploymentEvent;
+import io.zeebe.client.cmd.ClientException;
+import io.zeebe.model.bpmn.Bpmn;
+import io.zeebe.model.bpmn.BpmnModelInstance;
+import java.time.Duration;
+import java.util.Collections;
+import org.junit.Before;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.RuleChain;
+
+public class MessageCorrelationTest {
+
+  private static final String PROCESS_ID = ""process"";
+
+  public EmbeddedBrokerRule brokerRule = new EmbeddedBrokerRule();
+  public GrpcClientRule clientRule = new GrpcClientRule(brokerRule);
+
+  @Rule public RuleChain ruleChain = RuleChain.outerRule(brokerRule).around(clientRule);
+
+  private static final BpmnModelInstance WORKFLOW =
+      Bpmn.createExecutableProcess(PROCESS_ID)
+          .startEvent()
+          .intermediateCatchEvent(""catch-event"")
+          .message(c -> c.name(""order canceled"").zeebeCorrelationKey(""$.orderId""))
+          .endEvent()
+          .done();
+
+  @Before
+  public void init() {
+    final DeploymentEvent deploymentEvent =
+        clientRule
+            .getWorkflowClient()
+            .newDeployCommand()
+            .addWorkflowModel(WORKFLOW, ""wf.bpmn"")
+            .send()
+            .join();
+
+    clientRule.waitUntilDeploymentIsDone(deploymentEvent.getKey());
+  }
+
+  @Test
+  public void shouldCorrelateMessage() {
+    // given
+    clientRule
+        .getWorkflowClient()
+        .newCreateInstanceCommand()
+        .bpmnProcessId(PROCESS_ID)
+        .latestVersion()
+        .payload(Collections.singletonMap(""orderId"", ""order-123""))
+        .send()
+        .join();
+
+    // when
+    clientRule
+        .getWorkflowClient()
+        .newPublishMessageCommand()
+        .messageName(""order canceled"")
+        .correlationKey(""order-123"")
+        .payload(Collections.singletonMap(""foo"", ""bar""))
+        .send()
+        .join();
+
+    // then
+    assertWorkflowInstanceCompleted(PROCESS_ID);
+
+    assertElementCompleted(
+        PROCESS_ID,
+        ""catch-event"",
+        (catchEventOccurredEvent) ->
+            assertThat(catchEventOccurredEvent.getPayloadAsMap())
+                .containsExactly(entry(""orderId"", ""order-123""), entry(""foo"", ""bar"")));
+  }
+
+  @Test
+  public void shouldCorrelateMessageWithZeroTTL() {
+    // given
+    clientRule
+        .getWorkflowClient()
+        .newCreateInstanceCommand()
+        .bpmnProcessId(PROCESS_ID)
+        .latestVersion()
+        .payload(Collections.singletonMap(""orderId"", ""order-123""))
+        .send()
+        .join();
+
+    assertElementActivated(""catch-event"");
+
+    // when
+    clientRule
+        .getWorkflowClient()
+        .newPublishMessageCommand()
+        .messageName(""order canceled"")
+        .correlationKey(""order-123"")
+        .timeToLive(Duration.ZERO)
+        .send()
+        .join();
+
+    // then
+    assertElementCompleted(PROCESS_ID, ""catch-event"");
+  }
+
+  @Test
+  public void shouldNotCorrelateMessageAfterTTL() {
+    // given
+    clientRule
+        .getWorkflowClient()
+        .newPublishMessageCommand()
+        .messageName(""order canceled"")
+        .correlationKey(""order-123"")
+        .timeToLive(Duration.ZERO)
+        .payload(Collections.singletonMap(""msg"", ""failure""))
+        .send()
+        .join();
+
+    clientRule
+        .getWorkflowClient()
+        .newPublishMessageCommand()
+        .messageName(""order canceled"")
+        .correlationKey(""order-123"")
+        .timeToLive(Duration.ofMinutes(1))
+        .payload(Collections.singletonMap(""msg"", ""expected""))
+        .send()
+        .join();
+
+    // when
+    clientRule
+        .getWorkflowClient()
+        .newCreateInstanceCommand()
+        .bpmnProcessId(PROCESS_ID)
+        .latestVersion()
+        .payload(Collections.singletonMap(""orderId"", ""order-123""))
+        .send()
+        .join();
+
+    // then
+    assertElementCompleted(
+        PROCESS_ID,
+        ""catch-event"",
+        (catchEventOccurred) ->
+            assertThat(catchEventOccurred.getPayloadAsMap()).contains(entry(""msg"", ""expected"")));
+  }
+
+  @Test
+  public void shouldRejectMessageWithSameId() {
+    // given
+    clientRule
+        .getWorkflowClient()
+        .newPublishMessageCommand()
+        .messageName(""order canceled"")
+        .correlationKey(""order-123"")
+        .messageId(""foo"")
+        .send()
+        .join();
+
+    // when
+    final ZeebeFuture<Void> future =
+        clientRule
+            .getWorkflowClient()
+            .newPublishMessageCommand()
+            .messageName(""order canceled"")
+            .correlationKey(""order-123"")
+            .messageId(""foo"")
+            .send();
+
+    // then
+    assertThatThrownBy(future::join)
+        .isInstanceOf(ClientException.class)
+        .hasMessageContaining(""message with id 'foo' is already published"");
+  }
+}

diff --git a/rust/cubesql/src/compile/engine/udf.rs b/rust/cubesql/src/compile/engine/udf.rs
index f3991c0..549167a 100644
--- a/rust/cubesql/src/compile/engine/udf.rs
+++ b/rust/cubesql/src/compile/engine/udf.rs
@@ -3,13 +3,16 @@ use std::sync::Arc;
 
 use datafusion::{
     arrow::{
-        array::{ArrayRef, GenericStringArray, Int32Builder, StringBuilder, UInt32Builder},
+        array::{
+            ArrayRef, BooleanBuilder, GenericStringArray, Int32Builder, StringBuilder,
+            UInt32Builder,
+        },
         datatypes::DataType,
     },
     error::DataFusionError,
     logical_plan::create_udf,
     physical_plan::{
-        functions::{make_scalar_function, Volatility},
+        functions::{make_scalar_function, ReturnTypeFunction, Signature, Volatility},
         udf::ScalarUDF,
     },
 };
@@ -167,3 +170,24 @@ pub fn create_instr_udf() -> ScalarUDF {
         fun,
     )
 }
+
+pub fn create_isnull_udf() -> ScalarUDF {
+    let fun = make_scalar_function(move |args: &[ArrayRef]| {
+        assert!(args.len() == 1);
+
+        let mut builder = BooleanBuilder::new(1);
+        builder.append_value(args[0].is_null(0))?;
+
+        Ok(Arc::new(builder.finish()) as ArrayRef)
+    });
+
+    let return_type: ReturnTypeFunction =
+        Arc::new(move |_| Ok(Arc::new(DataType::Boolean).clone()));
+
+    ScalarUDF::new(
+        ""isnull"",
+        &Signature::any(1, Volatility::Immutable),
+        &return_type,
+        &fun,
+    )
+}
diff --git a/rust/cubesql/src/compile/mod.rs b/rust/cubesql/src/compile/mod.rs
index 891283b..9004ffe 100644
--- a/rust/cubesql/src/compile/mod.rs
+++ b/rust/cubesql/src/compile/mod.rs
@@ -36,7 +36,7 @@ use self::context::*;
 use self::engine::context::SystemVar;
 use self::engine::udf::{
     create_connection_id_udf, create_current_user_udf, create_db_udf, create_instr_udf,
-    create_user_udf, create_version_udf,
+    create_isnull_udf, create_user_udf, create_version_udf,
 };
 use self::parser::parse_sql_to_statement;
 
@@ -1415,6 +1415,7 @@ impl QueryPlanner {
         ctx.register_udf(create_user_udf(props));
         ctx.register_udf(create_current_user_udf(props));
         ctx.register_udf(create_instr_udf());
+        ctx.register_udf(create_isnull_udf());
 
         {
             let schema_provider = MemorySchemaProvider::new();
",3,"[""eb513f7eeea7865f15e5bd561a471d1f4381ea70"", ""2d416be63eeec9e7fdb90a62c40c8ad8f0672efa"", ""f0a4b62f4bd2a1ba2caf37c764b117b352a2f2b3""]","[""fix"", ""test"", ""feat""]"
"enable performance test trigger

This reverts commit 146c7b58154a5b3de957f87e3b193447e0576547. | dedup redundant imports","diff --git a/Jenkinsfile b/Jenkinsfile
index 399f8b8..c3f8fde 100644
--- a/Jenkinsfile
+++ b/Jenkinsfile
@@ -120,6 +120,12 @@ pipeline {
             }
         }
 
+        stage('Trigger Performance Tests') {
+            when { branch 'develop' }
+            steps {
+                build job: 'zeebe-cluster-performance-tests', wait: false
+            }
+        }
     }
 
     post {

diff --git a/ibis/backends/base/__init__.py b/ibis/backends/base/__init__.py
index effd44c..a59c0ec 100644
--- a/ibis/backends/base/__init__.py
+++ b/ibis/backends/base/__init__.py
@@ -31,7 +31,7 @@ import ibis.common.exceptions as exc
 import ibis.config
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 
 __all__ = ('BaseBackend', 'Database', 'connect')
 
diff --git a/ibis/backends/base/sql/__init__.py b/ibis/backends/base/sql/__init__.py
index e4f2129..7bbdaf9 100644
--- a/ibis/backends/base/sql/__init__.py
+++ b/ibis/backends/base/sql/__init__.py
@@ -12,7 +12,7 @@ import ibis.expr.analysis as an
 import ibis.expr.operations as ops
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.base import BaseBackend
 from ibis.backends.base.sql.compiler import Compiler
 
diff --git a/ibis/backends/base/sql/alchemy/__init__.py b/ibis/backends/base/sql/alchemy/__init__.py
index 71cc0e8..ab89d7d 100644
--- a/ibis/backends/base/sql/alchemy/__init__.py
+++ b/ibis/backends/base/sql/alchemy/__init__.py
@@ -11,7 +11,7 @@ import ibis
 import ibis.expr.operations as ops
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql import BaseSQLBackend
 from ibis.backends.base.sql.alchemy.database import AlchemyDatabase, AlchemyTable
 from ibis.backends.base.sql.alchemy.datatypes import (
diff --git a/ibis/backends/base/sql/alchemy/query_builder.py b/ibis/backends/base/sql/alchemy/query_builder.py
index 54c74ba..0ec432f 100644
--- a/ibis/backends/base/sql/alchemy/query_builder.py
+++ b/ibis/backends/base/sql/alchemy/query_builder.py
@@ -3,7 +3,7 @@ from __future__ import annotations
 import functools
 
 import sqlalchemy as sa
-import sqlalchemy.sql as sql
+from sqlalchemy import sql
 
 import ibis.expr.operations as ops
 import ibis.expr.schema as sch
diff --git a/ibis/backends/base/sql/compiler/base.py b/ibis/backends/base/sql/compiler/base.py
index 84102aa..fb44667 100644
--- a/ibis/backends/base/sql/compiler/base.py
+++ b/ibis/backends/base/sql/compiler/base.py
@@ -7,7 +7,7 @@ import toolz
 
 import ibis.expr.analysis as an
 import ibis.expr.operations as ops
-import ibis.util as util
+from ibis import util
 
 
 class DML(abc.ABC):
diff --git a/ibis/backends/base/sql/compiler/query_builder.py b/ibis/backends/base/sql/compiler/query_builder.py
index a2d5214..95f5e8d 100644
--- a/ibis/backends/base/sql/compiler/query_builder.py
+++ b/ibis/backends/base/sql/compiler/query_builder.py
@@ -8,7 +8,7 @@ import toolz
 import ibis.common.exceptions as com
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql.compiler.base import DML, QueryAST, SetOp
 from ibis.backends.base.sql.compiler.select_builder import SelectBuilder, _LimitSpec
 from ibis.backends.base.sql.compiler.translator import ExprTranslator, QueryContext
diff --git a/ibis/backends/base/sql/registry/main.py b/ibis/backends/base/sql/registry/main.py
index 77f70a5..586ace5 100644
--- a/ibis/backends/base/sql/registry/main.py
+++ b/ibis/backends/base/sql/registry/main.py
@@ -4,7 +4,7 @@ import ibis.common.exceptions as com
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql.registry import (
     aggregate,
     binary_infix,
diff --git a/ibis/backends/base/sql/registry/timestamp.py b/ibis/backends/base/sql/registry/timestamp.py
index 412eab1..3c8571f 100644
--- a/ibis/backends/base/sql/registry/timestamp.py
+++ b/ibis/backends/base/sql/registry/timestamp.py
@@ -3,7 +3,7 @@ from __future__ import annotations
 import ibis.common.exceptions as com
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
-import ibis.util as util
+from ibis import util
 
 
 def extract_field(sql_attr):
diff --git a/ibis/backends/clickhouse/tests/test_client.py b/ibis/backends/clickhouse/tests/test_client.py
index 8db6672..bb1b9ba 100644
--- a/ibis/backends/clickhouse/tests/test_client.py
+++ b/ibis/backends/clickhouse/tests/test_client.py
@@ -3,9 +3,9 @@ import pandas.testing as tm
 import pytest
 
 import ibis
-import ibis.config as config
 import ibis.expr.datatypes as dt
 import ibis.expr.types as ir
+from ibis import config
 from ibis.backends.clickhouse.tests.conftest import (
     CLICKHOUSE_HOST,
     CLICKHOUSE_PASS,
diff --git a/ibis/backends/conftest.py b/ibis/backends/conftest.py
index 3a974da..ba7ad75 100644
--- a/ibis/backends/conftest.py
+++ b/ibis/backends/conftest.py
@@ -20,7 +20,7 @@ if TYPE_CHECKING:
 import pytest
 
 import ibis
-import ibis.util as util
+from ibis import util
 from ibis.backends.base import _get_backend_names
 
 TEST_TABLES = {
diff --git a/ibis/backends/dask/execution/util.py b/ibis/backends/dask/execution/util.py
index 61bff7e..7ed0c10 100644
--- a/ibis/backends/dask/execution/util.py
+++ b/ibis/backends/dask/execution/util.py
@@ -9,13 +9,13 @@ import pandas as pd
 from dask.dataframe.groupby import SeriesGroupBy
 
 import ibis.backends.pandas.execution.util as pd_util
-import ibis.common.graph as graph
 import ibis.expr.analysis as an
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
 import ibis.util
 from ibis.backends.dask.core import execute
 from ibis.backends.pandas.trace import TraceTwoLevelDispatcher
+from ibis.common import graph
 from ibis.expr.scope import Scope
 
 if TYPE_CHECKING:
diff --git a/ibis/backends/duckdb/datatypes.py b/ibis/backends/duckdb/datatypes.py
index fd6b8f5..52c0719 100644
--- a/ibis/backends/duckdb/datatypes.py
+++ b/ibis/backends/duckdb/datatypes.py
@@ -3,7 +3,7 @@ from __future__ import annotations
 import parsy as p
 import toolz
 
-import ibis.util as util
+from ibis import util
 from ibis.common.parsing import (
     COMMA,
     FIELD,
diff --git a/ibis/backends/impala/__init__.py b/ibis/backends/impala/__init__.py
index 4ad2057..8299a28 100644
--- a/ibis/backends/impala/__init__.py
+++ b/ibis/backends/impala/__init__.py
@@ -20,7 +20,7 @@ import ibis.config
 import ibis.expr.datatypes as dt
 import ibis.expr.rules as rlz
 import ibis.expr.schema as sch
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql import BaseSQLBackend
 from ibis.backends.base.sql.ddl import (
     CTAS,
diff --git a/ibis/backends/impala/client.py b/ibis/backends/impala/client.py
index 6655ce7..78d526f 100644
--- a/ibis/backends/impala/client.py
+++ b/ibis/backends/impala/client.py
@@ -10,7 +10,7 @@ import sqlalchemy as sa
 import ibis.common.exceptions as com
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.base import Database
 from ibis.backends.base.sql.compiler import DDL, DML
 from ibis.backends.base.sql.ddl import (
diff --git a/ibis/backends/impala/pandas_interop.py b/ibis/backends/impala/pandas_interop.py
index f410a8b..e687884 100644
--- a/ibis/backends/impala/pandas_interop.py
+++ b/ibis/backends/impala/pandas_interop.py
@@ -22,7 +22,7 @@ from posixpath import join as pjoin
 import ibis.backends.pandas.client  # noqa: F401
 import ibis.common.exceptions as com
 import ibis.expr.schema as sch
-import ibis.util as util
+from ibis import util
 from ibis.config import options
 
 
diff --git a/ibis/backends/impala/tests/conftest.py b/ibis/backends/impala/tests/conftest.py
index 1075ebe..a815be5 100644
--- a/ibis/backends/impala/tests/conftest.py
+++ b/ibis/backends/impala/tests/conftest.py
@@ -13,8 +13,7 @@ import pytest
 
 import ibis
 import ibis.expr.types as ir
-import ibis.util as util
-from ibis import options
+from ibis import options, util
 from ibis.backends.base import BaseBackend
 from ibis.backends.conftest import TEST_TABLES, _random_identifier
 from ibis.backends.impala.compiler import ImpalaCompiler, ImpalaExprTranslator
diff --git a/ibis/backends/impala/tests/test_client.py b/ibis/backends/impala/tests/test_client.py
index 0b56054..3fcca3a 100644
--- a/ibis/backends/impala/tests/test_client.py
+++ b/ibis/backends/impala/tests/test_client.py
@@ -7,9 +7,9 @@ import pytz
 
 import ibis
 import ibis.common.exceptions as com
-import ibis.config as config
 import ibis.expr.datatypes as dt
 import ibis.expr.types as ir
+from ibis import config
 from ibis.tests.util import assert_equal
 
 pytest.importorskip(""impala"")
diff --git a/ibis/backends/impala/tests/test_ddl.py b/ibis/backends/impala/tests/test_ddl.py
index 870c4dc..2346a3d 100644
--- a/ibis/backends/impala/tests/test_ddl.py
+++ b/ibis/backends/impala/tests/test_ddl.py
@@ -6,7 +6,7 @@ import ibis
 import ibis.common.exceptions as com
 import ibis.expr.datatypes as dt
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql.ddl import fully_qualified_re
 from ibis.tests.util import assert_equal
 
diff --git a/ibis/backends/impala/tests/test_exprs.py b/ibis/backends/impala/tests/test_exprs.py
index cfc8552..1d6f44f 100644
--- a/ibis/backends/impala/tests/test_exprs.py
+++ b/ibis/backends/impala/tests/test_exprs.py
@@ -5,10 +5,10 @@ import pandas.testing as tm
 import pytest
 
 import ibis
-import ibis.expr.api as api
 import ibis.expr.types as ir
 from ibis import literal as L
 from ibis.backends.impala.compiler import ImpalaCompiler
+from ibis.expr import api
 from ibis.expr.datatypes import Category
 
 
diff --git a/ibis/backends/impala/tests/test_partition.py b/ibis/backends/impala/tests/test_partition.py
index 1f96e7d..44217a4 100644
--- a/ibis/backends/impala/tests/test_partition.py
+++ b/ibis/backends/impala/tests/test_partition.py
@@ -6,7 +6,7 @@ import pandas.testing as tm
 import pytest
 
 import ibis
-import ibis.util as util
+from ibis import util
 from ibis.tests.util import assert_equal
 
 pytest.importorskip(""impala"")
diff --git a/ibis/backends/impala/tests/test_udf.py b/ibis/backends/impala/tests/test_udf.py
index 895918b..fd950d5 100644
--- a/ibis/backends/impala/tests/test_udf.py
+++ b/ibis/backends/impala/tests/test_udf.py
@@ -9,11 +9,11 @@ import ibis
 import ibis.backends.impala as api
 import ibis.common.exceptions as com
 import ibis.expr.datatypes as dt
-import ibis.expr.rules as rules
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.impala import ddl
 from ibis.common.exceptions import IbisTypeError
+from ibis.expr import rules
 
 pytest.importorskip(""impala"")
 
diff --git a/ibis/backends/impala/udf.py b/ibis/backends/impala/udf.py
index c6f2ef6..8b8b552 100644
--- a/ibis/backends/impala/udf.py
+++ b/ibis/backends/impala/udf.py
@@ -21,7 +21,7 @@ import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.rules as rlz
 import ibis.udf.validate as v
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql.registry import fixed_arity, sql_type_names
 from ibis.backends.impala.compiler import ImpalaExprTranslator
 
diff --git a/ibis/backends/mysql/__init__.py b/ibis/backends/mysql/__init__.py
index c0ddacb..50b331a 100644
--- a/ibis/backends/mysql/__init__.py
+++ b/ibis/backends/mysql/__init__.py
@@ -8,7 +8,7 @@ import warnings
 from typing import Literal
 
 import sqlalchemy as sa
-import sqlalchemy.dialects.mysql as mysql
+from sqlalchemy.dialects import mysql
 
 import ibis.expr.datatypes as dt
 import ibis.expr.schema as sch
diff --git a/ibis/backends/mysql/compiler.py b/ibis/backends/mysql/compiler.py
index 13819cb..7456f71 100644
--- a/ibis/backends/mysql/compiler.py
+++ b/ibis/backends/mysql/compiler.py
@@ -1,7 +1,7 @@
 from __future__ import annotations
 
 import sqlalchemy as sa
-import sqlalchemy.dialects.mysql as mysql
+from sqlalchemy.dialects import mysql
 
 import ibis.expr.datatypes as dt
 from ibis.backends.base.sql.alchemy import AlchemyCompiler, AlchemyExprTranslator
diff --git a/ibis/backends/postgres/tests/test_functions.py b/ibis/backends/postgres/tests/test_functions.py
index 33c6d2e..0f377e3 100644
--- a/ibis/backends/postgres/tests/test_functions.py
+++ b/ibis/backends/postgres/tests/test_functions.py
@@ -11,9 +11,9 @@ import pytest
 from pytest import param
 
 import ibis
-import ibis.config as config
 import ibis.expr.datatypes as dt
 import ibis.expr.types as ir
+from ibis import config
 from ibis import literal as L
 from ibis.expr.window import rows_with_max_lookback
 
diff --git a/ibis/backends/pyspark/__init__.py b/ibis/backends/pyspark/__init__.py
index 1b42080..b994911 100644
--- a/ibis/backends/pyspark/__init__.py
+++ b/ibis/backends/pyspark/__init__.py
@@ -14,8 +14,7 @@ import ibis.config
 import ibis.expr.operations as ops
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
-import ibis.expr.types as types
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql import BaseSQLBackend
 from ibis.backends.base.sql.compiler import Compiler, TableSetFormatter
 from ibis.backends.base.sql.ddl import (
@@ -217,16 +216,16 @@ class Backend(BaseSQLBackend):
         **kwargs: Any,
     ) -> Any:
         """"""Execute an expression.""""""
-        if isinstance(expr, types.Table):
+        if isinstance(expr, ir.Table):
             return self.compile(expr, timecontext, params, **kwargs).toPandas()
-        elif isinstance(expr, types.Column):
+        elif isinstance(expr, ir.Column):
             # expression must be named for the projection
             if not expr.has_name():
                 expr = expr.name(""tmp"")
             return self.compile(
                 expr.to_projection(), timecontext, params, **kwargs
             ).toPandas()[expr.get_name()]
-        elif isinstance(expr, types.Scalar):
+        elif isinstance(expr, ir.Scalar):
             compiled = self.compile(expr, timecontext, params, **kwargs)
             if isinstance(compiled, Column):
                 # attach result column to a fake DataFrame and
diff --git a/ibis/backends/pyspark/tests/test_ddl.py b/ibis/backends/pyspark/tests/test_ddl.py
index 0288062..ccc8a97 100644
--- a/ibis/backends/pyspark/tests/test_ddl.py
+++ b/ibis/backends/pyspark/tests/test_ddl.py
@@ -5,7 +5,7 @@ import pytest
 
 import ibis
 import ibis.common.exceptions as com
-import ibis.util as util
+from ibis import util
 from ibis.tests.util import assert_equal
 
 pyspark = pytest.importorskip(""pyspark"")
diff --git a/ibis/backends/sqlite/tests/test_client.py b/ibis/backends/sqlite/tests/test_client.py
index 95aa24d..ad64700 100644
--- a/ibis/backends/sqlite/tests/test_client.py
+++ b/ibis/backends/sqlite/tests/test_client.py
@@ -5,8 +5,8 @@ import pandas.testing as tm
 import pytest
 
 import ibis
-import ibis.config as config
 import ibis.expr.types as ir
+from ibis import config
 
 pytest.importorskip(""sqlalchemy"")
 
diff --git a/ibis/expr/format.py b/ibis/expr/format.py
index e3d48cd..85fab3f 100644
--- a/ibis/expr/format.py
+++ b/ibis/expr/format.py
@@ -9,13 +9,13 @@ from typing import Any, Callable, Deque, Iterable, Mapping, Tuple
 import rich.pretty
 
 import ibis
-import ibis.common.graph as graph
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
 import ibis.expr.window as win
-import ibis.util as util
+from ibis import util
+from ibis.common import graph
 
 Aliases = Mapping[ops.TableNode, int]
 Deps = Deque[Tuple[int, ops.TableNode]]
diff --git a/ibis/expr/operations/relations.py b/ibis/expr/operations/relations.py
index 080ddcd..de44a15 100644
--- a/ibis/expr/operations/relations.py
+++ b/ibis/expr/operations/relations.py
@@ -11,7 +11,7 @@ import ibis.expr.operations as ops
 import ibis.expr.rules as rlz
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.common.annotations import attribute
 from ibis.expr.deferred import Deferred
 from ibis.expr.operations.core import Named, Node, Value
diff --git a/ibis/expr/rules.py b/ibis/expr/rules.py
index 9b1a3b7..d40700e 100644
--- a/ibis/expr/rules.py
+++ b/ibis/expr/rules.py
@@ -11,7 +11,7 @@ import ibis.common.exceptions as com
 import ibis.expr.datatypes as dt
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.common.annotations import attribute, optional
 from ibis.common.validators import (
     bool_,
diff --git a/ibis/expr/timecontext.py b/ibis/expr/timecontext.py
index 7ecd8e7..9620d6c 100644
--- a/ibis/expr/timecontext.py
+++ b/ibis/expr/timecontext.py
@@ -38,8 +38,8 @@ from typing import TYPE_CHECKING, Any
 import numpy as np
 
 import ibis.common.exceptions as com
-import ibis.config as config
 import ibis.expr.operations as ops
+from ibis import config
 
 if TYPE_CHECKING:
     import pandas as pd
diff --git a/ibis/expr/types/groupby.py b/ibis/expr/types/groupby.py
index 138f92e..97aaaa2 100644
--- a/ibis/expr/types/groupby.py
+++ b/ibis/expr/types/groupby.py
@@ -22,7 +22,7 @@ from typing import Iterable, Sequence
 import ibis.expr.analysis as an
 import ibis.expr.types as ir
 import ibis.expr.window as _window
-import ibis.util as util
+from ibis import util
 from ibis.expr.deferred import Deferred
 
 _function_types = tuple(
diff --git a/ibis/expr/window.py b/ibis/expr/window.py
index 5ef3bb1..3e0efdc 100644
--- a/ibis/expr/window.py
+++ b/ibis/expr/window.py
@@ -11,7 +11,7 @@ import toolz
 import ibis.expr.operations as ops
 import ibis.expr.rules as rlz
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.common.exceptions import IbisInputError
 from ibis.common.grounds import Comparable
 
diff --git a/ibis/tests/expr/test_decimal.py b/ibis/tests/expr/test_decimal.py
index 85d8eb2..12b809b 100644
--- a/ibis/tests/expr/test_decimal.py
+++ b/ibis/tests/expr/test_decimal.py
@@ -3,10 +3,10 @@ import operator
 import pytest
 
 import ibis
-import ibis.expr.api as api
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
+from ibis.expr import api
 
 
 def test_type_metadata(lineitem):
diff --git a/ibis/tests/expr/test_interactive.py b/ibis/tests/expr/test_interactive.py
index cea1945..0c5613b 100644
--- a/ibis/tests/expr/test_interactive.py
+++ b/ibis/tests/expr/test_interactive.py
@@ -14,7 +14,7 @@
 
 import pytest
 
-import ibis.config as config
+from ibis import config
 from ibis.tests.expr.mocks import MockBackend
 
 
diff --git a/ibis/tests/expr/test_table.py b/ibis/tests/expr/test_table.py
index 04f4a7d..3f77985 100644
--- a/ibis/tests/expr/test_table.py
+++ b/ibis/tests/expr/test_table.py
@@ -10,13 +10,13 @@ from pytest import param
 import ibis
 import ibis.common.exceptions as com
 import ibis.expr.analysis as an
-import ibis.expr.api as api
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
 from ibis import _
 from ibis import literal as L
 from ibis.common.exceptions import RelationError
+from ibis.expr import api
 from ibis.expr.types import Column, Table
 from ibis.tests.expr.mocks import MockAlchemyBackend, MockBackend
 from ibis.tests.util import assert_equal, assert_pickle_roundtrip
diff --git a/ibis/tests/expr/test_temporal.py b/ibis/tests/expr/test_temporal.py
index e76e71c..9a0f43f 100644
--- a/ibis/tests/expr/test_temporal.py
+++ b/ibis/tests/expr/test_temporal.py
@@ -5,10 +5,10 @@ import pytest
 from pytest import param
 
 import ibis
-import ibis.expr.api as api
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
+from ibis.expr import api
 
 
 def test_temporal_literals():
diff --git a/ibis/tests/expr/test_timestamp.py b/ibis/tests/expr/test_timestamp.py
index 6601c8b..7782787 100644
--- a/ibis/tests/expr/test_timestamp.py
+++ b/ibis/tests/expr/test_timestamp.py
@@ -5,11 +5,11 @@ import pandas as pd
 import pytest
 
 import ibis
-import ibis.expr.api as api
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.rules as rlz
 import ibis.expr.types as ir
+from ibis.expr import api
 
 
 def test_field_select(alltypes):
diff --git a/ibis/tests/expr/test_value_exprs.py b/ibis/tests/expr/test_value_exprs.py
index 4c3d475..9eb247c 100644
--- a/ibis/tests/expr/test_value_exprs.py
+++ b/ibis/tests/expr/test_value_exprs.py
@@ -15,13 +15,13 @@ from pytest import param
 import ibis
 import ibis.common.exceptions as com
 import ibis.expr.analysis as L
-import ibis.expr.api as api
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.rules as rlz
 import ibis.expr.types as ir
 from ibis import _, literal
 from ibis.common.exceptions import IbisTypeError
+from ibis.expr import api
 from ibis.tests.util import assert_equal
 
 
diff --git a/ibis/tests/expr/test_visualize.py b/ibis/tests/expr/test_visualize.py
index 5525944..253564f 100644
--- a/ibis/tests/expr/test_visualize.py
+++ b/ibis/tests/expr/test_visualize.py
@@ -9,8 +9,8 @@ import ibis.expr.types as ir
 
 pytest.importorskip('graphviz')
 
-import ibis.expr.api as api  # noqa: E402
 import ibis.expr.visualize as viz  # noqa: E402
+from ibis.expr import api  # noqa: E402
 
 pytestmark = pytest.mark.skipif(
     int(os.environ.get('CONDA_BUILD', 0)) == 1, reason='CONDA_BUILD defined'
diff --git a/ibis/tests/sql/test_sqlalchemy.py b/ibis/tests/sql/test_sqlalchemy.py
index 2ad5453..3aa8c3d 100644
--- a/ibis/tests/sql/test_sqlalchemy.py
+++ b/ibis/tests/sql/test_sqlalchemy.py
@@ -15,8 +15,8 @@
 import operator
 
 import pytest
-import sqlalchemy.sql as sql
 from sqlalchemy import func as F
+from sqlalchemy import sql
 from sqlalchemy import types as sat
 
 import ibis
diff --git a/ibis/tests/util.py b/ibis/tests/util.py
index f79d09a..025bfc7 100644
--- a/ibis/tests/util.py
+++ b/ibis/tests/util.py
@@ -5,7 +5,7 @@ from __future__ import annotations
 import pickle
 
 import ibis
-import ibis.util as util
+from ibis import util
 
 
 def assert_equal(left, right):
diff --git a/pyproject.toml b/pyproject.toml
index f2146d4..492ad9e 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -310,6 +310,7 @@ select = [
   ""PGH"", # pygrep-hooks
   ""PLC"", # pylint
   ""PLE"", # pylint
+  ""PLR"", # pylint import style
   ""PLW"", # pylint
   ""RET"", # flake8-return
   ""RUF"", # ruff-specific rules
",2,"[""80944b7a513b442afcb2d0d6c7d71c0d79365dba"", ""8d53d724275ebe4b2a0bb0bd7e2c2dfc399e049b""]","[""cicd"", ""refactor""]"
"fix test

Write another record so the commit position is updated and we can take a snapshot | set cursor position in setHorizontalRule correctly, fix #2429 | use an action for issue assignment","diff --git a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/clustering/ReaderCloseTest.java b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/clustering/ReaderCloseTest.java
index 24f1316..881c727 100644
--- a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/clustering/ReaderCloseTest.java
+++ b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/clustering/ReaderCloseTest.java
@@ -70,6 +70,14 @@ public class ReaderCloseTest {
             .getCluster()
             .getNodeId();
     clusteringRule.forceClusterToHaveNewLeader(followerId);
+    // because of https://github.com/camunda-cloud/zeebe/issues/8329
+    // we need to add another record so we can do a snapshot
+    clientRule
+        .getClient()
+        .newPublishMessageCommand()
+        .messageName(""test"")
+        .correlationKey(""test"")
+        .send();
 
     // when
     clusteringRule.triggerAndWaitForSnapshots();
@@ -78,6 +86,7 @@ public class ReaderCloseTest {
     for (final Broker broker : clusteringRule.getBrokers()) {
       assertThatFilesOfDeletedSegmentsDoesNotExist(broker);
     }
+    assertThat(leaderId).isNotEqualTo(clusteringRule.getLeaderForPartition(1).getNodeId());
   }
 
   private void assertThatFilesOfDeletedSegmentsDoesNotExist(final Broker leader)

diff --git a/packages/extension-horizontal-rule/src/horizontal-rule.ts b/packages/extension-horizontal-rule/src/horizontal-rule.ts
index 6f583e1..c905b63 100644
--- a/packages/extension-horizontal-rule/src/horizontal-rule.ts
+++ b/packages/extension-horizontal-rule/src/horizontal-rule.ts
@@ -49,15 +49,14 @@ export const HorizontalRule = Node.create<HorizontalRuleOptions>({
           // set cursor after horizontal rule
           .command(({ tr, dispatch }) => {
             if (dispatch) {
-              const { parent, pos } = tr.selection.$from
-              const posAfter = pos + 1
-              const nodeAfter = tr.doc.nodeAt(posAfter)
+              const { $to } = tr.selection
+              const posAfter = $to.end()
 
-              if (nodeAfter) {
-                tr.setSelection(TextSelection.create(tr.doc, posAfter))
+              if ($to.nodeAfter) {
+                tr.setSelection(TextSelection.create(tr.doc, $to.pos))
               } else {
                 // add node after horizontal rule if its the end of the document
-                const node = parent.type.contentMatch.defaultType?.create()
+                const node = $to.parent.type.contentMatch.defaultType?.create()
 
                 if (node) {
                   tr.insert(posAfter, node)

diff --git a/.github/workflows/assign.yml b/.github/workflows/assign.yml
index 29d92a8..758874e 100644
--- a/.github/workflows/assign.yml
+++ b/.github/workflows/assign.yml
@@ -8,8 +8,6 @@ jobs:
     runs-on: ubuntu-latest
     if: ${{ github.event.comment.body == '/take' }}
     steps:
-      - uses: actions/checkout@v2
-      - name: Assign issue ${{ github.event.issue.number }} to ${{ github.event.comment.user.login }}
-        run: gh issue edit ${{ github.event.issue.number }} --add-assignee ""${{ github.event.comment.user.login }}""
-        env:
-          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+      - uses: pozil/auto-assign-issue@v1.1.0
+        with:
+          assignees: ${{ github.event.comment.user.login }}
",3,"[""47df74d40becf915a9d89cdb887abd259b77def0"", ""34d80114704679118e9bb6058e0d6c7aa03fd4b5"", ""fb3a231b29bc8bff9270b99dd4aff9dad599f21f""]","[""test"", ""fix"", ""cicd""]"
make sure root is being watched and setRoot called when it changes,"diff --git a/packages/core/src/components/nav/nav.tsx b/packages/core/src/components/nav/nav.tsx
index 5aaacb6..27241ee 100644
--- a/packages/core/src/components/nav/nav.tsx
+++ b/packages/core/src/components/nav/nav.tsx
@@ -1,4 +1,4 @@
-import { Component, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
+import { Component, Element, Event, EventEmitter, Listen, Method, Prop, Watch } from '@stencil/core';
 import {
   Animation,
   AnimationController,
@@ -103,10 +103,19 @@ export class Nav implements PublicNav, NavContainer {
     }
     this.init = true;
     if (!this.useRouter) {
+      console.log('componentDidLoadImpl: ', this.root);
       componentDidLoadImpl(this);
     }
   }
 
+  @Watch('root')
+  updateRootComponent(): any {
+    console.log('updateRootComponent: ', this.root);
+    if (this.init) {
+      return this.setRoot(this.root);
+    }
+  }
+
   getViews(): PublicViewController[] {
     return getViews(this);
   }
diff --git a/packages/core/src/components/nav/test/set-root/index.html b/packages/core/src/components/nav/test/set-root/index.html
new file mode 100644
index 0000000..823c9ed
--- /dev/null
+++ b/packages/core/src/components/nav/test/set-root/index.html
@@ -0,0 +1,110 @@
+<!DOCTYPE html>
+<html dir=""ltr"">
+<head>
+  <meta charset=""UTF-8"">
+  <title>Nav</title>
+  <meta name=""viewport"" content=""width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no"">
+  <script src=""/dist/ionic.js""></script>
+</head>
+<body onload=""initiaize()"">
+  <ion-app>
+    <ion-nav root=""page-one""></ion-nav>
+  </ion-app>
+</body>
+
+<script>
+
+  class PageOne extends HTMLElement {
+    async connectedCallback() {
+      this.innerHTML = `
+      <ion-page>
+        <ion-header>
+          <ion-toolbar>
+            <ion-title>Page One</ion-title>
+          </ion-toolbar>
+        </ion-header>
+        <ion-content padding>
+          <h1>Page One</h1>
+          <ion-button class=""next"">Go to Page Two</ion-button>
+        </ion-content>
+      </ion-page>`;
+
+      const button = this.querySelector('ion-button');
+      button.addEventListener('click', async () => {
+        this.closest('ion-nav').push('page-two');
+      });
+    }
+  }
+
+  class PageTwo extends HTMLElement {
+    async connectedCallback() {
+      this.innerHTML = `
+        <ion-page>
+          <ion-header>
+            <ion-toolbar>
+              <ion-title>Page Two</ion-title>
+            </ion-toolbar>
+          </ion-header>
+          <ion-content padding>
+            <h1>Page Two</h1>
+            <ion-button class=""next"">Go to Page Three</ion-button>
+            <ion-button class=""previous"">Go Back</ion-button>
+          </ion-content>
+        </ion-page>`;
+
+      const previousButton = this.querySelector('ion-button.previous');
+      previousButton.addEventListener('click', async () => {
+        await this.closest('ion-nav').pop();
+      });
+
+      const nextButton = this.querySelector('ion-button.next');
+      nextButton.addEventListener('click', async () => {
+        await this.closest('ion-nav').push('page-three');
+      });
+    }
+  }
+
+  class PageThree extends HTMLElement {
+    async connectedCallback() {
+      this.innerHTML = `
+        <ion-page>
+          <ion-header>
+            <ion-toolbar>
+              <ion-title>Page Three</ion-title>
+            </ion-toolbar>
+          </ion-header>
+          <ion-content padding>
+            <h1>Page Three</h1>
+            <ion-button class=""previous"">Go Back</ion-button>
+          </ion-content>
+        </ion-page>`;
+
+      const previousButton = this.querySelector('ion-button.previous');
+      previousButton.addEventListener('click', async () => {
+        await this.closest('ion-nav').pop();
+      });
+    }
+  }
+
+  customElements.define('page-one', PageOne);
+  customElements.define('page-two', PageTwo);
+  customElements.define('page-three', PageThree);
+
+  async function initiaize() {
+    const nav = document.querySelector('ion-nav');
+    await nav.componentOnReady();
+    nav.root = 'page-one';
+
+    setInterval(() => {
+      if (nav.root === 'page-one') {
+        nav.root = 'page-two';
+      } else if ( nav.root === 'page-two') {
+        nav.root = 'page-three';
+      } else {
+        nav.root = 'page-one';
+      }
+    }, 1000);
+  }
+
+</script>
+</html>
",1,"[""4be836f5655fb5356fde5ddd7437125f8574705d""]","[""refactor""]"
"do not use scripts and binaries from the libcc repo | remove unnecessary lines from verify-wal test | document the use of export buckets for large pre-aggregations

Co-authored-by: Ray Paik <ray@cube.dev>
Co-authored-by: Artyom Keydunov <artyom@cube.dev>
Co-authored-by: Dmitry Patsura <talk@dmtry.me>","diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |

diff --git a/storage/wal/verifier_test.go b/storage/wal/verifier_test.go
index 61e1536..a44755f 100644
--- a/storage/wal/verifier_test.go
+++ b/storage/wal/verifier_test.go
@@ -138,22 +138,13 @@ func writeCorruptEntries(file *os.File, t *testing.T, n int) {
 		}
 	}
 
-
 	// Write some random bytes to the file to simulate corruption.
 	if _, err := file.Write(corruption); err != nil {
 		fatal(t, ""corrupt WAL segment"", err)
 	}
-	corrupt := []byte{1, 255, 0, 3, 45, 26, 110}
-
-	wrote, err := file.Write(corrupt)
-	if err != nil {
-		t.Fatal(err)
-	} else if wrote != len(corrupt) {
-		t.Fatal(""Error writing corrupt data to file"")
-	}
 
 	if err := file.Close(); err != nil {
-		t.Fatalf(""Error: filed to close file: %v\n"", err)
+		t.Fatalf(""Error: failed to close file: %v\n"", err)
 	}
 }
 

diff --git a/docs/content/Caching/Using-Pre-Aggregations.md b/docs/content/Caching/Using-Pre-Aggregations.md
index 7882a25..a927241 100644
--- a/docs/content/Caching/Using-Pre-Aggregations.md
+++ b/docs/content/Caching/Using-Pre-Aggregations.md
@@ -65,8 +65,8 @@ In development mode, Cube.js enables background refresh by default and will
 refresh all pre-aggregations marked with the
 [`scheduledRefresh`](/pre-aggregations#scheduled-refresh) parameter.
 
-Please consult the [Production Checklist][ref-production-checklist-refresh] for
-best practices on running background refresh in production environments.
+Please consult the [Production Checklist][ref-prod-list-refresh] for best
+practices on running background refresh in production environments.
 
 ```js
 cube(`Orders`, {
@@ -193,10 +193,20 @@ CUBEJS_EXT_DB_TYPE=<SUPPORTED_DB_TYPE_HERE>
 
 <!-- prettier-ignore-start -->
 [[warning |]]
-| Please be aware of the limitations when using internal and external (outside of Cube Store) pre-aggregations.
+| Please be aware of the limitations when using internal and external (outside
+| of Cube Store) pre-aggregations.
 <!-- prettier-ignore-end -->
 
-![](https://raw.githubusercontent.com/cube-js/cube.js/master/docs/content/Caching/pre-aggregations.png)
+<div
+  style=""text-align: center""
+>
+  <img
+  alt=""Internal vs External vs External with Cube Store diagram""
+  src=""https://raw.githubusercontent.com/cube-js/cube.js/master/docs/content/Caching/pre-aggregations.png""
+  style=""border: none""
+  width=""100%""
+  />
+</div>
 
 #### Some known limitations when using Postgres/MySQL as a storage layer listed below.
 
@@ -245,15 +255,75 @@ slow to return results.
 (such as AWS Athena and BigQuery). Repeatedly querying for this data can easily
 rack up costs.
 
+## Optimizing Pre-Aggregation Build Times
+
+<!-- prettier-ignore-start -->
+[[info | ]]
+| For ideal performance, pre-aggregations should be built using a dedicated
+| Refresh Worker. [See here for more details][ref-prod-list-refresh].
+<!-- prettier-ignore-end -->
+
+By default, Cube.js will use the source database as a temporary staging area for
+writing pre-aggregations to determine column types. The data is loaded back into
+memory before writing them to Cube Store (or an external database).
+
+![](build-regular.png)
+
+If the dataset is large (more than 100k rows), then Cube.js can face issues when
+the Node runtime runs out of memory.
+
+### Batching
+
+Batching is a more performant strategy where Cube.js sends compressed CSVs for
+Cube Store to ingest.
+
+![](build-batching.png)
+
+The performance scales to the amount of memory available on the Cube.js
+instance. Support is currently available for:
+
+- [AWS Athena][ref-connect-db-athena] (coming soon)
+- [AWS Redshift][ref-connect-db-redshift]
+- [BigQuery][ref-connect-db-bigquery]
+- [MySQL][ref-connect-db-mysql]
+- [Postgres][ref-connect-db-postgres]
+
+### Export bucket
+
+When dealing with larger pre-aggregations (more than 100k rows), performance can
+be significantly improved by using an export bucket. This allows the source
+database to persist data directly into cloud storage, which is then loaded into
+Cube Store in parallel:
+
+![](build-export-bucket.png)
+
+Export buckets are currently supported for the following databases:
+
+- [AWS Athena][ref-connect-db-athena] (coming soon)
+- [AWS Redshift][ref-connect-db-redshift]
+- [BigQuery][ref-connect-db-bigquery]
+- [Snowflake][ref-connect-db-snowflake]
+
+When using cloud storage, it is important to correctly configure any data
+retention policies to clean up the data in the export bucket as Cube.js does not
+currently manage this. For most use-cases, 1 day is sufficient.
+
 [wiki-partitioning]: https://en.wikipedia.org/wiki/Partition_(database)
+[ref-config-connect-db]: /connecting-to-the-database
+[ref-config-env]: /reference/environment-variables#cube-store
+[ref-connect-db-athena]: /connecting-to-the-database#notes-aws-athena
+[ref-connect-db-redshift]: /connecting-to-the-database#notes-aws-redshift
+[ref-connect-db-bigquery]: /connecting-to-the-database#notes-google-big-query
+[ref-connect-db-mysql]: /connecting-to-the-database#notes-my-sql
+[ref-connect-db-postgres]: /connecting-to-the-database#notes-aws-rds-postgres
+[ref-connect-db-snowflake]: /connecting-to-the-database#notes-snowflake
 [ref-schema-timedimension]: /types-and-formats#dimensions-types-time
 [ref-preaggs]: /pre-aggregations
 [ref-preagg-sched-refresh]: /pre-aggregations#scheduled-refresh
 [ref-preagg-time-part]: /pre-aggregations#rollup-time-partitioning
 [ref-preagg-segment-part]: /pre-aggregations#rollup-segment-partitioning
 [ref-preaggs-refresh-key]: /pre-aggregations#refresh-key
+[ref-prod-list-refresh]: /deployment/production-checklist#set-up-refresh-worker
 [ref-config-extdbtype]: /config#options-reference-external-db-type
 [ref-config-driverfactory]: /config#options-reference-driver-factory
 [ref-config-extdriverfactory]: /config#options-reference-external-driver-factory
-[ref-production-checklist-refresh]:
-  /deployment/production-checklist#set-up-refresh-worker
diff --git a/docs/content/Caching/build-batching.png b/docs/content/Caching/build-batching.png
new file mode 100755
index 0000000..d1e28b3
Binary files /dev/null and b/docs/content/Caching/build-batching.png differ
diff --git a/docs/content/Caching/build-export-bucket.png b/docs/content/Caching/build-export-bucket.png
new file mode 100755
index 0000000..7da2425
Binary files /dev/null and b/docs/content/Caching/build-export-bucket.png differ
diff --git a/docs/content/Caching/build-regular.png b/docs/content/Caching/build-regular.png
new file mode 100644
index 0000000..af4c3a2
Binary files /dev/null and b/docs/content/Caching/build-regular.png differ
diff --git a/docs/content/Configuration/Connecting-to-the-Database.md b/docs/content/Configuration/Connecting-to-the-Database.md
index 321518f..a16ccc4 100644
--- a/docs/content/Configuration/Connecting-to-the-Database.md
+++ b/docs/content/Configuration/Connecting-to-the-Database.md
@@ -49,20 +49,21 @@ CUBEJS_API_SECRET=secret
 The table below shows which environment variables are used for different
 databases:
 
-| Database                                               | Credentials                                                                                                                                                                                                                                                                                                                                          |
-| ------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
-| PostgreSQL, MySQL, AWS Redshift, Hive/SparkSQL, Oracle | `CUBEJS_DB_HOST`, `CUBEJS_DB_PORT`, `CUBEJS_DB_NAME`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`                                                                                                                                                                                                                                                             |
-| MS SQL                                                 | `CUBEJS_DB_HOST`, `CUBEJS_DB_PORT`, `CUBEJS_DB_NAME`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`, `CUBEJS_DB_DOMAIN`                                                                                                                                                                                                                                         |
-| ClickHouse                                             | `CUBEJS_DB_HOST`, `CUBEJS_DB_PORT`, `CUBEJS_DB_NAME`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`, `CUBEJS_DB_SSL`, `CUBEJS_DB_CLICKHOUSE_READONLY`                                                                                                                                                                                                           |
-| AWS Athena                                             | `CUBEJS_AWS_KEY`, `CUBEJS_AWS_SECRET`, `CUBEJS_AWS_REGION`, `CUBEJS_AWS_S3_OUTPUT_LOCATION`                                                                                                                                                                                                                                                          |
-| Google BigQuery                                        | `CUBEJS_DB_BQ_PROJECT_ID`, `CUBEJS_DB_BQ_KEY_FILE or CUBEJS_DB_BQ_CREDENTIALS`, `CUBEJS_DB_BQ_LOCATION`, `CUBEJS_DB_BQ_EXPORT_BUCKET`                                                                                                                                                                                                                |
-| MongoDB                                                | `CUBEJS_DB_HOST`, `CUBEJS_DB_NAME`, `CUBEJS_DB_PORT`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`, `CUBEJS_DB_SSL`, `CUBEJS_DB_SSL_CA`, `CUBEJS_DB_SSL_CERT`, `CUBEJS_DB_SSL_CIPHERS`, `CUBEJS_DB_SSL_PASSPHRASE`                                                                                                                                             |
-| Snowflake                                              | `CUBEJS_DB_SNOWFLAKE_ACCOUNT`, `CUBEJS_DB_SNOWFLAKE_REGION`, `CUBEJS_DB_SNOWFLAKE_WAREHOUSE`, `CUBEJS_DB_SNOWFLAKE_ROLE`, `CUBEJS_DB_SNOWFLAKE_CLIENT_SESSION_KEEP_ALIVE`, `CUBEJS_DB_NAME`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`, `CUBEJS_DB_SNOWFLAKE_AUTHENTICATOR`, `CUBEJS_DB_SNOWFLAKE_PRIVATE_KEY_PATH`, `CUBEJS_DB_SNOWFLAKE_PRIVATE_KEY_PASS` |
-| Presto                                                 | `CUBEJS_DB_HOST`, `CUBEJS_DB_PORT`, `CUBEJS_DB_CATALOG`, `CUBEJS_DB_SCHEMA`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`                                                                                                                                                                                                                                      |
-| Druid                                                  | `CUBEJS_DB_URL`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`, `CUBEJS_DB_SSL`                                                                                                                                                                                                                                                                                 |
-| SQLite                                                 | `CUBEJS_DB_NAME`                                                                                                                                                                                                                                                                                                                                     |
-| Databricks                                             | `CUBEJS_DB_NAME`, `CUBEJS_DB_DATABRICKS_URL`                                                                                                                                                                                                                                                                                                         |
-| Elasticsearch                                          | `CUBEJS_DB_URL`, `CUBEJS_DB_ELASTIC_QUERY_FORMAT`,`CUBEJS_DB_ELASTIC_OPENDISTRO` ,`CUBEJS_DB_ELASTIC_APIKEY_ID`,`CUBEJS_DB_ELASTIC_APIKEY_KEY`                                                                                                                                                                                                       |
+| Database                                 | Credentials                                                                                                                                                                                                                                                                                                                                          |
+| ---------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
+| PostgreSQL, MySQL, Hive/SparkSQL, Oracle | `CUBEJS_DB_HOST`, `CUBEJS_DB_PORT`, `CUBEJS_DB_NAME`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`                                                                                                                                                                                                                                                             |
+| AWS Redshift                             | `CUBEJS_DB_HOST`, `CUBEJS_DB_PORT`, `CUBEJS_DB_NAME`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`,                                                                                                                                                                                                                                                            |
+| MS SQL                                   | `CUBEJS_DB_HOST`, `CUBEJS_DB_PORT`, `CUBEJS_DB_NAME`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`, `CUBEJS_DB_DOMAIN`                                                                                                                                                                                                                                         |
+| ClickHouse                               | `CUBEJS_DB_HOST`, `CUBEJS_DB_PORT`, `CUBEJS_DB_NAME`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`, `CUBEJS_DB_SSL`, `CUBEJS_DB_CLICKHOUSE_READONLY`                                                                                                                                                                                                           |
+| AWS Athena                               | `CUBEJS_AWS_KEY`, `CUBEJS_AWS_SECRET`, `CUBEJS_AWS_REGION`, `CUBEJS_AWS_S3_OUTPUT_LOCATION`                                                                                                                                                                                                                                                          |
+| Google BigQuery                          | `CUBEJS_DB_BQ_PROJECT_ID`, `CUBEJS_DB_BQ_KEY_FILE or CUBEJS_DB_BQ_CREDENTIALS`, `CUBEJS_DB_BQ_LOCATION`,                                                                                                                                                                                                                                             |
+| MongoDB                                  | `CUBEJS_DB_HOST`, `CUBEJS_DB_NAME`, `CUBEJS_DB_PORT`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`, `CUBEJS_DB_SSL`, `CUBEJS_DB_SSL_CA`, `CUBEJS_DB_SSL_CERT`, `CUBEJS_DB_SSL_CIPHERS`, `CUBEJS_DB_SSL_PASSPHRASE`                                                                                                                                             |
+| Snowflake                                | `CUBEJS_DB_SNOWFLAKE_ACCOUNT`, `CUBEJS_DB_SNOWFLAKE_REGION`, `CUBEJS_DB_SNOWFLAKE_WAREHOUSE`, `CUBEJS_DB_SNOWFLAKE_ROLE`, `CUBEJS_DB_SNOWFLAKE_CLIENT_SESSION_KEEP_ALIVE`, `CUBEJS_DB_NAME`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`, `CUBEJS_DB_SNOWFLAKE_AUTHENTICATOR`, `CUBEJS_DB_SNOWFLAKE_PRIVATE_KEY_PATH`, `CUBEJS_DB_SNOWFLAKE_PRIVATE_KEY_PASS` |
+| Presto                                   | `CUBEJS_DB_HOST`, `CUBEJS_DB_PORT`, `CUBEJS_DB_CATALOG`, `CUBEJS_DB_SCHEMA`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`                                                                                                                                                                                                                                      |
+| Druid                                    | `CUBEJS_DB_URL`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`, `CUBEJS_DB_SSL`                                                                                                                                                                                                                                                                                 |
+| SQLite                                   | `CUBEJS_DB_NAME`                                                                                                                                                                                                                                                                                                                                     |
+| Databricks                               | `CUBEJS_DB_NAME`, `CUBEJS_DB_DATABRICKS_URL`                                                                                                                                                                                                                                                                                                         |
+| Elasticsearch                            | `CUBEJS_DB_URL`, `CUBEJS_DB_ELASTIC_QUERY_FORMAT`,`CUBEJS_DB_ELASTIC_OPENDISTRO` ,`CUBEJS_DB_ELASTIC_APIKEY_ID`,`CUBEJS_DB_ELASTIC_APIKEY_KEY`                                                                                                                                                                                                       |
 
 ## Multiple Databases
 
@@ -195,18 +196,25 @@ You can learn more about acquiring Google BigQuery credentials
 [here][link-bigquery-getting-started] and [here][link-bigquery-credentials].
 
 You can set the dataset location using the `CUBEJS_DB_BQ_LOCATION` environment
-variable.
+variable. All supported regions [can be found
+here][link-bigquery-regional-locations].
 
 ```dotenv
 CUBEJS_DB_BQ_LOCATION=us-central1
 ```
 
-You can find more supported regions [here][link-bigquery-regional-locations].
+#### Configuring an export bucket
 
-If your pre-aggregations dataset is too big to fit in memory, we **strongly**
-recommend configuring `CUBEJS_DB_BQ_EXPORT_BUCKET`. This will allow Cube.js to
-materialize results on an ""export"" bucket which are then loaded into BigQuery,
-providing better performance.
+<!-- prettier-ignore-start -->
+[[warning |]]
+| BigQuery only supports using Google Cloud Storage for export buckets.
+<!-- prettier-ignore-end -->
+
+##### Google Cloud Storage
+
+For [improved pre-aggregation performance with large
+datasets][ref-caching-large-preaggs], enable the export bucket functionality by
+configuring Cube.js with the following environment variables:
 
 <!-- prettier-ignore-start -->
 [[info |]]
@@ -216,7 +224,8 @@ providing better performance.
 <!-- prettier-ignore-end -->
 
 ```dotenv
-CUBEJS_DB_BQ_EXPORT_BUCKET=export_data_58148478376
+CUBEJS_DB_EXPORT_BUCKET=export_data_58148478376
+CUBEJS_DB_EXPORT_BUCKET_TYPE=gcp
 ```
 
 ### MSSQL
@@ -279,6 +288,73 @@ To connect to a Elasticsearch database, use `CUBEJS_DB_URL` with the username
 and password embedded in the URL, if required. If you're not using Elastic
 Cloud, you **must** specify `CUBEJS_DB_ELASTIC_QUERY_FORMAT`.
 
+### AWS Redshift
+
+#### Configuring an export bucket
+
+<!-- prettier-ignore-start -->
+[[warning |]]
+| AWS Redshift only supports using AWS S3 for export buckets.
+<!-- prettier-ignore-end -->
+
+##### AWS S3
+
+For [improved pre-aggregation performance with large
+datasets][ref-caching-large-preaggs], enable the export bucket functionality by
+configuring Cube.js with the following environment variables:
+
+<!-- prettier-ignore-start -->
+[[info |]]
+| Ensure the AWS credentials are correctly configured in IAM to allow reads and
+| writes to the export bucket.
+<!-- prettier-ignore-end -->
+
+```dotenv
+CUBEJS_DB_EXPORT_BUCKET_TYPE=s3
+CUBEJS_DB_EXPORT_BUCKET=my.bucket.on.s3
+CUBEJS_DB_EXPORT_BUCKET_AWS_KEY=<AWS_KEY>
+CUBEJS_DB_EXPORT_BUCKET_AWS_SECRET=<AWS_SECRET>
+CUBEJS_DB_EXPORT_BUCKET_AWS_REGION=<AWS_REGION>
+```
+
+### Snowflake
+
+#### Configuring an export bucket
+
+Snowflake supports using both AWS S3 and Google Cloud Storage for export bucket
+functionality.
+
+##### AWS S3
+
+<!-- prettier-ignore-start -->
+[[info |]]
+| Ensure the AWS credentials are correctly configured in IAM to allow reads and
+| writes to the export bucket.
+<!-- prettier-ignore-end -->
+
+```dotenv
+CUBEJS_DB_EXPORT_BUCKET_TYPE=s3
+CUBEJS_DB_EXPORT_BUCKET=my.bucket.on.s3
+CUBEJS_DB_EXPORT_BUCKET_AWS_KEY=<AWS_KEY>
+CUBEJS_DB_EXPORT_BUCKET_AWS_SECRET=<AWS_SECRET>
+CUBEJS_DB_EXPORT_BUCKET_AWS_REGION=<AWS_REGION>
+```
+
+##### Google Cloud Storage
+
+Before configuring Cube.js, an [integration must be created and configured in
+Snowflake][link-snowflake-gcs-integration]. Take note of the integration name
+(`gcs_int` from the example link) as you'll need it to configure Cube.js.
+
+Once the Snowflake integration is set up, configure Cube.js using the following:
+
+```dotenv
+CUBEJS_DB_EXPORT_BUCKET=snowflake-export-bucket
+CUBEJS_DB_EXPORT_BUCKET_TYPE=gcp
+CUBEJS_DB_EXPORT_GCS_CREDENTIALS=<BASE64_ENCODED_SERVICE_CREDENTIALS_JSON
+CUBEJS_DB_EXPORT_INTEGRATION=gcs_int
+```
+
 [link-java-guide]:
   https://github.com/cube-js/cube.js/blob/master/packages/cubejs-jdbc-driver/README.md#java-installation
 [link-cubejs-driver-guide]:
@@ -300,8 +376,11 @@ Cloud, you **must** specify `CUBEJS_DB_ELASTIC_QUERY_FORMAT`.
   https://console.cloud.google.com/apis/credentials/serviceaccountkey
 [link-heroku-postgres-issue]:
   https://help.heroku.com/3DELT3RK/why-can-t-my-third-party-utility-connect-to-heroku-postgres-with-ssl
+[link-snowflake-gcs-integration]:
+  https://docs.snowflake.com/en/user-guide/data-load-gcs-config.html
+[link-bigquery-regional-locations]:
+  https://cloud.google.com/bigquery/docs/locations#regional-locations
 [ref-cubejs-cli]: /using-the-cubejs-cli
 [ref-enabling-ssl]: #enabling-ssl
 [ref-env-var]: /reference/environment-variables#database-connection
-[link-bigquery-regional-locations]:
-  https://cloud.google.com/bigquery/docs/locations#regional-locations
+[ref-caching-large-preaggs]: /using-pre-aggregations#large-pre-aggregations
diff --git a/docs/content/Configuration/Environment-Variables-Reference.md b/docs/content/Configuration/Environment-Variables-Reference.md
index 692d2c7..6888697 100644
--- a/docs/content/Configuration/Environment-Variables-Reference.md
+++ b/docs/content/Configuration/Environment-Variables-Reference.md
@@ -124,6 +124,18 @@ databases [in this guide][link-connecting-to-db].
 | `CUBEJS_DB_SNOWFLAKE_PRIVATE_KEY_PASS`          | Snowflake            | The password for the private RSA key. Only required for encrypted keys                                                                                                                                      | A valid password for the encrypted private RSA key               |
 | `CUBEJS_DB_DATABRICKS_URL`                      | Databricks           | The URL for a JDBC connection                                                                                                                                                                               | A valid JDBC URL                                                 |
 
+## Export Bucket
+
+| Environment variable                 | Description                                                                                  | Possible Values                                                  |
+| ------------------------------------ | -------------------------------------------------------------------------------------------- | ---------------------------------------------------------------- |
+| `CUBEJS_DB_EXPORT_BUCKET`            | The name of a bucket in cloud storage                                                        | `exports-20210505`                                               |
+| `CUBEJS_DB_EXPORT_BUCKET_TYPE`       | The cloud provider where the bucket is hosted                                                | `gcs`, `s3`                                                      |
+| `CUBEJS_DB_EXPORT_BUCKET_AWS_KEY`    | The AWS Access Key ID to use for the export bucket                                           | A valid AWS Access Key ID                                        |
+| `CUBEJS_DB_EXPORT_BUCKET_AWS_SECRET` | The AWS Secret Access Key to use for the export bucket                                       | A valid AWS Secret Access Key                                    |
+| `CUBEJS_DB_EXPORT_BUCKET_AWS_REGION` | The AWS region of the export bucket                                                          | [A valid AWS region][link-aws-regions]                           |
+| `CUBEJS_DB_EXPORT_GCS_CREDENTIALS`   | A Base64 encoded JSON key file for connecting to Google Cloud                                | A valid Google Cloud JSON key file encoded as a Base64 string    |
+| `CUBEJS_DB_EXPORT_INTEGRATION`       | The name of the integration used in the database. Only required when using Snowflake and GCS | A valid string matching the name of the integration in Snowflake |
+
 ## Cube Store
 
 | Environment variable            | Description                                                                                                                             | Possible Values                                             |
",3,"[""45837af24a33308a70a3454f0f650f9fe728e272"", ""fba4326c72fc22d81aba6976a9fef1e4b6154fd9"", ""81f37be838d5e3af738908b1bcbf59fea2b45989""]","[""cicd"", ""refactor"", ""docs""]"
"remove appear css animation | fix monorepo.dir prop

Signed-off-by: Carlos Alexandro Becker <caarlos0@gmail.com>","diff --git a/src/popup/Popup.tsx b/src/popup/Popup.tsx
index d485bb6..2abc22a 100644
--- a/src/popup/Popup.tsx
+++ b/src/popup/Popup.tsx
@@ -269,7 +269,6 @@ export class Popup extends React.Component<{ t: TranslationFunction }, PopupStat
         <CSSTransition
           classNames='fade'
           in={!!currentTabUrl}
-          appear
           timeout={500}
           exit={false}
           mountOnEnter

diff --git a/www/docs/customization/monorepo.md b/www/docs/customization/monorepo.md
index 6d0e857..e45490f 100644
--- a/www/docs/customization/monorepo.md
+++ b/www/docs/customization/monorepo.md
@@ -18,7 +18,7 @@ project_name: subproj1
 
 monorepo:
   tag_prefix: subproject1/
-  folder: subproj1
+  dir: subproj1
 ```
 
 Then, you can release with (from the project's root directory):
@@ -30,11 +30,11 @@ goreleaser release --rm-dist -f ./subproj1/.goreleaser.yml
 Then, the following is different from a ""regular"" run:
 
 - GoReleaser will then look if current commit has a tag prefixed with `subproject1`, and also the previous tag with the same prefix;
-- Changelog will include only commits that contain changes to files within the `subproj1` folder;
+- Changelog will include only commits that contain changes to files within the `subproj1` directory;
 - Release name gets prefixed with `{{ .ProjectName }} ` if empty;
-- All build's `dir` setting get set to `monorepo.folder` if empty;
+- All build's `dir` setting get set to `monorepo.dir` if empty;
   - if yours is not, you might want to change that manually;
-- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.folder`;
+- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.dir`;
 - On templates, `{{.PrefixedTag}}` will be `monorepo.prefix/tag` (aka the actual tag name), and `{{.Tag}}` has the prefix stripped;
 
 The rest of the release process should work as usual.
",2,"[""47ef9104e4a89e80d7cc6c1950bc080841da4a7b"", ""9ed3c0c4a72af977fc9150512fb6538f20a94b22""]","[""refactor"", ""docs""]"
make jq use compact json for rebase branch query | autostart feature fixed,"diff --git a/.github/workflows/ibis-rebase-nightly.yml b/.github/workflows/ibis-rebase-nightly.yml
index 0e284b0..4a3ec7a 100644
--- a/.github/workflows/ibis-rebase-nightly.yml
+++ b/.github/workflows/ibis-rebase-nightly.yml
@@ -22,7 +22,7 @@ jobs:
               | cut -d ' ' -f2 \
               | grep -P '\d+\.x\.x' \
               | xargs printf '""%s""' \
-              | jq -s '{branch: .}')
+              | jq -rcMs '{branch: .}')
 
           echo ""::set-output name=matrix::$branches""
 

diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();
",2,"[""4638dcdf7011e8e42d11fde04f068f22ee20fa1d"", ""bed78248c941d57ad4cc20a455147e186e97c7a1""]","[""cicd"", ""fix""]"
better tested publishing flow | Improved Config Loading #423,"diff --git a/Makefile.toml b/Makefile.toml
index e7d2b20..490d6e2 100644
--- a/Makefile.toml
+++ b/Makefile.toml
@@ -82,7 +82,7 @@ end
 '''
 
 [tasks.build-plugins-release]
-env = { ""CARGO_MAKE_WORKSPACE_SKIP_MEMBERS"" = ["".""] }
+env = { ""CARGO_MAKE_WORKSPACE_INCLUDE_MEMBERS"" = [""default-plugins/status-bar"", ""default-plugins/strider"", ""default-plugins/tab-bar""] }
 run_task = { name = ""build-release"", fork = true }
 
 [tasks.wasm-opt-plugins]
@@ -129,15 +129,16 @@ args = [""install"", ""cross""]
 [tasks.publish]
 clear = true
 workspace = false
-dependencies = [""build-plugins-release"", ""wasm-opt-plugins"", ""release-commit"", ""build-release"", ""publish-zellij-tile"", ""publish-zellij-tile-utils"", ""publish-zellij-utils"", ""publish-zellij-client"", ""publish-zellij-server""]
+dependencies = [""build-plugins-release"", ""wasm-opt-plugins"", ""release-commit""]
 run_task = ""publish-zellij""
 
 [tasks.release-commit]
 dependencies = [""commit-all"", ""tag-release""]
 command = ""git""
-args = [""push"", ""--atomic"", ""upstream"", ""main"", ""v${CARGO_MAKE_CRATE_VERSION}""]
+args = [""push"", ""--atomic"", ""origin"", ""main"", ""v${CARGO_MAKE_CRATE_VERSION}""]
 
 [tasks.commit-all]
+ignore_errors = true
 command = ""git""
 args = [""commit"", ""-aem"", ""chore(release): v${CARGO_MAKE_CRATE_VERSION}""]
 
@@ -148,31 +149,32 @@ args = [""tag"", ""v${CARGO_MAKE_CRATE_VERSION}""]
 [tasks.publish-zellij-tile]
 ignore_errors = true
 cwd = ""zellij-tile""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-client]
+ignore_errors = true
 dependencies = [""publish-zellij-utils""]
 cwd = ""zellij-client""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-server]
+ignore_errors = true
 dependencies = [""publish-zellij-utils""]
 cwd = ""zellij-server""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-utils]
+ignore_errors = true
 dependencies = [""publish-zellij-tile""]
 cwd = ""zellij-utils""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-tile-utils]
 ignore_errors = true
 cwd = ""zellij-tile-utils""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij]
 dependencies = [""publish-zellij-client"", ""publish-zellij-server"", ""publish-zellij-utils""]
 command = ""cargo""
 args = [""publish""]
-
-

diff --git a/CHANGELOG.md b/CHANGELOG.md
index 76dd749..2087803 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -7,6 +7,7 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
 ## [Unreleased]
 * Fix the tab '(Sync)' suffix in named tabs (https://github.com/zellij-org/zellij/pull/410)
 * Improve performance when multiple panes are open (https://github.com/zellij-org/zellij/pull/318)
+* Improve error reporting and tests of configuration (https://github.com/zellij-org/zellij/pull/423)
 
 ## [0.6.0] - 2021-04-29
 * Doesn't quit anymore on single `q` press while in tab mode  (https://github.com/zellij-org/zellij/pull/342)
",2,"[""65574eea5da54bf4722ecb551b42f8ff6088f33b"", ""099861ff5b0f83773ca0af4c70e6e39be3b0336c""]","[""build"", ""docs""]"
"implement array flatten support | export a modal transition preset | initialize threejs objects in defaultRef, to fix undefined type errors","diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 2373dd7..4ce03b0 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -422,6 +422,7 @@ operation_registry.update(
         ops.ArrayZip: _array_zip,
         ops.ArraySort: unary(sa.func.array_sort),
         ops.ArrayRepeat: fixed_arity(sa.func.ibis_udfs.public.array_repeat, 2),
+        ops.ArrayFlatten: fixed_arity(sa.func.array_flatten, 1),
         ops.StringSplit: fixed_arity(sa.func.split, 2),
         # snowflake typeof only accepts VARIANT, so we cast
         ops.TypeOf: unary(lambda arg: sa.func.typeof(sa.func.to_variant(arg))),

diff --git a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
index f1066a1..ae93dca 100644
--- a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
+++ b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
@@ -79,3 +79,8 @@ export const DefaultTransition = Platform.select({
       ? FadeFromBottomAndroid
       : WipeFromBottomAndroid,
 });
+
+export const ModalTransition = Platform.select({
+  ios: ModalSlideFromBottomIOS,
+  default: DefaultTransition,
+});
diff --git a/packages/stack/src/views/Stack/Stack.tsx b/packages/stack/src/views/Stack/Stack.tsx
index cf1719c..47c1abf 100755
--- a/packages/stack/src/views/Stack/Stack.tsx
+++ b/packages/stack/src/views/Stack/Stack.tsx
@@ -14,7 +14,7 @@ import { Props as HeaderContainerProps } from '../Header/HeaderContainer';
 import StackItem from './StackItem';
 import {
   DefaultTransition,
-  ModalSlideFromBottomIOS,
+  ModalTransition,
 } from '../../TransitionConfigs/TransitionPresets';
 import { forNoAnimation } from '../../TransitionConfigs/HeaderStyleInterpolators';
 import {
@@ -301,9 +301,7 @@ export default class Stack extends React.Component<Props, State> {
     const focusedOptions = descriptors[focusedRoute.key].options;
 
     let defaultTransitionPreset =
-      mode === 'modal' && Platform.OS === 'ios'
-        ? ModalSlideFromBottomIOS
-        : DefaultTransition;
+      mode === 'modal' ? ModalTransition : DefaultTransition;
 
     if (headerMode === 'screen') {
       defaultTransitionPreset = {

diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number
",3,"[""d3c754f09502be979e5dcc79f968b15052590bd0"", ""535708ae50aecb452560a23356fd396f99ef13a2"", ""2561f4ade46fc9d59f289f328cc77733a6443697""]","[""feat"", ""refactor"", ""fix""]"
add test case with multiple partitions for message | cancel in-progress dep update jobs when a new one arrives [skip ci] | correct width when --no-quotes is used,"diff --git a/broker-core/src/main/java/io/zeebe/broker/subscription/command/SubscriptionCommandSender.java b/broker-core/src/main/java/io/zeebe/broker/subscription/command/SubscriptionCommandSender.java
index 693d1da..e3552d4 100644
--- a/broker-core/src/main/java/io/zeebe/broker/subscription/command/SubscriptionCommandSender.java
+++ b/broker-core/src/main/java/io/zeebe/broker/subscription/command/SubscriptionCommandSender.java
@@ -74,7 +74,7 @@ public class SubscriptionCommandSender {
       new CloseWorkflowInstanceSubscriptionCommand();
 
   private final ClientTransport subscriptionClient;
-  private final IntArrayList partitionIds;
+  private final IntArrayList partitionIds = new IntArrayList();
 
   private int partitionId;
   private TopologyPartitionListenerImpl partitionListener;
@@ -82,7 +82,6 @@ public class SubscriptionCommandSender {
   public SubscriptionCommandSender(
       final ClusterCfg clusterCfg, final ClientTransport subscriptionClient) {
     this.subscriptionClient = subscriptionClient;
-    partitionIds = new IntArrayList();
     partitionIds.addAll(clusterCfg.getPartitionIds());
   }
 
@@ -100,7 +99,8 @@ public class SubscriptionCommandSender {
       final DirectBuffer messageName,
       final DirectBuffer correlationKey) {
 
-    final int subscriptionPartitionId = getSubscriptionPartitionId(correlationKey);
+    final int subscriptionPartitionId =
+        SubscriptionUtil.getSubscriptionPartitionId(correlationKey, partitionIds.size());
 
     openMessageSubscriptionCommand.setSubscriptionPartitionId(subscriptionPartitionId);
     openMessageSubscriptionCommand.setWorkflowInstanceKey(workflowInstanceKey);
@@ -111,14 +111,6 @@ public class SubscriptionCommandSender {
     return sendSubscriptionCommand(subscriptionPartitionId, openMessageSubscriptionCommand);
   }
 
-  private int getSubscriptionPartitionId(final DirectBuffer correlationKey) {
-    if (partitionIds == null) {
-      throw new IllegalStateException(""no partition ids available"");
-    }
-
-    return SubscriptionUtil.getSubscriptionPartitionId(correlationKey, partitionIds.size());
-  }
-
   public boolean openWorkflowInstanceSubscription(
       final long workflowInstanceKey,
       final long elementInstanceKey,
diff --git a/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCatchElementTest.java b/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCatchElementTest.java
index 4baed4f..838c9ca 100644
--- a/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCatchElementTest.java
+++ b/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCatchElementTest.java
@@ -36,7 +36,6 @@ import io.zeebe.model.bpmn.Bpmn;
 import io.zeebe.model.bpmn.BpmnModelInstance;
 import io.zeebe.protocol.clientapi.RecordType;
 import io.zeebe.protocol.clientapi.ValueType;
-import io.zeebe.protocol.impl.SubscriptionUtil;
 import io.zeebe.protocol.intent.DeploymentIntent;
 import io.zeebe.protocol.intent.MessageSubscriptionIntent;
 import io.zeebe.protocol.intent.WorkflowInstanceIntent;
@@ -44,7 +43,6 @@ import io.zeebe.protocol.intent.WorkflowInstanceSubscriptionIntent;
 import io.zeebe.test.broker.protocol.clientapi.ClientApiRule;
 import io.zeebe.test.broker.protocol.clientapi.PartitionTestClient;
 import io.zeebe.test.util.record.RecordingExporter;
-import io.zeebe.util.buffer.BufferUtil;
 import java.util.List;
 import java.util.stream.Collectors;
 import org.agrona.DirectBuffer;
@@ -171,39 +169,6 @@ public class MessageCatchElementTest {
   }
 
   @Test
-  public void shouldOpenMessageSubscriptionsOnSamePartition() {
-    // given
-    final List<Integer> partitionIds = apiRule.getPartitionIds();
-
-    final String correlationKey = ""order-123"";
-
-    final PartitionTestClient workflowPartition = apiRule.partitionClient(partitionIds.get(0));
-    final PartitionTestClient subscriptionPartition =
-        apiRule.partitionClient(getPartitionId(correlationKey));
-
-    testClient.deploy(CATCH_EVENT_WORKFLOW);
-
-    // when
-    final long workflowInstanceKey1 =
-        workflowPartition.createWorkflowInstance(PROCESS_ID, asMsgPack(""orderId"", correlationKey));
-
-    final long workflowInstanceKey2 =
-        workflowPartition.createWorkflowInstance(PROCESS_ID, asMsgPack(""orderId"", correlationKey));
-
-    // then
-    final List<Record<MessageSubscriptionRecordValue>> subscriptions =
-        subscriptionPartition
-            .receiveMessageSubscriptions()
-            .withIntent(MessageSubscriptionIntent.OPENED)
-            .limit(2)
-            .collect(Collectors.toList());
-
-    assertThat(subscriptions)
-        .extracting(s -> s.getValue().getWorkflowInstanceKey())
-        .contains(workflowInstanceKey1, workflowInstanceKey2);
-  }
-
-  @Test
   public void shouldOpenWorkflowInstanceSubscription() {
     final long workflowInstanceKey =
         testClient.createWorkflowInstance(PROCESS_ID, asMsgPack(""orderId"", ""order-123""));
@@ -352,10 +317,4 @@ public class MessageCatchElementTest {
                 .exists())
         .isTrue();
   }
-
-  private int getPartitionId(final String correlationKey) {
-    final List<Integer> partitionIds = apiRule.getPartitionIds();
-    return SubscriptionUtil.getSubscriptionPartitionId(
-        BufferUtil.wrapString(correlationKey), partitionIds.size());
-  }
 }
diff --git a/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCorrelationMultiplePartitionsTest.java b/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCorrelationMultiplePartitionsTest.java
new file mode 100644
index 0000000..cf8261a
--- /dev/null
+++ b/broker-core/src/test/java/io/zeebe/broker/workflow/message/MessageCorrelationMultiplePartitionsTest.java
@@ -0,0 +1,134 @@
+/*
+ * Zeebe Broker Core
+ * Copyright  2017 camunda services GmbH (info@camunda.com)
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+package io.zeebe.broker.workflow.message;
+
+import static io.zeebe.broker.test.EmbeddedBrokerConfigurator.setPartitionCount;
+import static io.zeebe.test.util.MsgPackUtil.asMsgPack;
+import static org.assertj.core.api.Assertions.assertThat;
+import static org.assertj.core.api.Assertions.tuple;
+
+import io.zeebe.broker.test.EmbeddedBrokerRule;
+import io.zeebe.model.bpmn.Bpmn;
+import io.zeebe.model.bpmn.BpmnModelInstance;
+import io.zeebe.protocol.impl.SubscriptionUtil;
+import io.zeebe.protocol.intent.MessageSubscriptionIntent;
+import io.zeebe.protocol.intent.WorkflowInstanceIntent;
+import io.zeebe.test.broker.protocol.clientapi.ClientApiRule;
+import io.zeebe.test.broker.protocol.clientapi.PartitionTestClient;
+import io.zeebe.test.util.record.RecordingExporter;
+import io.zeebe.util.buffer.BufferUtil;
+import java.util.List;
+import java.util.stream.IntStream;
+import org.junit.Before;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.RuleChain;
+
+public class MessageCorrelationMultiplePartitionsTest {
+
+  private static final String CORRELATION_KEY_PARTITION_0 = ""item-2"";
+  private static final String CORRELATION_KEY_PARTITION_1 = ""item-1"";
+  private static final String CORRELATION_KEY_PARTITION_2 = ""item-0"";
+
+  private static final String PROCESS_ID = ""process"";
+
+  private static final BpmnModelInstance WORKFLOW =
+      Bpmn.createExecutableProcess(PROCESS_ID)
+          .startEvent()
+          .intermediateCatchEvent(""receive-message"")
+          .message(m -> m.name(""message"").zeebeCorrelationKey(""$.key""))
+          .endEvent(""end"")
+          .done();
+
+  public EmbeddedBrokerRule brokerRule = new EmbeddedBrokerRule(setPartitionCount(3));
+
+  public ClientApiRule apiRule = new ClientApiRule(brokerRule::getClientAddress);
+
+  @Rule public RuleChain ruleChain = RuleChain.outerRule(brokerRule).around(apiRule);
+
+  private PartitionTestClient testClient;
+
+  @Before
+  public void init() {
+    assertThat(getPartitionId(CORRELATION_KEY_PARTITION_0)).isEqualTo(0);
+    assertThat(getPartitionId(CORRELATION_KEY_PARTITION_1)).isEqualTo(1);
+    assertThat(getPartitionId(CORRELATION_KEY_PARTITION_2)).isEqualTo(2);
+
+    testClient = apiRule.partitionClient();
+
+    testClient.deploy(WORKFLOW);
+  }
+
+  @Test
+  public void shouldOpenMessageSubscriptionsOnDifferentPartitions() {
+    // when
+    IntStream.range(0, 10)
+        .forEach(
+            i -> {
+              testClient.createWorkflowInstance(
+                  PROCESS_ID, asMsgPack(""key"", CORRELATION_KEY_PARTITION_0));
+              testClient.createWorkflowInstance(
+                  PROCESS_ID, asMsgPack(""key"", CORRELATION_KEY_PARTITION_1));
+              testClient.createWorkflowInstance(
+                  PROCESS_ID, asMsgPack(""key"", CORRELATION_KEY_PARTITION_2));
+            });
+
+    // then
+    assertThat(
+            RecordingExporter.messageSubscriptionRecords(MessageSubscriptionIntent.OPENED)
+                .limit(30))
+        .extracting(r -> tuple(r.getMetadata().getPartitionId(), r.getValue().getCorrelationKey()))
+        .containsOnly(
+            tuple(0, CORRELATION_KEY_PARTITION_0),
+            tuple(1, CORRELATION_KEY_PARTITION_1),
+            tuple(2, CORRELATION_KEY_PARTITION_2));
+  }
+
+  @Test
+  public void shouldCorrelateMessageOnDifferentPartitions() {
+    // given
+    apiRule
+        .partitionClient(0)
+        .publishMessage(""message"", CORRELATION_KEY_PARTITION_0, asMsgPack(""p"", ""p0""));
+    apiRule
+        .partitionClient(1)
+        .publishMessage(""message"", CORRELATION_KEY_PARTITION_1, asMsgPack(""p"", ""p1""));
+    apiRule
+        .partitionClient(2)
+        .publishMessage(""message"", CORRELATION_KEY_PARTITION_2, asMsgPack(""p"", ""p2""));
+
+    // when
+    testClient.createWorkflowInstance(PROCESS_ID, asMsgPack(""key"", CORRELATION_KEY_PARTITION_0));
+    testClient.createWorkflowInstance(PROCESS_ID, asMsgPack(""key"", CORRELATION_KEY_PARTITION_1));
+    testClient.createWorkflowInstance(PROCESS_ID, asMsgPack(""key"", CORRELATION_KEY_PARTITION_2));
+
+    // then
+    assertThat(
+            RecordingExporter.workflowInstanceRecords(WorkflowInstanceIntent.END_EVENT_OCCURRED)
+                .withElementId(""end"")
+                .limit(3))
+        .extracting(r -> r.getValue().getPayloadAsMap().get(""p""))
+        .contains(""p0"", ""p1"", ""p2"");
+  }
+
+  private int getPartitionId(final String correlationKey) {
+    final List<Integer> partitionIds = apiRule.getPartitionIds();
+    return SubscriptionUtil.getSubscriptionPartitionId(
+        BufferUtil.wrapString(correlationKey), partitionIds.size());
+  }
+}
diff --git a/protocol-test-util/src/main/java/io/zeebe/test/broker/protocol/clientapi/PartitionTestClient.java b/protocol-test-util/src/main/java/io/zeebe/test/broker/protocol/clientapi/PartitionTestClient.java
index dac11a2..e2b8397 100644
--- a/protocol-test-util/src/main/java/io/zeebe/test/broker/protocol/clientapi/PartitionTestClient.java
+++ b/protocol-test-util/src/main/java/io/zeebe/test/broker/protocol/clientapi/PartitionTestClient.java
@@ -329,6 +329,7 @@ public class PartitionTestClient {
       final String messageName, final String correlationKey, final byte[] payload, final long ttl) {
     return apiRule
         .createCmdRequest()
+        .partitionId(partitionId)
         .type(ValueType.MESSAGE, MessageIntent.PUBLISH)
         .command()
         .put(""name"", messageName)
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerReprocessingTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerReprocessingTest.java
index 9a122d9..b7db67e 100644
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerReprocessingTest.java
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerReprocessingTest.java
@@ -619,14 +619,9 @@ public class BrokerReprocessingTest {
   }
 
   @Test
-  public void shouldCorrelateMessageAfterRestartIfEnteredBeforeA() throws Exception {
+  public void shouldCorrelateMessageAfterRestartIfEnteredBefore() throws Exception {
     // given
-    clientRule
-        .getWorkflowClient()
-        .newDeployCommand()
-        .addWorkflowModel(WORKFLOW_MESSAGE, ""message.bpmn"")
-        .send()
-        .join();
+    deploy(WORKFLOW_MESSAGE, ""message.bpmn"");
 
     final long workflowInstanceKey =
         startWorkflowInstance(PROCESS_ID, singletonMap(""orderId"", ""order-123""))
@@ -658,12 +653,7 @@ public class BrokerReprocessingTest {
   @Test
   public void shouldCorrelateMessageAfterRestartIfPublishedBefore() throws Exception {
     // given
-    clientRule
-        .getWorkflowClient()
-        .newDeployCommand()
-        .addWorkflowModel(WORKFLOW_MESSAGE, ""message.bpmn"")
-        .send()
-        .join();
+    deploy(WORKFLOW_MESSAGE, ""message.bpmn"");
 
     publishMessage(""order canceled"", ""order-123"", singletonMap(""foo"", ""bar""));
     reprocessingTrigger.accept(this);
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/MessageCorrelationTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/MessageCorrelationTest.java
deleted file mode 100644
index c6a05fb..0000000
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/MessageCorrelationTest.java
+++ /dev/null
@@ -1,176 +0,0 @@
-/*
- * Copyright  2017 camunda services GmbH (info@camunda.com)
- *
- * Licensed under the Apache License, Version 2.0 (the ""License"");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an ""AS IS"" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package io.zeebe.broker.it.workflow;
-
-import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertElementActivated;
-import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertElementCompleted;
-import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertWorkflowInstanceCompleted;
-import static org.assertj.core.api.Assertions.assertThat;
-import static org.assertj.core.api.Assertions.entry;
-
-import io.zeebe.broker.it.GrpcClientRule;
-import io.zeebe.broker.test.EmbeddedBrokerRule;
-import io.zeebe.client.api.events.DeploymentEvent;
-import io.zeebe.model.bpmn.Bpmn;
-import io.zeebe.model.bpmn.BpmnModelInstance;
-import java.util.Collections;
-import org.junit.Before;
-import org.junit.Rule;
-import org.junit.Test;
-import org.junit.rules.RuleChain;
-import org.junit.runner.RunWith;
-import org.junit.runners.Parameterized;
-import org.junit.runners.Parameterized.Parameter;
-import org.junit.runners.Parameterized.Parameters;
-
-@RunWith(Parameterized.class)
-public class MessageCorrelationTest {
-
-  public EmbeddedBrokerRule brokerRule = new EmbeddedBrokerRule();
-  public GrpcClientRule clientRule = new GrpcClientRule(brokerRule);
-
-  @Rule public RuleChain ruleChain = RuleChain.outerRule(brokerRule).around(clientRule);
-
-  private static final BpmnModelInstance CATCH_EVENT_WORKFLOW =
-      Bpmn.createExecutableProcess(""wf"")
-          .startEvent()
-          .intermediateCatchEvent(""receive-message"")
-          .message(m -> m.name(""order canceled"").zeebeCorrelationKey(""$.orderId""))
-          .sequenceFlowId(""to-end"")
-          .endEvent()
-          .done();
-
-  private static final BpmnModelInstance RECEIVE_TASK_WORKFLOW =
-      Bpmn.createExecutableProcess(""wf"")
-          .startEvent()
-          .receiveTask(""receive-message"")
-          .message(m -> m.name(""order canceled"").zeebeCorrelationKey(""$.orderId""))
-          .sequenceFlowId(""to-end"")
-          .endEvent()
-          .done();
-
-  @Parameter(0)
-  public String elementType;
-
-  @Parameter(1)
-  public BpmnModelInstance workflow;
-
-  @Parameters(name = ""{0}"")
-  public static final Object[][] parameters() {
-    return new Object[][] {
-      {""intermediate message catch event"", CATCH_EVENT_WORKFLOW},
-      {""receive task"", RECEIVE_TASK_WORKFLOW}
-    };
-  }
-
-  @Before
-  public void init() {
-    final DeploymentEvent deploymentEvent =
-        clientRule
-            .getWorkflowClient()
-            .newDeployCommand()
-            .addWorkflowModel(workflow, ""wf.bpmn"")
-            .send()
-            .join();
-
-    clientRule.waitUntilDeploymentIsDone(deploymentEvent.getKey());
-  }
-
-  @Test
-  public void shouldCorrelateMessageIfEnteredBefore() {
-    // given
-    clientRule
-        .getWorkflowClient()
-        .newCreateInstanceCommand()
-        .bpmnProcessId(""wf"")
-        .latestVersion()
-        .payload(""{\""orderId\"":\""order-123\""}"")
-        .send()
-        .join();
-
-    assertElementActivated(""receive-message"");
-
-    // when
-    clientRule
-        .getWorkflowClient()
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .send()
-        .join();
-
-    // then
-    assertWorkflowInstanceCompleted(""wf"");
-  }
-
-  @Test
-  public void shouldCorrelateMessageIfPublishedBefore() {
-    // given
-    clientRule
-        .getWorkflowClient()
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .send()
-        .join();
-
-    // when
-    clientRule
-        .getWorkflowClient()
-        .newCreateInstanceCommand()
-        .bpmnProcessId(""wf"")
-        .latestVersion()
-        .payload(""{\""orderId\"":\""order-123\""}"")
-        .send()
-        .join();
-
-    // then
-    assertWorkflowInstanceCompleted(""wf"");
-  }
-
-  @Test
-  public void shouldCorrelateMessageAndMergePayload() {
-    // given
-    clientRule
-        .getWorkflowClient()
-        .newCreateInstanceCommand()
-        .bpmnProcessId(""wf"")
-        .latestVersion()
-        .payload(""{\""orderId\"":\""order-123\""}"")
-        .send()
-        .join();
-
-    // when
-    clientRule
-        .getWorkflowClient()
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .payload(Collections.singletonMap(""foo"", ""bar""))
-        .send()
-        .join();
-
-    // then
-    assertWorkflowInstanceCompleted(""wf"");
-
-    assertElementCompleted(
-        ""wf"",
-        ""receive-message"",
-        (catchEventOccurredEvent) ->
-            assertThat(catchEventOccurredEvent.getPayloadAsMap())
-                .containsExactly(entry(""orderId"", ""order-123""), entry(""foo"", ""bar"")));
-  }
-}
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/PublishMessageTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/PublishMessageTest.java
deleted file mode 100644
index 7845eec..0000000
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/PublishMessageTest.java
+++ /dev/null
@@ -1,234 +0,0 @@
-/*
- * Copyright  2017 camunda services GmbH (info@camunda.com)
- *
- * Licensed under the Apache License, Version 2.0 (the ""License"");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an ""AS IS"" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package io.zeebe.broker.it.workflow;
-
-import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertElementActivated;
-import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertElementCompleted;
-import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertWorkflowInstanceCompleted;
-import static io.zeebe.broker.test.EmbeddedBrokerConfigurator.setPartitionCount;
-import static org.assertj.core.api.Assertions.assertThat;
-import static org.assertj.core.api.Assertions.assertThatThrownBy;
-import static org.assertj.core.api.Assertions.entry;
-
-import io.zeebe.broker.it.GrpcClientRule;
-import io.zeebe.broker.test.EmbeddedBrokerRule;
-import io.zeebe.client.api.ZeebeFuture;
-import io.zeebe.client.api.clients.WorkflowClient;
-import io.zeebe.client.api.events.DeploymentEvent;
-import io.zeebe.client.api.events.WorkflowInstanceEvent;
-import io.zeebe.client.cmd.ClientException;
-import io.zeebe.model.bpmn.Bpmn;
-import io.zeebe.model.bpmn.BpmnModelInstance;
-import java.time.Duration;
-import java.util.Collections;
-import org.junit.Before;
-import org.junit.Rule;
-import org.junit.Test;
-import org.junit.rules.RuleChain;
-
-public class PublishMessageTest {
-
-  private static final BpmnModelInstance WORKFLOW =
-      Bpmn.createExecutableProcess(""wf"")
-          .startEvent()
-          .intermediateCatchEvent(""catch-event"")
-          .message(c -> c.name(""order canceled"").zeebeCorrelationKey(""$.orderId""))
-          .endEvent()
-          .done();
-  public EmbeddedBrokerRule brokerRule = new EmbeddedBrokerRule(setPartitionCount(3));
-  public GrpcClientRule clientRule = new GrpcClientRule(brokerRule);
-
-  @Rule public RuleChain ruleChain = RuleChain.outerRule(brokerRule).around(clientRule);
-
-  private WorkflowClient workflowClient;
-
-  @Before
-  public void init() {
-
-    workflowClient = clientRule.getClient().workflowClient();
-
-    final DeploymentEvent deploymentEvent =
-        workflowClient.newDeployCommand().addWorkflowModel(WORKFLOW, ""wf.bpmn"").send().join();
-
-    clientRule.waitUntilDeploymentIsDone(deploymentEvent.getKey());
-  }
-
-  @Test
-  public void shouldCorrelateMessageToAllSubscriptions() {
-    // given
-    final WorkflowInstanceEvent wf =
-        workflowClient
-            .newCreateInstanceCommand()
-            .bpmnProcessId(""wf"")
-            .latestVersion()
-            .payload(""{\""orderId\"":\""order-123\""}"")
-            .send()
-            .join();
-
-    final WorkflowInstanceEvent wf2 =
-        workflowClient
-            .newCreateInstanceCommand()
-            .bpmnProcessId(""wf"")
-            .latestVersion()
-            .payload(""{\""orderId\"":\""order-123\""}"")
-            .send()
-            .join();
-
-    // when
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .send()
-        .join();
-
-    // then
-    assertWorkflowInstanceCompleted(""wf"", wf.getWorkflowInstanceKey());
-    assertWorkflowInstanceCompleted(""wf"", wf2.getWorkflowInstanceKey());
-  }
-
-  @Test
-  public void shouldCorrelateMessageWithZeroTTL() {
-    // given
-    workflowClient
-        .newCreateInstanceCommand()
-        .bpmnProcessId(""wf"")
-        .latestVersion()
-        .payload(""{\""orderId\"":\""order-123\""}"")
-        .send()
-        .join();
-
-    assertElementActivated(""catch-event"");
-
-    // when
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .timeToLive(Duration.ZERO)
-        .send()
-        .join();
-
-    // then
-    assertElementCompleted(""wf"", ""catch-event"");
-  }
-
-  @Test
-  public void shouldNotCorrelateMessageAfterTTL() {
-    // given
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .timeToLive(Duration.ZERO)
-        .payload(Collections.singletonMap(""msg"", ""failure""))
-        .send()
-        .join();
-
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .timeToLive(Duration.ofMinutes(1))
-        .payload(Collections.singletonMap(""msg"", ""expected""))
-        .send()
-        .join();
-
-    // when
-    workflowClient
-        .newCreateInstanceCommand()
-        .bpmnProcessId(""wf"")
-        .latestVersion()
-        .payload(""{\""orderId\"":\""order-123\""}"")
-        .send()
-        .join();
-
-    // then
-
-    assertElementCompleted(
-        ""wf"",
-        ""catch-event"",
-        (catchEventOccurred) ->
-            assertThat(catchEventOccurred.getPayloadAsMap()).contains(entry(""msg"", ""expected"")));
-  }
-
-  @Test
-  public void shouldCorrelateMessageOnDifferentPartitions() {
-    // given
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .send()
-        .join();
-
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-124"")
-        .send()
-        .join();
-
-    // when
-    final WorkflowInstanceEvent wf =
-        workflowClient
-            .newCreateInstanceCommand()
-            .bpmnProcessId(""wf"")
-            .latestVersion()
-            .payload(""{\""orderId\"":\""order-123\""}"")
-            .send()
-            .join();
-
-    final WorkflowInstanceEvent wf2 =
-        workflowClient
-            .newCreateInstanceCommand()
-            .bpmnProcessId(""wf"")
-            .latestVersion()
-            .payload(""{\""orderId\"":\""order-124\""}"")
-            .send()
-            .join();
-
-    // then
-    assertWorkflowInstanceCompleted(""wf"", wf.getWorkflowInstanceKey());
-    assertWorkflowInstanceCompleted(""wf"", wf2.getWorkflowInstanceKey());
-  }
-
-  @Test
-  public void shouldRejectMessageWithSameId() {
-    // given
-    workflowClient
-        .newPublishMessageCommand()
-        .messageName(""order canceled"")
-        .correlationKey(""order-123"")
-        .messageId(""foo"")
-        .send()
-        .join();
-
-    // when
-    final ZeebeFuture<Void> future =
-        workflowClient
-            .newPublishMessageCommand()
-            .messageName(""order canceled"")
-            .correlationKey(""order-123"")
-            .messageId(""foo"")
-            .send();
-
-    // then
-    assertThatThrownBy(future::join)
-        .isInstanceOf(ClientException.class)
-        .hasMessageContaining(""message with id 'foo' is already published"");
-  }
-}
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/message/MessageCorrelationMultiplePartitionsTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/message/MessageCorrelationMultiplePartitionsTest.java
new file mode 100644
index 0000000..0e37c95
--- /dev/null
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/message/MessageCorrelationMultiplePartitionsTest.java
@@ -0,0 +1,196 @@
+/*
+ * Copyright  2017 camunda services GmbH (info@camunda.com)
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package io.zeebe.broker.it.workflow.message;
+
+import static io.zeebe.broker.test.EmbeddedBrokerConfigurator.setPartitionCount;
+import static org.assertj.core.api.Assertions.assertThat;
+import static org.assertj.core.api.Assertions.tuple;
+
+import io.zeebe.broker.it.GrpcClientRule;
+import io.zeebe.broker.test.EmbeddedBrokerRule;
+import io.zeebe.client.api.events.DeploymentEvent;
+import io.zeebe.model.bpmn.Bpmn;
+import io.zeebe.model.bpmn.BpmnModelInstance;
+import io.zeebe.protocol.intent.MessageIntent;
+import io.zeebe.protocol.intent.MessageSubscriptionIntent;
+import io.zeebe.protocol.intent.WorkflowInstanceIntent;
+import io.zeebe.test.util.record.RecordingExporter;
+import java.util.Collections;
+import java.util.stream.IntStream;
+import org.junit.Before;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.RuleChain;
+
+public class MessageCorrelationMultiplePartitionsTest {
+
+  private static final String CORRELATION_KEY_PARTITION_0 = ""item-2"";
+  private static final String CORRELATION_KEY_PARTITION_1 = ""item-1"";
+  private static final String CORRELATION_KEY_PARTITION_2 = ""item-0"";
+
+  private static final String PROCESS_ID = ""process"";
+
+  public EmbeddedBrokerRule brokerRule = new EmbeddedBrokerRule(setPartitionCount(3));
+  public GrpcClientRule clientRule = new GrpcClientRule(brokerRule);
+
+  @Rule public RuleChain ruleChain = RuleChain.outerRule(brokerRule).around(clientRule);
+
+  private static final BpmnModelInstance WORKFLOW =
+      Bpmn.createExecutableProcess(PROCESS_ID)
+          .startEvent()
+          .intermediateCatchEvent()
+          .message(m -> m.name(""message"").zeebeCorrelationKey(""$.key""))
+          .endEvent(""end"")
+          .done();
+
+  @Before
+  public void init() {
+    final DeploymentEvent deploymentEvent =
+        clientRule
+            .getWorkflowClient()
+            .newDeployCommand()
+            .addWorkflowModel(WORKFLOW, ""wf.bpmn"")
+            .send()
+            .join();
+
+    clientRule.waitUntilDeploymentIsDone(deploymentEvent.getKey());
+  }
+
+  @Test
+  public void shouldOpenMessageSubscriptionsOnDifferentPartitions() {
+    // when
+    IntStream.range(0, 10)
+        .forEach(
+            i -> {
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_0));
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_1));
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_2));
+            });
+
+    // then
+    assertThat(
+            RecordingExporter.messageSubscriptionRecords(MessageSubscriptionIntent.OPENED)
+                .limit(30))
+        .extracting(r -> tuple(r.getMetadata().getPartitionId(), r.getValue().getCorrelationKey()))
+        .containsOnly(
+            tuple(0, CORRELATION_KEY_PARTITION_0),
+            tuple(1, CORRELATION_KEY_PARTITION_1),
+            tuple(2, CORRELATION_KEY_PARTITION_2));
+  }
+
+  @Test
+  public void shouldPublishMessageOnDifferentPartitions() {
+    // when
+    IntStream.range(0, 10)
+        .forEach(
+            i -> {
+              publishMessage(CORRELATION_KEY_PARTITION_0, Collections.singletonMap(""p"", ""p0""));
+              publishMessage(CORRELATION_KEY_PARTITION_1, Collections.singletonMap(""p"", ""p1""));
+              publishMessage(CORRELATION_KEY_PARTITION_2, Collections.singletonMap(""p"", ""p2""));
+            });
+
+    // then
+    assertThat(RecordingExporter.messageRecords(MessageIntent.PUBLISHED).limit(30))
+        .extracting(r -> tuple(r.getMetadata().getPartitionId(), r.getValue().getCorrelationKey()))
+        .containsOnly(
+            tuple(0, CORRELATION_KEY_PARTITION_0),
+            tuple(1, CORRELATION_KEY_PARTITION_1),
+            tuple(2, CORRELATION_KEY_PARTITION_2));
+  }
+
+  @Test
+  public void shouldCorrelateMessageOnDifferentPartitions() {
+    // given
+    publishMessage(CORRELATION_KEY_PARTITION_0, Collections.singletonMap(""p"", ""p0""));
+    publishMessage(CORRELATION_KEY_PARTITION_1, Collections.singletonMap(""p"", ""p1""));
+    publishMessage(CORRELATION_KEY_PARTITION_2, Collections.singletonMap(""p"", ""p2""));
+
+    // when
+    createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_0));
+    createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_1));
+    createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_2));
+
+    // then
+    assertThat(
+            RecordingExporter.workflowInstanceRecords(WorkflowInstanceIntent.END_EVENT_OCCURRED)
+                .withElementId(""end"")
+                .limit(3))
+        .extracting(r -> r.getValue().getPayloadAsMap().get(""p""))
+        .contains(""p0"", ""p1"", ""p2"");
+  }
+
+  @Test
+  public void shouldOpenMessageSubscriptionsOnSamePartitionsAfterRestart() {
+    // given
+    IntStream.range(0, 5)
+        .forEach(
+            i -> {
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_0));
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_1));
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_2));
+            });
+
+    assertThat(
+            RecordingExporter.messageSubscriptionRecords(MessageSubscriptionIntent.OPENED)
+                .limit(15)
+                .exists())
+        .isTrue();
+
+    // when
+    brokerRule.stopBroker();
+    brokerRule.startBroker();
+
+    IntStream.range(0, 5)
+        .forEach(
+            i -> {
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_0));
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_1));
+              createWorkflowInstance(Collections.singletonMap(""key"", CORRELATION_KEY_PARTITION_2));
+            });
+
+    // then
+    assertThat(
+            RecordingExporter.messageSubscriptionRecords(MessageSubscriptionIntent.OPENED)
+                .limit(30))
+        .extracting(r -> tuple(r.getMetadata().getPartitionId(), r.getValue().getCorrelationKey()))
+        .containsOnly(
+            tuple(0, CORRELATION_KEY_PARTITION_0),
+            tuple(1, CORRELATION_KEY_PARTITION_1),
+            tuple(2, CORRELATION_KEY_PARTITION_2));
+  }
+
+  private void createWorkflowInstance(Object payload) {
+    clientRule
+        .getWorkflowClient()
+        .newCreateInstanceCommand()
+        .bpmnProcessId(PROCESS_ID)
+        .latestVersion()
+        .payload(payload)
+        .send()
+        .join();
+  }
+
+  private void publishMessage(String correlationKey, Object payload) {
+    clientRule
+        .getWorkflowClient()
+        .newPublishMessageCommand()
+        .messageName(""message"")
+        .correlationKey(correlationKey)
+        .payload(payload)
+        .send()
+        .join();
+  }
+}
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/message/MessageCorrelationTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/message/MessageCorrelationTest.java
new file mode 100644
index 0000000..3b08572
--- /dev/null
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/workflow/message/MessageCorrelationTest.java
@@ -0,0 +1,198 @@
+/*
+ * Copyright  2017 camunda services GmbH (info@camunda.com)
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package io.zeebe.broker.it.workflow.message;
+
+import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertElementActivated;
+import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertElementCompleted;
+import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertWorkflowInstanceCompleted;
+import static org.assertj.core.api.Assertions.assertThat;
+import static org.assertj.core.api.Assertions.assertThatThrownBy;
+import static org.assertj.core.api.Assertions.entry;
+
+import io.zeebe.broker.it.GrpcClientRule;
+import io.zeebe.broker.test.EmbeddedBrokerRule;
+import io.zeebe.client.api.ZeebeFuture;
+import io.zeebe.client.api.events.DeploymentEvent;
+import io.zeebe.client.cmd.ClientException;
+import io.zeebe.model.bpmn.Bpmn;
+import io.zeebe.model.bpmn.BpmnModelInstance;
+import java.time.Duration;
+import java.util.Collections;
+import org.junit.Before;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.RuleChain;
+
+public class MessageCorrelationTest {
+
+  private static final String PROCESS_ID = ""process"";
+
+  public EmbeddedBrokerRule brokerRule = new EmbeddedBrokerRule();
+  public GrpcClientRule clientRule = new GrpcClientRule(brokerRule);
+
+  @Rule public RuleChain ruleChain = RuleChain.outerRule(brokerRule).around(clientRule);
+
+  private static final BpmnModelInstance WORKFLOW =
+      Bpmn.createExecutableProcess(PROCESS_ID)
+          .startEvent()
+          .intermediateCatchEvent(""catch-event"")
+          .message(c -> c.name(""order canceled"").zeebeCorrelationKey(""$.orderId""))
+          .endEvent()
+          .done();
+
+  @Before
+  public void init() {
+    final DeploymentEvent deploymentEvent =
+        clientRule
+            .getWorkflowClient()
+            .newDeployCommand()
+            .addWorkflowModel(WORKFLOW, ""wf.bpmn"")
+            .send()
+            .join();
+
+    clientRule.waitUntilDeploymentIsDone(deploymentEvent.getKey());
+  }
+
+  @Test
+  public void shouldCorrelateMessage() {
+    // given
+    clientRule
+        .getWorkflowClient()
+        .newCreateInstanceCommand()
+        .bpmnProcessId(PROCESS_ID)
+        .latestVersion()
+        .payload(Collections.singletonMap(""orderId"", ""order-123""))
+        .send()
+        .join();
+
+    // when
+    clientRule
+        .getWorkflowClient()
+        .newPublishMessageCommand()
+        .messageName(""order canceled"")
+        .correlationKey(""order-123"")
+        .payload(Collections.singletonMap(""foo"", ""bar""))
+        .send()
+        .join();
+
+    // then
+    assertWorkflowInstanceCompleted(PROCESS_ID);
+
+    assertElementCompleted(
+        PROCESS_ID,
+        ""catch-event"",
+        (catchEventOccurredEvent) ->
+            assertThat(catchEventOccurredEvent.getPayloadAsMap())
+                .containsExactly(entry(""orderId"", ""order-123""), entry(""foo"", ""bar"")));
+  }
+
+  @Test
+  public void shouldCorrelateMessageWithZeroTTL() {
+    // given
+    clientRule
+        .getWorkflowClient()
+        .newCreateInstanceCommand()
+        .bpmnProcessId(PROCESS_ID)
+        .latestVersion()
+        .payload(Collections.singletonMap(""orderId"", ""order-123""))
+        .send()
+        .join();
+
+    assertElementActivated(""catch-event"");
+
+    // when
+    clientRule
+        .getWorkflowClient()
+        .newPublishMessageCommand()
+        .messageName(""order canceled"")
+        .correlationKey(""order-123"")
+        .timeToLive(Duration.ZERO)
+        .send()
+        .join();
+
+    // then
+    assertElementCompleted(PROCESS_ID, ""catch-event"");
+  }
+
+  @Test
+  public void shouldNotCorrelateMessageAfterTTL() {
+    // given
+    clientRule
+        .getWorkflowClient()
+        .newPublishMessageCommand()
+        .messageName(""order canceled"")
+        .correlationKey(""order-123"")
+        .timeToLive(Duration.ZERO)
+        .payload(Collections.singletonMap(""msg"", ""failure""))
+        .send()
+        .join();
+
+    clientRule
+        .getWorkflowClient()
+        .newPublishMessageCommand()
+        .messageName(""order canceled"")
+        .correlationKey(""order-123"")
+        .timeToLive(Duration.ofMinutes(1))
+        .payload(Collections.singletonMap(""msg"", ""expected""))
+        .send()
+        .join();
+
+    // when
+    clientRule
+        .getWorkflowClient()
+        .newCreateInstanceCommand()
+        .bpmnProcessId(PROCESS_ID)
+        .latestVersion()
+        .payload(Collections.singletonMap(""orderId"", ""order-123""))
+        .send()
+        .join();
+
+    // then
+    assertElementCompleted(
+        PROCESS_ID,
+        ""catch-event"",
+        (catchEventOccurred) ->
+            assertThat(catchEventOccurred.getPayloadAsMap()).contains(entry(""msg"", ""expected"")));
+  }
+
+  @Test
+  public void shouldRejectMessageWithSameId() {
+    // given
+    clientRule
+        .getWorkflowClient()
+        .newPublishMessageCommand()
+        .messageName(""order canceled"")
+        .correlationKey(""order-123"")
+        .messageId(""foo"")
+        .send()
+        .join();
+
+    // when
+    final ZeebeFuture<Void> future =
+        clientRule
+            .getWorkflowClient()
+            .newPublishMessageCommand()
+            .messageName(""order canceled"")
+            .correlationKey(""order-123"")
+            .messageId(""foo"")
+            .send();
+
+    // then
+    assertThatThrownBy(future::join)
+        .isInstanceOf(ClientException.class)
+        .hasMessageContaining(""message with id 'foo' is already published"");
+  }
+}

diff --git a/.github/workflows/update-deps.yml b/.github/workflows/update-deps.yml
index 3a71e29..25f6f27 100644
--- a/.github/workflows/update-deps.yml
+++ b/.github/workflows/update-deps.yml
@@ -4,6 +4,11 @@ on:
     # run every 24 hours at midnight
     - cron: ""0 */24 * * *""
   workflow_dispatch:
+
+concurrency:
+  group: ${{ github.repository }}-${{ github.head_ref || github.sha }}-${{ github.workflow }}
+  cancel-in-progress: true
+
 jobs:
   generate_updates:
     runs-on: ubuntu-latest

diff --git a/src/output/grid.rs b/src/output/grid.rs
index 37f6c57..ce989e5 100644
--- a/src/output/grid.rs
+++ b/src/output/grid.rs
@@ -8,6 +8,8 @@ use crate::output::file_name::{Classify, Options as FileStyle};
 use crate::output::file_name::{EmbedHyperlinks, ShowIcons};
 use crate::theme::Theme;
 
+use super::file_name::QuoteStyle;
+
 #[derive(PartialEq, Eq, Debug, Copy, Clone)]
 pub struct Options {
     pub across: bool,
@@ -55,27 +57,34 @@ impl<'a> Render<'a> {
                 } else {
                     0
                 };
-
-            let space_filename_offset = if file.name.contains(' ') || file.name.contains('\'') {
-                2
-            } else {
-                0
+            let space_filename_offset = match self.file_style.quote_style {
+                QuoteStyle::QuoteSpaces if file.name.contains(' ') => 2,
+                QuoteStyle::NoQuotes => 0,
+                _ => 0, // Default case
             };
-
             let contents = filename.paint();
-            #[rustfmt::skip]
             let width = match (
                 filename.options.embed_hyperlinks,
                 filename.options.show_icons,
             ) {
-                ( EmbedHyperlinks::On, ShowIcons::Always(spacing) | ShowIcons::Automatic(spacing) )
-                    => filename.bare_width() + classification_width + 1 + (spacing as usize) + space_filename_offset,
-                ( EmbedHyperlinks::On, ShowIcons::Never )
-                    => filename.bare_width() + classification_width + space_filename_offset,
-                ( EmbedHyperlinks::Off, ShowIcons::Always(spacing) | ShowIcons::Automatic(spacing) )
-                    => filename.bare_width() + 1 + (spacing as usize) + space_filename_offset,
-                ( EmbedHyperlinks::Off, _ )
-                    => *contents.width(),
+                (
+                    EmbedHyperlinks::On,
+                    ShowIcons::Always(spacing) | ShowIcons::Automatic(spacing),
+                ) => {
+                    filename.bare_width()
+                        + classification_width
+                        + 1
+                        + (spacing as usize)
+                        + space_filename_offset
+                }
+                (EmbedHyperlinks::On, ShowIcons::Never) => {
+                    filename.bare_width() + classification_width + space_filename_offset
+                }
+                (
+                    EmbedHyperlinks::Off,
+                    ShowIcons::Always(spacing) | ShowIcons::Automatic(spacing),
+                ) => filename.bare_width() + 1 + (spacing as usize) + space_filename_offset,
+                (EmbedHyperlinks::Off, _) => *contents.width(),
             };
 
             grid.add(tg::Cell {
",3,"[""2d416be63eeec9e7fdb90a62c40c8ad8f0672efa"", ""c2300c94c6b7d1599387272b616e1d79e93723c7"", ""61eaa2d0cca9bd27d6c5f0a8f9b34200b77fdbb0""]","[""test"", ""cicd"", ""fix""]"
"support react@17 in peer deps

resolves #1478","diff --git a/packages/animated/package.json b/packages/animated/package.json
index 2249a2f..e35a1fd 100644
--- a/packages/animated/package.json
+++ b/packages/animated/package.json
@@ -33,6 +33,6 @@
     ""react-layout-effect"": ""^1.0.1""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8""
+    ""react"": ""^16.8.0  || ^17.0.0""
   }
 }
diff --git a/packages/core/package.json b/packages/core/package.json
index 584bbc2..c934253 100644
--- a/packages/core/package.json
+++ b/packages/core/package.json
@@ -36,7 +36,7 @@
     ""react-layout-effect"": ""^1.0.1""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8""
+    ""react"": ""^16.8.0  || ^17.0.0""
   },
   ""devDependencies"": {
     ""rafz"": ""^0.1.13""
diff --git a/packages/parallax/package.json b/packages/parallax/package.json
index 49f8391..5a181fe 100644
--- a/packages/parallax/package.json
+++ b/packages/parallax/package.json
@@ -31,6 +31,6 @@
     ""@react-spring/web"": ""~9.2.0-beta.0""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8""
+    ""react"": ""^16.8.0  || ^17.0.0""
   }
 }
diff --git a/packages/shared/package.json b/packages/shared/package.json
index 67d286c..12f7db3 100644
--- a/packages/shared/package.json
+++ b/packages/shared/package.json
@@ -33,6 +33,6 @@
     ""rafz"": ""^0.1.13""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8""
+    ""react"": ""^16.8.0  || ^17.0.0""
   }
 }
diff --git a/targets/konva/package.json b/targets/konva/package.json
index 17675ac..271d58c 100644
--- a/targets/konva/package.json
+++ b/targets/konva/package.json
@@ -34,7 +34,7 @@
   },
   ""peerDependencies"": {
     ""konva"": "">=2.6"",
-    ""react"": "">=16.8"",
+    ""react"": ""^16.8.0  || ^17.0.0"",
     ""react-konva"": "">=16.8""
   },
   ""devDependencies"": {
diff --git a/targets/native/package.json b/targets/native/package.json
index e97aa97..802a66c 100644
--- a/targets/native/package.json
+++ b/targets/native/package.json
@@ -33,7 +33,7 @@
     ""@react-spring/types"": ""~9.2.0-beta.0""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8"",
+    ""react"": ""^16.8.0  || ^17.0.0"",
     ""react-native"": "">=0.58""
   },
   ""devDependencies"": {
diff --git a/targets/web/package.json b/targets/web/package.json
index d74c25c..f7ac000 100644
--- a/targets/web/package.json
+++ b/targets/web/package.json
@@ -33,7 +33,7 @@
     ""@react-spring/types"": ""~9.2.0-beta.0""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8"",
+    ""react"": ""^16.8.0  || ^17.0.0"",
     ""react-dom"": "">=16.8""
   }
 }
diff --git a/targets/zdog/package.json b/targets/zdog/package.json
index aa57890..f65945a 100644
--- a/targets/zdog/package.json
+++ b/targets/zdog/package.json
@@ -33,7 +33,7 @@
     ""@react-spring/types"": ""~9.2.0-beta.0""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8"",
+    ""react"": ""^16.8.0  || ^17.0.0"",
     ""react-dom"": "">=16.8"",
     ""react-zdog"": "">=1.0"",
     ""zdog"": "">=1.0""
",1,"[""27169897c0e58bc4fbca724f290ad54fa39abec7""]","[""build""]"
"remove broken link

Fixes #1785","diff --git a/docs/content/Caching/Caching.md b/docs/content/Caching/Caching.md
index d873a52..9706dda 100644
--- a/docs/content/Caching/Caching.md
+++ b/docs/content/Caching/Caching.md
@@ -135,8 +135,9 @@ If nothing is found in the cache, the query is executed in the database and the 
 is returned as well as updating the cache.
 
 If an existing value is present in the cache and the `refreshKey` value for
-the query hasn't changed, the cached value will be returned. Otherwise, a
-[query renewal](#in-memory-cache-force-query-renewal) will be performed.
+the query hasn't changed, the cached value will be returned. Otherwise, a SQL query will be executed either against the pre-aggregations storage or the source database to populate the cache with the results and return them.
+
+
 
 ### Refresh Keys
 
",1,"[""c351088bce98594c740a39546ce3655c91554a5d""]","[""docs""]"
"group example | initialize threejs objects in defaultRef, to fix undefined type errors","diff --git a/src/build/arg_group.rs b/src/build/arg_group.rs
index 5201e97..e1b1991 100644
--- a/src/build/arg_group.rs
+++ b/src/build/arg_group.rs
@@ -43,7 +43,7 @@ use crate::util::{Id, Key};
 ///     .arg(""--minor         'auto increase minor'"")
 ///     .arg(""--patch         'auto increase patch'"")
 ///     .group(ArgGroup::with_name(""vers"")
-///          .args(&[""set-ver"", ""major"", ""minor"",""patch""])
+///          .args(&[""set-ver"", ""major"", ""minor"", ""patch""])
 ///          .required(true))
 ///     .try_get_matches_from(vec![""app"", ""--major"", ""--patch""]);
 /// // Because we used two args in the group it's an error

diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number
",2,"[""9849430b11b92ae58d94cfe4d0b06313c7eab550"", ""2561f4ade46fc9d59f289f328cc77733a6443697""]","[""docs"", ""fix""]"
remove unnecessary `parse_json` call in `ops.StructField` impl,"diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index cbddf8d..d5a0859 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -231,7 +231,7 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: fixed_arity(sa.func.regexp_substr, 3),
-        ops.RegexSearch: fixed_arity(lambda left, right: left.op('REGEXP')(right), 2),
+        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMillisecond: fixed_arity(
             lambda arg: sa.cast(
@@ -244,8 +244,7 @@ operation_registry.update(
             t.translate(op.arg), _TIMESTAMP_UNITS_TO_SCALE[op.unit]
         ),
         ops.StructField: lambda t, op: sa.cast(
-            sa.func.parse_json(sa.func.get(t.translate(op.arg), op.field)),
-            t.get_sqla_type(op.output_dtype),
+            sa.func.get(t.translate(op.arg), op.field), t.get_sqla_type(op.output_dtype)
         ),
         ops.NthValue: _nth_value,
     }
",1,"[""9e80231539aa307e607e2b82b35df9e09ede8385""]","[""refactor""]"
"improve test stability

* improve test stability by waiting until the message subscription is opened. Message subscriptions are opened outside of the context of the stream processor. Sometimes this may take a while.
* enable running the tests repeatably by fixing the engine rule | fixing deploying to kubernetes

Signed-off-by: Rajesh Rajendran <rjshrjndrn@gmail.com> | add `to_sql`

Co-authored-by: Gil Forsyth <gforsyth@users.noreply.github.com>","diff --git a/engine/src/test/java/io/zeebe/engine/processing/bpmn/subprocess/InterruptingEventSubprocessTest.java b/engine/src/test/java/io/zeebe/engine/processing/bpmn/subprocess/InterruptingEventSubprocessTest.java
index 0c539b9..ffaead1 100644
--- a/engine/src/test/java/io/zeebe/engine/processing/bpmn/subprocess/InterruptingEventSubprocessTest.java
+++ b/engine/src/test/java/io/zeebe/engine/processing/bpmn/subprocess/InterruptingEventSubprocessTest.java
@@ -334,22 +334,31 @@ public class InterruptingEventSubprocessTest {
             ""timer-event-subprocess"",
             s -> s.startEvent(""other-timer"").timerWithDuration(""P1D"").endEvent());
 
-    final long wfInstanceKey = createInstanceAndTriggerEvent(workflow(eventSubprocess));
+    final long wfInstanceKey = createInstanceAndWaitForTask(workflow(eventSubprocess));
+
+    RecordingExporter.messageSubscriptionRecords(MessageSubscriptionIntent.OPENED)
+        .withWorkflowInstanceKey(wfInstanceKey)
+        .withMessageName(""other-message"")
+        .await();
+
+    triggerEventSubprocess.accept(wfInstanceKey);
 
     // then
     assertThat(
-            RecordingExporter.messageSubscriptionRecords()
+            RecordingExporter.records()
+                .limitToWorkflowInstance(wfInstanceKey)
+                .messageSubscriptionRecords()
                 .withWorkflowInstanceKey(wfInstanceKey)
-                .withMessageName(""other-message"")
-                .limit(4))
+                .withMessageName(""other-message""))
         .extracting(Record::getIntent)
         .contains(MessageSubscriptionIntent.CLOSED);
 
     assertThat(
-            RecordingExporter.timerRecords()
+            RecordingExporter.records()
+                .limitToWorkflowInstance(wfInstanceKey)
+                .timerRecords()
                 .withWorkflowInstanceKey(wfInstanceKey)
-                .withHandlerNodeId(""other-timer"")
-                .limit(4))
+                .withHandlerNodeId(""other-timer""))
         .extracting(Record::getIntent)
         .contains(TimerIntent.CANCELED);
   }
diff --git a/engine/src/test/java/io/zeebe/engine/util/EngineRule.java b/engine/src/test/java/io/zeebe/engine/util/EngineRule.java
index 8576be5..50040f4 100644
--- a/engine/src/test/java/io/zeebe/engine/util/EngineRule.java
+++ b/engine/src/test/java/io/zeebe/engine/util/EngineRule.java
@@ -71,7 +71,7 @@ public final class EngineRule extends ExternalResource {
 
   private static final int PARTITION_ID = Protocol.DEPLOYMENT_PARTITION;
   private static final RecordingExporter RECORDING_EXPORTER = new RecordingExporter();
-  private StreamProcessorRule environmentRule;
+  private final StreamProcessorRule environmentRule;
   private final RecordingExporterTestWatcher recordingExporterTestWatcher =
       new RecordingExporterTestWatcher();
   private final int partitionCount;
@@ -80,7 +80,7 @@ public final class EngineRule extends ExternalResource {
 
   private final Int2ObjectHashMap<SubscriptionCommandMessageHandler> subscriptionHandlers =
       new Int2ObjectHashMap<>();
-  private final ExecutorService subscriptionHandlerExecutor = Executors.newSingleThreadExecutor();
+  private ExecutorService subscriptionHandlerExecutor;
 
   private EngineRule(final int partitionCount) {
     this(partitionCount, false);
@@ -115,6 +115,8 @@ public final class EngineRule extends ExternalResource {
 
   @Override
   protected void before() {
+    subscriptionHandlerExecutor = Executors.newSingleThreadExecutor();
+
     if (!explicitStart) {
       startProcessors();
     }
@@ -123,7 +125,6 @@ public final class EngineRule extends ExternalResource {
   @Override
   protected void after() {
     subscriptionHandlerExecutor.shutdown();
-    environmentRule = null;
     subscriptionHandlers.clear();
   }
 
diff --git a/engine/src/test/java/io/zeebe/engine/util/StreamProcessorRule.java b/engine/src/test/java/io/zeebe/engine/util/StreamProcessorRule.java
index 0f3da21..af6c50e 100755
--- a/engine/src/test/java/io/zeebe/engine/util/StreamProcessorRule.java
+++ b/engine/src/test/java/io/zeebe/engine/util/StreamProcessorRule.java
@@ -248,6 +248,7 @@ public final class StreamProcessorRule implements TestRule {
     @Override
     protected void after() {
       streams = null;
+      streamProcessingComposite = null;
     }
   }
 
diff --git a/test-util/src/main/java/io/zeebe/test/util/record/RecordStream.java b/test-util/src/main/java/io/zeebe/test/util/record/RecordStream.java
index 293df93..a3ede18 100644
--- a/test-util/src/main/java/io/zeebe/test/util/record/RecordStream.java
+++ b/test-util/src/main/java/io/zeebe/test/util/record/RecordStream.java
@@ -81,4 +81,9 @@ public final class RecordStream extends ExporterRecordStream<RecordValue, Record
     return new IncidentRecordStream(
         filter(r -> r.getValueType() == ValueType.INCIDENT).map(Record.class::cast));
   }
+
+  public MessageSubscriptionRecordStream messageSubscriptionRecords() {
+    return new MessageSubscriptionRecordStream(
+        filter(r -> r.getValueType() == ValueType.MESSAGE_SUBSCRIPTION).map(Record.class::cast));
+  }
 }

diff --git a/.github/workflows/frontend.yaml b/.github/workflows/frontend.yaml
index 7e42967..77e4abf 100644
--- a/.github/workflows/frontend.yaml
+++ b/.github/workflows/frontend.yaml
@@ -22,26 +22,22 @@ jobs:
           ${{ runner.OS }}-build-
           ${{ runner.OS }}-
 
+    - uses: azure/k8s-set-context@v1
+      with:
+        method: kubeconfig
+        kubeconfig: ${{ secrets.OSS_KUBECONFIG }} # Use content of kubeconfig in secret.
+      id: setcontext
     - name: Install
       run: npm install
 
-    - name: Build
-      run: npm run build:staging
-      env:
-        ENVIRONMENT: staging
-
-    - name: Deploy
-      env:
-        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
-        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
-        AWS_REGION: eu-central-1
-        AWS_S3_BUCKET_NAME: ${{ secrets.AWS_S3_BUCKET_NAME }}
+    - name: Build and deploy
       run: |
-        aws configure set default.s3.signature_version s3v4
-        aws --endpoint-url https://${{secrets.DOMAIN_NAME}}/frontend/ s3 cp \
-          --recursive \
-          --region ""$AWS_REGION"" \
-          public s3://$AWS_S3_BUCKET_NAME
+        cd frontend
+        bash build.sh
+        cp -arl public frontend
+        minio_pod=$(kubectl get po -n db -l app.kubernetes.io/name=minio -n db --output custom-columns=name:.metadata.name | tail -n+2)
+        kubectl -n db cp frontend $minio_pod:/data/
+        rm -rf frontend
 
     # - name: Debug Job
     #   if: ${{ failure() }}

diff --git a/docs/api/expressions/top_level.md b/docs/api/expressions/top_level.md
index efaffbd..34b529e 100644
--- a/docs/api/expressions/top_level.md
+++ b/docs/api/expressions/top_level.md
@@ -28,7 +28,7 @@ These methods and objects are available directly in the `ibis` module.
 ::: ibis.or_
 ::: ibis.param
 ::: ibis.show_sql
-::: ibis.sql
+::: ibis.to_sql
 ::: ibis.random
 ::: ibis.range_window
 ::: ibis.row_number
",3,"[""00be00f2dd0ba7e4bfa4f5dfb74135761f5f86ec"", ""3f2eec37f76c1ad9408e423e49fe5bfe3e17d943"", ""e2821a56c7d867b8b591f1777019843a2ffca797""]","[""test"", ""cicd"", ""docs""]"
"rename flags to valid names, fold VTypes into Flags | set name for topology module","diff --git a/package.json b/package.json
index faa6e93..9281604 100644
--- a/package.json
+++ b/package.json
@@ -105,7 +105,7 @@
     ""@picocss/pico"": ""^1.5.0"",
     ""@types/benchmark"": ""^2.1.1"",
     ""@types/canvas-confetti"": ""^1.4.2"",
-    ""@types/lodash"": ""^4.14.180"",
+    ""@types/lodash"": ""^4.14.181"",
     ""@types/node"": ""^17.0.23"",
     ""@types/virtual-dom"": ""^2.1.1"",
     ""@typescript-eslint/eslint-plugin"": ""^5.17.0"",
diff --git a/packages/million/createElement.ts b/packages/million/createElement.ts
index e900f97..cfea080 100644
--- a/packages/million/createElement.ts
+++ b/packages/million/createElement.ts
@@ -1,3 +1,4 @@
+import { resolveVNode } from './m';
 import {
   COLON_CHAR,
   DOMNode,
@@ -6,33 +7,29 @@ import {
   VElement,
   VEntity,
   VNode,
-  VTypes,
   XLINK_NS,
   XML_NS,
   X_CHAR,
 } from './types';
-import { resolveVNode } from './m';
 
 /**
  * Creates an Element from a VNode
  */
 export const createElement = (vnode?: VNode | VEntity | null, attachField = true): DOMNode => {
-  if (typeof vnode === 'object' && vnode?.type === VTypes.ENTITY) {
+  if (vnode === undefined || vnode === null) return document.createComment('');
+  if (typeof vnode === 'string') return document.createTextNode(vnode);
+  if (typeof vnode === 'object' && vnode?.flag === Flags.ENTITY) {
     if (vnode.el) return vnode.el;
     else return createElement(resolveVNode(vnode));
   }
-  if (vnode === undefined || vnode === null) return document.createComment('');
-  if (typeof vnode === 'string') return document.createTextNode(vnode);
-  const velement = <VElement>vnode;
 
-  // istanbul ignore next
-  const el = velement.props?.ns
-    ? <SVGElement>document.createElementNS(<string>velement.props?.ns, velement.tag)
-    : <HTMLElement>document.createElement(velement.tag);
+  const el = vnode.props?.ns
+    ? <SVGElement>document.createElementNS(<string>vnode.props?.ns, vnode.tag)
+    : <HTMLElement>document.createElement(vnode.tag);
 
-  if (velement.props) {
-    for (const propName in velement.props) {
-      const propValue = velement.props[propName];
+  if (vnode.props) {
+    for (const propName in vnode.props) {
+      const propValue = vnode.props[propName];
       if (propName.startsWith('on')) {
         const eventPropName = propName.slice(2).toLowerCase();
         el.addEventListener(eventPropName, <EventListener>propValue);
@@ -50,14 +47,12 @@ export const createElement = (vnode?: VNode | VEntity | null, attachField = true
     }
   }
 
-  if (velement.children) {
-    if (velement.flag === Flags.ONLY_TEXT_CHILDREN) {
-      el.textContent = Array.isArray(velement.children)
-        ? velement.children?.join('')
-        : velement.children;
+  if (vnode.children) {
+    if (vnode.flag === Flags.ELEMENT_TEXT_CHILDREN) {
+      el.textContent = Array.isArray(vnode.children) ? vnode.children?.join('') : vnode.children;
     } else {
-      for (let i = 0; i < velement.children.length; ++i) {
-        el.appendChild(createElement(velement.children[i], false));
+      for (let i = 0; i < vnode.children.length; ++i) {
+        el.appendChild(createElement(vnode.children[i], false));
       }
     }
   }
diff --git a/packages/million/drivers/useChildren.ts b/packages/million/drivers/useChildren.ts
index 6ce2dd9..26f0825 100644
--- a/packages/million/drivers/useChildren.ts
+++ b/packages/million/drivers/useChildren.ts
@@ -91,7 +91,7 @@ export const useChildren =
     // Flags allow for greater optimizability by reducing condition branches.
     // Generally, you should use a compiler to generate these flags, but
     // hand-writing them is also possible
-    if (!newVNodeChildren || newVNode.flag === Flags.NO_CHILDREN) {
+    if (!newVNodeChildren || newVNode.flag === Flags.ELEMENT_NO_CHILDREN) {
       if (!oldVNodeChildren) return finish(el);
 
       effects.push({
@@ -265,7 +265,7 @@ export const useChildren =
      *    d: 2, // <- check
      *  }
      */
-    if (newVNode.flag === Flags.ONLY_KEYED_CHILDREN) {
+    if (newVNode.flag === Flags.ELEMENT_KEYED_CHILDREN) {
       if (!el[NODE_OBJECT_POOL_FIELD]) el[NODE_OBJECT_POOL_FIELD] = new Map<string, DOMNode>();
 
       let oldHead = 0;
@@ -380,7 +380,7 @@ export const useChildren =
       return finish(el);
     }
 
-    if (newVNode.flag === Flags.ONLY_TEXT_CHILDREN) {
+    if (newVNode.flag === Flags.ELEMENT_TEXT_CHILDREN) {
       const oldString = Array.isArray(oldVNode?.children)
         ? oldVNode?.children.join('')
         : oldVNode?.children;
@@ -396,7 +396,7 @@ export const useChildren =
       return finish(el);
     }
 
-    if (newVNode.flag === undefined || newVNode.flag === Flags.ANY_CHILDREN) {
+    if (newVNode.flag === undefined || newVNode.flag === Flags.ELEMENT) {
       if (oldVNodeChildren && newVNodeChildren) {
         const commonLength = Math.min(oldVNodeChildren.length, newVNodeChildren.length);
 
diff --git a/packages/million/drivers/useNode.ts b/packages/million/drivers/useNode.ts
index 3b0d59e..fa78125 100644
--- a/packages/million/drivers/useNode.ts
+++ b/packages/million/drivers/useNode.ts
@@ -11,7 +11,6 @@ import {
   OLD_VNODE_FIELD,
   VEntity,
   VNode,
-  VTypes,
 } from '../types';
 
 /**
@@ -72,57 +71,55 @@ export const useNode = (drivers: any[]): any => {
         typeof resolvedNewVNode === 'object'
       ) {
         if (
-          resolvedNewVNode.flag === Flags.IGNORE_NODE ||
-          resolvedOldVNode.flag === Flags.IGNORE_NODE
+          resolvedNewVNode.flag === Flags.ELEMENT_IGNORE ||
+          resolvedOldVNode.flag === Flags.ELEMENT_IGNORE
         ) {
           return finish(el);
         }
-        if (resolvedOldVNode.type === VTypes.ELEMENT && resolvedNewVNode.type === VTypes.ELEMENT) {
-          if (
-            resolvedNewVNode.flag === Flags.REPLACE_NODE ||
-            resolvedOldVNode.flag === Flags.REPLACE_NODE
-          ) {
-            const newEl = createElement(newVNode);
-            el.replaceWith(newEl);
-            return finish(el);
-          }
+        if (
+          resolvedNewVNode.flag === Flags.ELEMENT_SKIP_DIFF ||
+          resolvedOldVNode.flag === Flags.ELEMENT_SKIP_DIFF
+        ) {
+          const newEl = createElement(newVNode);
+          el.replaceWith(newEl);
+          return finish(el);
+        }
 
-          // We handle two cases here:
-          // 1. Both keys are undefined so no comparison necessary
-          // 2. Keys are not the same
-          if (
-            (resolvedOldVNode.key === undefined && resolvedNewVNode.key === undefined) ||
-            resolvedOldVNode.key !== resolvedNewVNode?.key
-          ) {
-            if (resolvedOldVNode.tag !== resolvedNewVNode.tag) {
-              const newEl = createElement(resolvedNewVNode, false);
-              effects.push({
-                type: EffectTypes.REPLACE,
-                flush: () => el.replaceWith(newEl),
-              });
-              return finish(newEl);
-            }
+        // We handle two cases here:
+        // 1. Both keys are undefined so no comparison necessary
+        // 2. Keys are not the same
+        if (
+          (resolvedOldVNode.key === undefined && resolvedNewVNode.key === undefined) ||
+          resolvedOldVNode.key !== resolvedNewVNode?.key
+        ) {
+          if (resolvedOldVNode.tag !== resolvedNewVNode.tag) {
+            const newEl = createElement(resolvedNewVNode, false);
+            effects.push({
+              type: EffectTypes.REPLACE,
+              flush: () => el.replaceWith(newEl),
+            });
+            return finish(newEl);
+          }
 
-            for (let i = 0; i < drivers.length; ++i) {
-              commit(
-                () => {
-                  (<Driver>drivers[i])(
-                    el,
-                    resolvedNewVNode,
-                    resolvedOldVNode,
-                    commit,
-                    effects,
-                    nodeDriver,
-                  );
-                },
-                {
+          for (let i = 0; i < drivers.length; ++i) {
+            commit(
+              () => {
+                (<Driver>drivers[i])(
                   el,
-                  newVNode: resolvedNewVNode,
-                  oldVNode: resolvedOldVNode,
+                  resolvedNewVNode,
+                  resolvedOldVNode,
+                  commit,
                   effects,
-                },
-              );
-            }
+                  nodeDriver,
+                );
+              },
+              {
+                el,
+                newVNode: resolvedNewVNode,
+                oldVNode: resolvedOldVNode,
+                effects,
+              },
+            );
           }
         }
       }
diff --git a/packages/million/m.ts b/packages/million/m.ts
index 76bea2c..9a45754 100644
--- a/packages/million/m.ts
+++ b/packages/million/m.ts
@@ -4,10 +4,10 @@ import {
   DOMNode,
   Flags,
   VElement,
+  VElementFlags,
   VEntity,
   VNode,
   VProps,
-  VTypes,
 } from './types';
 
 /**
@@ -84,11 +84,11 @@ export const entity = (
     data.key = undefined;
   }
   return {
+    flag: Flags.ENTITY,
     data,
     resolve,
     el,
     key,
-    type: VTypes.ENTITY,
   };
 };
 
@@ -99,7 +99,7 @@ export const m = (
   tag: string,
   props?: VProps,
   children?: VNode[],
-  flag?: Flags,
+  flag: VElementFlags = Flags.ELEMENT,
   delta?: Delta[],
 ): VElement => {
   let key = undefined;
@@ -114,13 +114,12 @@ export const m = (
     key,
     flag,
     delta,
-    type: VTypes.ELEMENT,
   };
   return velement.tag.toLowerCase() === 'svg' ? svg(velement) : velement;
 };
 
 export const resolveVNode = (entity?: VNode | VEntity): VNode | null | undefined => {
-  if (typeof entity === 'object' && entity.type === VTypes.ENTITY) {
+  if (typeof entity === 'object' && entity.flag === Flags.ENTITY) {
     return resolveVNode(entity.resolve());
   }
   return entity;
diff --git a/packages/million/types.ts b/packages/million/types.ts
index 1ed6106..cb46234 100644
--- a/packages/million/types.ts
+++ b/packages/million/types.ts
@@ -22,6 +22,7 @@ export type VNode = VElement | string;
 export type Delta = [DeltaTypes, number];
 export type Hook = (el?: DOMNode, newVNode?: VNode, oldVNode?: VNode) => boolean;
 export type Commit = (work: () => void, data: ReturnType<Driver>) => void;
+export type VElementFlags = Exclude<Flags, Flags.ENTITY>;
 export type Driver = (
   el: DOMNode,
   newVNode?: VNode,
@@ -44,30 +45,31 @@ export interface Effect {
 }
 
 export interface VEntity {
-  type: VTypes.ENTITY;
-  el?: DOMNode;
-  key?: string;
+  flag: Flags.ENTITY;
   data: Record<string, unknown>;
   resolve: () => VNode;
+  el?: DOMNode;
+  key?: string;
 }
 
 export interface VElement {
-  type: VTypes.ELEMENT;
+  flag: VElementFlags;
   tag: string;
   props?: VProps;
   children?: VNode[];
   key?: string;
-  flag?: Flags;
   delta?: Delta[];
 }
 
 export enum Flags {
-  IGNORE_NODE,
-  REPLACE_NODE,
-  NO_CHILDREN,
-  ONLY_TEXT_CHILDREN,
-  ONLY_KEYED_CHILDREN,
-  ANY_CHILDREN,
+  ENTITY,
+  ELEMENT,
+  ELEMENT_LEAF,
+  ELEMENT_IGNORE,
+  ELEMENT_SKIP_DIFF,
+  ELEMENT_NO_CHILDREN,
+  ELEMENT_TEXT_CHILDREN,
+  ELEMENT_KEYED_CHILDREN,
 }
 
 export enum EffectTypes {
@@ -84,8 +86,3 @@ export const enum DeltaTypes {
   UPDATE,
   REMOVE,
 }
-
-export const enum VTypes {
-  ELEMENT,
-  ENTITY,
-}
diff --git a/packages/shared/h.ts b/packages/shared/h.ts
index b951bff..64962f1 100644
--- a/packages/shared/h.ts
+++ b/packages/shared/h.ts
@@ -1,7 +1,7 @@
 import type { FC, JSXVNode } from '../jsx-runtime/types';
 import { className, Flags, m, style, svg } from '../million/index';
 import { kebab } from '../million/m';
-import type { Delta, VNode, VProps } from '../million/types';
+import type { Delta, VElementFlags, VNode, VProps } from '../million/types';
 
 export const normalize = (jsxVNode: JSXVNode): VNode | VNode[] | undefined => {
   if (Array.isArray(jsxVNode)) {
@@ -23,7 +23,7 @@ export const normalize = (jsxVNode: JSXVNode): VNode | VNode[] | undefined => {
 
 export const h = (tag: string | FC, props?: VProps, ...children: JSXVNode[]) => {
   if (typeof tag === 'function') return tag(props);
-  let flag = Flags.NO_CHILDREN;
+  let flag = Flags.ELEMENT_NO_CHILDREN;
   let delta: Delta[] | undefined;
   const normalizedChildren: VNode[] = [];
   if (props) {
@@ -36,10 +36,10 @@ export const h = (tag: string | FC, props?: VProps, ...children: JSXVNode[]) => 
   if (children) {
     const keysInChildren = new Set();
     let hasVElementChildren = false;
-    flag = Flags.ANY_CHILDREN;
+    flag = Flags.ELEMENT;
 
     if (children.every((child) => typeof child === 'string')) {
-      flag = Flags.ONLY_TEXT_CHILDREN;
+      flag = Flags.ELEMENT_TEXT_CHILDREN;
     }
     let childrenLength = 0;
     for (let i = 0; i < children.length; ++i) {
@@ -68,15 +68,15 @@ export const h = (tag: string | FC, props?: VProps, ...children: JSXVNode[]) => 
       }
     }
     if (keysInChildren.size === childrenLength) {
-      flag = Flags.ONLY_KEYED_CHILDREN;
+      flag = Flags.ELEMENT_KEYED_CHILDREN;
     }
     if (!hasVElementChildren) {
-      flag = Flags.ONLY_TEXT_CHILDREN;
+      flag = Flags.ELEMENT_TEXT_CHILDREN;
     }
   }
   if (props) {
     if (typeof props.flag === 'number') {
-      flag = <Flags>props.flag;
+      flag = props.flag;
       props.flag = undefined;
     }
     if (typeof props.className === 'object') {
@@ -91,6 +91,6 @@ export const h = (tag: string | FC, props?: VProps, ...children: JSXVNode[]) => 
     }
   }
 
-  const vnode = m(tag, props, normalizedChildren, flag, delta);
+  const vnode = m(tag, props, normalizedChildren, <VElementFlags>flag, delta);
   return tag === 'svg' ? svg(vnode) : vnode;
 };
diff --git a/pnpm-lock.yaml b/pnpm-lock.yaml
index 24b34e6..9f074df 100644
--- a/pnpm-lock.yaml
+++ b/pnpm-lock.yaml
@@ -6,7 +6,7 @@ specifiers:
   '@picocss/pico': ^1.5.0
   '@types/benchmark': ^2.1.1
   '@types/canvas-confetti': ^1.4.2
-  '@types/lodash': ^4.14.180
+  '@types/lodash': ^4.14.181
   '@types/node': ^17.0.23
   '@types/virtual-dom': ^2.1.1
   '@typescript-eslint/eslint-plugin': ^5.17.0
@@ -50,7 +50,7 @@ devDependencies:
   '@picocss/pico': 1.5.0
   '@types/benchmark': 2.1.1
   '@types/canvas-confetti': 1.4.2
-  '@types/lodash': 4.14.180
+  '@types/lodash': 4.14.181
   '@types/node': 17.0.23
   '@types/virtual-dom': 2.1.1
   '@typescript-eslint/eslint-plugin': 5.17.0_689ff565753ecf7c3328c07fad067df5
@@ -732,8 +732,8 @@ packages:
       '@types/node': 17.0.23
     dev: true
 
-  /@types/lodash/4.14.180:
-    resolution: {integrity: sha512-XOKXa1KIxtNXgASAnwj7cnttJxS4fksBRywK/9LzRV5YxrF80BXZIGeQSuoESQ/VkUj30Ae0+YcuHc15wJCB2g==}
+  /@types/lodash/4.14.181:
+    resolution: {integrity: sha512-n3tyKthHJbkiWhDZs3DkhkCzt2MexYHXlX0td5iMplyfwketaOeKboEVBqzceH7juqvEg3q5oUoBFxSLu7zFag==}
     dev: true
 
   /@types/minimist/1.2.2:
diff --git a/test/m.test.ts b/test/m.test.ts
index dbcc2da..001c1de 100644
--- a/test/m.test.ts
+++ b/test/m.test.ts
@@ -1,6 +1,6 @@
 import { describe, expect, it } from 'vitest';
 import { className, Deltas, kebab, m, ns, style, svg } from '../packages/million/m';
-import { DeltaTypes, VElement, VNode, VTypes } from '../packages/million/types';
+import { DeltaTypes, Flags, VElement, VNode } from '../packages/million/types';
 
 export const expectEqualVNode = (vnode1: VNode, vnode2: VNode) => {
   expect(JSON.stringify(vnode1)).toEqual(JSON.stringify(vnode2));
@@ -8,14 +8,14 @@ export const expectEqualVNode = (vnode1: VNode, vnode2: VNode) => {
 
 describe.concurrent('m', () => {
   it('should create empty vnode with tag', () => {
-    expectEqualVNode(m('div'), { tag: 'div', type: VTypes.ELEMENT });
+    expectEqualVNode(m('div'), { tag: 'div', flag: Flags.ELEMENT });
   });
 
   it('should create vnode with tag and props', () => {
     expectEqualVNode(m('div', { id: 'app' }), {
       tag: 'div',
       props: { id: 'app' },
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     });
   });
 
@@ -23,7 +23,7 @@ describe.concurrent('m', () => {
     expectEqualVNode(m('div', undefined, ['foo']), {
       tag: 'div',
       children: ['foo'],
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     });
   });
 
@@ -31,7 +31,7 @@ describe.concurrent('m', () => {
     expectEqualVNode(m('div', undefined, ['foo', 'bar', 'baz']), {
       tag: 'div',
       children: ['foo', 'bar', 'baz'],
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     });
   });
 
@@ -41,10 +41,10 @@ describe.concurrent('m', () => {
       children: [
         {
           tag: 'div',
-          type: VTypes.ELEMENT,
+          flag: Flags.ELEMENT,
         },
       ],
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     });
   });
 
@@ -54,16 +54,16 @@ describe.concurrent('m', () => {
       children: [
         {
           tag: 'div',
-          type: VTypes.ELEMENT,
+          flag: Flags.ELEMENT,
         },
         'foo',
         {
           tag: 'div',
-          type: VTypes.ELEMENT,
+          flag: Flags.ELEMENT,
         },
         'bar',
       ],
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     });
   });
 
@@ -88,16 +88,16 @@ describe.concurrent('m', () => {
                   {
                     tag: 'div',
                     children: ['boo'],
-                    type: VTypes.ELEMENT,
+                    flag: Flags.ELEMENT,
                   },
                 ],
-                type: VTypes.ELEMENT,
+                flag: Flags.ELEMENT,
               },
             ],
-            type: VTypes.ELEMENT,
+            flag: Flags.ELEMENT,
           },
         ],
-        type: VTypes.ELEMENT,
+        flag: Flags.ELEMENT,
       },
     );
   });
@@ -112,7 +112,7 @@ describe.concurrent('m', () => {
         },
         children: undefined,
         key: undefined,
-        type: VTypes.ELEMENT,
+        flag: Flags.ELEMENT,
       },
     );
   });
@@ -125,7 +125,7 @@ describe.concurrent('m', () => {
       },
       children: undefined,
       key: undefined,
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     });
   });
 
@@ -148,10 +148,10 @@ describe.concurrent('m', () => {
         {
           tag: 'div',
           props: {},
-          type: VTypes.ELEMENT,
+          flag: Flags.ELEMENT,
         },
       ],
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     };
     ns(vnode.tag, vnode.props!, vnode.children);
     expectEqualVNode(vnode, {
@@ -164,10 +164,10 @@ describe.concurrent('m', () => {
           props: {
             ns: 'http://www.w3.org/2000/svg',
           },
-          type: VTypes.ELEMENT,
+          flag: Flags.ELEMENT,
         },
       ],
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     });
   });
 
@@ -181,10 +181,10 @@ describe.concurrent('m', () => {
         'foo',
         {
           tag: 'div',
-          type: VTypes.ELEMENT,
+          flag: Flags.ELEMENT,
         },
       ],
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     };
     ns(vnode.tag, vnode.props!, vnode.children);
     expectEqualVNode(vnode, {
@@ -194,21 +194,21 @@ describe.concurrent('m', () => {
         'foo',
         {
           tag: 'div',
-          type: VTypes.ELEMENT,
+          flag: Flags.ELEMENT,
         },
       ],
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     });
   });
 
   it('should attach ns to props using svg helper', () => {
     const vnode: VElement = {
       tag: 'svg',
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     };
     expectEqualVNode(svg(vnode), {
       tag: 'svg',
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
       props: { ns: 'http://www.w3.org/2000/svg' },
     });
   });
@@ -221,11 +221,11 @@ describe.concurrent('m', () => {
         'foo',
         {
           tag: 'div',
-          type: VTypes.ELEMENT,
+          flag: Flags.ELEMENT,
         },
       ],
       key: 'foo',
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     });
   });
 
diff --git a/test/render.test.ts b/test/render.test.ts
index 6ed6bfc..fcc9a2f 100644
--- a/test/render.test.ts
+++ b/test/render.test.ts
@@ -54,7 +54,7 @@ describe.concurrent('render', () => {
 
     el.textContent = 'foo';
 
-    patch(el, m('div', undefined, undefined, Flags.NO_CHILDREN));
+    patch(el, m('div', undefined, undefined, Flags.ELEMENT_NO_CHILDREN));
 
     expect(el.textContent).toEqual('');
   });
@@ -137,15 +137,15 @@ describe.concurrent('render', () => {
     const el = document.createElement('div');
     patch(
       el,
-      m('div', undefined, ['foo'], Flags.ONLY_TEXT_CHILDREN),
-      m('div', undefined, [], Flags.ONLY_TEXT_CHILDREN),
+      m('div', undefined, ['foo'], Flags.ELEMENT_TEXT_CHILDREN),
+      m('div', undefined, [], Flags.ELEMENT_TEXT_CHILDREN),
     );
     expect(el.textContent).toEqual('foo');
 
     patch(
       el,
-      m('div', undefined, [], Flags.NO_CHILDREN),
-      m('div', undefined, ['foo'], Flags.NO_CHILDREN),
+      m('div', undefined, [], Flags.ELEMENT_NO_CHILDREN),
+      m('div', undefined, ['foo'], Flags.ELEMENT_NO_CHILDREN),
     );
     expect(el.childNodes.length).toEqual(0);
   });
@@ -157,9 +157,9 @@ describe.concurrent('render', () => {
       'ul',
       undefined,
       list1.map((item) => m('li', { key: item }, [item])),
-      Flags.ONLY_KEYED_CHILDREN,
+      Flags.ELEMENT_KEYED_CHILDREN,
     );
-    patch(el, newVNode1, m('ul', undefined, undefined, Flags.NO_CHILDREN));
+    patch(el, newVNode1, m('ul', undefined, undefined, Flags.ELEMENT_NO_CHILDREN));
     expectEqualNode(el, createElement(newVNode1));
 
     const list2 = ['foo', 'baz', 'bar', 'foo1', 'bar1', 'baz1'];
@@ -167,7 +167,7 @@ describe.concurrent('render', () => {
       'ul',
       undefined,
       list2.map((item) => m('li', { key: item }, [item])),
-      Flags.ONLY_KEYED_CHILDREN,
+      Flags.ELEMENT_KEYED_CHILDREN,
     );
     patch(el, newVNode2, newVNode1);
     expectEqualNode(el, createElement(newVNode2));
@@ -177,7 +177,7 @@ describe.concurrent('render', () => {
       'ul',
       undefined,
       list3.map((item) => m('li', { key: item }, [item])),
-      Flags.ONLY_KEYED_CHILDREN,
+      Flags.ELEMENT_KEYED_CHILDREN,
     );
     patch(el, newVNode3, newVNode2);
     expectEqualNode(el, createElement(newVNode3));
@@ -187,7 +187,7 @@ describe.concurrent('render', () => {
       'ul',
       undefined,
       list4.map((item) => m('li', { key: item }, [item])),
-      Flags.ONLY_KEYED_CHILDREN,
+      Flags.ELEMENT_KEYED_CHILDREN,
     );
     patch(el, newVNode4, newVNode3);
     expectEqualNode(el, createElement(newVNode4));
@@ -197,7 +197,7 @@ describe.concurrent('render', () => {
       'ul',
       undefined,
       list5.map((item) => m('li', { key: item }, [item])),
-      Flags.ONLY_KEYED_CHILDREN,
+      Flags.ELEMENT_KEYED_CHILDREN,
     );
     patch(el, newVNode5, newVNode4);
     expectEqualNode(el, createElement(newVNode5));
@@ -207,7 +207,7 @@ describe.concurrent('render', () => {
       'ul',
       undefined,
       list6.map((item) => m('li', { key: item }, [item])),
-      Flags.ONLY_KEYED_CHILDREN,
+      Flags.ELEMENT_KEYED_CHILDREN,
     );
     patch(el, newVNode6, newVNode5);
     expectEqualNode(el, createElement(newVNode6));
@@ -217,7 +217,7 @@ describe.concurrent('render', () => {
       'ul',
       undefined,
       list7.map((item) => m('li', { key: item }, [item])),
-      Flags.ONLY_KEYED_CHILDREN,
+      Flags.ELEMENT_KEYED_CHILDREN,
     );
     patch(el, newVNode7, newVNode6);
     expectEqualNode(el, createElement(newVNode7));

diff --git a/topology/pom.xml b/topology/pom.xml
index 389508e..ee6239a 100644
--- a/topology/pom.xml
+++ b/topology/pom.xml
@@ -16,6 +16,7 @@
   </parent>
 
   <artifactId>zeebe-cluster-topology</artifactId>
+  <name>Zeebe Cluster Topology</name>
 
   <properties>
     <proto.dir>${maven.multiModuleProjectDirectory}/topology/src/main/resources/proto</proto.dir>
",2,"[""ed9e6ed444d4c2c830b498cee4665cbf1aaad84d"", ""8911a972222dc80a242f3f1d9b3596321b3fdeaa""]","[""refactor"", ""build""]"
"fixing deploying to kubernetes

Signed-off-by: Rajesh Rajendran <rjshrjndrn@gmail.com> | add user role enum

Signed-off-by: Braks <78412429+bcakmakoglu@users.noreply.github.com> | update basic test with colors","diff --git a/.github/workflows/frontend.yaml b/.github/workflows/frontend.yaml
index 7e42967..77e4abf 100644
--- a/.github/workflows/frontend.yaml
+++ b/.github/workflows/frontend.yaml
@@ -22,26 +22,22 @@ jobs:
           ${{ runner.OS }}-build-
           ${{ runner.OS }}-
 
+    - uses: azure/k8s-set-context@v1
+      with:
+        method: kubeconfig
+        kubeconfig: ${{ secrets.OSS_KUBECONFIG }} # Use content of kubeconfig in secret.
+      id: setcontext
     - name: Install
       run: npm install
 
-    - name: Build
-      run: npm run build:staging
-      env:
-        ENVIRONMENT: staging
-
-    - name: Deploy
-      env:
-        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
-        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
-        AWS_REGION: eu-central-1
-        AWS_S3_BUCKET_NAME: ${{ secrets.AWS_S3_BUCKET_NAME }}
+    - name: Build and deploy
       run: |
-        aws configure set default.s3.signature_version s3v4
-        aws --endpoint-url https://${{secrets.DOMAIN_NAME}}/frontend/ s3 cp \
-          --recursive \
-          --region ""$AWS_REGION"" \
-          public s3://$AWS_S3_BUCKET_NAME
+        cd frontend
+        bash build.sh
+        cp -arl public frontend
+        minio_pod=$(kubectl get po -n db -l app.kubernetes.io/name=minio -n db --output custom-columns=name:.metadata.name | tail -n+2)
+        kubectl -n db cp frontend $minio_pod:/data/
+        rm -rf frontend
 
     # - name: Debug Job
     #   if: ${{ failure() }}

diff --git a/packages/nc-gui-v2/lib/enums.ts b/packages/nc-gui-v2/lib/enums.ts
index e87b69a..c6751a3 100644
--- a/packages/nc-gui-v2/lib/enums.ts
+++ b/packages/nc-gui-v2/lib/enums.ts
@@ -1,3 +1,9 @@
+export enum Role {
+  Super = 'super',
+  Admin = 'admin',
+  User = 'user',
+}
+
 export enum Language {
   de = 'Deutsch',
   en = 'English',
diff --git a/packages/nc-gui-v2/lib/types.ts b/packages/nc-gui-v2/lib/types.ts
index bf152c4..dd8a1ce 100644
--- a/packages/nc-gui-v2/lib/types.ts
+++ b/packages/nc-gui-v2/lib/types.ts
@@ -1,11 +1,12 @@
 import type { ComputedRef, ToRefs } from 'vue'
+import type { Role } from '~/lib/enums'
 
 export interface User {
   id: string
   email: string
   firstname: string | null
   lastname: string | null
-  roles: string[]
+  roles: (Role | string)[]
 }
 
 export interface State {

diff --git a/core/src/components/label/test/basic/index.html b/core/src/components/label/test/basic/index.html
index d0b566c..377e58c 100644
--- a/core/src/components/label/test/basic/index.html
+++ b/core/src/components/label/test/basic/index.html
@@ -19,12 +19,32 @@
     </ion-header>
 
     <ion-content>
+      <div padding>
+        <ion-label>Default</ion-label>
+
+        <ion-label color=""secondary"">Secondary</ion-label>
+
+        <ion-label color=""tertiary"">Tertiary</ion-label>
+
+        <ion-label color=""danger"">Danger</ion-label>
+
+        <ion-label class=""custom"">Custom</ion-label>
+      </div>
+
       <ion-list>
         <ion-item>
           <ion-label>Default</ion-label>
           <ion-input></ion-input>
         </ion-item>
         <ion-item>
+          <ion-label color=""tertiary"">Tertiary</ion-label>
+          <ion-input></ion-input>
+        </ion-item>
+        <ion-item>
+          <ion-label class=""custom"">Custom</ion-label>
+          <ion-input></ion-input>
+        </ion-item>
+        <ion-item>
           <ion-label text-wrap>Wrap label this label just goes on and on and on</ion-label>
           <ion-input></ion-input>
         </ion-item>
@@ -42,6 +62,12 @@
         </ion-item>
       </ion-list>
     </ion-content>
+
+    <style>
+      .custom {
+        color: lightblue;
+      }
+    </style>
   </ion-app>
 </body>
 
",3,"[""3f2eec37f76c1ad9408e423e49fe5bfe3e17d943"", ""176a959eb80d17f9abc5c6b5354e6097be95b42d"", ""c3b5dc77ff3d89d389f6f3a868b17d0a8ca63074""]","[""cicd"", ""feat"", ""test""]"
switch to callback ref,"diff --git a/src/notebook/components/transforms/html.js b/src/notebook/components/transforms/html.js
index 83fc1fb..021cc65 100644
--- a/src/notebook/components/transforms/html.js
+++ b/src/notebook/components/transforms/html.js
@@ -8,16 +8,16 @@ type Props = {
 
 export default class HTMLDisplay extends React.Component {
   props: Props;
+  el: HTMLElement;
 
   componentDidMount(): void {
-    if (this.refs.here) {
-      if (document.createRange && Range && Range.prototype.createContextualFragment) {
-        const range = document.createRange();
-        const fragment = range.createContextualFragment(this.props.data);
-        ReactDOM.findDOMNode(this.refs.here).appendChild(fragment);
-      } else {
-        ReactDOM.findDOMNode(this.refs.here).innerHTML = this.props.data;
-      }
+    // Create a range to ensure that scripts are invoked from within the HTML
+    if (document.createRange && Range && Range.prototype.createContextualFragment) {
+      const range = document.createRange();
+      const fragment = range.createContextualFragment(this.props.data);
+      this.el.appendChild(fragment);
+    } else {
+      this.el.innerHTML = this.props.data;
     }
   }
 
@@ -27,7 +27,7 @@ export default class HTMLDisplay extends React.Component {
 
   render(): ?React.Element<any> {
     return (
-      <div ref=""here"" />
+      <div ref={(el) => { this.el = el; }} />
     );
   }
 }
",1,"[""ee4bf61fb8836e249fb4ef3507dc938e70696b3f""]","[""refactor""]"
add test for spurious cross join | fix scroll behavior in navigation | remove unnecessary start argument from `range`,"diff --git a/ibis/tests/sql/test_sqlalchemy.py b/ibis/tests/sql/test_sqlalchemy.py
index 4ad32a6..b2e5d72 100644
--- a/ibis/tests/sql/test_sqlalchemy.py
+++ b/ibis/tests/sql/test_sqlalchemy.py
@@ -841,3 +841,63 @@ def test_filter_group_by_agg_with_same_name():
     )
     ex = sa.select([t0]).where(t0.c.bigint_col == 60)
     _check(expr, ex)
+
+
+@pytest.fixture
+def person():
+    return ibis.table(
+        dict(id=""string"", personal=""string"", family=""string""),
+        name=""person"",
+    )
+
+
+@pytest.fixture
+def visited():
+    return ibis.table(
+        dict(id=""int32"", site=""string"", dated=""string""),
+        name=""visited"",
+    )
+
+
+@pytest.fixture
+def survey():
+    return ibis.table(
+        dict(
+            taken=""int32"",
+            person=""string"",
+            quant=""string"",
+            reading=""float32"",
+        ),
+        name=""survey"",
+    )
+
+
+def test_no_cross_join(person, visited, survey):
+    expr = person.join(survey, person.id == survey.person).join(
+        visited,
+        visited.id == survey.taken,
+    )
+
+    context = AlchemyContext(compiler=AlchemyCompiler)
+    _ = AlchemyCompiler.to_sql(expr, context)
+
+    t0 = context.get_ref(person)
+    t1 = context.get_ref(survey)
+    t2 = context.get_ref(visited)
+
+    from_ = t0.join(t1, t0.c.id == t1.c.person).join(t2, t2.c.id == t1.c.taken)
+    ex = sa.select(
+        [
+            t0.c.id.label(""id_x""),
+            t0.c.personal,
+            t0.c.family,
+            t1.c.taken,
+            t1.c.person,
+            t1.c.quant,
+            t1.c.reading,
+            t2.c.id.label(""id_y""),
+            t2.c.site,
+            t2.c.dated,
+        ]
+    ).select_from(from_)
+    _check(expr, ex)

diff --git a/website/layouts/Base.tsx b/website/layouts/Base.tsx
index 5959fd2..08d5674 100644
--- a/website/layouts/Base.tsx
+++ b/website/layouts/Base.tsx
@@ -90,12 +90,21 @@ function SidebarItem({
 type SidebarNodeWrapper = {
   children: React.ReactNode,
   node: Sitemap,
-  elementRef: React.MutableRefObject<HTMLLIElement | null>;
+  isActive: boolean;
 };
 
-function SidebarNodeWrapper({ children, node, elementRef }: SidebarNodeWrapper) {
+function SidebarNodeWrapper({ children, node, isActive }: SidebarNodeWrapper) {
+  const { asPath } = useRouter();
+  const nodeRef = useRef<HTMLLIElement | null>(null);
+
+  useEffect(() => {
+    if (isActive) {
+      nodeRef.current?.scrollIntoView({ behavior: 'smooth', block: 'nearest', inline: 'start' });
+    }
+  }, [asPath]);
+
   if (node.resource?.label) {
-    return <li ref={elementRef}>{children}</li>;
+    return <li ref={nodeRef}>{children}</li>;
   }
 
   return <>{children}</>;
@@ -109,14 +118,12 @@ type SidebarNodeProps = {
 
 function SidebarNode({ node, level, isNodeActive }: SidebarNodeProps) {
   const { asPath } = useRouter();
-  const nodeWrapperRef = useRef<HTMLLIElement | null>(null);
   const isFirstLevel = level === 1;
   const initialIsExpanded = !isFirstLevel || hasActiveChild(node);
   const [isExpanded, setIsExpanded] = useState(initialIsExpanded);
 
   useEffect(() => {
     setIsExpanded(initialIsExpanded);
-    nodeWrapperRef.current?.scrollIntoView({ behavior: 'smooth', block: 'nearest', inline: 'start' });
   }, [asPath]);
 
   const id = node.resource?.label?.toLowerCase().replace(/\s/g, '-');
@@ -136,7 +143,7 @@ function SidebarNode({ node, level, isNodeActive }: SidebarNodeProps) {
   }
 
   return (
-    <SidebarNodeWrapper node={node} elementRef={nodeWrapperRef}>
+    <SidebarNodeWrapper node={node} isActive={isNodeActive(node)}>
       <>
         {node.resource?.label ? (
           <SidebarItem

diff --git a/ibis/backends/dask/tests/execution/test_window.py b/ibis/backends/dask/tests/execution/test_window.py
index 75a7331..6bfc5e3 100644
--- a/ibis/backends/dask/tests/execution/test_window.py
+++ b/ibis/backends/dask/tests/execution/test_window.py
@@ -489,7 +489,7 @@ def test_project_list_scalar(npartitions):
     expr = table.mutate(res=table.ints.quantile([0.5, 0.95]))
     result = expr.execute()
 
-    expected = pd.Series([[1.0, 1.9] for _ in range(0, 3)], name=""res"")
+    expected = pd.Series([[1.0, 1.9] for _ in range(3)], name=""res"")
     tm.assert_series_equal(result.res, expected)
 
 
diff --git a/ibis/backends/pandas/tests/execution/test_window.py b/ibis/backends/pandas/tests/execution/test_window.py
index 8f292b3..effa372 100644
--- a/ibis/backends/pandas/tests/execution/test_window.py
+++ b/ibis/backends/pandas/tests/execution/test_window.py
@@ -436,7 +436,7 @@ def test_project_list_scalar():
     expr = table.mutate(res=table.ints.quantile([0.5, 0.95]))
     result = expr.execute()
 
-    expected = pd.Series([[1.0, 1.9] for _ in range(0, 3)], name=""res"")
+    expected = pd.Series([[1.0, 1.9] for _ in range(3)], name=""res"")
     tm.assert_series_equal(result.res, expected)
 
 
diff --git a/ibis/backends/pyspark/tests/test_basic.py b/ibis/backends/pyspark/tests/test_basic.py
index 3850919..14fe677 100644
--- a/ibis/backends/pyspark/tests/test_basic.py
+++ b/ibis/backends/pyspark/tests/test_basic.py
@@ -19,7 +19,7 @@ from ibis.backends.pyspark.compiler import _can_be_replaced_by_column_name  # no
 def test_basic(con):
     table = con.table(""basic_table"")
     result = table.compile().toPandas()
-    expected = pd.DataFrame({""id"": range(0, 10), ""str_col"": ""value""})
+    expected = pd.DataFrame({""id"": range(10), ""str_col"": ""value""})
 
     tm.assert_frame_equal(result, expected)
 
@@ -28,9 +28,7 @@ def test_projection(con):
     table = con.table(""basic_table"")
     result1 = table.mutate(v=table[""id""]).compile().toPandas()
 
-    expected1 = pd.DataFrame(
-        {""id"": range(0, 10), ""str_col"": ""value"", ""v"": range(0, 10)}
-    )
+    expected1 = pd.DataFrame({""id"": range(10), ""str_col"": ""value"", ""v"": range(10)})
 
     result2 = (
         table.mutate(v=table[""id""])
@@ -44,8 +42,8 @@ def test_projection(con):
         {
             ""id"": range(0, 20, 2),
             ""str_col"": ""value"",
-            ""v"": range(0, 10),
-            ""v2"": range(0, 10),
+            ""v"": range(10),
+            ""v2"": range(10),
         }
     )
 
",3,"[""8dac3fe5a7a56356ca95547fcf7925bec8d9c1dd"", ""4b5604063fcb8ff457bcb61fdbea85c6b3a5c620"", ""15f8d95754a0b6865ea475ca9e515272a07bf6ba""]","[""test"", ""fix"", ""refactor""]"
"skip if related view/hook/column of a filter is not found

Signed-off-by: Pranav C <pranavxc@gmail.com>","diff --git a/packages/nocodb/src/lib/version-upgrader/ncFilterUpgrader.ts b/packages/nocodb/src/lib/version-upgrader/ncFilterUpgrader.ts
index 1515f88..6c250bd 100644
--- a/packages/nocodb/src/lib/version-upgrader/ncFilterUpgrader.ts
+++ b/packages/nocodb/src/lib/version-upgrader/ncFilterUpgrader.ts
@@ -21,7 +21,13 @@ export default async function ({ ncMeta }: NcUpgraderCtx) {
     } else {
       continue;
     }
-    if (filter.project_id != model.project_id) {
+
+    // skip if related model is not found
+    if (!model) {
+      continue;
+    }
+
+    if (filter.project_id !== model.project_id) {
       await ncMeta.metaUpdate(
         null,
         null,
",1,"[""ab1e60a97c6d5c688dacbd23bca40cb8f20c4ac3""]","[""fix""]"
fixed start types for size and opacity | added vue3 readme | update version (nightly.0),"diff --git a/core/main/src/Core/Particle.ts b/core/main/src/Core/Particle.ts
index 1aa6fba..6ea6ffc 100644
--- a/core/main/src/Core/Particle.ts
+++ b/core/main/src/Core/Particle.ts
@@ -271,7 +271,7 @@ export class Particle implements IParticle {
             }
         }
 
-        const sizeAnimation = this.options.size.animation;
+        const sizeAnimation = sizeOptions.animation;
 
         if (sizeAnimation.enable) {
             this.size.status = AnimationStatus.increasing;
@@ -279,7 +279,8 @@ export class Particle implements IParticle {
             if (!randomSize) {
                 switch (sizeAnimation.startValue) {
                     case StartValueType.min:
-                        this.size.value = sizeAnimation.minimumValue * pxRatio;
+                        this.size.value = NumberUtils.getRangeMin(sizeOptions.value) * pxRatio;
+                        this.size.status = AnimationStatus.increasing;
 
                         break;
 
@@ -287,11 +288,14 @@ export class Particle implements IParticle {
                         this.size.value = NumberUtils.randomInRange(
                             NumberUtils.setRangeValue(sizeAnimation.minimumValue * pxRatio, this.size.value)
                         );
+                        this.size.status =
+                            Math.random() >= 0.5 ? AnimationStatus.increasing : AnimationStatus.decreasing;
 
                         break;
 
                     case StartValueType.max:
                     default:
+                        this.size.value = NumberUtils.getRangeMax(sizeOptions.value) * pxRatio;
                         this.size.status = AnimationStatus.decreasing;
 
                         break;
@@ -393,7 +397,8 @@ export class Particle implements IParticle {
             if (!randomOpacity) {
                 switch (opacityAnimation.startValue) {
                     case StartValueType.min:
-                        this.opacity.value = opacityAnimation.minimumValue;
+                        this.opacity.value = NumberUtils.getRangeMin(this.opacity.value);
+                        this.opacity.status = AnimationStatus.increasing;
 
                         break;
 
@@ -401,11 +406,14 @@ export class Particle implements IParticle {
                         this.opacity.value = NumberUtils.randomInRange(
                             NumberUtils.setRangeValue(opacityAnimation.minimumValue, this.opacity.value)
                         );
+                        this.opacity.status =
+                            Math.random() >= 0.5 ? AnimationStatus.increasing : AnimationStatus.decreasing;
 
                         break;
 
                     case StartValueType.max:
                     default:
+                        this.opacity.value = NumberUtils.getRangeMax(this.opacity.value);
                         this.opacity.status = AnimationStatus.decreasing;
 
                         break;
diff --git a/presets/confetti/src/options.ts b/presets/confetti/src/options.ts
index 7fc6225..a713425 100644
--- a/presets/confetti/src/options.ts
+++ b/presets/confetti/src/options.ts
@@ -28,7 +28,7 @@ export const loadOptions = (confettiOptions: RecursivePartial<IConfettiOptions>)
                 animation: {
                     enable: true,
                     minimumValue: 0,
-                    speed: 2,
+                    speed: 0.5,
                     startValue: ""max"",
                     destroy: ""min"",
                 },

diff --git a/core/main/README.md b/core/main/README.md
index e5e4c93..e9cfda9 100644
--- a/core/main/README.md
+++ b/core/main/README.md
@@ -217,7 +217,7 @@ You can find the instructions [here](https://github.com/matteobruni/tsparticles/
 
 You can find the instructions [here](https://github.com/matteobruni/tsparticles/blob/master/components/svelte/README.md)
 
-### VueJS
+### VueJS 2.x
 
 #### `particles.vue`
 
@@ -225,6 +225,14 @@ You can find the instructions [here](https://github.com/matteobruni/tsparticles/
 
 You can find the instructions [here](https://github.com/matteobruni/tsparticles/blob/master/components/vue/README.md)
 
+### VueJS 3.x
+
+#### `particles.vue3`
+
+[![npm](https://img.shields.io/npm/v/particles.vue3)](https://www.npmjs.com/package/particles.vue3) [![npm](https://img.shields.io/npm/dm/particles.vue3)](https://www.npmjs.com/package/particles.vue3)
+
+You can find the instructions [here](https://github.com/matteobruni/tsparticles/blob/master/components/vue3/README.md)
+
 ---
 
 ## **_Demo / Generator_**
diff --git a/core/main/tsconfig.json b/core/main/tsconfig.json
index 7916bc5..72399c0 100644
--- a/core/main/tsconfig.json
+++ b/core/main/tsconfig.json
@@ -107,10 +107,14 @@
               ""source"": ""../../components/react/README.md""
             },
             {
-              ""title"": ""Vue"",
+              ""title"": ""Vue 2.x"",
               ""source"": ""../../components/vue/README.md""
             },
             {
+              ""title"": ""Vue 3.x"",
+              ""source"": ""../../components/vue3/README.md""
+            },
+            {
               ""title"": ""Svelte"",
               ""source"": ""../../components/svelte/README.md""
             },

diff --git a/Cargo.lock b/Cargo.lock
index f949506..6a10219 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -94,7 +94,7 @@ dependencies = [
 
 [[package]]
 name = ""els""
-version = ""0.1.22""
+version = ""0.1.23-nightly.0""
 dependencies = [
  ""erg_common"",
  ""erg_compiler"",
@@ -105,7 +105,7 @@ dependencies = [
 
 [[package]]
 name = ""erg""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""els"",
  ""erg_common"",
@@ -115,7 +115,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_common""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""backtrace-on-stack-overflow"",
  ""crossterm"",
@@ -126,7 +126,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_compiler""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""erg_common"",
  ""erg_parser"",
@@ -134,7 +134,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_parser""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""erg_common"",
  ""unicode-xid"",
diff --git a/Cargo.toml b/Cargo.toml
index 04fdad7..ecc45e5 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -20,7 +20,7 @@ members = [
 ]
 
 [workspace.package]
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 authors = [""erg-lang team <moderation.erglang@gmail.com>""]
 license = ""MIT OR Apache-2.0""
 edition = ""2021""
@@ -64,10 +64,10 @@ full-repl = [""erg_common/full-repl""]
 full = [""els"", ""full-repl"", ""unicode"", ""pretty""]
 
 [workspace.dependencies]
-erg_common = { version = ""0.6.10"", path = ""./crates/erg_common"" }
-erg_parser = { version = ""0.6.10"", path = ""./crates/erg_parser"" }
-erg_compiler = { version = ""0.6.10"", path = ""./crates/erg_compiler"" }
-els = { version = ""0.1.22"", path = ""./crates/els"" }
+erg_common = { version = ""0.6.11-nightly.0"", path = ""./crates/erg_common"" }
+erg_parser = { version = ""0.6.11-nightly.0"", path = ""./crates/erg_parser"" }
+erg_compiler = { version = ""0.6.11-nightly.0"", path = ""./crates/erg_compiler"" }
+els = { version = ""0.1.23-nightly.0"", path = ""./crates/els"" }
 
 [dependencies]
 erg_common = { workspace = true }
diff --git a/crates/els/Cargo.toml b/crates/els/Cargo.toml
index bc031e6..7c9455f 100644
--- a/crates/els/Cargo.toml
+++ b/crates/els/Cargo.toml
@@ -2,7 +2,7 @@
 name = ""els""
 description = ""An Erg compiler frontend for IDEs, implements LSP.""
 documentation = ""http://docs.rs/els""
-version = ""0.1.22""
+version = ""0.1.23-nightly.0""
 authors.workspace = true
 license.workspace = true
 edition.workspace = true
",3,"[""06960183db42cba1b1f1a8077660ba8c801c9e18"", ""e4c3e2cff769ce46d22d5c8f7dd527510443a8a7"", ""607ecc92b5f8c084304e406eec725b7dcfa0a562""]","[""fix"", ""docs"", ""build""]"
"rename flags to valid names, fold VTypes into Flags","diff --git a/package.json b/package.json
index faa6e93..9281604 100644
--- a/package.json
+++ b/package.json
@@ -105,7 +105,7 @@
     ""@picocss/pico"": ""^1.5.0"",
     ""@types/benchmark"": ""^2.1.1"",
     ""@types/canvas-confetti"": ""^1.4.2"",
-    ""@types/lodash"": ""^4.14.180"",
+    ""@types/lodash"": ""^4.14.181"",
     ""@types/node"": ""^17.0.23"",
     ""@types/virtual-dom"": ""^2.1.1"",
     ""@typescript-eslint/eslint-plugin"": ""^5.17.0"",
diff --git a/packages/million/createElement.ts b/packages/million/createElement.ts
index e900f97..cfea080 100644
--- a/packages/million/createElement.ts
+++ b/packages/million/createElement.ts
@@ -1,3 +1,4 @@
+import { resolveVNode } from './m';
 import {
   COLON_CHAR,
   DOMNode,
@@ -6,33 +7,29 @@ import {
   VElement,
   VEntity,
   VNode,
-  VTypes,
   XLINK_NS,
   XML_NS,
   X_CHAR,
 } from './types';
-import { resolveVNode } from './m';
 
 /**
  * Creates an Element from a VNode
  */
 export const createElement = (vnode?: VNode | VEntity | null, attachField = true): DOMNode => {
-  if (typeof vnode === 'object' && vnode?.type === VTypes.ENTITY) {
+  if (vnode === undefined || vnode === null) return document.createComment('');
+  if (typeof vnode === 'string') return document.createTextNode(vnode);
+  if (typeof vnode === 'object' && vnode?.flag === Flags.ENTITY) {
     if (vnode.el) return vnode.el;
     else return createElement(resolveVNode(vnode));
   }
-  if (vnode === undefined || vnode === null) return document.createComment('');
-  if (typeof vnode === 'string') return document.createTextNode(vnode);
-  const velement = <VElement>vnode;
 
-  // istanbul ignore next
-  const el = velement.props?.ns
-    ? <SVGElement>document.createElementNS(<string>velement.props?.ns, velement.tag)
-    : <HTMLElement>document.createElement(velement.tag);
+  const el = vnode.props?.ns
+    ? <SVGElement>document.createElementNS(<string>vnode.props?.ns, vnode.tag)
+    : <HTMLElement>document.createElement(vnode.tag);
 
-  if (velement.props) {
-    for (const propName in velement.props) {
-      const propValue = velement.props[propName];
+  if (vnode.props) {
+    for (const propName in vnode.props) {
+      const propValue = vnode.props[propName];
       if (propName.startsWith('on')) {
         const eventPropName = propName.slice(2).toLowerCase();
         el.addEventListener(eventPropName, <EventListener>propValue);
@@ -50,14 +47,12 @@ export const createElement = (vnode?: VNode | VEntity | null, attachField = true
     }
   }
 
-  if (velement.children) {
-    if (velement.flag === Flags.ONLY_TEXT_CHILDREN) {
-      el.textContent = Array.isArray(velement.children)
-        ? velement.children?.join('')
-        : velement.children;
+  if (vnode.children) {
+    if (vnode.flag === Flags.ELEMENT_TEXT_CHILDREN) {
+      el.textContent = Array.isArray(vnode.children) ? vnode.children?.join('') : vnode.children;
     } else {
-      for (let i = 0; i < velement.children.length; ++i) {
-        el.appendChild(createElement(velement.children[i], false));
+      for (let i = 0; i < vnode.children.length; ++i) {
+        el.appendChild(createElement(vnode.children[i], false));
       }
     }
   }
diff --git a/packages/million/drivers/useChildren.ts b/packages/million/drivers/useChildren.ts
index 6ce2dd9..26f0825 100644
--- a/packages/million/drivers/useChildren.ts
+++ b/packages/million/drivers/useChildren.ts
@@ -91,7 +91,7 @@ export const useChildren =
     // Flags allow for greater optimizability by reducing condition branches.
     // Generally, you should use a compiler to generate these flags, but
     // hand-writing them is also possible
-    if (!newVNodeChildren || newVNode.flag === Flags.NO_CHILDREN) {
+    if (!newVNodeChildren || newVNode.flag === Flags.ELEMENT_NO_CHILDREN) {
       if (!oldVNodeChildren) return finish(el);
 
       effects.push({
@@ -265,7 +265,7 @@ export const useChildren =
      *    d: 2, // <- check
      *  }
      */
-    if (newVNode.flag === Flags.ONLY_KEYED_CHILDREN) {
+    if (newVNode.flag === Flags.ELEMENT_KEYED_CHILDREN) {
       if (!el[NODE_OBJECT_POOL_FIELD]) el[NODE_OBJECT_POOL_FIELD] = new Map<string, DOMNode>();
 
       let oldHead = 0;
@@ -380,7 +380,7 @@ export const useChildren =
       return finish(el);
     }
 
-    if (newVNode.flag === Flags.ONLY_TEXT_CHILDREN) {
+    if (newVNode.flag === Flags.ELEMENT_TEXT_CHILDREN) {
       const oldString = Array.isArray(oldVNode?.children)
         ? oldVNode?.children.join('')
         : oldVNode?.children;
@@ -396,7 +396,7 @@ export const useChildren =
       return finish(el);
     }
 
-    if (newVNode.flag === undefined || newVNode.flag === Flags.ANY_CHILDREN) {
+    if (newVNode.flag === undefined || newVNode.flag === Flags.ELEMENT) {
       if (oldVNodeChildren && newVNodeChildren) {
         const commonLength = Math.min(oldVNodeChildren.length, newVNodeChildren.length);
 
diff --git a/packages/million/drivers/useNode.ts b/packages/million/drivers/useNode.ts
index 3b0d59e..fa78125 100644
--- a/packages/million/drivers/useNode.ts
+++ b/packages/million/drivers/useNode.ts
@@ -11,7 +11,6 @@ import {
   OLD_VNODE_FIELD,
   VEntity,
   VNode,
-  VTypes,
 } from '../types';
 
 /**
@@ -72,57 +71,55 @@ export const useNode = (drivers: any[]): any => {
         typeof resolvedNewVNode === 'object'
       ) {
         if (
-          resolvedNewVNode.flag === Flags.IGNORE_NODE ||
-          resolvedOldVNode.flag === Flags.IGNORE_NODE
+          resolvedNewVNode.flag === Flags.ELEMENT_IGNORE ||
+          resolvedOldVNode.flag === Flags.ELEMENT_IGNORE
         ) {
           return finish(el);
         }
-        if (resolvedOldVNode.type === VTypes.ELEMENT && resolvedNewVNode.type === VTypes.ELEMENT) {
-          if (
-            resolvedNewVNode.flag === Flags.REPLACE_NODE ||
-            resolvedOldVNode.flag === Flags.REPLACE_NODE
-          ) {
-            const newEl = createElement(newVNode);
-            el.replaceWith(newEl);
-            return finish(el);
-          }
+        if (
+          resolvedNewVNode.flag === Flags.ELEMENT_SKIP_DIFF ||
+          resolvedOldVNode.flag === Flags.ELEMENT_SKIP_DIFF
+        ) {
+          const newEl = createElement(newVNode);
+          el.replaceWith(newEl);
+          return finish(el);
+        }
 
-          // We handle two cases here:
-          // 1. Both keys are undefined so no comparison necessary
-          // 2. Keys are not the same
-          if (
-            (resolvedOldVNode.key === undefined && resolvedNewVNode.key === undefined) ||
-            resolvedOldVNode.key !== resolvedNewVNode?.key
-          ) {
-            if (resolvedOldVNode.tag !== resolvedNewVNode.tag) {
-              const newEl = createElement(resolvedNewVNode, false);
-              effects.push({
-                type: EffectTypes.REPLACE,
-                flush: () => el.replaceWith(newEl),
-              });
-              return finish(newEl);
-            }
+        // We handle two cases here:
+        // 1. Both keys are undefined so no comparison necessary
+        // 2. Keys are not the same
+        if (
+          (resolvedOldVNode.key === undefined && resolvedNewVNode.key === undefined) ||
+          resolvedOldVNode.key !== resolvedNewVNode?.key
+        ) {
+          if (resolvedOldVNode.tag !== resolvedNewVNode.tag) {
+            const newEl = createElement(resolvedNewVNode, false);
+            effects.push({
+              type: EffectTypes.REPLACE,
+              flush: () => el.replaceWith(newEl),
+            });
+            return finish(newEl);
+          }
 
-            for (let i = 0; i < drivers.length; ++i) {
-              commit(
-                () => {
-                  (<Driver>drivers[i])(
-                    el,
-                    resolvedNewVNode,
-                    resolvedOldVNode,
-                    commit,
-                    effects,
-                    nodeDriver,
-                  );
-                },
-                {
+          for (let i = 0; i < drivers.length; ++i) {
+            commit(
+              () => {
+                (<Driver>drivers[i])(
                   el,
-                  newVNode: resolvedNewVNode,
-                  oldVNode: resolvedOldVNode,
+                  resolvedNewVNode,
+                  resolvedOldVNode,
+                  commit,
                   effects,
-                },
-              );
-            }
+                  nodeDriver,
+                );
+              },
+              {
+                el,
+                newVNode: resolvedNewVNode,
+                oldVNode: resolvedOldVNode,
+                effects,
+              },
+            );
           }
         }
       }
diff --git a/packages/million/m.ts b/packages/million/m.ts
index 76bea2c..9a45754 100644
--- a/packages/million/m.ts
+++ b/packages/million/m.ts
@@ -4,10 +4,10 @@ import {
   DOMNode,
   Flags,
   VElement,
+  VElementFlags,
   VEntity,
   VNode,
   VProps,
-  VTypes,
 } from './types';
 
 /**
@@ -84,11 +84,11 @@ export const entity = (
     data.key = undefined;
   }
   return {
+    flag: Flags.ENTITY,
     data,
     resolve,
     el,
     key,
-    type: VTypes.ENTITY,
   };
 };
 
@@ -99,7 +99,7 @@ export const m = (
   tag: string,
   props?: VProps,
   children?: VNode[],
-  flag?: Flags,
+  flag: VElementFlags = Flags.ELEMENT,
   delta?: Delta[],
 ): VElement => {
   let key = undefined;
@@ -114,13 +114,12 @@ export const m = (
     key,
     flag,
     delta,
-    type: VTypes.ELEMENT,
   };
   return velement.tag.toLowerCase() === 'svg' ? svg(velement) : velement;
 };
 
 export const resolveVNode = (entity?: VNode | VEntity): VNode | null | undefined => {
-  if (typeof entity === 'object' && entity.type === VTypes.ENTITY) {
+  if (typeof entity === 'object' && entity.flag === Flags.ENTITY) {
     return resolveVNode(entity.resolve());
   }
   return entity;
diff --git a/packages/million/types.ts b/packages/million/types.ts
index 1ed6106..cb46234 100644
--- a/packages/million/types.ts
+++ b/packages/million/types.ts
@@ -22,6 +22,7 @@ export type VNode = VElement | string;
 export type Delta = [DeltaTypes, number];
 export type Hook = (el?: DOMNode, newVNode?: VNode, oldVNode?: VNode) => boolean;
 export type Commit = (work: () => void, data: ReturnType<Driver>) => void;
+export type VElementFlags = Exclude<Flags, Flags.ENTITY>;
 export type Driver = (
   el: DOMNode,
   newVNode?: VNode,
@@ -44,30 +45,31 @@ export interface Effect {
 }
 
 export interface VEntity {
-  type: VTypes.ENTITY;
-  el?: DOMNode;
-  key?: string;
+  flag: Flags.ENTITY;
   data: Record<string, unknown>;
   resolve: () => VNode;
+  el?: DOMNode;
+  key?: string;
 }
 
 export interface VElement {
-  type: VTypes.ELEMENT;
+  flag: VElementFlags;
   tag: string;
   props?: VProps;
   children?: VNode[];
   key?: string;
-  flag?: Flags;
   delta?: Delta[];
 }
 
 export enum Flags {
-  IGNORE_NODE,
-  REPLACE_NODE,
-  NO_CHILDREN,
-  ONLY_TEXT_CHILDREN,
-  ONLY_KEYED_CHILDREN,
-  ANY_CHILDREN,
+  ENTITY,
+  ELEMENT,
+  ELEMENT_LEAF,
+  ELEMENT_IGNORE,
+  ELEMENT_SKIP_DIFF,
+  ELEMENT_NO_CHILDREN,
+  ELEMENT_TEXT_CHILDREN,
+  ELEMENT_KEYED_CHILDREN,
 }
 
 export enum EffectTypes {
@@ -84,8 +86,3 @@ export const enum DeltaTypes {
   UPDATE,
   REMOVE,
 }
-
-export const enum VTypes {
-  ELEMENT,
-  ENTITY,
-}
diff --git a/packages/shared/h.ts b/packages/shared/h.ts
index b951bff..64962f1 100644
--- a/packages/shared/h.ts
+++ b/packages/shared/h.ts
@@ -1,7 +1,7 @@
 import type { FC, JSXVNode } from '../jsx-runtime/types';
 import { className, Flags, m, style, svg } from '../million/index';
 import { kebab } from '../million/m';
-import type { Delta, VNode, VProps } from '../million/types';
+import type { Delta, VElementFlags, VNode, VProps } from '../million/types';
 
 export const normalize = (jsxVNode: JSXVNode): VNode | VNode[] | undefined => {
   if (Array.isArray(jsxVNode)) {
@@ -23,7 +23,7 @@ export const normalize = (jsxVNode: JSXVNode): VNode | VNode[] | undefined => {
 
 export const h = (tag: string | FC, props?: VProps, ...children: JSXVNode[]) => {
   if (typeof tag === 'function') return tag(props);
-  let flag = Flags.NO_CHILDREN;
+  let flag = Flags.ELEMENT_NO_CHILDREN;
   let delta: Delta[] | undefined;
   const normalizedChildren: VNode[] = [];
   if (props) {
@@ -36,10 +36,10 @@ export const h = (tag: string | FC, props?: VProps, ...children: JSXVNode[]) => 
   if (children) {
     const keysInChildren = new Set();
     let hasVElementChildren = false;
-    flag = Flags.ANY_CHILDREN;
+    flag = Flags.ELEMENT;
 
     if (children.every((child) => typeof child === 'string')) {
-      flag = Flags.ONLY_TEXT_CHILDREN;
+      flag = Flags.ELEMENT_TEXT_CHILDREN;
     }
     let childrenLength = 0;
     for (let i = 0; i < children.length; ++i) {
@@ -68,15 +68,15 @@ export const h = (tag: string | FC, props?: VProps, ...children: JSXVNode[]) => 
       }
     }
     if (keysInChildren.size === childrenLength) {
-      flag = Flags.ONLY_KEYED_CHILDREN;
+      flag = Flags.ELEMENT_KEYED_CHILDREN;
     }
     if (!hasVElementChildren) {
-      flag = Flags.ONLY_TEXT_CHILDREN;
+      flag = Flags.ELEMENT_TEXT_CHILDREN;
     }
   }
   if (props) {
     if (typeof props.flag === 'number') {
-      flag = <Flags>props.flag;
+      flag = props.flag;
       props.flag = undefined;
     }
     if (typeof props.className === 'object') {
@@ -91,6 +91,6 @@ export const h = (tag: string | FC, props?: VProps, ...children: JSXVNode[]) => 
     }
   }
 
-  const vnode = m(tag, props, normalizedChildren, flag, delta);
+  const vnode = m(tag, props, normalizedChildren, <VElementFlags>flag, delta);
   return tag === 'svg' ? svg(vnode) : vnode;
 };
diff --git a/pnpm-lock.yaml b/pnpm-lock.yaml
index 24b34e6..9f074df 100644
--- a/pnpm-lock.yaml
+++ b/pnpm-lock.yaml
@@ -6,7 +6,7 @@ specifiers:
   '@picocss/pico': ^1.5.0
   '@types/benchmark': ^2.1.1
   '@types/canvas-confetti': ^1.4.2
-  '@types/lodash': ^4.14.180
+  '@types/lodash': ^4.14.181
   '@types/node': ^17.0.23
   '@types/virtual-dom': ^2.1.1
   '@typescript-eslint/eslint-plugin': ^5.17.0
@@ -50,7 +50,7 @@ devDependencies:
   '@picocss/pico': 1.5.0
   '@types/benchmark': 2.1.1
   '@types/canvas-confetti': 1.4.2
-  '@types/lodash': 4.14.180
+  '@types/lodash': 4.14.181
   '@types/node': 17.0.23
   '@types/virtual-dom': 2.1.1
   '@typescript-eslint/eslint-plugin': 5.17.0_689ff565753ecf7c3328c07fad067df5
@@ -732,8 +732,8 @@ packages:
       '@types/node': 17.0.23
     dev: true
 
-  /@types/lodash/4.14.180:
-    resolution: {integrity: sha512-XOKXa1KIxtNXgASAnwj7cnttJxS4fksBRywK/9LzRV5YxrF80BXZIGeQSuoESQ/VkUj30Ae0+YcuHc15wJCB2g==}
+  /@types/lodash/4.14.181:
+    resolution: {integrity: sha512-n3tyKthHJbkiWhDZs3DkhkCzt2MexYHXlX0td5iMplyfwketaOeKboEVBqzceH7juqvEg3q5oUoBFxSLu7zFag==}
     dev: true
 
   /@types/minimist/1.2.2:
diff --git a/test/m.test.ts b/test/m.test.ts
index dbcc2da..001c1de 100644
--- a/test/m.test.ts
+++ b/test/m.test.ts
@@ -1,6 +1,6 @@
 import { describe, expect, it } from 'vitest';
 import { className, Deltas, kebab, m, ns, style, svg } from '../packages/million/m';
-import { DeltaTypes, VElement, VNode, VTypes } from '../packages/million/types';
+import { DeltaTypes, Flags, VElement, VNode } from '../packages/million/types';
 
 export const expectEqualVNode = (vnode1: VNode, vnode2: VNode) => {
   expect(JSON.stringify(vnode1)).toEqual(JSON.stringify(vnode2));
@@ -8,14 +8,14 @@ export const expectEqualVNode = (vnode1: VNode, vnode2: VNode) => {
 
 describe.concurrent('m', () => {
   it('should create empty vnode with tag', () => {
-    expectEqualVNode(m('div'), { tag: 'div', type: VTypes.ELEMENT });
+    expectEqualVNode(m('div'), { tag: 'div', flag: Flags.ELEMENT });
   });
 
   it('should create vnode with tag and props', () => {
     expectEqualVNode(m('div', { id: 'app' }), {
       tag: 'div',
       props: { id: 'app' },
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     });
   });
 
@@ -23,7 +23,7 @@ describe.concurrent('m', () => {
     expectEqualVNode(m('div', undefined, ['foo']), {
       tag: 'div',
       children: ['foo'],
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     });
   });
 
@@ -31,7 +31,7 @@ describe.concurrent('m', () => {
     expectEqualVNode(m('div', undefined, ['foo', 'bar', 'baz']), {
       tag: 'div',
       children: ['foo', 'bar', 'baz'],
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     });
   });
 
@@ -41,10 +41,10 @@ describe.concurrent('m', () => {
       children: [
         {
           tag: 'div',
-          type: VTypes.ELEMENT,
+          flag: Flags.ELEMENT,
         },
       ],
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     });
   });
 
@@ -54,16 +54,16 @@ describe.concurrent('m', () => {
       children: [
         {
           tag: 'div',
-          type: VTypes.ELEMENT,
+          flag: Flags.ELEMENT,
         },
         'foo',
         {
           tag: 'div',
-          type: VTypes.ELEMENT,
+          flag: Flags.ELEMENT,
         },
         'bar',
       ],
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     });
   });
 
@@ -88,16 +88,16 @@ describe.concurrent('m', () => {
                   {
                     tag: 'div',
                     children: ['boo'],
-                    type: VTypes.ELEMENT,
+                    flag: Flags.ELEMENT,
                   },
                 ],
-                type: VTypes.ELEMENT,
+                flag: Flags.ELEMENT,
               },
             ],
-            type: VTypes.ELEMENT,
+            flag: Flags.ELEMENT,
           },
         ],
-        type: VTypes.ELEMENT,
+        flag: Flags.ELEMENT,
       },
     );
   });
@@ -112,7 +112,7 @@ describe.concurrent('m', () => {
         },
         children: undefined,
         key: undefined,
-        type: VTypes.ELEMENT,
+        flag: Flags.ELEMENT,
       },
     );
   });
@@ -125,7 +125,7 @@ describe.concurrent('m', () => {
       },
       children: undefined,
       key: undefined,
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     });
   });
 
@@ -148,10 +148,10 @@ describe.concurrent('m', () => {
         {
           tag: 'div',
           props: {},
-          type: VTypes.ELEMENT,
+          flag: Flags.ELEMENT,
         },
       ],
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     };
     ns(vnode.tag, vnode.props!, vnode.children);
     expectEqualVNode(vnode, {
@@ -164,10 +164,10 @@ describe.concurrent('m', () => {
           props: {
             ns: 'http://www.w3.org/2000/svg',
           },
-          type: VTypes.ELEMENT,
+          flag: Flags.ELEMENT,
         },
       ],
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     });
   });
 
@@ -181,10 +181,10 @@ describe.concurrent('m', () => {
         'foo',
         {
           tag: 'div',
-          type: VTypes.ELEMENT,
+          flag: Flags.ELEMENT,
         },
       ],
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     };
     ns(vnode.tag, vnode.props!, vnode.children);
     expectEqualVNode(vnode, {
@@ -194,21 +194,21 @@ describe.concurrent('m', () => {
         'foo',
         {
           tag: 'div',
-          type: VTypes.ELEMENT,
+          flag: Flags.ELEMENT,
         },
       ],
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     });
   });
 
   it('should attach ns to props using svg helper', () => {
     const vnode: VElement = {
       tag: 'svg',
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     };
     expectEqualVNode(svg(vnode), {
       tag: 'svg',
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
       props: { ns: 'http://www.w3.org/2000/svg' },
     });
   });
@@ -221,11 +221,11 @@ describe.concurrent('m', () => {
         'foo',
         {
           tag: 'div',
-          type: VTypes.ELEMENT,
+          flag: Flags.ELEMENT,
         },
       ],
       key: 'foo',
-      type: VTypes.ELEMENT,
+      flag: Flags.ELEMENT,
     });
   });
 
diff --git a/test/render.test.ts b/test/render.test.ts
index 6ed6bfc..fcc9a2f 100644
--- a/test/render.test.ts
+++ b/test/render.test.ts
@@ -54,7 +54,7 @@ describe.concurrent('render', () => {
 
     el.textContent = 'foo';
 
-    patch(el, m('div', undefined, undefined, Flags.NO_CHILDREN));
+    patch(el, m('div', undefined, undefined, Flags.ELEMENT_NO_CHILDREN));
 
     expect(el.textContent).toEqual('');
   });
@@ -137,15 +137,15 @@ describe.concurrent('render', () => {
     const el = document.createElement('div');
     patch(
       el,
-      m('div', undefined, ['foo'], Flags.ONLY_TEXT_CHILDREN),
-      m('div', undefined, [], Flags.ONLY_TEXT_CHILDREN),
+      m('div', undefined, ['foo'], Flags.ELEMENT_TEXT_CHILDREN),
+      m('div', undefined, [], Flags.ELEMENT_TEXT_CHILDREN),
     );
     expect(el.textContent).toEqual('foo');
 
     patch(
       el,
-      m('div', undefined, [], Flags.NO_CHILDREN),
-      m('div', undefined, ['foo'], Flags.NO_CHILDREN),
+      m('div', undefined, [], Flags.ELEMENT_NO_CHILDREN),
+      m('div', undefined, ['foo'], Flags.ELEMENT_NO_CHILDREN),
     );
     expect(el.childNodes.length).toEqual(0);
   });
@@ -157,9 +157,9 @@ describe.concurrent('render', () => {
       'ul',
       undefined,
       list1.map((item) => m('li', { key: item }, [item])),
-      Flags.ONLY_KEYED_CHILDREN,
+      Flags.ELEMENT_KEYED_CHILDREN,
     );
-    patch(el, newVNode1, m('ul', undefined, undefined, Flags.NO_CHILDREN));
+    patch(el, newVNode1, m('ul', undefined, undefined, Flags.ELEMENT_NO_CHILDREN));
     expectEqualNode(el, createElement(newVNode1));
 
     const list2 = ['foo', 'baz', 'bar', 'foo1', 'bar1', 'baz1'];
@@ -167,7 +167,7 @@ describe.concurrent('render', () => {
       'ul',
       undefined,
       list2.map((item) => m('li', { key: item }, [item])),
-      Flags.ONLY_KEYED_CHILDREN,
+      Flags.ELEMENT_KEYED_CHILDREN,
     );
     patch(el, newVNode2, newVNode1);
     expectEqualNode(el, createElement(newVNode2));
@@ -177,7 +177,7 @@ describe.concurrent('render', () => {
       'ul',
       undefined,
       list3.map((item) => m('li', { key: item }, [item])),
-      Flags.ONLY_KEYED_CHILDREN,
+      Flags.ELEMENT_KEYED_CHILDREN,
     );
     patch(el, newVNode3, newVNode2);
     expectEqualNode(el, createElement(newVNode3));
@@ -187,7 +187,7 @@ describe.concurrent('render', () => {
       'ul',
       undefined,
       list4.map((item) => m('li', { key: item }, [item])),
-      Flags.ONLY_KEYED_CHILDREN,
+      Flags.ELEMENT_KEYED_CHILDREN,
     );
     patch(el, newVNode4, newVNode3);
     expectEqualNode(el, createElement(newVNode4));
@@ -197,7 +197,7 @@ describe.concurrent('render', () => {
       'ul',
       undefined,
       list5.map((item) => m('li', { key: item }, [item])),
-      Flags.ONLY_KEYED_CHILDREN,
+      Flags.ELEMENT_KEYED_CHILDREN,
     );
     patch(el, newVNode5, newVNode4);
     expectEqualNode(el, createElement(newVNode5));
@@ -207,7 +207,7 @@ describe.concurrent('render', () => {
       'ul',
       undefined,
       list6.map((item) => m('li', { key: item }, [item])),
-      Flags.ONLY_KEYED_CHILDREN,
+      Flags.ELEMENT_KEYED_CHILDREN,
     );
     patch(el, newVNode6, newVNode5);
     expectEqualNode(el, createElement(newVNode6));
@@ -217,7 +217,7 @@ describe.concurrent('render', () => {
       'ul',
       undefined,
       list7.map((item) => m('li', { key: item }, [item])),
-      Flags.ONLY_KEYED_CHILDREN,
+      Flags.ELEMENT_KEYED_CHILDREN,
     );
     patch(el, newVNode7, newVNode6);
     expectEqualNode(el, createElement(newVNode7));
",1,"[""ed9e6ed444d4c2c830b498cee4665cbf1aaad84d""]","[""refactor""]"
Improved Config Loading #423,"diff --git a/CHANGELOG.md b/CHANGELOG.md
index 76dd749..2087803 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -7,6 +7,7 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
 ## [Unreleased]
 * Fix the tab '(Sync)' suffix in named tabs (https://github.com/zellij-org/zellij/pull/410)
 * Improve performance when multiple panes are open (https://github.com/zellij-org/zellij/pull/318)
+* Improve error reporting and tests of configuration (https://github.com/zellij-org/zellij/pull/423)
 
 ## [0.6.0] - 2021-04-29
 * Doesn't quit anymore on single `q` press while in tab mode  (https://github.com/zellij-org/zellij/pull/342)
",1,"[""099861ff5b0f83773ca0af4c70e6e39be3b0336c""]","[""docs""]"
[gn] fix include_dirs ordering error | better layout for block and segment,"diff --git a/BUILD.gn b/BUILD.gn
index 11adaa7..ed64b17 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -240,6 +240,14 @@ static_library(""electron_lib"") {
     ""brightray"",
     ""build/node"",
   ]
+  include_dirs = [
+    ""chromium_src"",
+    ""."",
+    ""$target_gen_dir"",
+    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
+    # API of blink, then delete this include dir.
+    ""//third_party/WebKit/Source"",
+  ]
   if (enable_desktop_capturer) {
     deps += [ ""//third_party/webrtc/modules/desktop_capture"" ]
   }
@@ -275,14 +283,6 @@ static_library(""electron_lib"") {
     # Disable warnings for g_settings_list_schemas.
     ""GLIB_DISABLE_DEPRECATION_WARNINGS"",
   ]
-  include_dirs = [
-    ""chromium_src"",
-    ""."",
-    ""$target_gen_dir"",
-    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
-    # API of blink, then delete this include dir.
-    ""//third_party/WebKit/Source"",
-  ]
   if (is_component_build) {
     defines += [
       # Import V8 symbols from shared library (node.dll / libnode.so)

diff --git a/docs/docs/config-block.md b/docs/docs/config-block.md
new file mode 100644
index 0000000..df1ee54
--- /dev/null
+++ b/docs/docs/config-block.md
@@ -0,0 +1,60 @@
+---
+id: config-block
+title: Block
+sidebar_label: Block
+---
+
+Let's take a closer look at what defines a block.
+
+```json
+{
+  ""$schema"": ""https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/schema.json"",
+  ...
+  ""blocks"": [
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""left"",
+      ""segments"": [
+        ...
+      ]
+    }
+  ]
+}
+```
+
+- type: `prompt` | `rprompt`
+- newline: `boolean`
+- alignment: `left` | `right`
+- vertical_offset: `int`
+- horizontal_offset: `int`
+- segments: `array` of one or more `segments`
+
+### Type
+
+Tells the engine what to do with the block. There are three options:
+
+- `prompt` renders one or more segments
+- `rprompt` renders one or more segments aligned to the right of the cursor. Only one `rprompt` block is permitted.
+Supported on [ZSH][rprompt], Bash and Powershell.
+
+### Newline
+
+Start the block on a new line. Defaults to `false`.
+
+### Alignment
+
+Tell the engine if the block should be left or right-aligned.
+
+### Vertical offset
+
+Move the block up or down x lines. For example, `vertical_offset: 1` moves the prompt down one line, `vertical_offset: -1`
+moves it up one line.
+
+### Horizontal offset
+
+Moves the segment to the left or the right to have it exactly where you want it to be. Works like `vertical_offset`
+but on a horizontal level where a negative number moves the block left and a positive number right.
+
+### Segments
+
+Array of one or more segments.
diff --git a/docs/docs/config-example.md b/docs/docs/config-example.md
new file mode 100644
index 0000000..c180c4f
--- /dev/null
+++ b/docs/docs/config-example.md
@@ -0,0 +1,96 @@
+---
+id: config-sample
+title: Sample
+sidebar_label: Sample
+---
+
+```json
+{
+  ""final_space"": true,
+  ""blocks"": [
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""right"",
+      ""vertical_offset"": -1,
+      ""segments"": [
+        {
+          ""type"": ""time"",
+          ""style"": ""plain"",
+          ""foreground"": ""#007ACC"",
+          ""properties"": {
+            ""time_format"": ""15:04:05""
+          }
+        }
+      ]
+    },
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""left"",
+      ""newline"": true,
+      ""segments"": [
+        {
+          ""type"": ""session"",
+          ""style"": ""diamond"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#ffb300"",
+          ""leading_diamond"": ""\uE0B6"",
+          ""trailing_diamond"": ""\uE0B0"",
+          ""properties"": {
+            ""postfix"": "" ""
+          }
+        },
+        {
+          ""type"": ""path"",
+          ""style"": ""powerline"",
+          ""powerline_symbol"": ""\uE0B0"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#61AFEF"",
+          ""properties"": {
+            ""prefix"": "" \uE5FF "",
+            ""style"": ""folder"",
+            ""exclude_folders"": [
+              ""/super/secret/project""
+            ],
+            ""enable_hyperlink"": false
+          }
+        },
+        {
+          ""type"": ""git"",
+          ""style"": ""powerline"",
+          ""foreground"": ""#193549"",
+          ""foreground_templates"": [
+            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#ffffff{{ end }}""
+          ],
+          ""background"": ""#2e9599"",
+          ""background_templates"": [
+            ""{{ if or (.Working.Changed) (.Staging.Changed) }}#f36943{{ end }}"",
+            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#a8216b{{ end }}"",
+            ""{{ if gt .Ahead 0 }}#35b5ff{{ end }}"",
+            ""{{ if gt .Behind 0 }}#f89cfa{{ end }}""
+          ],
+          ""powerline_symbol"": ""\uE0B0"",
+          ""properties"": {
+            ""fetch_status"": true,
+            ""branch_max_length"": 25,
+            ""template"": ""{{ .HEAD }}{{ .BranchStatus }}""
+          }
+        },
+        {
+          ""type"": ""exit"",
+          ""style"": ""diamond"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#00897b"",
+          ""background_templates"": [""{{ if gt .Code 0 }}#e91e63{{ end }}""],
+          ""leading_diamond"": """",
+          ""trailing_diamond"": ""\uE0B4"",
+          ""properties"": {
+            ""always_enabled"": true,
+            ""template"": ""\uE23A"",
+            ""prefix"": ""<parentBackground>\uE0B0</> ""
+          }
+        }
+      ]
+    }
+  ]
+}
+```
diff --git a/docs/docs/config-overview.md b/docs/docs/config-overview.md
index 1fdbcba..b554869 100644
--- a/docs/docs/config-overview.md
+++ b/docs/docs/config-overview.md
@@ -1,7 +1,7 @@
 ---
 id: config-overview
-title: Overview
-sidebar_label: Overview
+title: General
+sidebar_label: General
 ---
 
 Oh My Posh renders your prompt based on the definition of _blocks_ (like Lego) which contain one or more _segments_.
@@ -64,332 +64,7 @@ boxes with question marks, set up your terminal to use a [supported font][font] 
 - terminal_background: `string` [color][colors] - terminal background color, set to your terminal's background color when
 you notice black elements in Windows Terminal or the Visual Studio Code integrated terminal
 
-## Block
-
-Let's take a closer look at what defines a block.
-
-- type: `prompt` | `rprompt`
-- newline: `boolean`
-- alignment: `left` | `right`
-- vertical_offset: `int`
-- horizontal_offset: `int`
-- segments: `array` of one or more `segments`
-
-### Type
-
-Tells the engine what to do with the block. There are three options:
-
-- `prompt` renders one or more segments
-- `rprompt` renders one or more segments aligned to the right of the cursor. Only one `rprompt` block is permitted.
-Supported on [ZSH][rprompt], Bash and Powershell.
-
-### Newline
-
-Start the block on a new line. Defaults to `false`.
-
-### Alignment
-
-Tell the engine if the block should be left or right-aligned.
-
-### Vertical offset
-
-Move the block up or down x lines. For example, `vertical_offset: 1` moves the prompt down one line, `vertical_offset: -1`
-moves it up one line.
-
-### Horizontal offset
-
-Moves the segment to the left or the right to have it exactly where you want it to be. Works like `vertical_offset`
-but on a horizontal level where a negative number moves the block left and a positive number right.
-
-### Segments
-
-Array of one or more segments.
-
-## Segment
-
-A segment is a part of the prompt with a certain context. There are different types available out-of-the-box, if you're
-looking for what's included, feel free to skip this part and browse through the [segments][segments]. Keep reading to
-understand how to configure a segment.
-
-- type: `string` any of the included [segments][segments]
-- style: `powerline` | `plain` | `diamond`
-- powerline_symbol: `string`
-- invert_powerline: `boolean`
-- leading_diamond: `string`
-- trailing_diamond: `string`
-- foreground: `string` [color][colors]
-- foreground_templates: `array` of `string` values
-- background: `string` [color][colors]
-- background_templates: `array` of `string` values
-- properties: `array` of `Property`: `string`
-
-### Type
-
-Takes the `string` value referencing which segment logic it needs to run (see [segments][segments] for possible values).
-
-### Style
-
-Oh Hi! You made it to a really interesting part, great! Style defines how a prompt is rendered. Looking at the most prompt
-themes out there, we identified 3 types. All of these require a different configuration and depending on the look
-you want to achieve you might need to understand/use them all.
-
-#### Powerline
-
-What started it all for us. Makes use of a single symbol (`powerline_symbol`) to separate the segments. It takes the
-background color of the previous segment (or transparent if none) and the foreground of the current one (or transparent
-if we're at the last segment). Expects segments to have a colored background, else there little use for this one.
-
-#### Plain
-
-Simple. Colored text on a transparent background. Make sure to set `foreground` for maximum enjoyment.
-Segments will be separated by empty spaces unless you specify `''` for the `prefix` and `postfix` settings for the segment.
-
-#### Diamond
-
-While Powerline works great with a single symbol, sometimes you want a segment to have a different start and end symbol.
-Just like a diamond: `< my segment text >`. The difference between this and plain is that the diamond symbols take the
-segment background as their foreground color.
-
-### Powerline symbol
-
-Text character to use when `""style"": ""powerline""`.
-
-### Invert Powerline
-
-If `true` this swaps the foreground and background colors. Can be useful when the character you want does not exist
-in the perfectly mirrored variant for example.
-
-### Leading diamond
-
-Text character to use at the start of the segment. Will take the background color of the segment as
-its foreground color.
-
-### Trailing diamond
-
-Text character to use at the end of the segment. Will take the background color of the segment as its foreground color.
-
-### Foreground
-
-[Color][colors] to use as the segment text foreground color. Also supports transparency using the `transparent` keyword.
-
-### Foreground Templates
-
-Array if string templates to define the foreground color for the given Segment based on the Segment's Template Properties.
-Under the hood this uses go's [text/template][go-text-template] feature extended with [sprig][sprig] and
-offers a few standard properties to work with. For supported Segments, look for the **Template Properties** section in
-the documentation.
-
-The following sample is based on the [AWS Segment][aws].
-
-```json
-{
-  ""type"": ""aws"",
-  ""style"": ""powerline"",
-  ""powerline_symbol"": ""\uE0B0"",
-  ""foreground"": ""#ffffff"",
-  ""background"": ""#111111"",
-  ""foreground_templates"": [
-    ""{{if contains \""default\"" .Profile}}#FFA400{{end}}"",
-    ""{{if contains \""jan\"" .Profile}}#f1184c{{end}}""
-  ],
-  ""properties"": {
-    ""prefix"": "" \uE7AD ""
-  }
-}
-```
-
-The logic is as follows: when `background_templates` contains an array, we will check every template line until there's
-one that returns a non-empty string. So, when the contents of `.Profile` contain the word `default`, the first template
-returns `#FFA400` and that's the color that will be used. If it contains `jan`, it returns `#f1184c`. When none of the
-templates returns a value, the foreground value `#ffffff` is used.
-
-### Background
-
-[Color][colors] to use as the segment text background color. Also supports transparency using the `transparent` keyword.
-
-### Background Templates
-
-Same as [Foreground Templates][fg-templ] but for the background color.
-
-### Properties
-
-An array of **Properties** with a value. This is used inside of the segment logic to tweak what the output of the segment
-will be. Segments have the ability to define their own Properties, but there are some general ones being used by the
-engine which allow you to customize the output even more.
-
-#### General-purpose properties
-
-You can use these on any segment, the engine is responsible for adding them correctly.
-
-- prefix: `string`
-- postfix: `string`
-- include_folders: `[]string`
-- exclude_folders: `[]string`
-
-##### Prefix
-
-The string content will be put in front of the segment's output text. Useful for symbols, text or other customizations.
-If this is not set, it will be an empty space in `plain` mode. If you want to remove the space before the segment,
-specify this as `''`.
-
-##### Postfix
-
-The string content will be put after the segment's output text. Useful for symbols, text or other customizations.
-If this is not set, it will default to an empty space in `plain` mode. If you want to remove the space after the segment,
-specify this as `''`.
-
-##### Include / Exclude Folders
-
-Sometimes you might want to have a segment only rendered in certain folders. If `include_folders` is specified,
-the segment will only be rendered when in one of those locations. If `exclude_folders` is specified, the segment
-will not be rendered when in one of the excluded locations.
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects""
-]
-```
-
-```json
-""exclude_folders"": [
-  ""/Users/posh/Projects""
-]
-```
-
-The strings specified in these properties are evaluated as [regular expressions][regex]. You
-can use any valid regular expression construct, but the regular expression must match the entire directory
-name. The following will match `/Users/posh/Projects/Foo` but not `/home/Users/posh/Projects/Foo`.
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects.*""
-]
-```
-
-You can also combine these properties:
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects.*""
-],
-""exclude_folders"": [
-  ""/Users/posh/Projects/secret-project.*""
-]
-```
-
-##### Notes
-
-- Oh My Posh will accept both `/` and `\` as path separators for a folder and will match regardless of which
-is used by the current operating system.
-- Because the strings are evaluated as regular expressions, if you want to use a `\` in a Windows
-directory name, you need to specify it as `\\\\`.
-- The character `~` at the start of a specified folder will match the user's home directory.
-- The comparison is case-insensitive on Windows and macOS, but case-sensitive on other operating systems.
-
-This means that for user Bill, who has a user account `Bill` on Windows and `bill` on Linux,  `~/Foo` might match
-`C:\Users\Bill\Foo` or `C:\Users\Bill\foo` on Windows but only `/home/bill/Foo` on Linux.
-
-## Full Sample
-
-```json
-{
-  ""final_space"": true,
-  ""blocks"": [
-    {
-      ""type"": ""prompt"",
-      ""alignment"": ""right"",
-      ""vertical_offset"": -1,
-      ""segments"": [
-        {
-          ""type"": ""time"",
-          ""style"": ""plain"",
-          ""foreground"": ""#007ACC"",
-          ""properties"": {
-            ""time_format"": ""15:04:05""
-          }
-        }
-      ]
-    },
-    {
-      ""type"": ""prompt"",
-      ""alignment"": ""left"",
-      ""newline"": true,
-      ""segments"": [
-        {
-          ""type"": ""session"",
-          ""style"": ""diamond"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#ffb300"",
-          ""leading_diamond"": ""\uE0B6"",
-          ""trailing_diamond"": ""\uE0B0"",
-          ""properties"": {
-            ""postfix"": "" ""
-          }
-        },
-        {
-          ""type"": ""path"",
-          ""style"": ""powerline"",
-          ""powerline_symbol"": ""\uE0B0"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#61AFEF"",
-          ""properties"": {
-            ""prefix"": "" \uE5FF "",
-            ""style"": ""folder"",
-            ""exclude_folders"": [
-              ""/super/secret/project""
-            ],
-            ""enable_hyperlink"": false
-          }
-        },
-        {
-          ""type"": ""git"",
-          ""style"": ""powerline"",
-          ""foreground"": ""#193549"",
-          ""foreground_templates"": [
-            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#ffffff{{ end }}""
-          ],
-          ""background"": ""#2e9599"",
-          ""background_templates"": [
-            ""{{ if or (.Working.Changed) (.Staging.Changed) }}#f36943{{ end }}"",
-            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#a8216b{{ end }}"",
-            ""{{ if gt .Ahead 0 }}#35b5ff{{ end }}"",
-            ""{{ if gt .Behind 0 }}#f89cfa{{ end }}""
-          ],
-          ""powerline_symbol"": ""\uE0B0"",
-          ""properties"": {
-            ""fetch_status"": true,
-            ""branch_max_length"": 25,
-            ""template"": ""{{ .HEAD }}{{ .BranchStatus }}""
-          }
-        },
-        {
-          ""type"": ""exit"",
-          ""style"": ""diamond"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#00897b"",
-          ""background_templates"": [""{{ if gt .Code 0 }}#e91e63{{ end }}""],
-          ""leading_diamond"": """",
-          ""trailing_diamond"": ""\uE0B4"",
-          ""properties"": {
-            ""always_enabled"": true,
-            ""template"": ""\uE23A"",
-            ""prefix"": ""<parentBackground>\uE0B0</> ""
-          }
-        }
-      ]
-    }
-  ]
-}
-```
-
 [releases]: https://github.com/JanDeDobbeleer/oh-my-posh/releases/latest
 [font]: /docs/config-fonts
 [schema]: https://github.com/JanDeDobbeleer/oh-my-posh/blob/main/themes/schema.json
 [themes]: https://github.com/JanDeDobbeleer/oh-my-posh/tree/main/themes
-[segments]: /docs/battery
-[colors]: /docs/config-colors
-[go-text-template]: https://golang.org/pkg/text/template/
-[sprig]: https://masterminds.github.io/sprig/
-[fg-templ]: /docs/config-overview#foreground-templates
-[regex]: https://www.regular-expressions.info/tutorial.html
-[aws]: /docs/aws
diff --git a/docs/docs/config-segment.md b/docs/docs/config-segment.md
new file mode 100644
index 0000000..08a66e4
--- /dev/null
+++ b/docs/docs/config-segment.md
@@ -0,0 +1,219 @@
+---
+id: config-segment
+title: Segment
+sidebar_label: Segment
+---
+
+A segment is a part of the prompt with a certain context. There are different types available out-of-the-box, if you're
+looking for what's included, feel free to skip this part and browse through the [segments][segments]. Keep reading to
+understand how to configure a segment.
+
+```json
+{
+  ""$schema"": ""https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/schema.json"",
+  ...
+  ""blocks"": [
+    {
+      ...
+      ""segments"": [
+        {
+          ""type"": ""path"",
+          ""style"": ""powerline"",
+          ""powerline_symbol"": ""\uE0B0"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#61AFEF"",
+          ""properties"": {
+            ...
+          }
+        }
+      ]
+    }
+  ]
+}
+```
+
+- type: `string` any of the included [segments][segments]
+- style: `powerline` | `plain` | `diamond`
+- powerline_symbol: `string`
+- invert_powerline: `boolean`
+- leading_diamond: `string`
+- trailing_diamond: `string`
+- foreground: `string` [color][colors]
+- foreground_templates: `array` of `string` values
+- background: `string` [color][colors]
+- background_templates: `array` of `string` values
+- properties: `array` of `Property`: `string`
+
+## Type
+
+Takes the `string` value referencing which segment logic it needs to run (see [segments][segments] for possible values).
+
+## Style
+
+Oh Hi! You made it to a really interesting part, great! Style defines how a prompt is rendered. Looking at the most prompt
+themes out there, we identified 3 types. All of these require a different configuration and depending on the look
+you want to achieve you might need to understand/use them all.
+
+### Powerline
+
+What started it all for us. Makes use of a single symbol (`powerline_symbol`) to separate the segments. It takes the
+background color of the previous segment (or transparent if none) and the foreground of the current one (or transparent
+if we're at the last segment). Expects segments to have a colored background, else there little use for this one.
+
+### Plain
+
+Simple. Colored text on a transparent background. Make sure to set `foreground` for maximum enjoyment.
+Segments will be separated by empty spaces unless you specify `''` for the `prefix` and `postfix` settings for the segment.
+
+### Diamond
+
+While Powerline works great with a single symbol, sometimes you want a segment to have a different start and end symbol.
+Just like a diamond: `< my segment text >`. The difference between this and plain is that the diamond symbols take the
+segment background as their foreground color.
+
+## Powerline symbol
+
+Text character to use when `""style"": ""powerline""`.
+
+## Invert Powerline
+
+If `true` this swaps the foreground and background colors. Can be useful when the character you want does not exist
+in the perfectly mirrored variant for example.
+
+## Leading diamond
+
+Text character to use at the start of the segment. Will take the background color of the segment as
+its foreground color.
+
+## Trailing diamond
+
+Text character to use at the end of the segment. Will take the background color of the segment as its foreground color.
+
+## Foreground
+
+[Color][colors] to use as the segment text foreground color. Also supports transparency using the `transparent` keyword.
+
+## Foreground Templates
+
+Array if string templates to define the foreground color for the given Segment based on the Segment's Template Properties.
+Under the hood this uses go's [text/template][go-text-template] feature extended with [sprig][sprig] and
+offers a few standard properties to work with. For supported Segments, look for the **Template Properties** section in
+the documentation.
+
+The following sample is based on the [AWS Segment][aws].
+
+```json
+{
+  ""type"": ""aws"",
+  ""style"": ""powerline"",
+  ""powerline_symbol"": ""\uE0B0"",
+  ""foreground"": ""#ffffff"",
+  ""background"": ""#111111"",
+  ""foreground_templates"": [
+    ""{{if contains \""default\"" .Profile}}#FFA400{{end}}"",
+    ""{{if contains \""jan\"" .Profile}}#f1184c{{end}}""
+  ],
+  ""properties"": {
+    ""prefix"": "" \uE7AD ""
+  }
+}
+```
+
+The logic is as follows: when `background_templates` contains an array, we will check every template line until there's
+one that returns a non-empty string. So, when the contents of `.Profile` contain the word `default`, the first template
+returns `#FFA400` and that's the color that will be used. If it contains `jan`, it returns `#f1184c`. When none of the
+templates returns a value, the foreground value `#ffffff` is used.
+
+## Background
+
+[Color][colors] to use as the segment text background color. Also supports transparency using the `transparent` keyword.
+
+## Background Templates
+
+Same as [Foreground Templates][fg-templ] but for the background color.
+
+## Properties
+
+An array of **Properties** with a value. This is used inside of the segment logic to tweak what the output of the segment
+will be. Segments have the ability to define their own Properties, but there are some general ones being used by the
+engine which allow you to customize the output even more.
+
+### General-purpose properties
+
+You can use these on any segment, the engine is responsible for adding them correctly.
+
+- prefix: `string`
+- postfix: `string`
+- include_folders: `[]string`
+- exclude_folders: `[]string`
+
+#### Prefix
+
+The string content will be put in front of the segment's output text. Useful for symbols, text or other customizations.
+If this is not set, it will be an empty space in `plain` mode. If you want to remove the space before the segment,
+specify this as `''`.
+
+#### Postfix
+
+The string content will be put after the segment's output text. Useful for symbols, text or other customizations.
+If this is not set, it will default to an empty space in `plain` mode. If you want to remove the space after the segment,
+specify this as `''`.
+
+#### Include / Exclude Folders
+
+Sometimes you might want to have a segment only rendered in certain folders. If `include_folders` is specified,
+the segment will only be rendered when in one of those locations. If `exclude_folders` is specified, the segment
+will not be rendered when in one of the excluded locations.
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects""
+]
+```
+
+```json
+""exclude_folders"": [
+  ""/Users/posh/Projects""
+]
+```
+
+The strings specified in these properties are evaluated as [regular expressions][regex]. You
+can use any valid regular expression construct, but the regular expression must match the entire directory
+name. The following will match `/Users/posh/Projects/Foo` but not `/home/Users/posh/Projects/Foo`.
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects.*""
+]
+```
+
+You can also combine these properties:
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects.*""
+],
+""exclude_folders"": [
+  ""/Users/posh/Projects/secret-project.*""
+]
+```
+
+#### Notes
+
+- Oh My Posh will accept both `/` and `\` as path separators for a folder and will match regardless of which
+is used by the current operating system.
+- Because the strings are evaluated as regular expressions, if you want to use a `\` in a Windows
+directory name, you need to specify it as `\\\\`.
+- The character `~` at the start of a specified folder will match the user's home directory.
+- The comparison is case-insensitive on Windows and macOS, but case-sensitive on other operating systems.
+
+This means that for user Bill, who has a user account `Bill` on Windows and `bill` on Linux,  `~/Foo` might match
+`C:\Users\Bill\Foo` or `C:\Users\Bill\foo` on Windows but only `/home/bill/Foo` on Linux.
+
+[segments]: /docs/battery
+[colors]: /docs/config-colors
+[go-text-template]: https://golang.org/pkg/text/template/
+[sprig]: https://masterminds.github.io/sprig/
+[fg-templ]: /docs/config-overview#foreground-templates
+[regex]: https://www.regular-expressions.info/tutorial.html
+[aws]: /docs/aws
diff --git a/docs/docs/segment-environment.md b/docs/docs/segment-environment.md
index f35bc87..982a0a5 100644
--- a/docs/docs/segment-environment.md
+++ b/docs/docs/segment-environment.md
@@ -34,7 +34,7 @@ New-Alias -Name 'Set-PoshContext' -Value 'Set-EnvVar' -Scope Global -Force
 
 The segment will show when the value of the environment variable isn't empty.
 
-## Sample Configuration
+## Sample *Configuration*
 
 ```json
 {
diff --git a/docs/sidebars.js b/docs/sidebars.js
index a75163e..8f151a2 100644
--- a/docs/sidebars.js
+++ b/docs/sidebars.js
@@ -20,6 +20,9 @@ module.exports = {
       label: "" Configuration"",
       items: [
         ""config-overview"",
+        ""config-block"",
+        ""config-segment"",
+        ""config-sample"",
         ""config-title"",
         ""config-colors"",
         ""config-text-style"",
",2,"[""c44cf88a6ec54e5ddd99d8348bcc57b301ec7945"", ""cb1f48b56ae0de93acb72e48726c7d610a1d538e""]","[""build"", ""docs""]"
fix `memtable` docstrings,"diff --git a/ibis/expr/api.py b/ibis/expr/api.py
index 93fabaa..66a2ea9 100644
--- a/ibis/expr/api.py
+++ b/ibis/expr/api.py
@@ -403,15 +403,21 @@ def memtable(
     >>> import ibis
     >>> t = ibis.memtable([{""a"": 1}, {""a"": 2}])
     >>> t
+    PandasInMemoryTable
+      data:
+        DataFrameProxy:
+             a
+          0  1
+          1  2
 
     >>> t = ibis.memtable([{""a"": 1, ""b"": ""foo""}, {""a"": 2, ""b"": ""baz""}])
     >>> t
     PandasInMemoryTable
       data:
-        ((1, 'foo'), (2, 'baz'))
-      schema:
-        a int8
-        b string
+        DataFrameProxy:
+             a    b
+          0  1  foo
+          1  2  baz
 
     Create a table literal without column names embedded in the data and pass
     `columns`
@@ -420,10 +426,22 @@ def memtable(
     >>> t
     PandasInMemoryTable
       data:
-        ((1, 'foo'), (2, 'baz'))
-      schema:
-        a int8
-        b string
+        DataFrameProxy:
+             a    b
+          0  1  foo
+          1  2  baz
+
+    Create a table literal without column names embedded in the data. Ibis
+    generates column names if none are provided.
+
+    >>> t = ibis.memtable([(1, ""foo""), (2, ""baz"")])
+    >>> t
+    PandasInMemoryTable
+      data:
+        DataFrameProxy:
+             col0 col1
+          0     1  foo
+          1     2  baz
     """"""
     if columns is not None and schema is not None:
         raise NotImplementedError(
",1,"[""72bc0f5172c0a3d17bde29cfc00db4c60d2fee3a""]","[""docs""]"
split release docs build into separate workflow | don't delay rendering if initialLayout is not specified | better tested publishing flow,"diff --git a/.github/workflows/ibis-docs-lint.yml b/.github/workflows/ibis-docs-lint.yml
index 753d57d..3e0aa15 100644
--- a/.github/workflows/ibis-docs-lint.yml
+++ b/.github/workflows/ibis-docs-lint.yml
@@ -88,14 +88,14 @@ jobs:
         run: poetry run pytest --benchmark-only --benchmark-json .benchmarks/output.json ibis/tests/benchmarks
 
       - uses: tibdex/github-app-token@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         id: generate-token
         with:
           app_id: ${{ secrets.SQUAWK_BOT_APP_ID }}
           private_key: ${{ secrets.SQUAWK_BOT_APP_PRIVATE_KEY }}
 
       - uses: benchmark-action/github-action-benchmark@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         with:
           tool: pytest
           github-token: ${{ steps.generate-token.outputs.token }}
@@ -107,6 +107,7 @@ jobs:
 
   docs:
     runs-on: ubuntu-latest
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
     needs:
       # wait on benchmarks to prevent a race condition when pushing to the
       # gh-pages branch
@@ -124,51 +125,25 @@ jobs:
           authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
           extraPullNames: nix-community,poetry2nix
 
-      - name: Generate a GitHub token
-        if: ${{ github.event_name == 'push' }}
-        uses: tibdex/github-app-token@v1
-        id: generate_token
-        with:
-          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
-          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
-
-      - name: checkout
-        if: ${{ github.event_name == 'push' }}
-        uses: actions/checkout@v3
-        with:
-          fetch-depth: 0
-          token: ${{ steps.generate_token.outputs.token }}
-
       - name: checkout
-        if: ${{ github.event_name != 'push' }}
         uses: actions/checkout@v3
 
-      - name: Configure git info
-        if: ${{ github.event_name == 'push' }}
-        run: |
-          set -euo pipefail
-
-          git config user.name 'ibis-docs-bot[bot]'
-          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
-
       - name: build docs
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c mkdocs build
 
       - name: verify internal links
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c just checklinks --offline --no-progress
 
-      - name: Pull gh-pages changes
+      - name: Configure git info
         if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
-          git fetch origin gh-pages
-          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
 
       - name: build and push dev docs
-        if: ${{ github.event_name == 'push' && !startsWith(github.ref, 'refs/tags/') }}
+        if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
@@ -180,19 +155,6 @@ jobs:
               --message 'docs(dev): ibis@${{ github.sha }}' \
                 dev
 
-      - name: build and push docs on tag
-        if: ${{ github.event_name == 'push' && startsWith(github.ref, 'refs/tags/') }}
-        run: |
-          set -euo pipefail
-
-          nix develop -f shell.nix --keep-going -c \
-            mic deploy \
-              --push \
-              --rebase \
-              --prefix docs \
-              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
-              ""${GITHUB_REF_NAME}"" latest
-
   simulate_release:
     runs-on: ubuntu-latest
     steps:
diff --git a/.github/workflows/ibis-docs-release.yml b/.github/workflows/ibis-docs-release.yml
new file mode 100644
index 0000000..da7ee49
--- /dev/null
+++ b/.github/workflows/ibis-docs-release.yml
@@ -0,0 +1,63 @@
+# vim: filetype=yaml
+name: Docs Release Build
+
+on:
+  release:
+    types:
+      - published
+jobs:
+  docs:
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
+    runs-on: ubuntu-latest
+    steps:
+      - name: install nix
+        uses: cachix/install-nix-action@v17
+        with:
+          nix_path: nixpkgs=channel:nixos-unstable-small
+
+      - name: setup cachix
+        uses: cachix/cachix-action@v10
+        with:
+          name: ibis
+          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
+          extraPullNames: nix-community,poetry2nix
+
+      - name: Generate a GitHub token
+        uses: tibdex/github-app-token@v1
+        id: generate_token
+        with:
+          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
+          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
+
+      - name: checkout
+        uses: actions/checkout@v3
+        with:
+          fetch-depth: 0
+          token: ${{ steps.generate_token.outputs.token }}
+
+      - name: Configure git info
+        run: |
+          set -euo pipefail
+
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
+
+      - name: Pull gh-pages changes
+        run: |
+          set -euo pipefail
+
+          git fetch origin gh-pages
+          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+
+      - name: build and push docs on tag
+        run: |
+          set -euo pipefail
+
+          nix develop -f shell.nix --keep-going -c \
+            mic deploy \
+              --push \
+              --rebase \
+              --update-aliases \
+              --prefix docs \
+              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
+              ""${GITHUB_REF_NAME}"" latest

diff --git a/packages/react-native-tab-view/example/src/BottomBarIconTextExample.js b/packages/react-native-tab-view/example/src/BottomBarIconTextExample.js
index fcc4708..397e6e6 100644
--- a/packages/react-native-tab-view/example/src/BottomBarIconTextExample.js
+++ b/packages/react-native-tab-view/example/src/BottomBarIconTextExample.js
@@ -1,7 +1,7 @@
 /* @flow */
 
 import React, { Component } from 'react';
-import { Animated, View, Text, Dimensions, StyleSheet } from 'react-native';
+import { Animated, View, Text, StyleSheet } from 'react-native';
 import { TabViewAnimated, TabBar } from 'react-native-tab-view';
 import { Ionicons } from '@exponent/vector-icons';
 
@@ -13,7 +13,6 @@ const styles = StyleSheet.create({
     backgroundColor: '#222',
   },
   tab: {
-    opacity: 1,
     padding: 0,
   },
   icon: {
@@ -50,11 +49,6 @@ const styles = StyleSheet.create({
   },
 });
 
-const initialLayout = {
-  height: 0,
-  width: Dimensions.get('window').width,
-};
-
 export default class TopBarIconExample extends Component {
 
   static title = 'Bottom bar with indicator';
@@ -80,14 +74,16 @@ export default class TopBarIconExample extends Component {
   };
 
   _renderIndicator = (props) => {
-    const { width, position } = props;
+    const { width, opacity, position } = props;
 
-    const translateX = Animated.multiply(position, new Animated.Value(width));
+    const translateX = Animated.multiply(position, width);
 
     return (
       <Animated.View
-        style={[ styles.indicator, { width: width - 8, transform: [ { translateX } ] } ]}
-      />
+        style={[ styles.container, { width, opacity, transform: [ { translateX } ] } ]}
+      >
+        <View style={styles.indicator} />
+      </Animated.View>
     );
   };
 
@@ -146,7 +142,6 @@ export default class TopBarIconExample extends Component {
         renderScene={this._renderScene}
         renderFooter={this._renderFooter}
         onRequestChangeTab={this._handleChangeTab}
-        initialLayout={initialLayout}
       />
     );
   }
diff --git a/packages/react-native-tab-view/example/src/CoverflowExample.js b/packages/react-native-tab-view/example/src/CoverflowExample.js
index 8950c0e..2336591 100644
--- a/packages/react-native-tab-view/example/src/CoverflowExample.js
+++ b/packages/react-native-tab-view/example/src/CoverflowExample.js
@@ -2,7 +2,7 @@
 /* eslint-disable import/no-commonjs */
 
 import React, { Component } from 'react';
-import { Animated, View, Image, Text, Dimensions, StyleSheet } from 'react-native';
+import { Animated, View, Image, Text, StyleSheet } from 'react-native';
 import { TabViewAnimated, TabViewPagerPan } from 'react-native-tab-view';
 
 const styles = StyleSheet.create({
@@ -48,11 +48,6 @@ const ALBUMS = {
   'Lost Horizons': require('../assets/album-art-8.jpg'),
 };
 
-const initialLayout = {
-  height: 0,
-  width: Dimensions.get('window').width,
-};
-
 export default class CoverflowExample extends Component {
 
   static title = 'Coverflow';
@@ -142,7 +137,6 @@ export default class CoverflowExample extends Component {
         renderPager={this._renderPager}
         renderScene={this._renderScene}
         onRequestChangeTab={this._handleChangeTab}
-        initialLayout={initialLayout}
       />
     );
   }
diff --git a/packages/react-native-tab-view/example/src/ScrollViewsExample.js b/packages/react-native-tab-view/example/src/ScrollViewsExample.js
index 94fefbb..5be3b69 100644
--- a/packages/react-native-tab-view/example/src/ScrollViewsExample.js
+++ b/packages/react-native-tab-view/example/src/ScrollViewsExample.js
@@ -28,11 +28,6 @@ const styles = StyleSheet.create({
   },
 });
 
-const initialLayout = {
-  height: 0,
-  width: Dimensions.get('window').width,
-};
-
 export default class TopBarTextExample extends Component {
 
   static title = 'Scroll views';
@@ -104,6 +99,7 @@ export default class TopBarTextExample extends Component {
         renderLabel={this._renderLabel(props)}
         indicatorStyle={styles.indicator}
         tabStyle={styles.tab}
+        tabWidth={80}
         style={styles.tabbar}
       />
     );
@@ -130,7 +126,6 @@ export default class TopBarTextExample extends Component {
         renderScene={this._renderScene}
         renderHeader={this._renderHeader}
         onRequestChangeTab={this._handleChangeTab}
-        initialLayout={initialLayout}
       />
     );
   }
diff --git a/packages/react-native-tab-view/example/src/TopBarIconExample.js b/packages/react-native-tab-view/example/src/TopBarIconExample.js
index d13755f..5464981 100644
--- a/packages/react-native-tab-view/example/src/TopBarIconExample.js
+++ b/packages/react-native-tab-view/example/src/TopBarIconExample.js
@@ -1,7 +1,7 @@
 /* @flow */
 
 import React, { Component } from 'react';
-import { View, Dimensions, StyleSheet } from 'react-native';
+import { View, StyleSheet } from 'react-native';
 import { TabViewAnimated, TabBarTop } from 'react-native-tab-view';
 import { Ionicons } from '@exponent/vector-icons';
 
@@ -22,11 +22,6 @@ const styles = StyleSheet.create({
   },
 });
 
-const initialLayout = {
-  height: 0,
-  width: Dimensions.get('window').width,
-};
-
 export default class TopBarIconExample extends Component {
 
   static title = 'Icon only top bar';
@@ -93,7 +88,6 @@ export default class TopBarIconExample extends Component {
         renderScene={this._renderScene}
         renderHeader={this._renderHeader}
         onRequestChangeTab={this._handleChangeTab}
-        initialLayout={initialLayout}
       />
     );
   }
diff --git a/packages/react-native-tab-view/example/src/TopBarTextExample.js b/packages/react-native-tab-view/example/src/TopBarTextExample.js
index 30307ad..454533d 100644
--- a/packages/react-native-tab-view/example/src/TopBarTextExample.js
+++ b/packages/react-native-tab-view/example/src/TopBarTextExample.js
@@ -1,7 +1,7 @@
 /* @flow */
 
 import React, { Component } from 'react';
-import { View, Dimensions, StyleSheet } from 'react-native';
+import { View, StyleSheet } from 'react-native';
 import { TabViewAnimated, TabBarTop } from 'react-native-tab-view';
 
 const styles = StyleSheet.create({
@@ -25,11 +25,6 @@ const styles = StyleSheet.create({
   },
 });
 
-const initialLayout = {
-  height: 0,
-  width: Dimensions.get('window').width,
-};
-
 export default class TopBarTextExample extends Component {
 
   static title = 'Scrollable top bar';
@@ -90,7 +85,6 @@ export default class TopBarTextExample extends Component {
         renderScene={this._renderScene}
         renderHeader={this._renderHeader}
         onRequestChangeTab={this._handleChangeTab}
-        initialLayout={initialLayout}
       />
     );
   }
diff --git a/packages/react-native-tab-view/src/TabBar.js b/packages/react-native-tab-view/src/TabBar.js
index 615e85a..a03d8e5 100644
--- a/packages/react-native-tab-view/src/TabBar.js
+++ b/packages/react-native-tab-view/src/TabBar.js
@@ -92,6 +92,7 @@ type Props = SceneRendererProps & {
 
 type State = {
   offset: Animated.Value;
+  visibility: Animated.Value;
 }
 
 export default class TabBar extends Component<DefaultProps, Props, State> {
@@ -115,8 +116,15 @@ export default class TabBar extends Component<DefaultProps, Props, State> {
 
   state: State = {
     offset: new Animated.Value(0),
+    visibility: new Animated.Value(0),
   };
 
+  componentWillMount() {
+    if (this.props.layout.width || this.props.tabWidth) {
+      this.state.visibility.setValue(1);
+    }
+  }
+
   componentDidMount() {
     this._adjustScroll(this.props.navigationState.index);
     this._positionListener = this.props.subscribe('position', this._adjustScroll);
@@ -126,6 +134,16 @@ export default class TabBar extends Component<DefaultProps, Props, State> {
     if (this.props.navigationState !== nextProps.navigationState) {
       this._resetScrollOffset(nextProps);
     }
+
+    if (
+        (this.props.tabWidth !== nextProps.tabWidth && nextProps.tabWidth) ||
+        (this.props.layout.width !== nextProps.layout.width && nextProps.layout.width)
+     ) {
+      Animated.timing(this.state.visibility, {
+        toValue: 1,
+        duration: 150,
+      }).start();
+    }
   }
 
   componentWillUnmount() {
@@ -282,7 +300,8 @@ export default class TabBar extends Component<DefaultProps, Props, State> {
           {this.props.renderIndicator ?
             this.props.renderIndicator({
               ...this.props,
-              width: tabWidth,
+              width: new Animated.Value(tabWidth),
+              opacity: this.state.visibility,
             }) :
             null
           }
@@ -307,10 +326,10 @@ export default class TabBar extends Component<DefaultProps, Props, State> {
             {routes.map((route, i) => {
               const focused = index === i;
               const outputRange = inputRange.map(inputIndex => inputIndex === i ? 1 : 0.7);
-              const opacity = position.interpolate({
+              const opacity = Animated.multiply(this.state.visibility, position.interpolate({
                 inputRange,
                 outputRange,
-              });
+              }));
               const scene = {
                 route,
                 focused,
@@ -348,14 +367,14 @@ export default class TabBar extends Component<DefaultProps, Props, State> {
                   }}
                 >
                   <View style={styles.container}>
-                    <Animated.View style={[ styles.tabitem, { opacity, width: tabWidth }, tabStyle, this.props.tabStyle ]}>
+                    <Animated.View style={[ styles.tabitem, { opacity }, tabWidth ? { width: tabWidth } : null, tabStyle, this.props.tabStyle ]}>
                       {icon}
                       {label}
                     </Animated.View>
                     {badge ?
-                      <View style={styles.badge}>
+                      <Animated.View style={[ styles.badge, { opacity: this.state.visibility } ]}>
                         {badge}
-                      </View> : null
+                      </Animated.View> : null
                     }
                   </View>
                 </TouchableItem>
diff --git a/packages/react-native-tab-view/src/TabBarTop.js b/packages/react-native-tab-view/src/TabBarTop.js
index 0960d4e..84dd6e2 100644
--- a/packages/react-native-tab-view/src/TabBarTop.js
+++ b/packages/react-native-tab-view/src/TabBarTop.js
@@ -28,7 +28,8 @@ const styles = StyleSheet.create({
 });
 
 type IndicatorProps = SceneRendererProps & {
-  width: number;
+  width: Animated.Valye;
+  opacity: Animated.Value;
 }
 
 type Props = SceneRendererProps & {
@@ -50,13 +51,13 @@ export default class TabBarTop extends Component<void, Props, void> {
   );
 
   _renderIndicator = (props: IndicatorProps) => {
-    const { width, position } = props;
+    const { width, opacity, position } = props;
 
-    const translateX = Animated.multiply(position, new Animated.Value(width));
+    const translateX = Animated.multiply(position, width);
 
     return (
       <Animated.View
-        style={[ styles.indicator, { width, transform: [ { translateX } ] }, this.props.indicatorStyle ]}
+        style={[ styles.indicator, { width, opacity, transform: [ { translateX } ] }, this.props.indicatorStyle ]}
       />
     );
   };
diff --git a/packages/react-native-tab-view/src/TabViewAnimated.js b/packages/react-native-tab-view/src/TabViewAnimated.js
index d484816..4499748 100644
--- a/packages/react-native-tab-view/src/TabViewAnimated.js
+++ b/packages/react-native-tab-view/src/TabViewAnimated.js
@@ -94,19 +94,17 @@ export default class TabViewAnimated extends Component<DefaultProps, Props, Stat
   };
 
   _renderItems = (props: SceneRendererProps) => {
-    if (props.layout.width === 0) {
-      return null;
-    }
-
     const { renderPager, renderHeader, renderFooter } = this.props;
+    const { navigationState, layout } = props;
+    const currentRoute = navigationState.routes[navigationState.index];
 
     return (
       <View style={styles.container}>
         {renderHeader && renderHeader(props)}
         {renderPager({
           ...props,
-          children: props.navigationState.routes.map((route, index) => (
-            <View key={route.key} style={{ width: props.layout.width }}>
+          children: layout.width ? navigationState.routes.map((route, index) => (
+            <View key={route.key} style={{ width: layout.width }}>
               {this._renderScene({
                 ...props,
                 route,
@@ -114,7 +112,16 @@ export default class TabViewAnimated extends Component<DefaultProps, Props, Stat
                 focused: index === props.navigationState.index,
               })}
             </View>
-          )),
+          )) : (
+            <View key={currentRoute.key} style={styles.container}>
+              {this._renderScene({
+                ...props,
+                route: currentRoute,
+                index: navigationState.index,
+                focused: true,
+              })}
+            </View>
+          ),
         })}
         {renderFooter && renderFooter(props)}
       </View>

diff --git a/Makefile.toml b/Makefile.toml
index e7d2b20..490d6e2 100644
--- a/Makefile.toml
+++ b/Makefile.toml
@@ -82,7 +82,7 @@ end
 '''
 
 [tasks.build-plugins-release]
-env = { ""CARGO_MAKE_WORKSPACE_SKIP_MEMBERS"" = ["".""] }
+env = { ""CARGO_MAKE_WORKSPACE_INCLUDE_MEMBERS"" = [""default-plugins/status-bar"", ""default-plugins/strider"", ""default-plugins/tab-bar""] }
 run_task = { name = ""build-release"", fork = true }
 
 [tasks.wasm-opt-plugins]
@@ -129,15 +129,16 @@ args = [""install"", ""cross""]
 [tasks.publish]
 clear = true
 workspace = false
-dependencies = [""build-plugins-release"", ""wasm-opt-plugins"", ""release-commit"", ""build-release"", ""publish-zellij-tile"", ""publish-zellij-tile-utils"", ""publish-zellij-utils"", ""publish-zellij-client"", ""publish-zellij-server""]
+dependencies = [""build-plugins-release"", ""wasm-opt-plugins"", ""release-commit""]
 run_task = ""publish-zellij""
 
 [tasks.release-commit]
 dependencies = [""commit-all"", ""tag-release""]
 command = ""git""
-args = [""push"", ""--atomic"", ""upstream"", ""main"", ""v${CARGO_MAKE_CRATE_VERSION}""]
+args = [""push"", ""--atomic"", ""origin"", ""main"", ""v${CARGO_MAKE_CRATE_VERSION}""]
 
 [tasks.commit-all]
+ignore_errors = true
 command = ""git""
 args = [""commit"", ""-aem"", ""chore(release): v${CARGO_MAKE_CRATE_VERSION}""]
 
@@ -148,31 +149,32 @@ args = [""tag"", ""v${CARGO_MAKE_CRATE_VERSION}""]
 [tasks.publish-zellij-tile]
 ignore_errors = true
 cwd = ""zellij-tile""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-client]
+ignore_errors = true
 dependencies = [""publish-zellij-utils""]
 cwd = ""zellij-client""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-server]
+ignore_errors = true
 dependencies = [""publish-zellij-utils""]
 cwd = ""zellij-server""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-utils]
+ignore_errors = true
 dependencies = [""publish-zellij-tile""]
 cwd = ""zellij-utils""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-tile-utils]
 ignore_errors = true
 cwd = ""zellij-tile-utils""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij]
 dependencies = [""publish-zellij-client"", ""publish-zellij-server"", ""publish-zellij-utils""]
 command = ""cargo""
 args = [""publish""]
-
-
",3,"[""32845e1bbd1efb5dbc16f671049509a409ba25ce"", ""e9233ae3f7811707945fc2de60971595d83c578d"", ""65574eea5da54bf4722ecb551b42f8ff6088f33b""]","[""cicd"", ""fix"", ""build""]"
"enable user to re-order attachment in modal view

re #383

Signed-off-by: Pranav C <pranavxc@gmail.com> | export a modal transition preset | add test for spurious cross join","diff --git a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
index 7e9d06c..cbc5775 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
@@ -18,13 +18,16 @@
     </div>
 
     <div class=""d-flex align-center img-container"">
-      <div v-for=""(item,i) in localState"" :key=""i"" class=""thumbnail align-center justify-center d-flex"">
+      <div
+        v-for=""(item,i) in localState""
+        :key=""item.url""
+        class=""thumbnail align-center justify-center d-flex""
+      >
         <v-tooltip bottom>
           <template #activator=""{on}"">
             <!--            <img alt=""#"" v-if=""isImage(item.title)"" :src=""item.url"" v-on=""on"" @click=""selectImage(item.url,i)"">-->
             <v-img
               v-if=""isImage(item.title)""
-              :key=""item.url""
               lazy-src=""https://via.placeholder.com/60.png?text=Loading...""
               alt=""#""
               max-height=""33px""
@@ -89,7 +92,11 @@
 
           <div class=""d-flex flex-wrap h-100"">
             <v-container fluid style=""max-height:calc(90vh - 80px);overflow-y: auto"">
-              <v-row>
+              <draggable
+                v-model=""localState""
+                class=""row""
+                @update=""onOrderUpdate""
+              >
                 <v-col v-for=""(item,i) in localState"" :key=""i"" cols=""4"">
                   <v-card
                     class=""modal-thumbnail-card align-center justify-center d-flex""
@@ -125,7 +132,7 @@
                     {{ item.title }}
                   </p>
                 </v-col>
-              </v-row>
+              </draggable>
             </v-container>
           </div>
         </v-card-text>
@@ -216,9 +223,12 @@
 
 <script>
 import FileSaver from 'file-saver'
+import draggable from 'vuedraggable'
 import { isImage } from '@/components/project/spreadsheet/helpers/imageExt'
+
 export default {
   name: 'EditableAttachmentCell',
+  components: { draggable },
   props: ['dbAlias', 'value', 'active', 'isLocked', 'meta', 'column'],
   data: () => ({
     carousel: null,
@@ -301,6 +311,10 @@ export default {
       this.$emit('input', JSON.stringify(this.localState))
       this.$emit('update')
     },
+    onOrderUpdate() {
+      this.$emit('input', JSON.stringify(this.localState))
+      this.$emit('update')
+    },
     removeItem(i) {
       this.localState.splice(i, 1)
       this.$emit('input', JSON.stringify(this.localState))
@@ -394,18 +408,19 @@ export default {
   top: 5px;
   right: 5px
 }
-.modal-thumbnail-card{
+
+.modal-thumbnail-card {
 
   .download-icon {
     position: absolute;
     bottom: 5px;
     right: 5px;
-    opacity:0;
-    transition:.4s opacity;
+    opacity: 0;
+    transition: .4s opacity;
   }
 
-  &:hover .download-icon{
-    opacity:1
+  &:hover .download-icon {
+    opacity: 1
   }
 }
 

diff --git a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
index f1066a1..ae93dca 100644
--- a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
+++ b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
@@ -79,3 +79,8 @@ export const DefaultTransition = Platform.select({
       ? FadeFromBottomAndroid
       : WipeFromBottomAndroid,
 });
+
+export const ModalTransition = Platform.select({
+  ios: ModalSlideFromBottomIOS,
+  default: DefaultTransition,
+});
diff --git a/packages/stack/src/views/Stack/Stack.tsx b/packages/stack/src/views/Stack/Stack.tsx
index cf1719c..47c1abf 100755
--- a/packages/stack/src/views/Stack/Stack.tsx
+++ b/packages/stack/src/views/Stack/Stack.tsx
@@ -14,7 +14,7 @@ import { Props as HeaderContainerProps } from '../Header/HeaderContainer';
 import StackItem from './StackItem';
 import {
   DefaultTransition,
-  ModalSlideFromBottomIOS,
+  ModalTransition,
 } from '../../TransitionConfigs/TransitionPresets';
 import { forNoAnimation } from '../../TransitionConfigs/HeaderStyleInterpolators';
 import {
@@ -301,9 +301,7 @@ export default class Stack extends React.Component<Props, State> {
     const focusedOptions = descriptors[focusedRoute.key].options;
 
     let defaultTransitionPreset =
-      mode === 'modal' && Platform.OS === 'ios'
-        ? ModalSlideFromBottomIOS
-        : DefaultTransition;
+      mode === 'modal' ? ModalTransition : DefaultTransition;
 
     if (headerMode === 'screen') {
       defaultTransitionPreset = {

diff --git a/ibis/tests/sql/test_sqlalchemy.py b/ibis/tests/sql/test_sqlalchemy.py
index 4ad32a6..b2e5d72 100644
--- a/ibis/tests/sql/test_sqlalchemy.py
+++ b/ibis/tests/sql/test_sqlalchemy.py
@@ -841,3 +841,63 @@ def test_filter_group_by_agg_with_same_name():
     )
     ex = sa.select([t0]).where(t0.c.bigint_col == 60)
     _check(expr, ex)
+
+
+@pytest.fixture
+def person():
+    return ibis.table(
+        dict(id=""string"", personal=""string"", family=""string""),
+        name=""person"",
+    )
+
+
+@pytest.fixture
+def visited():
+    return ibis.table(
+        dict(id=""int32"", site=""string"", dated=""string""),
+        name=""visited"",
+    )
+
+
+@pytest.fixture
+def survey():
+    return ibis.table(
+        dict(
+            taken=""int32"",
+            person=""string"",
+            quant=""string"",
+            reading=""float32"",
+        ),
+        name=""survey"",
+    )
+
+
+def test_no_cross_join(person, visited, survey):
+    expr = person.join(survey, person.id == survey.person).join(
+        visited,
+        visited.id == survey.taken,
+    )
+
+    context = AlchemyContext(compiler=AlchemyCompiler)
+    _ = AlchemyCompiler.to_sql(expr, context)
+
+    t0 = context.get_ref(person)
+    t1 = context.get_ref(survey)
+    t2 = context.get_ref(visited)
+
+    from_ = t0.join(t1, t0.c.id == t1.c.person).join(t2, t2.c.id == t1.c.taken)
+    ex = sa.select(
+        [
+            t0.c.id.label(""id_x""),
+            t0.c.personal,
+            t0.c.family,
+            t1.c.taken,
+            t1.c.person,
+            t1.c.quant,
+            t1.c.reading,
+            t2.c.id.label(""id_y""),
+            t2.c.site,
+            t2.c.dated,
+        ]
+    ).select_from(from_)
+    _check(expr, ex)
",3,"[""fd8e563cc19ca4684885d4692acee6bebcca4ada"", ""535708ae50aecb452560a23356fd396f99ef13a2"", ""8dac3fe5a7a56356ca95547fcf7925bec8d9c1dd""]","[""feat"", ""refactor"", ""test""]"
